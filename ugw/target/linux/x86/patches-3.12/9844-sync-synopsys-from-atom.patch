# HG changeset patch
# Parent 0a64b62c61fd8b49fb1e80d6e481839f8d4f6756

diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_api.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_api.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_api.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_api.c
@@ -2044,1249 +2044,6 @@ static int config_ptpoffloading(int sock
 	return ret;
 }
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-
-/* Initialize default parameters for Channel 0, 1 and 2.
- */
-static void DWC_ETH_QOS_init_default_pg(struct DWC_ETH_QOS_pg_user_input *pg_params)
-{
-	struct DWC_ETH_QOS_pg_user_ch_input *pg_user_ch_input = pg_params->ch_input;
-	unsigned int qInx;
-	unsigned int bandwidth = 100/tx_queue_count;
-
-	/* duration of experiment is 5 Sec by default */
-	pg_params->duration_of_exp = 5;
-	pg_params->dma_ch_en = 1;
-
-	pg_params->ch_tx_rx_arb_scheme = 0;
-	pg_params->ch_use_tx_high_prio = 0;
-	pg_params->ch_tx_rx_prio_ratio = 0;
-	pg_params->dma_tx_arb_algo = eDWC_ETH_QOS_DMA_TX_WRR;
-	pg_params->queue_dcb_algorithm = eDWC_ETH_QOS_DCB_WRR;
-
-	pg_params->mac_lb_mode = 0; /* 0 => No MAC Loopback; 1 => MAC Loopback On */
-	pg_params->speed_100M_1G = 0;     /* This is valid only after receiving after the test  */
-
-	/* configure Channel qInx to DWC_ETH_QOS_QUEUE_CNT */
-	for (qInx = 0; qInx < tx_queue_count; qInx++) {
-		memset(&pg_user_ch_input[qInx], 0, sizeof(struct DWC_ETH_QOS_pg_user_ch_input));
-
-		pg_params->dma_ch_en |= (0x1 << qInx);
-		if (qInx == 0) {
-			pg_user_ch_input[qInx].ch_arb_weight = 0;
-			pg_user_ch_input[qInx].ch_fr_size = 1500;
-			pg_user_ch_input[qInx].ch_bw_alloc = bandwidth;
-
-			/* AVB can't be used on queue-0 */
-			pg_user_ch_input[qInx].ch_operating_mode = eDWC_ETH_QOS_QDCB;
-			pg_user_ch_input[qInx].ch_CreditControl = 0;
-
-			/* slot facility not available for 0
-			 * do not change below values */
-			pg_user_ch_input[qInx].ch_tx_desc_slot_no_start = 0;
-			pg_user_ch_input[qInx].ch_tx_desc_slot_no_skip = 0;
-			pg_user_ch_input[qInx].ch_AvgBits = 0;
-			pg_user_ch_input[qInx].ch_AvgBits_interrupt_count = 0;
-			pg_user_ch_input[qInx].ch_use_slot_no_check = 0;
-			pg_user_ch_input[qInx].ch_use_adv_slot_no_check = 0;
-			pg_user_ch_input[qInx].ch_slot_count_to_use = 0;
-
-			/* debug parameters */
-			pg_user_ch_input[qInx].ch_max_tx_frame_cnt = 255;
-			pg_user_ch_input[qInx].ch_debug_mode = 0;
-
-		} else {
-			pg_user_ch_input[qInx].ch_arb_weight = 0;
-			pg_user_ch_input[qInx].ch_fr_size = 1500;
-			pg_user_ch_input[qInx].ch_bw_alloc = bandwidth;
-
-			pg_user_ch_input[qInx].ch_operating_mode = eDWC_ETH_QOS_QDCB;
-			pg_user_ch_input[qInx].ch_CreditControl = 0;
-			pg_user_ch_input[qInx].ch_avb_algorithm = eDWC_ETH_QOS_AVB_CBS;
-
-			pg_user_ch_input[qInx].ch_tx_desc_slot_no_start = 0;
-			pg_user_ch_input[qInx].ch_tx_desc_slot_no_skip = 0;
-			pg_user_ch_input[qInx].ch_AvgBits = 0;
-			pg_user_ch_input[qInx].ch_AvgBits_interrupt_count = 0;
-			pg_user_ch_input[qInx].ch_use_slot_no_check = 0;
-			pg_user_ch_input[qInx].ch_use_adv_slot_no_check = 0;
-			pg_user_ch_input[qInx].ch_slot_count_to_use = 0;
-
-			/* debug parameters */
-			pg_user_ch_input[qInx].ch_max_tx_frame_cnt = 255;
-			pg_user_ch_input[qInx].ch_debug_mode = 0;
-		}
-	}
-}
-
-static void DWC_ETH_QOS_calculate_slope(struct DWC_ETH_QOS_PGStruct *pg_struct,
-		struct DWC_ETH_QOS_pg_ch_input *pg_ch_input, unsigned int qInx)
-{
-	unsigned int multiplier = 1;
-
-	if (connected_speed == SPEED_1000)
-		multiplier = 2;
-
-	pg_ch_input[qInx].ch_IdleSlope = get_idle_slope(pg_ch_input[qInx].ch_bw);
-	pg_ch_input[qInx].ch_SendSlope = get_send_slope(pg_ch_input[qInx].ch_bw);
-
-	pg_ch_input[qInx].ch_HiCredit = get_hi_credit(pg_ch_input[qInx].ch_bw);
-	pg_ch_input[qInx].ch_LoCredit = get_low_credit(pg_ch_input[qInx].ch_bw);
-
-	return;
-}
-
-static void DWC_ETH_QOS_calculate_queue_weight(struct DWC_ETH_QOS_PGStruct *pg_struct,
-		struct DWC_ETH_QOS_pg_ch_input *pg_ch_input,
-		unsigned int max_frame_size,
-		unsigned int qInx)
-{
-	pg_ch_input[qInx].ch_queue_weight =
-		DWC_ETH_QOS_get_dcb_queue_weights(pg_struct->queue_dcb_algorithm,
-			pg_ch_input[qInx].ch_bw, max_frame_size);
-
-	return;
-}
-
-/*
- * Copies Channel parameters from pg user struct to pg kernel struct.
- */
-static void DWC_ETH_QOS_populate_pg_struct(struct DWC_ETH_QOS_pg_user_input *pg_params,
-					struct DWC_ETH_QOS_PGStruct *pg_struct)
-{
-	struct DWC_ETH_QOS_pg_user_ch_input *pg_user_ch_input = pg_params->ch_input;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = pg_struct->pg_ch_input;
-	unsigned int qInx, channel_enable = 0, max_frame_size = 0;
-
-	pg_struct->ch_SelMask = pg_params->dma_ch_en;
-	pg_struct->DurationOfExp = pg_params->duration_of_exp;
-
-	pg_struct->PrioTagForAV = 5; /* Priority of Ch2 */
-
-	pg_struct->ch_tx_rx_arb_scheme = pg_params->ch_tx_rx_arb_scheme;
-	pg_struct->ch_use_tx_high_prio = pg_params->ch_use_tx_high_prio;
-	pg_struct->ch_tx_rx_prio_ratio = pg_params->ch_tx_rx_prio_ratio;
-	pg_struct->dma_tx_arb_algo = pg_params->dma_tx_arb_algo;
-	pg_struct->queue_dcb_algorithm = pg_params->queue_dcb_algorithm;
-	pg_struct->mac_lb_mode = pg_params->mac_lb_mode;
-
-	channel_enable = pg_params->dma_ch_en;
-	max_frame_size = pg_user_ch_input[0].ch_fr_size;
-	for (qInx = 0; qInx < tx_queue_count; qInx++) {
-		if (pg_user_ch_input[0].ch_fr_size > max_frame_size)
-			max_frame_size = pg_user_ch_input[0].ch_fr_size;
-	}
-
-	for (qInx = 0; qInx < tx_queue_count; qInx++) {
-		/* updating parameters only if channel is enabled */
-		if (channel_enable & (1 << qInx)) {
-			/* copy Channel qInx parameters */
-			pg_ch_input[qInx].ch_arb_weight = pg_user_ch_input[qInx].ch_arb_weight;
-			pg_ch_input[qInx].ch_bw = pg_user_ch_input[qInx].ch_bw_alloc;
-
-			DWC_ETH_QOS_calculate_queue_weight(pg_struct, pg_ch_input, max_frame_size, qInx);
-
-			pg_ch_input[qInx].ch_frame_size = pg_user_ch_input[qInx].ch_fr_size;
-			pg_ch_input[qInx].ch_debug_mode = pg_user_ch_input[qInx].ch_debug_mode;
-			pg_ch_input[qInx].ch_max_tx_frame_cnt = pg_user_ch_input[qInx].ch_max_tx_frame_cnt;
-			pg_ch_input[qInx].ch_operating_mode = pg_user_ch_input[qInx].ch_operating_mode;
-			pg_ch_input[qInx].ch_AvgBits = pg_user_ch_input[qInx].ch_AvgBits;
-			pg_ch_input[qInx].ch_AvgBits_interrupt_count =
-				pg_user_ch_input[qInx].ch_AvgBits_interrupt_count;
-
-			pg_ch_input[qInx].ch_avb_algorithm = pg_user_ch_input[qInx].ch_avb_algorithm;
-			pg_ch_input[qInx].ch_CreditControl = pg_user_ch_input[qInx].ch_CreditControl;
-
-			DWC_ETH_QOS_calculate_slope(pg_struct, pg_ch_input, qInx);
-
-			pg_ch_input[qInx].ch_EnableSlotCheck = pg_user_ch_input[qInx].ch_use_slot_no_check;
-			pg_ch_input[qInx].ch_EnableAdvSlotCheck = pg_user_ch_input[qInx].ch_use_adv_slot_no_check;
-			pg_ch_input[qInx].ch_SlotCount = pg_user_ch_input[qInx].ch_slot_count_to_use;
-			pg_ch_input[qInx].ch_tx_desc_slot_no_start = pg_user_ch_input[qInx].ch_tx_desc_slot_no_start;
-			pg_ch_input[qInx].ch_tx_desc_slot_no_skip = pg_user_ch_input[qInx].ch_tx_desc_slot_no_skip;
-
-			pg_ch_input[qInx].ch_FramecountTx = 0;
-			pg_ch_input[qInx].ch_FramecountRx = 0;
-		}
-		else {
-			pg_ch_input[qInx].ch_bw = 0;
-		}
-	}
-}
-
-static int DWC_ETH_QOS_send_pg_param_to_driver(int sockfd, char *ifname,
-						struct DWC_ETH_QOS_PGStruct *pg_struct)
-{
-	struct ifreq ifr;
-	struct ifr_data_struct data;
-	int ret = 0;
-
-	strcpy(ifr.ifr_ifrn.ifrn_name, ifname);
-	data.cmd = DWC_ETH_QOS_PG_TEST;
-	data.flags = DWC_ETH_QOS_PG_SET_CONFIG;
-	data.ptr = pg_struct;
-	data.qInx = 0;
-
-	ifr.ifr_ifru.ifru_data = &data;
-
-	ret = ioctl(sockfd, DWC_ETH_QOS_PRV_IOCTL, &ifr);
-	if (ret < 0)
-		printf("IOCTL Error\n");
-	else
-		printf
-		    ("Successfully configured PG parameters\n");
-
-	return ret;
-}
-
-static int DWC_ETH_QOS_config_hw_for_pg_test(int sockfd, char *ifname)
-{
-	struct ifreq ifr;
-	struct ifr_data_struct data;
-	int ret = 0;
-
-	strcpy(ifr.ifr_ifrn.ifrn_name, ifname);
-	data.cmd = DWC_ETH_QOS_PG_TEST;
-	data.flags = DWC_ETH_QOS_PG_CONFIG_HW;
-	data.ptr = NULL;
-	data.qInx = 0;
-
-	ifr.ifr_ifru.ifru_data = &data;
-
-	ret = ioctl(sockfd, DWC_ETH_QOS_PRV_IOCTL, &ifr);
-	if (ret < 0)
-		printf("IOCTL Error\n");
-	else
-		printf
-		    ("Successfully configured the HW for Test\n");
-
-	return ret;
-}
-
-static int DWC_ETH_QOS_run_pg_test(int sockfd, char *ifname,
-				struct DWC_ETH_QOS_PGStruct *pg_struct)
-{
-	struct ifreq ifr;
-	struct ifr_data_struct data;
-	int ret = 0;
-
-	strcpy(ifr.ifr_ifrn.ifrn_name, ifname);
-	data.cmd = DWC_ETH_QOS_PG_TEST;
-	data.flags = DWC_ETH_QOS_PG_RUN_TEST;
-	data.ptr = pg_struct;
-	data.qInx = 0;
-
-	ifr.ifr_ifru.ifru_data = &data;
-
-	ret = ioctl(sockfd, DWC_ETH_QOS_PRV_IOCTL, &ifr);
-	if (ret < 0)
-		printf("IOCTL Error\n");
-	else
-		printf
-		    ("PG Test Started\n");
-
-	return ret;
-}
-
-static int DWC_ETH_QOS_check_test_done(int sockfd, char *ifname)
-{
-	struct ifreq ifr;
-	struct ifr_data_struct data;
-	int ret = 0;
-
-	strcpy(ifr.ifr_ifrn.ifrn_name, ifname);
-	data.cmd = DWC_ETH_QOS_PG_TEST;
-	data.flags = DWC_ETH_QOS_PG_TEST_DONE;
-	data.qInx = 0;
-
-	ifr.ifr_ifru.ifru_data = &data;
-
-	ret = ioctl(sockfd, DWC_ETH_QOS_PRV_IOCTL, &ifr);
-	if (ret < 0)
-		printf("IOCTL Error\n");
-	else
-		ret = data.test_done;
-
-	return ret;
-}
-
-static int DWC_ETH_QOS_get_pg_result_from_hw(int sockfd, char *ifname,
-				struct DWC_ETH_QOS_PGStruct *pg_struct)
-{
-	struct ifreq ifr;
-	struct ifr_data_struct data;
-	int ret = 0;
-
-	strcpy(ifr.ifr_ifrn.ifrn_name, ifname);
-	data.cmd = DWC_ETH_QOS_PG_TEST;
-	data.flags = DWC_ETH_QOS_PG_GET_RESULT;
-	data.ptr = pg_struct;
-	data.qInx = 0;
-
-	ifr.ifr_ifru.ifru_data = &data;
-
-	ret = ioctl(sockfd, DWC_ETH_QOS_PRV_IOCTL, &ifr);
-	if (ret < 0)
-		printf("IOCTL Error\n");
-	else
-		printf
-		    ("Successfully Retrieved PG Results\n");
-
-	return ret;
-}
-
-
-static void DWC_ETH_QOS_process_ch_params(struct DWC_ETH_QOS_pg_user_ch_input *pg_user_ch_input,
-					int user_input,
-					int ch_no)
-{
-	char user_string[10];
-
-	switch(user_input) {
-	case 00:
-		printf("(%d00) Channel %d Frame size in bytes (only payload)          : %04d\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_fr_size);
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input > 48) && (user_input <= 1500))
-			pg_user_ch_input[ch_no].ch_fr_size = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 01:
-		printf("(%d01) Channel %d Bandwidth Allocation                        : %02d%%\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_bw_alloc);
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input > 0) && (user_input <= 75))
-			pg_user_ch_input[ch_no].ch_bw_alloc = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 02:
-		printf("(%d02) Channel %d Enable Slot Number Check  <1/0>             : %s\n",
-			ch_no, ch_no,
-			(pg_user_ch_input[ch_no].ch_use_slot_no_check ? "YES" : "NO"));
-		printf("     [0 - Disable slot number check]\n");
-		printf("     [1 - Enable slot number check]\n");
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input == 0) || (user_input == 1))
-			pg_user_ch_input[ch_no].ch_use_slot_no_check = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 03:
-		printf("(%d03) Channel %d Enabled advance Slot check <1/0>            : %s\n",
-			ch_no, ch_no,
-			(pg_user_ch_input[ch_no].ch_use_adv_slot_no_check ? "YES" : "NO"));
-		printf("     [0 - Disable advance slot number check]\n");
-		printf("     [1 - Enable advance slot number check]\n");
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input == 0) || (user_input == 1))
-			pg_user_ch_input[ch_no].ch_use_adv_slot_no_check = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 04:
-		printf("(%d04) Channel %d Slot Counter for AVB Reporting <1/2/4/8/16> : %01d\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_slot_count_to_use);
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input == 1) || (user_input == 2) || (user_input == 4) ||
-		    (user_input == 8) || (user_input == 16))
-			pg_user_ch_input[ch_no].ch_slot_count_to_use = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 05:
-		printf("(%d05a) Channel %d AVB algorithm <0/1>         : %s\n",
-			ch_no, ch_no,
-			(pg_user_ch_input[ch_no].ch_avb_algorithm == eDWC_ETH_QOS_AVB_SP ?
-			"Strict Priority" : "Credit Based Shaper"));
-		printf("     [0 - Strict Priority Algorithm]\n");
-		printf("     [1 - Credit Shaper Algorithm]\n");
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input == 0) || (user_input == 1)) {
-			pg_user_ch_input[ch_no].ch_avb_algorithm = user_input;
-		}
-		else
-			printf("Invalid input\n");
-
-		printf("(%d05b) Channel %d Uses Credit Control <0/1>        : %s\n",
-			ch_no, ch_no,
-			(pg_user_ch_input[ch_no].ch_CreditControl ? "YES" : "NO"));
-		printf("     [0 - No Credit Control]\n");
-		printf("     [1 - Enforce Credit Control]\n");
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input == 0) || (user_input == 1)) {
-			pg_user_ch_input[ch_no].ch_CreditControl = user_input;
-		}
-		else
-			printf("Invalid input\n");
-		break;
-	case 06:
-		printf("(%d06) Channel %d Tx Desc Starting Slot No <0 .. 15>          : %01x\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_tx_desc_slot_no_start);
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input >= 0) && (user_input <= 15))
-			pg_user_ch_input[ch_no].ch_tx_desc_slot_no_start = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 07:
-		printf("(%d07) Channel %d Tx Desc Slot No Skip count <0 .. 15>        : %01x\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_tx_desc_slot_no_skip);
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input >= 0) && (user_input <= 15))
-			pg_user_ch_input[ch_no].ch_tx_desc_slot_no_skip = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case  8:
-		printf("(%d08) Channel %d Arbitration Weight        <0,1,2,3,4,5,6,7> : %01x\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_arb_weight);
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input >= 0) && (user_input <= 7))
-			pg_user_ch_input[ch_no].ch_arb_weight = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 9:
-		printf("(%d09) Channel %d Operating mode                              : %01x\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_operating_mode);
-		printf("        <0-Not enabled, 1-AVB, 2-DCB, 3-Generic>\n");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input >= 0) && (user_input <= 3))
-			pg_user_ch_input[ch_no].ch_operating_mode = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 10:
-		printf("(%d10) Channel %d enable debug mode                          : %d\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_debug_mode);
-		printf("        <0 - disable debug mode, 1 - enable debug mode>\n");
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if ((user_input == 0) || (user_input == 1))
-			pg_user_ch_input[ch_no].ch_debug_mode = user_input;
-		else
-			printf("Invalid input\n");
-		break;
-	case 11:
-		printf("(%d11) Channel %d maximum Tx packet count                   : %d\n",
-			ch_no, ch_no, pg_user_ch_input[ch_no].ch_max_tx_frame_cnt);
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		pg_user_ch_input[ch_no].ch_max_tx_frame_cnt = user_input;
-		break;
-	default:
-		printf("Invalid Option\n");
-	}
-}
-
-static void DWC_ETH_QOS_get_pg_params(struct DWC_ETH_QOS_pg_user_input *pg_params)
-{
-	struct DWC_ETH_QOS_pg_user_ch_input *pg_user_ch_input = pg_params->ch_input;
-	char user_string[10];
-	int user_input = 0;
-	int i;
-	int input_limit;
-
-	do {
-		system("clear");
-
-		printf("--------------------------------------------------\n");
-		printf("Select the Options Below:\n");
-		printf("--------------------------------------------------\n");
-
-		printf("(1000) Duration to run the Experiment(seconds)               : %02d\n\n",
-			pg_params->duration_of_exp);
-		printf("(1001) DMA Channel Enable                                    : %#02x\n\n",
-			pg_params->dma_ch_en);
-		printf("(1002) DMA Tx and Rx Priority Scheme(0/1)                    : %01d\n",
-			pg_params->ch_tx_rx_arb_scheme);
-		printf("     [0 - Weighted Round Robin, 1 - Fixed Priority]\n");
-		printf("(1003) DMA Tx has High Priority over Rx(0/1)                 : %01d\n",
-			pg_params->ch_use_tx_high_prio);
-		printf("     [0 - Rx has High Priority, 1 - Tx has High Priority]\n");
-		printf("(1004) DMA Tx and Rx Priority Ratio                          : %01d\n",
-			pg_params->ch_tx_rx_prio_ratio);
-		printf("     [Tx:Rx or Rx:Tx, 0=> 1:1, 1=>2:1, 2=>3:1, 3=>4:1\n"
-		       "                      4=> 5:1, 5=>6:1, 6=>7:1, 7=>8:1]\n");
-		printf("(1005) DMA Transmit Arbitration algorithm                    : %01d\n",
-				pg_params->dma_tx_arb_algo);
-		printf("     [0 - Fixed priority\n");
-		printf("      1 - WSP (Weighted strict priority)\n");
-		printf("      2 - WRR (Weighted Round Robin]\n");
-		printf("(1006) MTL DCB algorithm                                     : %01d\n",
-			pg_params->queue_dcb_algorithm);
-		printf("     [0 - WRR  (Weighted Round Robin)\n"
-		       "      1 - WFQ  (Weighted Fair Queuing)\n"
-		       "      2 - DWRR (Deficit Weighted Round Robin)\n"
-		       "      3 - SP   (Strict Priority)]\n");
-		printf("(1007) MAC Loop-Back Mode                                    : %01d\n",
-			pg_params->mac_lb_mode);
-		printf("     [0 - Disable MAC Loop-Back Mode \n"
-		       "      1 - Enable  MAC Loop-Back Mode ]\n");
-
-		for (i = 0; i < tx_queue_count; i++) {
-			printf("\n");
-			printf("(%d00) Channel %d Frame size in bytes (only payload)          : %04d\n",
-				i, i, pg_user_ch_input[i].ch_fr_size);
-			printf("(%d01) Channel %d Bandwidth Allocation                        : %02d%%\n",
-				i, i, pg_user_ch_input[i].ch_bw_alloc);
-			printf("(%d02) Channel %d Enable Slot Number Check                    : %s\n",
-				i, i, pg_user_ch_input[i].ch_use_slot_no_check ? "YES" : "NO");
-			printf("(%d03) Channel %d Enable advance Slot slot check              : %s\n",
-				i, i, (pg_user_ch_input[i].ch_use_adv_slot_no_check ? "YES" : "NO"));
-			printf("(%d04) Channel %d Slot Counter for AVB Reporting              : %01d\n",
-				i, i, pg_user_ch_input[i].ch_slot_count_to_use);
-			printf("(%d05) Channel %d AVB Algorithm                               : %s\n",
-				i, i, (pg_user_ch_input[i].ch_avb_algorithm == eDWC_ETH_QOS_AVB_SP ?
-				"Strict Priority" : "Credit Based Shaper"));
-			printf("       Channel %d Uses Credit Control(0/1)                    : %s\n",
-				i, (pg_user_ch_input[i].ch_CreditControl ? "YES" : "NO"));
-			printf("(%d06) Channel %d Tx Desc Starting Slot No <0 .. 15>          : %01x\n",
-				i, i, pg_user_ch_input[i].ch_tx_desc_slot_no_start);
-			printf("(%d07) Channel %d Tx Desc Slot No Skip count <0 .. 15>        : %01x\n",
-				i, i, pg_user_ch_input[i].ch_tx_desc_slot_no_skip);
-			printf("(%d08) Channel %d Arbitration Weight   <1,2,3,4,5,6,7,8>      : %01x\n",
-				i, i, pg_user_ch_input[i].ch_arb_weight);
-			printf("(%d09) Channel %d Operating mode                              : %01x\n",
-				i, i, pg_user_ch_input[i].ch_operating_mode);
-			printf("        <0-Not enabled, 1-AVB, 2-DCB, 3-Generic>\n");
-			printf("(%d10) Channel %d enable debug mode                           : %s\n",
-				i, i, (pg_user_ch_input[i].ch_debug_mode ? "YES" : "NO"));
-			printf("(%d11) Channel %d maximum Tx packet limit                     : %d\n",
-				i, i, pg_user_ch_input[i].ch_max_tx_frame_cnt);
-			printf("\n");
-		}
-		printf("\n");
-		printf("(9999) To quit this menu\n\n");
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		/*0 - 99 for Q0, 100 to 199 for Q1,, etc, hence input limit is number of queues * 100. */
-		input_limit = tx_queue_count * 100;
-
-		if (user_input == 1000) {
-			printf("(1000) Duration to run the Experiment (Seconds) <1 ... 200>   :%02d\n\n",
-				pg_params->duration_of_exp);
-			printf("Your Option here::");
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%d", &user_input);
-			if ((user_input > 0) && (user_input <= 200))
-				pg_params->duration_of_exp = user_input;
-		}
-		else if (user_input == 1001) {
-			printf("(1001) DMA Channel Enabled                                    :%#02x\n\n",
-				pg_params->dma_ch_en);
-			printf("Your Option here::");
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%x", &user_input);
-			if (user_input < (1 << tx_queue_count))
-				pg_params->dma_ch_en = user_input;
-			else
-				printf("Device supports only %d channels/queues\n",
-						tx_queue_count);
-		}
-		else if (user_input == 1002) {
-			printf("(1002) DMA Tx and Rx Priority Scheme <0/1>                    : %01d\n",
-				pg_params->ch_tx_rx_arb_scheme);
-			printf("     [0 - Weighted Round Robin, 1 - Strict Priority]\n");
-			printf("Your Option here::");
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%d", &user_input);
-			if ((user_input == 0) || (user_input == 1))
-				pg_params->ch_tx_rx_arb_scheme = user_input;
-			else
-				printf("Invalid input\n");
-		}
-		else if (user_input == 1003) {
-			printf("(1003) DMA Tx has High Priority over Rx <0/1>                 : %01d\n",
-				pg_params->ch_use_tx_high_prio);
-			printf("     [0 - Rx has High Priority, 1 - Tx has High Priority]\n");
-			printf("Your Option here::");
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%d", &user_input);
-			if ((user_input == 0) || (user_input == 1))
-				pg_params->ch_use_tx_high_prio = user_input;
-			else
-				printf("Invalid input\n");
-		}
-		else if (user_input == 1004) {
-			printf("(1004) DMA Tx and Rx Priority Ratio  <0/1/2/3>                : %01d\n",
-				pg_params->ch_tx_rx_prio_ratio);
-			printf("     [Tx:Rx or Rx:Tx, 0=> 1:1, 1=>2:1, 2=>3:1, 3=>4:1\n"
-			     "                      4=> 5:1, 5=>6:1, 6=>7:1, 7=>8:1]\n");
-			printf("Your Option here::");
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%d", &user_input);
-			if ((user_input >= 0) && (user_input <= 3))
-				pg_params->ch_tx_rx_prio_ratio = user_input;
-			else
-				printf("Invalid input\n");
-		}
-		else if (user_input == 1005) {
-			printf("(1005) DMA Transmit Arbitration algorithm                    : %01d\n",
-					pg_params->dma_tx_arb_algo);
-			printf("     [0 - Fixed priority\n");
-			printf("      1 - WSP (Weighted strict priority)\n");
-			printf("      2 - WRR (Weighted Round Robin]\n");
-			printf("Your Option here::");
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%d", &user_input);
-			if ((user_input >= 0) && (user_input <= 2))
-				pg_params->dma_tx_arb_algo = user_input;
-			else
-				printf("Invalid input\n");
-		}
-		else if (user_input == 1006) {
-			printf("(1006) MTL DCB algorithm                                      : %01d\n",
-				pg_params->queue_dcb_algorithm);
-			printf("     [0 - WRR  (Weighted Round Robin)\n"
-						 "      1 - WFQ  (Weighted Fair Queuing)\n"
-						 "      2 - DWRR (Deficit Weighted Round Robin)\n"
-						 "      3 - SP   (Strict Priority)]\n");
-			printf("Your Option here::");
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%d", &user_input);
-			if ((user_input >= 0) && (user_input <= 3))
-				pg_params->queue_dcb_algorithm = user_input;
-			else
-				printf("Invalid input\n");
-		}
-		else if (user_input == 1007) {
-			printf("(1007) mac_lb_mode                                            : %01d\n",
-				 pg_params->mac_lb_mode);
-			printf("     [0 - Disable MAC Loop-Back Mode \n"
-					 "      1 - Enable  MAC Loop-Back Mode ]\n");
-			printf("Your Option here::");
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%d", &user_input);
-			if ((user_input >= 0) && (user_input <= 1))
-				pg_params->mac_lb_mode = user_input;
-			else
-				printf("Invalid input\n");
-		}
-
-		else if ((user_input >= 0) && (user_input <= 99)
-				&& (user_input < input_limit)) { /* ch 0 parameter */
-			DWC_ETH_QOS_process_ch_params(pg_user_ch_input,
-					user_input, 0);
-		}
-		else if ((user_input >= 100) && (user_input <= 199)
-				&& (user_input < input_limit)) { /* ch 1 parameter */
-			DWC_ETH_QOS_process_ch_params(pg_user_ch_input,
-					(user_input - 100), 1);
-		}
-		else if ((user_input >= 200) && (user_input <= 299)
-				&& (user_input < input_limit)) { /* ch 2 parameter */
-			DWC_ETH_QOS_process_ch_params(pg_user_ch_input,
-				(user_input - 200), 2);
-		}
-		else if ((user_input >= 300) && (user_input <= 399)
-				&& (user_input < input_limit)) { /* ch 3 parameter */
-			DWC_ETH_QOS_process_ch_params(pg_user_ch_input,
-				(user_input - 300), 3);
-		}
-		else if ((user_input >= 400) && (user_input <= 499)
-				&& (user_input < input_limit)) { /* ch 4 parameter */
-			DWC_ETH_QOS_process_ch_params(pg_user_ch_input,
-				(user_input - 400), 4);
-		}
-		else if ((user_input >= 500) && (user_input <= 599)
-				&& (user_input < input_limit)) { /* ch 5 parameter */
-			DWC_ETH_QOS_process_ch_params(pg_user_ch_input,
-				(user_input - 500), 5);
-		}
-		else if ((user_input >= 600) && (user_input <= 699)
-				&& (user_input < input_limit)) { /* ch 6 parameter */
-			DWC_ETH_QOS_process_ch_params(pg_user_ch_input,
-				(user_input - 600), 6);
-		}
-		else if ((user_input >= 700) && (user_input <= 799)
-				&& (user_input < input_limit)) { /* ch 7 parameter */
-			DWC_ETH_QOS_process_ch_params(pg_user_ch_input,
-				(user_input - 700), 7);
-		}
-	} while (user_input != 9999);
-}
-
-static void DWC_ETH_QOS_gen_pg_report_in_file(struct DWC_ETH_QOS_pg_user_input *pg_params,
-					struct DWC_ETH_QOS_PGStruct *pg_struct, FILE *fp)
-{
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = pg_struct->pg_ch_input;
-	char user_string[10], *string;
-	int user_input = 0;
-	int i, display_avb_algo = 0, display_dcb_algo;
-	unsigned long totalbytes = 0, totalbits = 0, time = pg_params->duration_of_exp;
-	unsigned long long totalbytes_tx = 0;
-
-	float ch_bw = 0, total_ch_bw = 0, total_nonav_bw = 0;
-	char *space = "                                                  ";
-
-	if (fp == stdout)
-		system("clear");
-
-	fprintf(fp, "===================================================================\n");
-
-	display_avb_algo = 0;
-	for (i = 0; i < tx_queue_count; i++) {
-		if (pg_ch_input[i].ch_operating_mode == eDWC_ETH_QOS_QAVB) {
-			display_avb_algo = 1;
-			break;
-		}
-	}
-	display_dcb_algo = 0;
-	for (i = 0; i < tx_queue_count; i++) {
-		if (pg_ch_input[i].ch_operating_mode == eDWC_ETH_QOS_QDCB) {
-			display_dcb_algo = 1;
-			break;
-		}
-	}
-
-	fprintf(fp, "Duration Of The Experiment (Seconds)       : %02d\n",
-		pg_params->duration_of_exp);
-	fprintf(fp, "DMA Channel Enabled                        : %#02x\n",
-		pg_params->dma_ch_en);
-	fprintf(fp, "Tx:Rx Prio Scheme                          : %s\n",
-		pg_params->ch_tx_rx_arb_scheme ? "SP" : "RR");
-	fprintf(fp, "Tx has High Prio over Rx                   : %s\n",
-		pg_params->ch_use_tx_high_prio ? "YES" : "NO");
-	fprintf(fp, "Tx:Rx Prio Ratio (for RR)                  : %01d\n",
-		pg_params->ch_tx_rx_prio_ratio);
-	fprintf(fp, "DMA Transmit Arbitration algorithm         : %01d\n",
-			pg_params->dma_tx_arb_algo);
-	if (display_dcb_algo) {
-		fprintf(fp, "MTL DCB algorithm                          : ");
-		switch (pg_params->queue_dcb_algorithm) {
-			case eDWC_ETH_QOS_DCB_WRR:
-				fprintf(fp, "WRR (Weighted Round Robin)\n");
-				break;
-			case eDWC_ETH_QOS_DCB_WFQ:
-				fprintf(fp, "WFQ (Weighted Fair Queuing)\n");
-				break;
-			case eDWC_ETH_QOS_DCB_DWRR:
-				fprintf(fp, "DWRR (Deficit Weighted Round Robin)\n");
-				break;
-			case eDWC_ETH_QOS_DCB_SP:
-				fprintf(fp, "SP (Strict Priority)\n");
-				break;
-		}
-	}
-    fprintf(fp, "mac_lb_mode                                : %01d\n",
-			    pg_params->mac_lb_mode);
-	fprintf(fp, "speed_100M_1G mode                         : %d\n",
-		        pg_struct->speed_100M_1G);
-
-	fprintf(fp, "\n");
-	fprintf(fp, "-------------------------------------------------------------------\n");
-	fprintf(fp, "Parameters\n");
-	fprintf(fp, "-------------------------------------------------------------------\n");
-
-	fprintf(fp, "Ch Operating mode\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		switch (pg_ch_input[i].ch_operating_mode) {
-		case eDWC_ETH_QOS_QAVB:
-			string = "Audio Video Bridging";
-			break;
-		case eDWC_ETH_QOS_QDCB:
-			string = "Data Centric Bridging";
-			break;
-		case eDWC_ETH_QOS_QGENERIC:
-			string = "Non DCB (Generic)";
-			break;
-		case eDWC_ETH_QOS_QDISABLED:
-			string = "Queue operating disabled";
-			break;
-		}
-		fprintf(fp, "%s[CH%d]  %s\n",
-			space, i, string);
-	}
-
-	fprintf(fp, "Ch Prio Weights [DMA]\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %01d\n",
-			space, i, pg_ch_input[i].ch_arb_weight);
-	}
-
-	fprintf(fp, "Queue Weights [MTL]\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %03d\n",
-			space, i, pg_ch_input[i].ch_queue_weight);
-	}
-
-	fprintf(fp, "Slot Number Check Enabled ?\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %s\n",
-			space, i, pg_ch_input[i].ch_EnableSlotCheck ? "YES" : "NO");
-	}
-
-	fprintf(fp, "Adv Slot Number Check Enabled ?\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %s\n",
-			space, i, pg_ch_input[i].ch_EnableAdvSlotCheck ? "YES" : "NO");
-	}
-
-	fprintf(fp, "Slot Counter for Avg bit Report\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %01d\n",
-			space, i, pg_ch_input[i].ch_SlotCount);
-	}
-
-	fprintf(fp, "Ch Avb Bits\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %lu\n",
-			space, i, pg_ch_input[i].ch_AvgBits);
-	}
-
-	fprintf(fp, "Ch Avb Bits Interrupt count\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %lu\n",
-			space, i, pg_ch_input[i].ch_AvgBits_interrupt_count);
-	}
-
-	if (display_avb_algo) {
-		fprintf(fp, "Ch AVB Algorithm\n");
-		for (i = 0; i < tx_queue_count; i++) {
-			if (pg_ch_input[i].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				fprintf(fp, "%s[CH%d]  %s\n", space, i,
-						(pg_ch_input[i].ch_avb_algorithm == eDWC_ETH_QOS_AVB_SP) ?
-						"Strict Priority" : "Credit Based Shaper");
-		}
-
-		fprintf(fp, "Ch uses Credit Control ?\n");
-		for (i = 0; i < tx_queue_count; i++) {
-			if (pg_ch_input[i].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				fprintf(fp, "%s[CH%d]  %s\n",
-						space, i, pg_ch_input[i].ch_CreditControl ? "YES" : "NO");
-		}
-
-		fprintf(fp, "Ch Idle Slope\n");
-		for (i = 0; i < tx_queue_count; i++) {
-			if (pg_ch_input[i].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				fprintf(fp, "%s[CH%d]  %#08x\n",
-						space, i, pg_ch_input[i].ch_IdleSlope);
-		}
-
-		fprintf(fp, "Ch Send Slope\n");
-		for (i = 0; i < tx_queue_count; i++) {
-			if (pg_ch_input[i].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				fprintf(fp, "%s[CH%d]  %#08x\n",
-						space, i, pg_ch_input[i].ch_SendSlope);
-		}
-
-		fprintf(fp, "Ch High Credit\n");
-		for (i = 0; i < tx_queue_count; i++) {
-			if (pg_ch_input[i].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				fprintf(fp, "%s[CH%d]  %#08x\n",
-						space, i, pg_ch_input[i].ch_HiCredit);
-		}
-
-		fprintf(fp, "Ch Low Credit\n");
-		for (i = 0; i < tx_queue_count; i++) {
-			if (pg_ch_input[i].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				fprintf(fp, "%s[CH%d]  %#08x\n",
-						space, i, pg_ch_input[i].ch_LoCredit);
-		}
-	}
-
-	/* required only for debugging */
-	fprintf(fp, "Debug mode\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %s\n",
-			space, i, (pg_ch_input[i].ch_debug_mode ? "YES" : "NO"));
-	}
-
-	/* required only for debugging */
-	fprintf(fp, "Maximum Tx packet limit for debug mode\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %d\n",
-			space, i, pg_ch_input[i].ch_max_tx_frame_cnt);
-	}
-
-	fprintf(fp, "Frame size\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %03d\n",
-			space, i, pg_ch_input[i].ch_frame_size);
-	}
-
-	fprintf(fp, "Ch Tx Frame Count\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %ld\n",
-			space, i, pg_ch_input[i].ch_FramecountTx);
-	}
-
-	fprintf(fp, "Ch Rx Frame Count\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %ld\n",
-			space, i, pg_ch_input[i].ch_FramecountRx);
-	}
-
-	fprintf(fp, "Band Width Allocation\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		fprintf(fp, "%s[CH%d]  %03d%%\n",
-			space, i, pg_ch_input[i].ch_bw);
-	}
-	total_nonav_bw = 0;
-	for (i = 0; i < tx_queue_count; i++) {
-		if (pg_ch_input[i].ch_operating_mode != eDWC_ETH_QOS_QAVB)
-			total_nonav_bw += pg_ch_input[i].ch_bw;
-	}
-	if (total_nonav_bw < 25)
-		printf("WARNING: Total bandwidth for Non-AVB queues has gone below 25%%\n\n");
-
-	fprintf(fp, "Ch BW utilization Achieved (based on Tx)\n");
-	/* total = add_up(queue-rx-frames-count x queue-frame-size)
-	 * individual-queue = ((queue-rx-frame-count x queue-frame-size) x 100) / total */
-	totalbytes = 0;
-	for (i = 0; i < tx_queue_count; i++) {
-		totalbytes += (pg_ch_input[i].ch_FramecountTx * pg_ch_input[i].ch_frame_size);
-	}
-	for (i = 0; i < tx_queue_count; i++) {
-		ch_bw = (pg_ch_input[i].ch_FramecountTx * pg_ch_input[i].ch_frame_size);
-		if (ch_bw)
-			ch_bw = (float)((ch_bw * 100)/totalbytes);
-		fprintf(fp, "%s[CH%d]  %3.2F%%\n",
-			space, i, ch_bw);
-	}
-
-	fprintf(fp, "Ch BW utilization Achieved (based on Rx)\n");
-	/* total = add_up(queue-rx-frames-count x queue-frame-size)
-	 * individual-queue = ((queue-rx-frame-count x queue-frame-size) x 100) / total */
-	totalbytes = 0;
-	totalbytes_tx = 0;
-	for (i = 0; i < rx_queue_count; i++) {
-		totalbytes += (pg_ch_input[i].ch_FramecountRx * pg_ch_input[i].ch_frame_size);
-		totalbytes_tx += (pg_ch_input[i].ch_FramecountTx * pg_ch_input[i].ch_frame_size);
-	}
-	for (i = 0; i < rx_queue_count; i++) {
-		ch_bw = (pg_ch_input[i].ch_FramecountRx * pg_ch_input[i].ch_frame_size);
-		if (ch_bw)
-			ch_bw = (float)((ch_bw * 100)/totalbytes_tx);
-		fprintf(fp, "%s[CH%d]  %3.2F%%\n",
-			space, i, ch_bw);
-	}
-
-	fprintf(fp, "Ch BW utilization Achieved on Tx in Mbps\n");
-	for (i = 0; i < tx_queue_count; i++) {
-		ch_bw = (pg_ch_input[i].ch_FramecountTx * (pg_ch_input[i].ch_frame_size + 8 + 4) * 8);
-		if (ch_bw)
-			ch_bw = (float)((ch_bw/time)/(1024*1024));
-		fprintf(fp, "%s[CH%d]  %3.2F Mbps\n",
-			space, i, ch_bw);
-		total_ch_bw += ch_bw;
-	}
-	fprintf(fp, "%s----------------\n", space);
-	fprintf(fp, "%sTotal %3.2F Mbps\n", space, total_ch_bw);
-
-	fprintf(fp, "===================================================================\n");
-	fprintf(fp, "\n");
-
-	if (fp == stdout) {
-		printf("Enter 99 to return to main menu::");
-		do {
-			fscanf(stdin, "%s", user_string);
-			sscanf(user_string, "%d", &user_input);
-			if (user_input != 99)
-				printf("Invalid option %d\n", user_input);
-		} while(user_input != 99);
-	}
-}
-
-
-static void DWC_ETH_QOS_gen_pg_report(struct DWC_ETH_QOS_pg_user_input *pg_params,
-					struct DWC_ETH_QOS_PGStruct *pg_struct)
-{
-#ifdef PGTEST_LOGFILE
-	FILE *fp = NULL;
-	time_t mytime;
-	struct tm *mytm;
-	char file_name[64], time_str[3][8], date_str[2][8];
-#endif
-
-	DWC_ETH_QOS_gen_pg_report_in_file(pg_params, pg_struct, stdout);
-
-#ifdef PGTEST_LOGFILE
-
-	/* log in file */
-	mytime = time(NULL);
-	mytm = localtime(&mytime);
-	if (!mytm) {
-		printf("Error in fetching system time\n");
-		printf("No log file will be created\n");
-		return;
-	}
-
-	sprintf(time_str[0], "%d", (mytm->tm_hour % 12));
-	sprintf(time_str[1], "%d", mytm->tm_min);
-	sprintf(time_str[2], "%d", mytm->tm_sec);
-	switch (mytm->tm_mon) {
-		case 0: sprintf(date_str[0], "Jan"); break;
-		case 1: sprintf(date_str[0], "Feb"); break;
-		case 2: sprintf(date_str[0], "Mar"); break;
-		case 3: sprintf(date_str[0], "Apr"); break;
-		case 4: sprintf(date_str[0], "May"); break;
-		case 5: sprintf(date_str[0], "June"); break;
-		case 6: sprintf(date_str[0], "Jul"); break;
-		case 7: sprintf(date_str[0], "Aug"); break;
-		case 8: sprintf(date_str[0], "Sep"); break;
-		case 9: sprintf(date_str[0], "Oct"); break;
-		case 10: sprintf(date_str[0], "Nov"); break;
-		case 11: sprintf(date_str[0], "Dec"); break;
-	}
-	sprintf(date_str[1], "%d", mytm->tm_mday);
-	sprintf(file_name, "pgtest_%s_%s_%s_%s_%s.log",
-			date_str[0], date_str[1], time_str[0], time_str[1], time_str[2]);
-
-	fp = fopen(file_name, "w+");
-	if (fp == NULL) {
-		printf("Error in file open\n");
-		printf("No log file will be created\n");
-		return;
-	}
-	fprintf(fp, "Report generated on %s %s, %s:%s:%s\n\n",
-			date_str[0], date_str[1], time_str[0], time_str[1], time_str[2]);
-	DWC_ETH_QOS_gen_pg_report_in_file(pg_params, pg_struct, fp);
-	fclose(fp);
-#endif
-
-	return;
-}
-
-static void DWC_ETH_QOS_print_pg_struct(struct DWC_ETH_QOS_PGStruct *pg_struct)
-{
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = pg_struct->pg_ch_input;
-	char user_string[10];
-	int user_input = 0;
-	int i;
-
-	system("clear");
-	printf("ch_SelMask                          = %#02x\n",
-		pg_struct->ch_SelMask);
-	printf("DurationOfExp                       = %02d\n",
-		pg_struct->DurationOfExp);
-	printf("PrioTagForAV                        = %#02x\n",
-		pg_struct->PrioTagForAV);
-	printf("ch_tx_rx_arb_scheme                 = %s\n",
-		pg_struct->ch_tx_rx_arb_scheme ? "SP" : "RR");
-	printf("ch_use_tx_high_prio                 = %01d\n",
-		pg_struct->ch_use_tx_high_prio);
-	printf("ch_tx_rx_prio_ratio                 = %01d\n",
-		pg_struct->ch_tx_rx_prio_ratio);
-
-	for (i = 0; i < tx_queue_count; i++) {
-		printf("\n");
-		printf("Ch%d ch_arb_weight                  = %01d\n",
-			i, pg_ch_input[i].ch_arb_weight);
-		printf("Ch%d ch_bw                          = %03d%%\n",
-			i, pg_ch_input[i].ch_bw);
-		printf("Ch%d ch_queue_weight                = %03d\n",
-			i, pg_ch_input[i].ch_queue_weight);
-		printf("Ch%d ch_frame_size                  = %03d\n",
-			i, pg_ch_input[i].ch_frame_size);
-		printf("Ch%d ch_EnableSlotCheck             = %s\n",
-			i, pg_ch_input[i].ch_EnableSlotCheck ? "YES" : "NO");
-		printf("Ch%d ch_EnableAdvSlotCheck          = %s\n",
-			i, pg_ch_input[i].ch_EnableAdvSlotCheck ? "YES" : "NO");
-		printf("Ch%d ch_avb_algorithm               = %s\n",
-			i, ((pg_ch_input[i].ch_avb_algorithm == eDWC_ETH_QOS_AVB_SP) ?
-				"Strict Priority" : "Credit Based Shaper"));
-		printf("Ch%d ch_SlotCount                   = %01d\n",
-			i, pg_ch_input[i].ch_SlotCount);
-		printf("Ch%d ch_CreditControl               = %s\n",
-			i, pg_ch_input[i].ch_CreditControl ? "YES" : "NO");
-		printf("Ch%d ch_SendSlope                   = %#08x\n",
-			i, pg_ch_input[i].ch_SendSlope);
-		printf("Ch%d ch_IdleSlope                   = %#08x\n",
-			i, pg_ch_input[i].ch_IdleSlope);
-		printf("Ch%d ch_HiCredit                    = %#08x\n",
-			i, pg_ch_input[i].ch_HiCredit);
-		printf("Ch%d ch_LoCredit                    = %#08x\n",
-			i, pg_ch_input[i].ch_LoCredit);
-		printf("Ch%d ch_FramecountTx                = %ld\n",
-			i, pg_ch_input[i].ch_FramecountTx);
-		printf("Ch%d ch_FramecountRx                = %ld\n",
-			i, pg_ch_input[i].ch_FramecountRx);
-		printf("Ch%d ch_tx_desc_slot_no_start       = %#01x\n",
-			i, pg_ch_input[i].ch_tx_desc_slot_no_start);
-		printf("Ch%d ch_tx_desc_slot_no_skip        = %#01x\n",
-			i, pg_ch_input[i].ch_tx_desc_slot_no_skip);
-	}
-
-	printf("\n");
-	printf("Enter 99 to return to main menu::");
-	do {
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-		if (user_input != 99)
-			printf("Invalid option %d\n", user_input);
-	} while(user_input != 99);
-}
-
-static int DWC_ETH_QOS_reset_run_parameters(struct DWC_ETH_QOS_PGStruct *pg_struct)
-{
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = pg_struct->pg_ch_input;
-	unsigned int qInx = 0;
-
-	sleep(1);
-	for (qInx = 0; qInx < tx_queue_count; qInx++) {
-		pg_ch_input[qInx].ch_FramecountTx = 0;
-		pg_ch_input[qInx].ch_AvgBits = 0;
-		pg_ch_input[qInx].ch_AvgBits_interrupt_count = 0;
-		pg_ch_input[qInx].tx_interrupts = 0;
-		pg_ch_input[qInx].interrupt_prints = 0;
-	}
-
-	for (qInx = 0; qInx < rx_queue_count; qInx++) {
-		pg_ch_input[qInx].ch_FramecountRx = 0;
-	}
-
-	return 0;
-}
-
-static int DWC_ETH_QOS_display_progress(int sockfd, char *ifname,
-		struct DWC_ETH_QOS_PGStruct *pg_struct,
-		struct DWC_ETH_QOS_pg_user_input *pg_params)
-{
-	int test_run = 1, total_seconds = 0;
-	int dots = 3, user_input, i, blinker = 0;
-	char user_string[10];
-
-	printf("\n");
-	do {
-		/* print progress */
-		printf("[%3dsecs] ", total_seconds);
-		blinker = (total_seconds % dots);
-		for (i = 0; i < dots; i++) {
-			if (i <= blinker)
-				printf(".");
-			else
-				printf(" ");
-		}
-		fflush(stdout);
-
-		/* wait!! */
-		sleep(1);
-
-		/* clear display for next progress update */
-		printf("\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b");
-		for (i = 0; i < dots; i++) {
-			printf("\b");
-		}
-		fflush(stdout);
-		total_seconds++;
-
-		/* check for test complete */
-		test_run = DWC_ETH_QOS_check_test_done(sockfd, ifname);
-	} while (test_run);
-
-	printf("\n");
-	printf("RUN HAS COMPLETED\n");
-	printf("\n");
-	printf("Enter any number to view the run results::");
-	fscanf(stdin, "%s", user_string);
-	sscanf(user_string, "%d", &user_input);
-
-	DWC_ETH_QOS_get_pg_result_from_hw(sockfd, ifname, pg_struct);
-	DWC_ETH_QOS_gen_pg_report(pg_params, pg_struct);
-
-	return 0;
-}
-
-/* returun 0 success and -ve number on failure */
-static int DWC_ETH_QOS_pg_test(int sockfd, char *ifname)
-{
-	struct DWC_ETH_QOS_pg_user_input pg_params;
-	struct DWC_ETH_QOS_PGStruct pg_struct;
-	char user_string[10];
-	int user_input = 0;
-
-	if (tx_queue_count <= 0 || rx_queue_count <= 0) {
-		printf("ERROR: Tx/Rx Queue count is zero\n");
-		return -1;
-	}
-
-	DWC_ETH_QOS_init_default_pg(&pg_params);
-	DWC_ETH_QOS_populate_pg_struct(&pg_params, &pg_struct);
-	DWC_ETH_QOS_send_pg_param_to_driver(sockfd, ifname, &pg_struct);
-	DWC_ETH_QOS_config_hw_for_pg_test(sockfd, ifname);
-
-	printf("You are about to start PG Testing....\n");
-	do {
-		system("clear");
-		printf("--------------------------------------------\n");
-		printf("Select the Option Below:\n");
-		printf("--------------------------------------------\n");
-
-		printf("(01) Show/Get the PG Parameters\n");
-		printf("(02) Send Parameters to Driver\n");
-		printf("(03) Configure HW for PG Test\n");
-		printf("(04) Run PG test\n");
-		printf("(05) Show PG Test Reports\n");
-		printf("(06) Print PG Structure\n");
-		printf("(99) To quit this menu\n\n");
-
-		printf("Your Option here::");
-		fscanf(stdin, "%s", user_string);
-		sscanf(user_string, "%d", &user_input);
-
-		switch (user_input) {
-		case 01:
-			DWC_ETH_QOS_get_pg_params(&pg_params);
-			DWC_ETH_QOS_populate_pg_struct(&pg_params, &pg_struct);
-			break;
-		case 02:
-			DWC_ETH_QOS_send_pg_param_to_driver(sockfd, ifname, &pg_struct);
-			break;
-		case 03:
-			DWC_ETH_QOS_config_hw_for_pg_test(sockfd, ifname);
-			break;
-		case 04:
-			/* reset selected PG parameters in app and kernel before run */
-			DWC_ETH_QOS_reset_run_parameters(&pg_struct);
-			DWC_ETH_QOS_send_pg_param_to_driver(sockfd, ifname, &pg_struct);
-			DWC_ETH_QOS_run_pg_test(sockfd, ifname, &pg_struct);
-			DWC_ETH_QOS_display_progress(sockfd, ifname, &pg_struct, &pg_params);
-			break;
-		case 05:
-			DWC_ETH_QOS_get_pg_result_from_hw(sockfd, ifname, &pg_struct);
-			DWC_ETH_QOS_gen_pg_report(&pg_params, &pg_struct);
-			break;
-		case 06:
-			DWC_ETH_QOS_print_pg_struct(&pg_struct);
-			break;
-		case 99:
-			printf("Exiting....\n");
-			break;
-		default:
-			printf("Sorry, wrong input....\n");
-		}
-	} while(user_input != 99);
-
-	return 0;
-}
-
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 void usage_common(char *cmd)
 {
 	if (print_all) {
@@ -3635,12 +2392,6 @@ void usage_avb()
 			"\n");
 }
 
-void usage_pgtest()
-{
-	usage_common("pgtest");
-	fprintf(stderr, "\n\n");
-}
-
 void usage_split_hdr()
 {
 	usage_common("split_hdr");
@@ -3812,7 +2563,6 @@ void print_all_usage()
 	usage_queue_count();
 	usage_dcb();
 	usage_avb();
-	usage_pgtest();
 	usage_split_hdr();
 	usage_l3_l4_filter();
 	usage_ip4_filter();
@@ -4036,13 +2786,7 @@ main(int argc, char *argv[])
 			}
 			ret = program_avb_algorithm(sockfd, argv[1], argv[3],
 					argv[4], argv[5], argv[6]);
-		}
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-		else if (0 == strcmp(argv[2], "pgtest")) {
-			ret = DWC_ETH_QOS_pg_test(sockfd, argv[1]);
-		}
-#endif /* DWC_ETH_QOS_CONFIG_PGTEST */
-		else if (0 == strcmp(argv[2], "split_hdr")) {
+		} else if (0 == strcmp(argv[2], "split_hdr")) {
 			if (argc < 4) {
 				usage_split_hdr();
 				goto argc_failed;
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_desc.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_desc.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_desc.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_desc.c
@@ -296,7 +296,7 @@ static void DWC_ETH_QOS_wrapper_tx_descr
 	struct DWC_ETH_QOS_tx_buffer *buffer = GET_TX_BUF_PTR(qInx, 0);
 	tx_descriptor_t *desc = GET_TX_DESC_PTR(qInx, 0);
 	dma_addr_t desc_dma = GET_TX_DESC_DMA_ADDR(qInx, 0);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 
 	DBGPR("-->DWC_ETH_QOS_wrapper_tx_descriptor_init_single_q: "\
 		"qInx = %u\n", qInx);
@@ -306,11 +306,6 @@ static void DWC_ETH_QOS_wrapper_tx_descr
 		GET_TX_DESC_DMA_ADDR(qInx, i) =
 		    (desc_dma + sizeof(tx_descriptor_t) * i);
 		GET_TX_BUF_PTR(qInx, i) = &buffer[i];
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-		if (DWC_ETH_QOS_alloc_tx_buf_pg(pdata, GET_TX_BUF_PTR(qInx, i),
-			GFP_KERNEL))
-			break;
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
 	}
 
 	desc_data->cur_tx = 0;
@@ -319,12 +314,7 @@ static void DWC_ETH_QOS_wrapper_tx_descr
 	desc_data->tx_pkt_queued = 0;
 	desc_data->packet_count = 0;
 	desc_data->free_desc_cnt = TX_DESC_CNT;
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	hw_if->tx_desc_init_pg(pdata, qInx);
-#else
 	hw_if->tx_desc_init(pdata, qInx);
-#endif
 	desc_data->cur_tx = 0;
 
 	DBGPR("<--DWC_ETH_QOS_wrapper_tx_descriptor_init_single_q\n");
@@ -354,7 +344,7 @@ static void DWC_ETH_QOS_wrapper_rx_descr
 	struct DWC_ETH_QOS_rx_buffer *buffer = GET_RX_BUF_PTR(qInx, 0);
 	rx_descriptor_t *desc = GET_RX_DESC_PTR(qInx, 0);
 	dma_addr_t desc_dma = GET_RX_DESC_DMA_ADDR(qInx, 0);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 
 	DBGPR("-->DWC_ETH_QOS_wrapper_rx_descriptor_init_single_q: "\
 		"qInx = %u\n", qInx);
@@ -366,15 +356,9 @@ static void DWC_ETH_QOS_wrapper_rx_descr
 		GET_RX_DESC_DMA_ADDR(qInx, i) =
 		    (desc_dma + sizeof(rx_descriptor_t) * i);
 		GET_RX_BUF_PTR(qInx, i) = &buffer[i];
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-		if (DWC_ETH_QOS_alloc_rx_buf_pg(pdata, GET_RX_BUF_PTR(qInx, i), GFP_KERNEL))
-			break;
-#else
 		/* allocate skb & assign to each desc */
 		if (pdata->alloc_rx_buf(pdata, GET_RX_BUF_PTR(qInx, i), GFP_KERNEL))
 			break;
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 		wmb();
 	}
 
@@ -383,13 +367,8 @@ static void DWC_ETH_QOS_wrapper_rx_descr
 	desc_data->skb_realloc_idx = 0;
 	desc_data->skb_realloc_threshold = MIN_RX_DESC_CNT;
 	desc_data->pkt_received = 0;
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	hw_if->rx_desc_init_pg(pdata, qInx);
-#else
+	desc_data->cur_rx = 0;
 	hw_if->rx_desc_init(pdata, qInx);
-#endif
-	desc_data->cur_rx = 0;
 
 	DBGPR("<--DWC_ETH_QOS_wrapper_rx_descriptor_init_single_q\n");
 }
@@ -481,18 +460,10 @@ static void DWC_ETH_QOS_rx_free_mem(stru
 static void DWC_ETH_QOS_tx_free_mem(struct DWC_ETH_QOS_prv_data *pdata)
 {
 	DBGPR("-->DWC_ETH_QOS_tx_free_mem\n");
-
 	/* free TX descriptor */
 	DWC_ETH_QOS_tx_desc_free_mem(pdata, DWC_ETH_QOS_TX_QUEUE_CNT);
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	/* free TX skb's */
-	DWC_ETH_QOS_tx_skb_free_mem(pdata, DWC_ETH_QOS_TX_QUEUE_CNT);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 	/* free TX buffer */
 	DWC_ETH_QOS_tx_buf_free_mem(pdata, DWC_ETH_QOS_TX_QUEUE_CNT);
-
 	DBGPR("<--DWC_ETH_QOS_tx_free_mem\n");
 }
 
@@ -504,17 +475,17 @@ static void DWC_ETH_QOS_tx_free_mem(stru
  *
  * \return void
  */
-
 static void DWC_ETH_QOS_tx_skb_free_mem_single_q(struct DWC_ETH_QOS_prv_data *pdata,
 							uint32_t qInx)
 {
 	uint32_t i;
-
+	struct DWC_ETH_QOS_tx_buffer *buffer = NULL;
 	DBGPR("-->DWC_ETH_QOS_tx_skb_free_mem_single_q: qInx = %u\n", qInx);
-
-	for (i = 0; i < TX_DESC_CNT; i++)
-		DWC_ETH_QOS_unmap_tx_skb(pdata, GET_TX_BUF_PTR(qInx, i));
-
+	for (i = 0; i < TX_DESC_CNT; i++) {
+		buffer = GET_TX_BUF_PTR(qInx, i);
+		if (buffer)
+		DWC_ETH_QOS_unmap_tx_skb(pdata, buffer);
+	}
 	DBGPR("<--DWC_ETH_QOS_tx_skb_free_mem_single_q\n");
 }
 
@@ -527,51 +498,16 @@ static void DWC_ETH_QOS_tx_skb_free_mem_
 *
 * \retval void.
 */
-
 static void DWC_ETH_QOS_tx_skb_free_mem(struct DWC_ETH_QOS_prv_data *pdata,
 					uint32_t tx_qCnt)
 {
 	uint32_t qInx;
-
 	DBGPR("-->DWC_ETH_QOS_tx_skb_free_mem: tx_qCnt = %d\n", tx_qCnt);
-
 	for (qInx = 0; qInx < tx_qCnt; qInx++)
 		DWC_ETH_QOS_tx_skb_free_mem_single_q(pdata, qInx);
-
 	DBGPR("<--DWC_ETH_QOS_tx_skb_free_mem\n");
 }
 
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-/*!
- * \details This function is used to release Rx socket buffer.
- *
- * \param[in] pdata  pointer to private device structure.
- * \param[in] buffer  pointer to rx wrapper buffer structure.
- *
- * \return void
- */
-static void DWC_ETH_QOS_unmap_rx_skb_pg(struct DWC_ETH_QOS_prv_data *pdata,
-				     struct DWC_ETH_QOS_rx_buffer *buffer)
-{
-	//DBGPR("-->DWC_ETH_QOS_unmap_rx_skb_pg\n");
-
-	/* unmap the first buffer */
-	if (buffer->dma) {
-		dma_unmap_single(&pdata->pdev->dev, buffer->dma,
-				 DWC_ETH_QOS_PG_FRAME_SIZE, DMA_FROM_DEVICE);
-		buffer->dma = 0;
-	}
-
-	if (buffer->skb) {
-		dev_kfree_skb_any(buffer->skb);
-		buffer->skb = NULL;
-	}
-
-	//DBGPR("<--DWC_ETH_QOS_unmap_rx_skb_pg\n");
-}
-#endif
-
 /*!
  * \details This function is invoked by other function to free
  * the rx socket buffers.
@@ -580,30 +516,24 @@ static void DWC_ETH_QOS_unmap_rx_skb_pg(
  *
  * \return void
  */
-
 static void DWC_ETH_QOS_rx_skb_free_mem_single_q(struct DWC_ETH_QOS_prv_data *pdata,
 							uint32_t qInx)
 {
 	struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
 	    GET_RX_WRAPPER_DESC(qInx);
+	struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
 	uint32_t i;
-
 	DBGPR("-->DWC_ETH_QOS_rx_skb_free_mem_single_q: qInx = %u\n", qInx);
-
 	for (i = 0; i < RX_DESC_CNT; i++) {
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-		DWC_ETH_QOS_unmap_rx_skb_pg(pdata, GET_RX_BUF_PTR(qInx, i));
-#else
-		DWC_ETH_QOS_unmap_rx_skb(pdata, GET_RX_BUF_PTR(qInx, i));
-#endif
+		buffer = GET_RX_BUF_PTR(qInx, i);
+		if (buffer) {
+			DWC_ETH_QOS_unmap_rx_skb(pdata, buffer);
+		}
 	}
-
 	/* there are also some cached data from a chained rx */
 	if (desc_data->skb_top)
 		dev_kfree_skb_any(desc_data->skb_top);
-
 	desc_data->skb_top = NULL;
-
 	DBGPR("<--DWC_ETH_QOS_rx_skb_free_mem_single_q\n");
 }
 
@@ -616,17 +546,13 @@ static void DWC_ETH_QOS_rx_skb_free_mem_
 *
 * \retval void.
 */
-
 static void DWC_ETH_QOS_rx_skb_free_mem(struct DWC_ETH_QOS_prv_data *pdata,
 					uint32_t rx_qCnt)
 {
 	uint32_t qInx;
-
 	DBGPR("-->DWC_ETH_QOS_rx_skb_free_mem: rx_qCnt = %d\n", rx_qCnt);
-
 	for (qInx = 0; qInx < rx_qCnt; qInx++)
 		DWC_ETH_QOS_rx_skb_free_mem_single_q(pdata, qInx);
-
 	DBGPR("<--DWC_ETH_QOS_rx_skb_free_mem\n");
 }
 
@@ -639,7 +565,6 @@ static void DWC_ETH_QOS_rx_skb_free_mem(
 *
 * \retval void.
 */
-
 static void DWC_ETH_QOS_tx_buf_free_mem(struct DWC_ETH_QOS_prv_data *pdata,
 					uint32_t tx_qCnt)
 {
@@ -1075,16 +1000,11 @@ err_out_dma_map_fail:
 *
 * \return void
 */
-
 static void DWC_ETH_QOS_unmap_tx_skb(struct DWC_ETH_QOS_prv_data *pdata,
 				     struct DWC_ETH_QOS_tx_buffer *buffer)
 {
 	DBGPR("-->DWC_ETH_QOS_unmap_tx_skb\n");
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	buffer->len = DWC_ETH_QOS_PG_FRAME_SIZE;
-#endif
-
 	if (buffer->dma) {
 		if (buffer->buf1_mapped_as_page == Y_TRUE)
 			dma_unmap_page((&pdata->pdev->dev), buffer->dma,
@@ -1195,7 +1115,7 @@ static void DWC_ETH_QOS_re_alloc_skb(str
 	struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
 	    GET_RX_WRAPPER_DESC(qInx);
 	struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
-	struct hw_if_struct *hw_if = &pdata->hw_if;
+	hw_interface_t *hw_if = &pdata->hw_if;
 	int tail_idx;
 
 	DBGPR("-->DWC_ETH_QOS_re_alloc_skb: desc_data->skb_realloc_idx = %d "\
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_dev.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_dev.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_dev.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_dev.c
@@ -36,149 +36,6 @@
 #include "DWC_ETH_QOS_yapphdr.h"
 #include "DWC_ETH_QOS_yregacc.h"
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-
-static int prepare_dev_pktgen(struct DWC_ETH_QOS_prv_data *pdata)
-{
-   uint32_t qInx = 0;
-   /* set MAC loop back mode */
-   DWC_REG_WR_BIT(MAC_MCR, MAC_MCR_LM, 0x1);
-   /* Do not strip received VLAN tag */
-   DWC_REG_WR_FIELD(MAC_VLANTR, MAC_VLANTR_EVLS, 0x0);
-   /* set promiscuous mode */
-   DWC_REG_WR_BIT(MAC_PFR, MAC_PFR_PR, 0x1);
-   /* disable autopad or CRC stripping */
-   DWC_REG_WR_BIT(MAC_MCR, MAC_MCR_ACS, 0x0);
-   /* enable drop tx status */
-   DWC_REG_WR_BIT(MTL_OMR, MTL_OMR_DTXSTS, 0x1);
-   for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-      /* enable avg bits per slot interrupt */
-      DWC_REG_WR_BIT(MTL_TXQ_ECR(qInx), MTL_TXQ_ECR_ABPSSIE, 0x1);
-      /* enable OSF mode */
-      DWC_REG_WR_BIT(DMA_TCR(qInx), DMA_TCR_OSP, 0x1);
-      /* disable slot checks */
-      DWC_REG_WR(DMA_SFCSR(qInx), 0x0);
-   }
-   return Y_SUCCESS;
-}
-
-/*!
-* \brief This sequence is used to configure slot count The software
-* can program the number of slots(of duration 125us) over which the
-* average transmitted bits per slot need to be computed for
-* channel 1 to 7 when CBS alogorithm is enabled.
-* \param[in] qInx
-* \param[in] slot_count
-* \return Success or Failure
-* \retval  0 Success
-* \retval -1 Failure
-*/
-static int set_slot_count(uint32_t qInx, uint8_t slot_count)
-{
-   if (slot_count == 1) {
-      DWC_REG_WR_FIELD(MTL_TXQ_ECR(qInx), MTL_TXQ_ECR_SLC, 0x0);
-   } else if (slot_count == 2) {
-      DWC_REG_WR_FIELD(MTL_TXQ_ECR(qInx), MTL_TXQ_ECR_SLC, 0x1);
-   } else if (slot_count == 4) {
-      DWC_REG_WR_FIELD(MTL_TXQ_ECR(qInx), MTL_TXQ_ECR_SLC, 0x3);
-   } else if (slot_count == 8) {
-      DWC_REG_WR_FIELD(MTL_TXQ_ECR(qInx), MTL_TXQ_ECR_SLC, 0x4);
-   } else if (slot_count == 16) {
-      DWC_REG_WR_FIELD(MTL_TXQ_ECR(qInx), MTL_TXQ_ECR_SLC, 0x5);
-   }
-
-  return Y_SUCCESS;
-}
-
-/*!
-* \brief This sequence is used to enable/disable slot interrupt:
-* When this bit is set,the MAC asserts an interrupt when the average
-* bits per slot status is updated for channel 1 to 7.
-* \param[in] qInx
-* \return Success or Failure
-* \retval  0 Success
-* \retval -1 Failure
-*/
-static int config_slot_interrupt(uint32_t qInx, uint8_t slot_int)
-{
-   DWC_REG_WR_BIT(MTL_TXQ_ECR(qInx), MTL_TXQ_ECR_ABPSSIE, slot_int);
-   return Y_SUCCESS;
-}
-
-/*!
-* \brief This sequence is used to configure DMA Tx:Rx/Rx:Tx
-* Priority Ratio These bits control the priority ratio in WRR
-* arbitration between the TX and RX DAM.
-* \param[in] prio_ratio
-* \return Success or Failure
-* \retval  0 Success
-* \retval -1 Failure
-*/
-static int set_tx_rx_prio_ratio(uint8_t prio_ratio)
-{
-   DWC_REG_WR_FIELD(DMA_BMR, DMA_BMR_PR, prio_ratio);
-   return Y_SUCCESS;
-}
-
-/*!
-* \brief This sequence is used to configure DMA Transmit Arbitration algorithm
-* \param[in] arb_algo
-* \return Success or Failure
-* \retval  0 Success
-* \retval -1 Failure
-*/
-static int set_dma_tx_arb_algorithm(uint8_t arb_algo)
-{
-   DWC_REG_WR_FIELD(DMA_BMR, DMA_BMR_TAA, arb_algo);
-   return Y_SUCCESS;
-}
-
-/*!
-* \brief This sequence is used to configure DMA Tx Priority When this
-* bit is set, it indicates that the TX DMA has higher priority than
-* the RX DMA during arbitration for the system-side bus.
-* \param[in] prio
-* \return Success or Failure
-* \retval  0 Success
-* \retval -1 Failure
-*/
-static int set_tx_rx_prio(uint8_t prio)
-{
-   DWC_REG_WR_BIT(DMA_BMR, DMA_BMR_TXPR, prio);
-   return Y_SUCCESS;
-}
-
-/*!
-* \brief This sequence is used to configure DMA Tx/Rx Arbitration Scheme
-* This bit specifies the arbitration scheme between the Tx and Rx paths
-* of all channels.
-* \param[in] prio_policy
-* \return Success or Failure
-* \retval  0 Success
-* \retval -1 Failure
-*/
-static int set_tx_rx_prio_policy(uint8_t prio_policy)
-{
-   DWC_REG_WR_BIT(DMA_BMR, DMA_BMR_DA, prio_policy);
-   return Y_SUCCESS;
-}
-
-/*!
-* \brief This sequence is used to configure TX Channel Weight
-* \param[in] qInx
-* \param[in] weight
-* \return Success or Failure
-* \retval  0 Success
-* \retval -1 Failure
-*/
-static int set_ch_arb_weights(uint32_t qInx, uint8_t weight)
-{
-   if (weight > 0 && weight < 9)
-      DWC_REG_WR_FIELD(DMA_TCR(qInx), DMA_TCR_TCW, weight - 1);
-   return Y_SUCCESS;
-}
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 /*!
 * \brief This sequence is used to enable/disable MAC loopback mode
 * \param[in] enb_dis
@@ -1367,71 +1224,64 @@ static int disable_mmc_interrupts(void)
 static int config_mmc_counters(void)
 {
    uint32_t varMMC_CNTRL;
-   /* set COUNTER RESET */
-   /* set RESET ON READ */
-   /* set COUNTER PRESET */
-   /* set FULL_HALF PRESET */
    varMMC_CNTRL = DWC_REG_RD(MMC_CR);
    varMMC_CNTRL &= 0x10a;
+   /* set COUNTER RESET */
    VAR32_SET_BIT(varMMC_CNTRL, MMC_CR_CNTRST, 0x1);
+   /* set RESET ON READ */
    VAR32_SET_BIT(varMMC_CNTRL, MMC_CR_RSTONRD, 0x1);
+   /* set COUNTER PRESET */
    VAR32_SET_BIT(varMMC_CNTRL, MMC_CR_CNTPRST, 0x1);
+   /* set FULL_HALF PRESET */
    VAR32_SET_BIT(varMMC_CNTRL, MMC_CR_CNTPRSTLVL, 0x1);
    DWC_REG_WR(MMC_CR, varMMC_CNTRL);
    return Y_SUCCESS;
 }
 
-/*!
-* \brief This sequence is used to disable given DMA channel rx interrupts
-* \param[in] qInx
-*/
-static void disable_rx_interrupt(uint32_t qInx)
+/* Disable given DMA channel rx interrupts */
+static void disable_rx_interrupt(uint32_t qInx, hw_config_t *hw_cfg)
 {
    /* Disable Rx interrupts */
-   DWC_REG_WR_BIT(DMA_IER(qInx), DMA_IER_RBUE, 0x0);
-   DWC_REG_WR_BIT(DMA_IER(qInx), DMA_IER_RIE, 0x0);
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_RBUE, 0x0);
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_RIE, 0x0);
+   DWC_REG_WR(DMA_IER(qInx), hw_cfg->dma_ier);
+
    /* Clear any Rx pending interrupt */
    DWC_REG_WR_BIT(DMA_SR(qInx), DMA_SR_RBU, 0x1);
    DWC_REG_WR_BIT(DMA_SR(qInx), DMA_SR_RI, 0x1);
 }
 
-/*!
-* \brief This sequence is used to enable given DMA channel rx interrupts
-* \param[in] qInx
-*/
-static void enable_rx_interrupt(uint32_t qInx)
+/* Enable given DMA channel rx interrupts */
+static void enable_rx_interrupt(uint32_t qInx, hw_config_t *hw_cfg)
 {
-   DWC_REG_WR_BIT(DMA_IER(qInx), DMA_IER_RBUE, 0x1);
-   DWC_REG_WR_BIT(DMA_IER(qInx), DMA_IER_RIE, 0x1);
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_RBUE, 0x1);
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_RIE, 0x1);
+   DWC_REG_WR(DMA_IER(qInx), hw_cfg->dma_ier);
 }
 
-/*!
-* \brief This sequence is used to disable given DMA channel tx interrupts
-* \param[in] qInx
-*/
-static void disable_tx_interrupt(uint32_t qInx)
+/*Disable given DMA channel tx interrupts */
+static void disable_tx_interrupt(uint32_t qInx, hw_config_t *hw_cfg)
 {
    /* Disable and clear Tx interrupts */
 #ifdef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-   DWC_REG_WR_BIT(DMA_IER(qInx), DMA_IER_TIE, 0x0);
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_TIE, 0x0);
+#else
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_TBUE, 0x0)
+#endif
+   DWC_REG_WR(DMA_IER(qInx), hw_cfg->dma_ier);
    DWC_REG_WR_BIT(DMA_SR(qInx), DMA_SR_TI, 0x1);
-#else
-   DWC_REG_WR_BIT(DMA_IER(qInx), DMA_IER_TBUE, 0x0);
    DWC_REG_WR_BIT(DMA_SR(qInx), DMA_SR_TBU, 0x1);
-#endif
 }
 
-/*!
-* \brief This sequence is used to enable given DMA channel tx interrupts
-* \param[in] qInx
-*/
-static void enable_tx_interrupt(uint32_t qInx)
+/* Enable given DMA channel tx interrupts */
+static void enable_tx_interrupt(uint32_t qInx, hw_config_t *hw_cfg)
 {
 #ifdef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-   DWC_REG_WR_BIT(DMA_IER(qInx), DMA_IER_TIE, 0x1);
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_TIE, 0x1);
 #else
-   DWC_REG_WR_BIT(DMA_IER(qInx), DMA_IER_TBUE, 0x1);
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_TBUE, 0x1)
 #endif
+   DWC_REG_WR(DMA_IER(qInx), hw_cfg->dma_ier);
 }
 
 static void configure_sa_via_reg(uint32_t cmd)
@@ -1828,7 +1678,6 @@ static int stop_dma_rx(uint32_t qInx)
    return ret;
 }
 
-
 /*!
 * \param[in] qInx
 * \return Success or Failure
@@ -1940,43 +1789,43 @@ static int start_mac_tx_rx(void)
    return Y_SUCCESS;
 }
 
-
 /*!
 * \brief This sequence is used to enable DMA interrupts
 * \return Success or Failure
 * \retval  0 Success
 * \retval -1 Failure
 */
-static int enable_dma_interrupts(uint32_t qInx, uint32_t version)
+static int enable_dma_interrupts(uint32_t qInx, uint32_t version,
+                                 hw_config_t *hw_cfg)
 {
    uint32_t varDMA_SR;
-   uint32_t varDMA_IER;
    /* Clear any current set interrupt */
    varDMA_SR = DWC_REG_RD(DMA_SR(qInx));
    DWC_REG_WR(DMA_SR(qInx), varDMA_SR);
-   /* Read current interrupt enable status register */
-   varDMA_IER = DWC_REG_RD(DMA_IER(qInx));
-   /* Reset all interrupts except CDEE and RWTE */
-   varDMA_IER &= ((1 << DMA_IER_CDEE_OFF) | (1 << DMA_IER_RWTE_OFF));
    /* Enable required DMA interrupts */
-   VAR32_SET_BIT(varDMA_IER, DMA_IER_TXSE, 0x1); /* Transmit Stoppped */
-   VAR32_SET_BIT(varDMA_IER, DMA_IER_RIE, 0x1);  /* Receive Interrupt */
-   VAR32_SET_BIT(varDMA_IER, DMA_IER_RBUE, 0x1); /* Receive Buffer Unavailable */
-   VAR32_SET_BIT(varDMA_IER, DMA_IER_RSE, 0x1);  /* Receive Stoppped */
-   VAR32_SET_BIT(varDMA_IER, DMA_IER_FBEE, 0x1); /* Fatal Bus Error */
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_RIE, 0x1);  /* Receive Interrupt */
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_RBUE, 0x1); /* Receive Buffer Unavailable */
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_FBEE, 0x1); /* Fatal Bus Error */
+
+#if 0
+   // THESE ARE NOT NEEDED
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_TSE, 0x1);  /* Transmit Stoppped */
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_RSE, 0x1);  /* Receive Stoppped */
+#endif
+
    if (version == MAC_VER_4_00) {
-      VAR32_SET_BIT(varDMA_IER, DMA_IER_AIE_4_00, 0x1);  /* Abnormal Interrupt Summary */
-      VAR32_SET_BIT(varDMA_IER, DMA_IER_NIE_4_00, 0x1);  /* Normal Interrupt Summary */
+      VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_AIE_4_00, 0x1);  /* Abnormal Interrupt Summary */
+      VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_NIE_4_00, 0x1);  /* Normal Interrupt Summary */
    } else {
-      VAR32_SET_BIT(varDMA_IER, DMA_IER_AIE_4_10, 0x1);  /* Abnormal Interrupt Summary */
-      VAR32_SET_BIT(varDMA_IER, DMA_IER_NIE_4_10, 0x1);  /* Normal Interrupt Summary */
+      VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_AIE_4_10, 0x1);  /* Abnormal Interrupt Summary */
+      VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_NIE_4_10, 0x1);  /* Normal Interrupt Summary */
    }
 #ifdef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-   VAR32_SET_BIT(varDMA_IER, DMA_IER_TIE, 0x1); /* Transmit Interrupt */
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_TIE, 0x1); /* Transmit Interrupt */
 #else
-   VAR32_SET_BIT(varDMA_IER, DMA_IER_TBUE, 0x1); /* Transmit Buffer Unavailable */
+   VAR32_SET_BIT(hw_cfg->dma_ier, DMA_IER_TBUE, 0x1); /* Transmit Buffer Unavailable */
 #endif
-   DWC_REG_WR(DMA_IER(qInx), varDMA_IER);
+   DWC_REG_WR(DMA_IER(qInx), hw_cfg->dma_ier);
 
    return Y_SUCCESS;
 }
@@ -2883,30 +2732,22 @@ static int get_tx_descriptor_last(tx_des
    return VAR32_GET_BIT(txdesc->TDES3, NORMAL_WB_TDES3_LD);
 }
 
-/*!
-* \brief Exit routine
-* \details Exit function that unregisters the device, deallocates buffers,
-* unbinds the driver from controlling the device etc.
-*
-* \return Returns successful execution of the routine
-* \retval Y_SUCCESS Function executed successfully
-*/
-static int DWC_ETH_QOS_yexit(void)
+/* Sotware reset */
+static int DWC_ETH_QOS_sw_reset(void)
 {
    uint32_t retryCount = 1000;
-   DBGPR("-->DWC_ETH_QOS_yexit\n");
+   DBGPR("-->DWC_ETH_QOS_sw_reset\n");
    /* Issue a software reset */
    DWC_REG_WR_BIT(DMA_BMR, DMA_BMR_SWR, 0x1);
    udelay(10);
    /* Wait for software reset */
    while(DWC_REG_RD_BIT(DMA_BMR, DMA_BMR_SWR) && --retryCount)
       mdelay(1);
-   DBGPR("<--DWC_ETH_QOS_yexit\n");
+   DBGPR("<--DWC_ETH_QOS_sw_reset\n");
 
    return Y_SUCCESS;
 }
 
-
 /*!
 * \details This API will calculate per queue FIFO size.
 *
@@ -3099,7 +2940,6 @@ static int configure_mtl_queue(uint32_t 
    return Y_SUCCESS;
 }
 
-
 static int configure_dma_channel(uint32_t qInx,
          struct DWC_ETH_QOS_prv_data *pdata)
 {
@@ -3131,7 +2971,7 @@ static int configure_dma_channel(uint32_
    CFG_PRINT("%s Rx watchdog timer\n",
       (rx_desc_data->use_riwt ? "Enabled" : "Disabled"));
 
-   enable_dma_interrupts(qInx, pdata->version);
+   enable_dma_interrupts(qInx, pdata->version, &pdata->hw_cfg);
    /* set PBLx8 */
    DWC_REG_WR_BIT(DMA_CR(qInx), DMA_CR_PBLx8, 0x1);
    /* set TX PBL = 256 */
@@ -3155,13 +2995,8 @@ static int configure_dma_channel(uint32_
    CFG_PRINT("%s Rx Split header mode\n",
       (pdata->rx_split_hdr ? "Enabled" : "Disabled"));
 
-   /*
-    * For PG don't start TX DMA now.
-    */
-#ifndef DWC_ETH_QOS_CONFIG_PGTEST
    /* start TX DMA */
    DWC_REG_WR_BIT(DMA_TCR(qInx), DMA_TCR_ST, 0x1);
-#endif
    /* start RX DMA */
    DWC_REG_WR_BIT(DMA_RCR(qInx), DMA_RCR_SR, 0x1);
 
@@ -3176,23 +3011,20 @@ static int configure_dma_channel(uint32_
 * \retval  0 Success
 * \retval -1 Failure
 */
-static int enable_mac_interrupts(void)
+static int enable_mac_interrupts(hw_config_t *hw_cfg)
 {
-   uint32_t varmac_ier = DWC_REG_RD(MAC_IER);
-   /* Enable following interrupts */
-   /* RGSMIIIM - RGMII/SMII interrupt Enable */
-   /* PCSLCHGIM -  PCS Link Status Interrupt Enable */
-   /* PCSANCIM - PCS AN Completion Interrupt Enable */
-   /* PMTIM - PMT Interrupt Enable */
-   /* LPIIM - LPI Interrupt Enable */
-   varmac_ier &= 0x1008;
-   VAR32_SET_BIT(varmac_ier, MAC_IER_RGMIIIE, 0x1);
-   VAR32_SET_BIT(varmac_ier, MAC_IER_PCSLCHGIE, 0x1);
-   VAR32_SET_BIT(varmac_ier, MAC_IER_PCSANCIE, 0x1);
-   VAR32_SET_BIT(varmac_ier, MAC_IER_PMTIE, 0x1);
-   VAR32_SET_BIT(varmac_ier, MAC_IER_LPIIE, 0x1);
-   DWC_REG_WR(MAC_IER, varmac_ier);
-   CFG_PRINT("[%s] MAC_IER = 0x%08x\n", __FUNCTION__, varmac_ier);
+   /* RGMII/SMII interrupt */
+   VAR32_SET_BIT(hw_cfg->mac_ier, MAC_IER_RGMIIIE, 0x1);
+   /* PCS Link Status Interrupt */
+   VAR32_SET_BIT(hw_cfg->mac_ier, MAC_IER_PCSLCHGIE, 0x1);
+   /* PCS AN Completion Interrupt */
+   VAR32_SET_BIT(hw_cfg->mac_ier, MAC_IER_PCSANCIE, 0x1);
+
+   /* LPIIM - LPI Interrupt Enable - THIS IS ONLY REQUIRED FOR EEE */
+   VAR32_SET_BIT(hw_cfg->mac_ier, MAC_IER_LPIIE, 0x1);
+
+   DWC_REG_WR(MAC_IER, hw_cfg->mac_ier);
+   CFG_PRINT("[%s] MAC_IER = 0x%08x\n", __FUNCTION__, hw_cfg->mac_ier);
    return Y_SUCCESS;
 }
 
@@ -3290,7 +3122,7 @@ static int configure_mac(struct DWC_ETH_
       config_mmc_counters();
    }
 
-   enable_mac_interrupts();
+   enable_mac_interrupts(&pdata->hw_cfg);
 
    DBGPR("<--configure_mac\n");
 
@@ -3343,103 +3175,6 @@ static int DWC_ETH_QOS_yinit(struct DWC_
    return Y_SUCCESS;
 }
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-
-/*!
-* \brief This sequence is used to initialize the tx descriptors.
-* \param[in] pdata
-*/
-
-static void tx_descriptor_init_pg(struct DWC_ETH_QOS_prv_data *pdata,
-               uint32_t qInx)
-{
-   struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data =
-      GET_TX_WRAPPER_DESC(qInx);
-   tx_descriptor_t *TX_NORMAL_DESC =
-      GET_TX_DESC_PTR(qInx, tx_desc_data->cur_tx);
-   struct DWC_ETH_QOS_tx_buffer *buffer =
-      GET_TX_BUF_PTR(qInx, tx_desc_data->cur_tx);
-   int i;
-   int start_index = tx_desc_data->cur_tx;
-
-   DBGPR("-->tx_descriptor_init_pg\n");
-
-   /* initialze all descriptors. */
-
-   for (i = 0; i < TX_DESC_CNT; i++) {
-      /* update buffer 1 address pointer to zero */
-      TX_NORMAL_DESC->TDES0 = 0;
-      /* update buffer 2 address pointer to zero */
-      TX_NORMAL_DESC->TDES1 = 0;
-      /* set all other control bits (IC, TTSE, B2L & B1L) to zero */
-      TX_NORMAL_DESC->TDES2 = 0;
-      /* set all other control bits (OWN, CTXT, FD, LD, CPC, CIC etc) to zero */
-      TX_NORMAL_DESC->TDES3 = 0;
-
-      INCR_TX_DESC_INDEX(tx_desc_data->cur_tx, 1);
-      TX_NORMAL_DESC = GET_TX_DESC_PTR(qInx, tx_desc_data->cur_tx);
-      buffer = GET_TX_BUF_PTR(qInx, tx_desc_data->cur_tx);
-   }
-   /* update the total no of Tx descriptors count */
-   DWC_REG_WR(DMA_TDRLR(qInx), (TX_DESC_CNT - 1));
-   /* update the starting address of desc chain/ring */
-   DWC_REG_WR(DMA_TDLAR(qInx), GET_TX_DESC_DMA_ADDR(qInx, start_index));
-
-   DBGPR("<--tx_descriptor_init_pg\n");
-}
-
-/*!
-* \brief This sequence is used to initialize the rx descriptors.
-* \param[in] pdata
-*/
-
-static void rx_descriptor_init_pg(struct DWC_ETH_QOS_prv_data *pdata, uint32_t qInx)
-{
-   struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data =
-       GET_RX_WRAPPER_DESC(qInx);
-   struct DWC_ETH_QOS_rx_buffer *buffer =
-       GET_RX_BUF_PTR(qInx, rx_desc_data->cur_rx);
-   rx_descriptor_t *RX_NORMAL_DESC =
-       GET_RX_DESC_PTR(qInx, rx_desc_data->cur_rx);
-   int i;
-   int start_index = rx_desc_data->cur_rx;
-   int last_index;
-
-   DBGPR("-->rx_descriptor_init_pg\n");
-
-   /* initialize all desc */
-
-   for (i = 0; i < RX_DESC_CNT; i++) {
-      memset(RX_NORMAL_DESC, 0, sizeof(rx_descriptor_t));
-      /* update buffer 1 address pointer */
-      RX_NORMAL_DESC->RDES0 = buffer->dma;
-      /* set to zero  */
-      RX_NORMAL_DESC->RDES1 = 0;
-
-      /* set buffer 2 address pointer to zero */
-      RX_NORMAL_DESC->RDES2 = 0;
-      /* set control bits - OWN, INTE and BUF1V */
-      RX_NORMAL_DESC->RDES3 = 0xc1000000;
-
-      INCR_RX_DESC_INDEX(rx_desc_data->cur_rx, 1);
-      RX_NORMAL_DESC =
-         GET_RX_DESC_PTR(qInx, rx_desc_data->cur_rx);
-      buffer = GET_RX_BUF_PTR(qInx, rx_desc_data->cur_rx);
-   }
-   /* update the total no of Rx descriptors count */
-   DWC_REG_WR_FIELD(DMA_RDRLR(qInx), DMA_RDRLR_RDRL, (RX_DESC_CNT - 1));
-   /* update the Rx Descriptor Tail Pointer */
-   last_index = GET_CURRENT_RCVD_LAST_DESC_INDEX(start_index, 0);
-   DWC_REG_WR(DMA_RDTPR(qInx), GET_RX_DESC_DMA_ADDR(qInx, last_index));
-   /* update the starting address of desc chain/ring */
-   DWC_REG_WR(DMA_RDLAR(qInx), GET_RX_DESC_DMA_ADDR(qInx, start_index));
-
-   DBGPR("<--rx_descriptor_init_pg\n");
-}
-
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
-
 /*!
 * \brief API to initialize the function pointers.
 *
@@ -3452,7 +3187,7 @@ static void rx_descriptor_init_pg(struct
 * \return void.
 */
 
-void DWC_ETH_QOS_init_function_ptrs_dev(struct hw_if_struct *hw_if)
+void DWC_ETH_QOS_init_function_ptrs_dev(hw_interface_t *hw_if)
 {
 
    DBGPR("-->DWC_ETH_QOS_init_function_ptrs_dev\n");
@@ -3492,7 +3227,7 @@ void DWC_ETH_QOS_init_function_ptrs_dev(
    hw_if->pre_xmit = pre_transmit;
    hw_if->dev_read = device_read;
    hw_if->init = DWC_ETH_QOS_yinit;
-   hw_if->exit = DWC_ETH_QOS_yexit;
+   hw_if->sw_reset = DWC_ETH_QOS_sw_reset;
    /* Descriptor related Sequences have to be initialized here */
    hw_if->tx_desc_init = tx_descriptor_init;
    hw_if->rx_desc_init = rx_descriptor_init;
@@ -3515,11 +3250,9 @@ void DWC_ETH_QOS_init_function_ptrs_dev(
    hw_if->disable_remote_pmt = disable_remote_pmt_operation;
    hw_if->configure_rwk_filter = configure_rwk_filter_registers;
 
-    /* for TX vlan control */
-    hw_if->enable_vlan_reg_control = configure_reg_vlan_control;
-    hw_if->enable_vlan_desc_control = configure_desc_vlan_control;
-
-
+   /* for TX vlan control */
+   hw_if->enable_vlan_reg_control = configure_reg_vlan_control;
+   hw_if->enable_vlan_desc_control = configure_desc_vlan_control;
 
    /* for rx vlan stripping */
    hw_if->config_rx_outer_vlan_stripping =
@@ -3586,18 +3319,6 @@ void DWC_ETH_QOS_init_function_ptrs_dev(
    hw_if->config_low_credit = config_low_credit;
    hw_if->config_slot_num_check = config_slot_num_check;
    hw_if->config_advance_slot_num_check = config_advance_slot_num_check;
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-   hw_if->tx_desc_init_pg = tx_descriptor_init_pg;
-   hw_if->rx_desc_init_pg = rx_descriptor_init_pg;
-   hw_if->set_ch_arb_weights = set_ch_arb_weights;
-   hw_if->config_slot_interrupt = config_slot_interrupt;
-   hw_if->set_slot_count = set_slot_count;
-   hw_if->set_tx_rx_prio_policy = set_tx_rx_prio_policy;
-   hw_if->set_tx_rx_prio = set_tx_rx_prio;
-   hw_if->set_tx_rx_prio_ratio = set_tx_rx_prio_ratio;
-   hw_if->set_dma_tx_arb_algorithm = set_dma_tx_arb_algorithm;
-   hw_if->prepare_dev_pktgen = prepare_dev_pktgen;
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
 
    /* for hw time stamping */
    hw_if->config_hw_time_stamping = config_hw_time_stamping;
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_drv.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_drv.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_drv.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_drv.c
@@ -39,6 +39,10 @@
 #include "DWC_ETH_QOS_drv.h"
 #include "DWC_ETH_QOS_yregacc.h"
 
+/* Priority constants for NAPI scheduling */
+#define HI_PRIORITY_INT  0x1
+#define LO_PRIORITY_INT  0x2
+
 /* SA(Source Address) operations on TX */
 unsigned char mac_addr0[6] = { 0x00, 0x11, 0x22, 0x33, 0x44, 0x55 };
 unsigned char mac_addr1[6] = { 0x00, 0x66, 0x77, 0x88, 0x99, 0xaa };
@@ -47,28 +51,62 @@ unsigned char mac_addr1[6] = { 0x00, 0x6
  * set default mode as GENERIC
  * */
 static int q_op_mode[DWC_ETH_QOS_MAX_TX_QUEUE_CNT] = {
-	DWC_ETH_QOS_Q_GENERIC,
-	DWC_ETH_QOS_Q_GENERIC,
-	DWC_ETH_QOS_Q_GENERIC,
-	DWC_ETH_QOS_Q_GENERIC,
-	DWC_ETH_QOS_Q_GENERIC,
-	DWC_ETH_QOS_Q_GENERIC,
-	DWC_ETH_QOS_Q_GENERIC,
-	DWC_ETH_QOS_Q_GENERIC
+   DWC_ETH_QOS_Q_GENERIC,
+   DWC_ETH_QOS_Q_GENERIC,
+   DWC_ETH_QOS_Q_GENERIC,
+   DWC_ETH_QOS_Q_GENERIC,
+   DWC_ETH_QOS_Q_GENERIC,
+   DWC_ETH_QOS_Q_GENERIC,
+   DWC_ETH_QOS_Q_GENERIC,
+   DWC_ETH_QOS_Q_GENERIC
 };
 module_param_array(q_op_mode, int, NULL, S_IRUGO | S_IWUSR);
 MODULE_PARM_DESC(q_op_mode,
-	"MTL queue operation mode [0-DISABLED, 1-AVB, 2-DCB, 3-GENERIC]");
+   "MTL queue operation mode [0-DISABLED, 1-AVB, 2-DCB, 3-GENERIC]");
 
 #ifdef GBE_DEBUG
 
+#define __dwc_dump_skb(skb) \
+do { \
+	pr_err("skb %p: skb->sk=%p, skb->dev=%s, skb_dst(skb)->dev=%s," \
+		 " skb->len=%d, skb->hdr_len=%d, skb->skb_iif=%d, skb->queue_mapping=%d," \
+		 " skb_mac_header(skb)=%p, skb_network_header(skb)=%p," \
+		 " skb_transport_header(skb)=%p, skb->head=%p, skb->data=%p, skb->tail=%p," \
+		 " skb->end=%p\n", \
+		skb, skb->sk,	\
+		skb->dev ? skb->dev->name : "NULL", \
+		skb_dst(skb) ? (skb_dst(skb)->dev ? skb_dst(skb)->dev->name : "NA") : "NA", \
+		skb->len, skb->hdr_len, skb->skb_iif, skb->queue_mapping, \
+		skb_mac_header(skb), skb_network_header(skb), \
+		skb_transport_header(skb), skb->head, skb->data, skb->tail, \
+		skb->end); \
+	pr_err("eth header: src=%pM, dst=%pM, proto=%d\n", \
+		eth_hdr(skb)->h_source, eth_hdr(skb)->h_dest, eth_hdr(skb)->h_proto); \
+	if (ip_hdr(skb) && ip_hdr(skb)->version == 4) { \
+		pr_err("ip header: src=%pI4, dst=%pI4, protocol=%d (%s)\n", \
+			&ip_hdr(skb)->saddr, &ip_hdr(skb)->daddr, ip_hdr(skb)->protocol, \
+			ip_hdr(skb)->protocol == IPPROTO_TCP ? "tcp" : \
+			(ip_hdr(skb)->protocol == IPPROTO_UDP ? "udp" : "")); \
+	} else if (ip_hdr(skb) && ip_hdr(skb)->version == 6) { \
+		pr_err("ip header: src=%pI6, dst=%pI6, nexthdr=%d (%s)\n", \
+			&ipv6_hdr(skb)->saddr, &ipv6_hdr(skb)->daddr, ipv6_hdr(skb)->nexthdr, \
+			ipv6_hdr(skb)->nexthdr == IPPROTO_TCP ? "tcp" : \
+			(ipv6_hdr(skb)->nexthdr == IPPROTO_UDP ? "udp" : "")); \
+	} else { \
+		pr_err("not an IP packet\n"); \
+	} \
+} while (0);
+
 extern bool print_tx_pkts;
 extern bool print_rx_pkts;
 
 #define PRINT_SKB_INFO(MSG, PARAM, SKB) \
-   printk(KERN_INFO MSG "Data[0x%08x] Tail[0x%08x] End[0x%08x]\n", \
-          PARAM, (uint32_t)(SKB)->data, \
-          (uint32_t)(SKB)->tail, (uint32_t)(SKB)->end)
+do { \
+   printk(KERN_INFO MSG "Data[0x%08x] Tail[0x%08x] End[0x%08x]\n",\
+             PARAM, (uint32_t)(SKB)->data, \
+             (uint32_t)(SKB)->tail, (uint32_t)(SKB)->end);\
+   __dwc_dump_skb(skb); \
+} while (0);
 
 static inline void print_skb(struct sk_buff *skb, bool isRx)
 {
@@ -89,7 +127,7 @@ static inline void print_skb(struct sk_b
    printk(KERN_ALERT "TYPE[%04x] LENGTH[%d]\n",
           (buffer[12] << 8 | buffer[13]) & 0xFFFF, length);
    printk("------------------------------------------------------\n");
-   for (i=0; i < length && i < 1600; i++)	{
+   for (i=0; i < length && i < 1600; i++)   {
       if ((i % 16) == 0) {
          printk("%06x ", i);
       }
@@ -128,56 +166,145 @@ static inline int replace_crc(struct sk_
 
 void DWC_ETH_QOS_stop_all_ch_tx_dma(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t qInx;
-	DBGPR("-->DWC_ETH_QOS_stop_all_ch_tx_dma\n");
-	for(qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++)
-		hw_if->stop_dma_tx(qInx);
-	DBGPR("<--DWC_ETH_QOS_stop_all_ch_tx_dma\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t qInx;
+   DBGPR("-->DWC_ETH_QOS_stop_all_ch_tx_dma\n");
+   for(qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++)
+      hw_if->stop_dma_tx(qInx);
+   DBGPR("<--DWC_ETH_QOS_stop_all_ch_tx_dma\n");
 }
 
 static void DWC_ETH_QOS_stop_all_ch_rx_dma(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t qInx;
-	DBGPR("-->DWC_ETH_QOS_stop_all_ch_rx_dma\n");
-	for(qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
-		hw_if->stop_dma_rx(qInx);
-	DBGPR("<--DWC_ETH_QOS_stop_all_ch_rx_dma\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t qInx;
+   DBGPR("-->DWC_ETH_QOS_stop_all_ch_rx_dma\n");
+   for(qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
+      hw_if->stop_dma_rx(qInx);
+   DBGPR("<--DWC_ETH_QOS_stop_all_ch_rx_dma\n");
 }
 
 static void DWC_ETH_QOS_start_all_ch_tx_dma(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t i;
-	DBGPR("-->DWC_ETH_QOS_start_all_ch_tx_dma\n");
-	for(i = 0; i < DWC_ETH_QOS_TX_QUEUE_CNT; i++)
-		hw_if->start_dma_tx(i);
-	DBGPR("<--DWC_ETH_QOS_start_all_ch_tx_dma\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t i;
+   DBGPR("-->DWC_ETH_QOS_start_all_ch_tx_dma\n");
+   for(i = 0; i < DWC_ETH_QOS_TX_QUEUE_CNT; i++)
+      hw_if->start_dma_tx(i);
+   DBGPR("<--DWC_ETH_QOS_start_all_ch_tx_dma\n");
 }
 
 static void DWC_ETH_QOS_start_all_ch_rx_dma(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t i;
-	DBGPR("-->DWC_ETH_QOS_start_all_ch_rx_dma\n");
-	for(i = 0; i < DWC_ETH_QOS_RX_QUEUE_CNT; i++)
-		hw_if->start_dma_rx(i);
-	DBGPR("<--DWC_ETH_QOS_start_all_ch_rx_dma\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t i;
+   DBGPR("-->DWC_ETH_QOS_start_all_ch_rx_dma\n");
+   for(i = 0; i < DWC_ETH_QOS_RX_QUEUE_CNT; i++)
+      hw_if->start_dma_rx(i);
+   DBGPR("<--DWC_ETH_QOS_start_all_ch_rx_dma\n");
 }
 
 static void DWC_ETH_QOS_napi_enable(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	DBGPR("-->DWC_ETH_QOS_napi_enable\n");
-	napi_enable(&pdata->rx_napi);
-	DBGPR("<--DWC_ETH_QOS_napi_enable\n");
+   DBGPR("-->DWC_ETH_QOS_napi_enable\n");
+   napi_enable(&pdata->rx_napi);
+   DBGPR("<--DWC_ETH_QOS_napi_enable\n");
 }
 
 static void DWC_ETH_QOS_napi_disable(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	DBGPR("-->DWC_ETH_QOS_napi_disable\n");
-	napi_disable(&pdata->rx_napi);
-	DBGPR("<--DWC_ETH_QOS_napi_disable\n");
+   DBGPR("-->DWC_ETH_QOS_napi_disable\n");
+   napi_disable(&pdata->rx_napi);
+   DBGPR("<--DWC_ETH_QOS_napi_disable\n");
+}
+
+#ifdef YDEBUG
+
+static void DWC_ETH_QOS_tx_desc_mang_ds_dump(struct DWC_ETH_QOS_prv_data *pdata)
+{
+   struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data = NULL;
+   tx_descriptor_t *tx_desc = NULL;
+   int qInx, i;
+
+   printk(KERN_ALERT "/**** TX DESC MANAGEMENT DATA STRUCTURE DUMP ****/\n");
+
+   printk(KERN_ALERT "TX_DESC_QUEUE_CNT = %d\n", DWC_ETH_QOS_TX_QUEUE_CNT);
+   for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
+      tx_desc_data = GET_TX_WRAPPER_DESC(qInx);
+      printk(KERN_ALERT "DMA CHANNEL = %d\n", qInx);
+      printk(KERN_ALERT "\tcur_tx           = %d\n", tx_desc_data->cur_tx);
+      printk(KERN_ALERT "\tdirty_tx         = %d\n", tx_desc_data->dirty_tx);
+      printk(KERN_ALERT "\tfree_desc_cnt    = %d\n", tx_desc_data->free_desc_cnt);
+      printk(KERN_ALERT "\ttx_pkt_queued    = %d\n", tx_desc_data->tx_pkt_queued);
+      printk(KERN_ALERT "\tqueue_stopped    = %d\n", tx_desc_data->queue_stopped);
+      printk(KERN_ALERT "\tpacket_count     = %d\n", tx_desc_data->packet_count);
+      printk(KERN_ALERT "\ttx_threshold_val = %d\n", tx_desc_data->tx_threshold_val);
+      printk(KERN_ALERT "\ttsf_on           = %d\n", tx_desc_data->tsf_on);
+      printk(KERN_ALERT "\tosf_on           = %d\n", tx_desc_data->osf_on);
+      printk(KERN_ALERT "\ttx_pbl           = %d\n", tx_desc_data->tx_pbl);
+
+      printk(KERN_ALERT "\t[<desc_add> <index >] = <TDES0> : <TDES1> : <TDES2> : <TDES3>\n");
+      for (i = 0; i < TX_DESC_CNT; i++) {
+         tx_desc = GET_TX_DESC_PTR(qInx, i);
+         printk(KERN_ALERT "\t[%4p %03d] = %#x : %#x : %#x : %#x\n",
+            tx_desc, i, tx_desc->TDES0, tx_desc->TDES1,
+            tx_desc->TDES2, tx_desc->TDES3);
+      }
+   }
+
+   printk(KERN_ALERT "/************************************************/\n");
+}
+
+static void DWC_ETH_QOS_rx_desc_mang_ds_dump(struct DWC_ETH_QOS_prv_data *pdata)
+{
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data = NULL;
+   rx_descriptor_t *rx_desc = NULL;
+   int qInx, i;
+
+   printk(KERN_ALERT "/**** RX DESC MANAGEMENT DATA STRUCTURE DUMP ****/\n");
+   printk(KERN_ALERT "RX_DESC_QUEUE_CNT = %d\n", DWC_ETH_QOS_RX_QUEUE_CNT);
+
+   for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
+      rx_desc_data = GET_RX_WRAPPER_DESC(qInx);
+      printk(KERN_ALERT "DMA CHANNEL = %d\n", qInx);
+      printk(KERN_ALERT "\tcur_rx                = %d\n", rx_desc_data->cur_rx);
+      printk(KERN_ALERT "\tdirty_rx              = %d\n", rx_desc_data->dirty_rx);
+      printk(KERN_ALERT "\tpkt_received          = %d\n", rx_desc_data->pkt_received);
+      printk(KERN_ALERT "\tskb_realloc_idx       = %d\n", rx_desc_data->skb_realloc_idx);
+      printk(KERN_ALERT "\tskb_realloc_threshold = %d\n", rx_desc_data->skb_realloc_threshold);
+      printk(KERN_ALERT "\tuse_riwt              = %d\n", rx_desc_data->use_riwt);
+      printk(KERN_ALERT "\trx_riwt               = %d\n", rx_desc_data->rx_riwt);
+      printk(KERN_ALERT "\trx_coal_frames        = %d\n", rx_desc_data->rx_coal_frames);
+      printk(KERN_ALERT "\trx_threshold_val      = %d\n", rx_desc_data->rx_threshold_val);
+      printk(KERN_ALERT "\trsf_on                = %d\n", rx_desc_data->rsf_on);
+      printk(KERN_ALERT "\trx_pbl                = %d\n", rx_desc_data->rx_pbl);
+
+      printk(KERN_ALERT "\t[<desc_add> <index >] = <RDES0> : <RDES1> : <RDES2> : <RDES3>\n");
+      for (i = 0; i < RX_DESC_CNT; i++) {
+         rx_desc = GET_RX_DESC_PTR(qInx, i);
+         printk(KERN_ALERT "\t[%4p %03d] = %#x : %#x : %#x : %#x\n",
+            rx_desc, i, rx_desc->RDES0, rx_desc->RDES1,
+            rx_desc->RDES2, rx_desc->RDES3);
+      }
+   }
+
+   printk(KERN_ALERT "/************************************************/\n");
+}
+
+#endif
+
+static void DWC_ETH_QOS_restart_phy(struct DWC_ETH_QOS_prv_data *pdata)
+{
+   DBGPR("-->DWC_ETH_QOS_restart_phy\n");
+
+   pdata->oldlink = 0;
+   pdata->speed = 0;
+   pdata->oldduplex = -1;
+
+   if (pdata->phydev)
+      phy_start_aneg(pdata->phydev);
+
+   DBGPR("<--DWC_ETH_QOS_restart_phy\n");
 }
 
 /*!
@@ -190,121 +317,45 @@ static void DWC_ETH_QOS_napi_disable(str
  *
  * \param[in] pdata  pointer to private data structure.
  *
- * \return void
+ * \return controller power status (gbe_power_state_t)
  */
-
-static void DWC_ETH_QOS_stop_dev(struct DWC_ETH_QOS_prv_data *pdata)
+static gbe_power_state_t DWC_ETH_QOS_stop_dev(
+   struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct desc_if_struct *desc_if = &(pdata->desc_if);
-
-	DBGPR("-->DWC_ETH_QOS_stop_dev\n");
-
-	netif_tx_disable(pdata->dev);
-
-	DWC_ETH_QOS_napi_disable(pdata);
-
-	/* stop DMA TX/RX */
-	DWC_ETH_QOS_stop_all_ch_tx_dma(pdata);
-	DWC_ETH_QOS_stop_all_ch_rx_dma(pdata);
-
-	/* issue software reset to device */
-	hw_if->exit();
-
-	/* free tx skb's */
-	desc_if->tx_skb_free_mem(pdata, DWC_ETH_QOS_TX_QUEUE_CNT);
-	/* free rx skb's */
-	desc_if->rx_skb_free_mem(pdata, DWC_ETH_QOS_RX_QUEUE_CNT);
-
-	DBGPR("<--DWC_ETH_QOS_stop_dev\n");
-}
-
-#ifdef YDEBUG
-static void DWC_ETH_QOS_tx_desc_mang_ds_dump(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data = NULL;
-	tx_descriptor_t *tx_desc = NULL;
-	int qInx, i;
-
-	printk(KERN_ALERT "/**** TX DESC MANAGEMENT DATA STRUCTURE DUMP ****/\n");
-
-	printk(KERN_ALERT "TX_DESC_QUEUE_CNT = %d\n", DWC_ETH_QOS_TX_QUEUE_CNT);
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		tx_desc_data = GET_TX_WRAPPER_DESC(qInx);
-		printk(KERN_ALERT "DMA CHANNEL = %d\n", qInx);
-		printk(KERN_ALERT "\tcur_tx           = %d\n", tx_desc_data->cur_tx);
-		printk(KERN_ALERT "\tdirty_tx         = %d\n", tx_desc_data->dirty_tx);
-		printk(KERN_ALERT "\tfree_desc_cnt    = %d\n", tx_desc_data->free_desc_cnt);
-		printk(KERN_ALERT "\ttx_pkt_queued    = %d\n", tx_desc_data->tx_pkt_queued);
-		printk(KERN_ALERT "\tqueue_stopped    = %d\n", tx_desc_data->queue_stopped);
-		printk(KERN_ALERT "\tpacket_count     = %d\n", tx_desc_data->packet_count);
-		printk(KERN_ALERT "\ttx_threshold_val = %d\n", tx_desc_data->tx_threshold_val);
-		printk(KERN_ALERT "\ttsf_on           = %d\n", tx_desc_data->tsf_on);
-		printk(KERN_ALERT "\tosf_on           = %d\n", tx_desc_data->osf_on);
-		printk(KERN_ALERT "\ttx_pbl           = %d\n", tx_desc_data->tx_pbl);
-
-		printk(KERN_ALERT "\t[<desc_add> <index >] = <TDES0> : <TDES1> : <TDES2> : <TDES3>\n");
-		for (i = 0; i < TX_DESC_CNT; i++) {
-			tx_desc = GET_TX_DESC_PTR(qInx, i);
-			printk(KERN_ALERT "\t[%4p %03d] = %#x : %#x : %#x : %#x\n",
-				tx_desc, i, tx_desc->TDES0, tx_desc->TDES1,
-				tx_desc->TDES2, tx_desc->TDES3);
-		}
-	}
-
-	printk(KERN_ALERT "/************************************************/\n");
-}
-
-
-static void DWC_ETH_QOS_rx_desc_mang_ds_dump(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data = NULL;
-	rx_descriptor_t *rx_desc = NULL;
-	int qInx, i;
-
-	printk(KERN_ALERT "/**** RX DESC MANAGEMENT DATA STRUCTURE DUMP ****/\n");
-	printk(KERN_ALERT "RX_DESC_QUEUE_CNT = %d\n", DWC_ETH_QOS_RX_QUEUE_CNT);
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
-		rx_desc_data = GET_RX_WRAPPER_DESC(qInx);
-		printk(KERN_ALERT "DMA CHANNEL = %d\n", qInx);
-		printk(KERN_ALERT "\tcur_rx                = %d\n", rx_desc_data->cur_rx);
-		printk(KERN_ALERT "\tdirty_rx              = %d\n", rx_desc_data->dirty_rx);
-		printk(KERN_ALERT "\tpkt_received          = %d\n", rx_desc_data->pkt_received);
-		printk(KERN_ALERT "\tskb_realloc_idx       = %d\n", rx_desc_data->skb_realloc_idx);
-		printk(KERN_ALERT "\tskb_realloc_threshold = %d\n", rx_desc_data->skb_realloc_threshold);
-		printk(KERN_ALERT "\tuse_riwt              = %d\n", rx_desc_data->use_riwt);
-		printk(KERN_ALERT "\trx_riwt               = %d\n", rx_desc_data->rx_riwt);
-		printk(KERN_ALERT "\trx_coal_frames        = %d\n", rx_desc_data->rx_coal_frames);
-		printk(KERN_ALERT "\trx_threshold_val      = %d\n", rx_desc_data->rx_threshold_val);
-		printk(KERN_ALERT "\trsf_on                = %d\n", rx_desc_data->rsf_on);
-		printk(KERN_ALERT "\trx_pbl                = %d\n", rx_desc_data->rx_pbl);
-
-		printk(KERN_ALERT "\t[<desc_add> <index >] = <RDES0> : <RDES1> : <RDES2> : <RDES3>\n");
-		for (i = 0; i < RX_DESC_CNT; i++) {
-			rx_desc = GET_RX_DESC_PTR(qInx, i);
-			printk(KERN_ALERT "\t[%4p %03d] = %#x : %#x : %#x : %#x\n",
-				rx_desc, i, rx_desc->RDES0, rx_desc->RDES1,
-				rx_desc->RDES2, rx_desc->RDES3);
-		}
-	}
-
-	printk(KERN_ALERT "/************************************************/\n");
-}
-#endif
-
-static void DWC_ETH_QOS_restart_phy(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	DBGPR("-->DWC_ETH_QOS_restart_phy\n");
-
-	pdata->oldlink = 0;
-	pdata->speed = 0;
-	pdata->oldduplex = -1;
-
-	if (pdata->phydev)
-		phy_start_aneg(pdata->phydev);
-
-	DBGPR("<--DWC_ETH_QOS_restart_phy\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct desc_if_struct *desc_if = &(pdata->desc_if);
+   gbe_power_state_t ret = GBE_RUN_STATE;
+
+   CFG_PRINT("-->DWC_ETH_QOS_stop_dev\n");
+
+   if (pdata->power_state & DWC_ETH_QOS_NETIP_WAKEUP) {
+      WRN_PRINT("Device is in StandBy\n");
+      ret = GBE_STANDBY_STATE;
+      goto stop_dev_exit;
+   }
+
+   if (pdata->power_state & DWC_ETH_QOS_NETIP_PWRUP) {
+      CFG_PRINT("Device waking up from StandBy\n");
+   } else if (netif_running(pdata->dev)) {
+      CFG_PRINT("Device is not running\n");
+      netif_tx_disable(pdata->dev);
+      DWC_ETH_QOS_napi_disable(pdata);
+      /* Stop DMA TX/RX */
+      DWC_ETH_QOS_stop_all_ch_tx_dma(pdata);
+      DWC_ETH_QOS_stop_all_ch_rx_dma(pdata);
+   } else {
+      ret = GBE_STOP_STATE;
+   }
+   /* Issue software reset to device */
+   hw_if->sw_reset();
+   /* Free tx skb's */
+   desc_if->tx_skb_free_mem(pdata, DWC_ETH_QOS_TX_QUEUE_CNT);
+   /* Free rx skb's */
+   desc_if->rx_skb_free_mem(pdata, DWC_ETH_QOS_RX_QUEUE_CNT);
+
+stop_dev_exit:
+   CFG_PRINT("<--DWC_ETH_QOS_stop_dev\n");
+   return ret;
 }
 
 /*!
@@ -321,44 +372,51 @@ static void DWC_ETH_QOS_restart_phy(stru
  */
 static void DWC_ETH_QOS_start_dev(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct desc_if_struct *desc_if = &(pdata->desc_if);
-
-	DBGPR("-->DWC_ETH_QOS_start_dev\n");
-
-	/* reset all variables */
-	DWC_ETH_QOS_default_common_confs(pdata);
-	DWC_ETH_QOS_default_tx_confs(pdata);
-	DWC_ETH_QOS_default_rx_confs(pdata);
-
-	DWC_ETH_QOS_configure_rx_fun_ptr(pdata);
-
-	DWC_ETH_QOS_napi_enable(pdata);
-
-	/* reinit descriptor */
-	desc_if->wrapper_tx_desc_init(pdata);
-	desc_if->wrapper_rx_desc_init(pdata);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct desc_if_struct *desc_if = &(pdata->desc_if);
+
+   CFG_PRINT("-->DWC_ETH_QOS_start_dev\n");
+
+   /* reset all variables */
+   DWC_ETH_QOS_default_common_confs(pdata);
+   DWC_ETH_QOS_default_tx_confs(pdata);
+   DWC_ETH_QOS_default_rx_confs(pdata);
+
+   DWC_ETH_QOS_configure_rx_fun_ptr(pdata);
+
+   DWC_ETH_QOS_napi_enable(pdata);
+
+   /* reinit descriptor */
+   desc_if->wrapper_tx_desc_init(pdata);
+   desc_if->wrapper_rx_desc_init(pdata);
 
 #ifdef YDEBUG
-	DWC_ETH_QOS_tx_desc_mang_ds_dump(pdata);
-	DWC_ETH_QOS_rx_desc_mang_ds_dump(pdata);
+   DWC_ETH_QOS_tx_desc_mang_ds_dump(pdata);
+   DWC_ETH_QOS_rx_desc_mang_ds_dump(pdata);
 #endif
 
-	/* initializes MAC and DMA */
-	hw_if->init(pdata);
-
-	if (pdata->vlan_hash_filtering)
-		hw_if->update_vlan_hash_table_reg(pdata->vlan_ht_or_id);
-	else
-		hw_if->update_vlan_id(pdata->vlan_ht_or_id);
-
-	DWC_ETH_QOS_restart_phy(pdata);
-
-	pdata->eee_enabled = DWC_ETH_QOS_eee_init(pdata);
-
-	netif_tx_wake_all_queues(pdata->dev);
-
-	DBGPR("<--DWC_ETH_QOS_start_dev\n");
+   /* initializes MAC and DMA */
+   hw_if->init(pdata);
+
+   if (pdata->vlan_hash_filtering)
+      hw_if->update_vlan_hash_table_reg(pdata->vlan_ht_or_id);
+   else
+      hw_if->update_vlan_id(pdata->vlan_ht_or_id);
+
+   if (pdata->phydev) {
+      DWC_ETH_QOS_restart_phy(pdata);
+      pdata->eee_enabled = DWC_ETH_QOS_eee_init(pdata);
+   } else
+      pdata->eee_enabled = false;
+
+   if (pdata->mux_cfg == GMCR_GMAC5_TO_GMAC4) {
+      hw_if->set_full_duplex();
+      hw_if->set_speed(pdata, gbe_config_to_speed(pdata->rate));
+   }
+
+   netif_tx_wake_all_queues(pdata->dev);
+
+   CFG_PRINT("<--DWC_ETH_QOS_start_dev\n");
 }
 
 /*!
@@ -372,98 +430,96 @@ static void DWC_ETH_QOS_start_dev(struct
  *
  * \return void
  */
-
 static void DWC_ETH_QOS_restart_dev(struct DWC_ETH_QOS_prv_data *pdata,
-					uint32_t qInx)
+               uint32_t qInx)
 {
-	struct desc_if_struct *desc_if = &(pdata->desc_if);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-
-	DBGPR("-->DWC_ETH_QOS_restart_dev\n");
-
-	netif_stop_subqueue(pdata->dev, qInx);
-	DWC_ETH_QOS_napi_disable(pdata);
-
-	/* stop DMA TX/RX */
-	hw_if->stop_dma_tx(qInx);
-	hw_if->stop_dma_rx(qInx);
-
-	/* free tx skb's */
-	desc_if->tx_skb_free_mem_single_q(pdata, qInx);
-	/* free rx skb's */
-	desc_if->rx_skb_free_mem_single_q(pdata, qInx);
-
-	if ((DWC_ETH_QOS_TX_QUEUE_CNT == 0) &&
-		(DWC_ETH_QOS_RX_QUEUE_CNT == 0)) {
-		/* issue software reset to device */
-		hw_if->exit();
-
-		DWC_ETH_QOS_configure_rx_fun_ptr(pdata);
-		DWC_ETH_QOS_default_common_confs(pdata);
-	}
-	/* reset all variables */
-	DWC_ETH_QOS_default_tx_confs_single_q(pdata, qInx);
-	DWC_ETH_QOS_default_rx_confs_single_q(pdata, qInx);
-
-	/* reinit descriptor */
-	desc_if->wrapper_tx_desc_init_single_q(pdata, qInx);
-	desc_if->wrapper_rx_desc_init_single_q(pdata, qInx);
-
-	DWC_ETH_QOS_napi_enable(pdata);
-
-	/* initializes MAC and DMA
-	 * NOTE : Do we need to init only one channel
-	 * which generate FBE*/
-	hw_if->init(pdata);
-
-	DWC_ETH_QOS_restart_phy(pdata);
-
-	netif_wake_subqueue(pdata->dev, qInx);
-
-	DBGPR("<--DWC_ETH_QOS_restart_dev\n");
+   struct desc_if_struct *desc_if = &(pdata->desc_if);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+
+   DBGPR("-->DWC_ETH_QOS_restart_dev\n");
+
+   netif_stop_subqueue(pdata->dev, qInx);
+   DWC_ETH_QOS_napi_disable(pdata);
+
+   /* stop DMA TX/RX */
+   hw_if->stop_dma_tx(qInx);
+   hw_if->stop_dma_rx(qInx);
+
+   /* free tx skb's */
+   desc_if->tx_skb_free_mem_single_q(pdata, qInx);
+   /* free rx skb's */
+   desc_if->rx_skb_free_mem_single_q(pdata, qInx);
+
+   if ((DWC_ETH_QOS_TX_QUEUE_CNT == 0) &&
+      (DWC_ETH_QOS_RX_QUEUE_CNT == 0)) {
+      /* issue software reset to device */
+      hw_if->sw_reset();
+
+      DWC_ETH_QOS_configure_rx_fun_ptr(pdata);
+      DWC_ETH_QOS_default_common_confs(pdata);
+   }
+   /* reset all variables */
+   DWC_ETH_QOS_default_tx_confs_single_q(pdata, qInx);
+   DWC_ETH_QOS_default_rx_confs_single_q(pdata, qInx);
+
+   /* reinit descriptor */
+   desc_if->wrapper_tx_desc_init_single_q(pdata, qInx);
+   desc_if->wrapper_rx_desc_init_single_q(pdata, qInx);
+
+   DWC_ETH_QOS_napi_enable(pdata);
+
+   /* initializes MAC and DMA
+    * NOTE : Do we need to init only one channel
+    * which generate FBE*/
+   hw_if->init(pdata);
+
+   DWC_ETH_QOS_restart_phy(pdata);
+
+   netif_wake_subqueue(pdata->dev, qInx);
+
+   DBGPR("<--DWC_ETH_QOS_restart_dev\n");
 }
 
 void DWC_ETH_QOS_disable_rx_interrupts(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t qInx;
-	DBGPR("-->DWC_ETH_QOS_disable_rx_interrupts\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
-		hw_if->disable_rx_interrupt(qInx);
-	DBGPR("<--DWC_ETH_QOS_disable_rx_interrupts\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t qInx;
+   DBGPR("-->DWC_ETH_QOS_disable_rx_interrupts\n");
+   for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
+      hw_if->disable_rx_interrupt(qInx, &pdata->hw_cfg);
+   DBGPR("<--DWC_ETH_QOS_disable_rx_interrupts\n");
 }
 
 void DWC_ETH_QOS_enable_rx_interrupts(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t qInx;
-	DBGPR("-->DWC_ETH_QOS_enable_rx_interrupts\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
-		hw_if->enable_rx_interrupt(qInx);
-	DBGPR("<--DWC_ETH_QOS_enable_rx_interrupts\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t qInx;
+   DBGPR("-->DWC_ETH_QOS_enable_rx_interrupts\n");
+   for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
+      hw_if->enable_rx_interrupt(qInx, &pdata->hw_cfg);
+   DBGPR("<--DWC_ETH_QOS_enable_rx_interrupts\n");
 }
 
 void DWC_ETH_QOS_disable_tx_interrupts(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t qInx;
-	DBGPR("-->DWC_ETH_QOS_disable_tx_interrupts\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++)
-		hw_if->disable_tx_interrupt(qInx);
-	DBGPR("<--DWC_ETH_QOS_disable_tx_interrupts\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t qInx;
+   DBGPR("-->DWC_ETH_QOS_disable_tx_interrupts\n");
+   for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++)
+      hw_if->disable_tx_interrupt(qInx, &pdata->hw_cfg);
+   DBGPR("<--DWC_ETH_QOS_disable_tx_interrupts\n");
 }
 
 void DWC_ETH_QOS_enable_tx_interrupts(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t qInx;
-	DBGPR("-->DWC_ETH_QOS_enable_tx_interrupts\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++)
-		hw_if->enable_tx_interrupt(qInx);
-	DBGPR("<--DWC_ETH_QOS_enable_tx_interrupts\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t qInx;
+   DBGPR("-->DWC_ETH_QOS_enable_tx_interrupts\n");
+   for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++)
+      hw_if->enable_tx_interrupt(qInx, &pdata->hw_cfg);
+   DBGPR("<--DWC_ETH_QOS_enable_tx_interrupts\n");
 }
 
-
 /*!
 * \brief Interrupt Service Routine
 * \details Interrupt Service Routine
@@ -473,196 +529,197 @@ void DWC_ETH_QOS_enable_tx_interrupts(st
 * \return returns positive integer
 * \retval IRQ_HANDLED
 */
-
-#define HI_PRIORITY_INT  0x1
-#define LO_PRIORITY_INT  0x2
-
-irqreturn_t DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS(int irq, void *device_id)
+irqreturn_t DWC_ETH_QOS_ISR(int irq, void *device_id)
 {
-	uint32_t varDMA_ISR;
-	uint32_t varDMA_SR;
-	uint32_t varMAC_ISR;
-	uint32_t varMAC_PMTCSR;
-	uint32_t varDMA_IER;
-	struct DWC_ETH_QOS_prv_data *pdata =
-	    (struct DWC_ETH_QOS_prv_data *)device_id;
-	struct net_device *dev = pdata->dev;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t qInx;
-	uint32_t varMAC_ANS = 0, varMAC_PCS = 0;
-	unsigned int sched_rx_napi = 0, atom_ims = 0, gmac5_int = 0;
-	void __iomem *reg_base = pdata->gbe_base;
-
-	DBGPR("-->DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS\n");
-
-	if (pdata->version == MAC_VER_4_00) {
-		// Read and clear interrupt in Atom Interrupt Controller
-		atom_ims = GBE_REG_RD(GBE_ATOM_IMS); //Interrupts are cleared when IMS is read
-		gmac5_int = VAR32_GET_BIT(atom_ims, GBE_ATOM_INTC);
-		if (!gmac5_int)
-			printk(KERN_ALERT "GMAC5 interrupt with bit not set on IC!\n");
-	}
-
-	varDMA_ISR = DWC_REG_RD(DMA_ISR);
-	varMAC_ISR = DWC_REG_RD(MAC_ISR);
-	if (varDMA_ISR == 0x0) {
-		printk(KERN_ALERT "Unexpected GMAC5 interrupt - DMA(0x%08x) MAC(0x%08x)!\n", varDMA_ISR, varMAC_ISR);
-		netss_interrupt_ack(NETSS_INTERUPT_GBE);
-		return IRQ_NONE;
-	}
-
-	/* Handle DMA interrupts */
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-
-		varDMA_SR = DWC_REG_RD(DMA_SR(qInx));
-		/* clear interrupts */
-		DWC_REG_WR(DMA_SR(qInx), varDMA_SR);
-
-		varDMA_IER = DWC_REG_RD(DMA_IER(qInx));
-		/* handle only those DMA interrupts which are enabled */
-		varDMA_SR &= varDMA_IER;
-
-		DBGPR("DMA_SR[%d] = %#lx\n", qInx, varDMA_SR);
-
-		if (varDMA_SR == 0)
-			continue;
-
-		if (VAR32_GET_BIT(varDMA_SR, DMA_SR_RI)) {
-			pdata->xstats.rx_normal_irq_n[qInx]++;
-			sched_rx_napi |= LO_PRIORITY_INT;
-		}
-		if (VAR32_GET_BIT(varDMA_SR, DMA_SR_RBU)) {
-			pdata->xstats.rx_buf_unavailable_irq_n[qInx]++;
-			sched_rx_napi |= HI_PRIORITY_INT;
-		}
-		if (VAR32_GET_BIT(varDMA_SR, DMA_SR_TI)) {
-			pdata->xstats.tx_normal_irq_n[qInx]++;
+   uint32_t varDMA_ISR;
+   uint32_t varDMA_SR;
+   uint32_t varMAC_ISR;
+   uint32_t varMAC_PMTCSR;
+   struct DWC_ETH_QOS_prv_data *pdata =
+       (struct DWC_ETH_QOS_prv_data *)device_id;
+   struct net_device *dev = pdata->dev;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   hw_config_t *hw_cfg = &(pdata->hw_cfg);
+   uint32_t qInx;
+   uint32_t varMAC_ANS = 0, varMAC_PCS = 0;
+   unsigned int sched_rx_napi = 0, atom_ims = 0;
+   void __iomem *reg_base = pdata->gbe_base;
+
+   DBGPR("-->DWC_ETH_QOS_ISR\n");
+
+   /* Clock is gated when NetIP is powered down and any
+      register operation will hang the system. */
+   BUG_ON(pdata->power_state & DWC_ETH_QOS_NETIP_WAKEUP);
+
+   if (pdata->version == MAC_VER_4_00) {
+      // Read and clear interrupt in Atom Interrupt Controller
+      atom_ims = GBE_REG_RD(GBE_ATOM_IMS); //Interrupts are cleared when IMS is read
+      if (!VAR32_GET_BIT(atom_ims, GBE_ATOM_INTC))
+         printk(KERN_ALERT "GMAC5 interrupt with bit not set on IC!\n");
+   }
+
+   varDMA_ISR = DWC_REG_RD(DMA_ISR);
+   varMAC_ISR = DWC_REG_RD(MAC_ISR);
+   if (varDMA_ISR == 0x0 &&
+      !(pdata->power_state & DWC_ETH_QOS_NETIP_PWRDWN)) {
+      printk(KERN_ALERT "Unexpected interrupt - DMA(0x%08x) MAC(0x%08x)!\n",
+         varDMA_ISR, varMAC_ISR);
+      netss_interrupt_ack(NETSS_INTERUPT_GBE);
+      return IRQ_NONE;
+   }
+
+   /* Handle DMA interrupts */
+   for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
+
+      varDMA_SR = DWC_REG_RD(DMA_SR(qInx));
+      /* Clear interrupts */
+      DWC_REG_WR(DMA_SR(qInx), varDMA_SR);
+      /* Handle only enabled DMA interrupts */
+      varDMA_SR &= hw_cfg->dma_ier;
+
+      DBGPR("DMA_SR[%d] = 0x%08x\n", qInx, varDMA_SR);
+
+      if (varDMA_SR == 0)
+         continue;
+
+      if (VAR32_GET_BIT(varDMA_SR, DMA_SR_RI)) {
+         pdata->xstats.rx_normal_irq_n[qInx]++;
+         sched_rx_napi |= LO_PRIORITY_INT;
+      }
+      if (VAR32_GET_BIT(varDMA_SR, DMA_SR_RBU)) {
+         pdata->xstats.rx_buf_unavailable_irq_n[qInx]++;
+         sched_rx_napi |= HI_PRIORITY_INT;
+      }
+      if (VAR32_GET_BIT(varDMA_SR, DMA_SR_TI)) {
+         pdata->xstats.tx_normal_irq_n[qInx]++;
 #ifdef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-			sched_rx_napi |= LO_PRIORITY_INT;
+         sched_rx_napi |= LO_PRIORITY_INT;
 #else
-			DWC_ETH_QOS_tx_interrupt(dev, pdata, qInx);
+         DWC_ETH_QOS_tx_interrupt(dev, pdata, qInx);
 #endif
-		}
-		if (VAR32_GET_BIT(varDMA_SR, DMA_SR_TPS)) {
-			pdata->xstats.tx_process_stopped_irq_n[qInx]++;
-			printk(KERN_ALERT "Tx stopped interrupt!\n");
-		}
-		if (VAR32_GET_BIT(varDMA_SR, DMA_SR_TBU)) {
-			pdata->xstats.tx_buf_unavailable_irq_n[qInx]++;
+      }
+      if (VAR32_GET_BIT(varDMA_SR, DMA_SR_TPS)) {
+         pdata->xstats.tx_process_stopped_irq_n[qInx]++;
+         DBGPR("Tx stopped interrupt!\n");
+      }
+      if (VAR32_GET_BIT(varDMA_SR, DMA_SR_TBU)) {
+         pdata->xstats.tx_buf_unavailable_irq_n[qInx]++;
 #ifdef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-			sched_rx_napi |= LO_PRIORITY_INT;
+         sched_rx_napi |= LO_PRIORITY_INT;
 #else
-			DWC_ETH_QOS_tx_interrupt(dev, pdata, qInx);
+         DWC_ETH_QOS_tx_interrupt(dev, pdata, qInx);
 #endif
-		}
-		if (VAR32_GET_BIT(varDMA_SR, DMA_SR_RPS)) {
-			pdata->xstats.rx_process_stopped_irq_n[qInx]++;
-		}
-		if (VAR32_GET_BIT(varDMA_SR, DMA_SR_RWT)) {
-			pdata->xstats.rx_watchdog_irq_n++;
-		}
-		if (VAR32_GET_BIT(varDMA_SR, DMA_SR_FBE)) {
-			pdata->xstats.fatal_bus_error_irq_n++;
-			DWC_ETH_QOS_restart_dev(pdata, qInx);
-		}
-	}
-
-	/* Schedule Rx NAPI, if required*/
-	if (sched_rx_napi) {
-		if (pdata->rx_napi_pending) {
-			printk(KERN_ALERT "DMA interrupt while in polling!\n");
-		} else {
-			spin_lock(&pdata->lock);
-			DWC_ETH_QOS_disable_rx_interrupts(pdata);
+      }
+      if (VAR32_GET_BIT(varDMA_SR, DMA_SR_RPS)) {
+         pdata->xstats.rx_process_stopped_irq_n[qInx]++;
+         DBGPR("Rx stopped interrupt!\n");
+      }
+      if (VAR32_GET_BIT(varDMA_SR, DMA_SR_RWT)) {
+         pdata->xstats.rx_watchdog_irq_n++;
+      }
+      if (VAR32_GET_BIT(varDMA_SR, DMA_SR_FBE)) {
+         pdata->xstats.fatal_bus_error_irq_n++;
+         DWC_ETH_QOS_restart_dev(pdata, qInx);
+      }
+   }
+
+   /* Schedule Rx NAPI, if required*/
+   if (sched_rx_napi) {
+      if (pdata->rx_napi_pending) {
+         printk(KERN_ALERT "DMA interrupt while in polling!\n");
+      } else {
+         spin_lock(&pdata->lock);
+         DWC_ETH_QOS_disable_rx_interrupts(pdata);
 #ifdef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-			DWC_ETH_QOS_disable_tx_interrupts(pdata);
+         DWC_ETH_QOS_disable_tx_interrupts(pdata);
 #endif
-			pdata->rx_napi_pending = true;
-			spin_unlock(&pdata->lock);
-			if (sched_rx_napi & HI_PRIORITY_INT) // || itr_mode == NONE
-				/* Schedule NAPI now */
-				napi_schedule(&pdata->rx_napi);
-			else
-				/* Delay schedule of NAPI */
-				hrtimer_start(&pdata->rx_itr_timer,
-					ns_to_ktime(pdata->itr_latency), HRTIMER_MODE_REL);
-		}
-	}
-
-	/* Handle MAC interrupts */
-	if (VAR32_GET_BIT(varDMA_ISR, DMA_ISR_MACIS)) {
-		/* handle only those MAC interrupts which are enabled */
-		varMAC_ISR &= DWC_REG_RD(MAC_IER);
-
-		/* PMT interrupt */
-		if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_PMTIS)) {
-			pdata->xstats.pmt_irq_n++;
-			varMAC_PMTCSR = DWC_REG_RD(MAC_PMT_CSR);
-			DBGPR("PMT interrupt: varMAC_PMTCSR = 0x%08x\n", varMAC_PMTCSR);
-			if (pdata->power_down)
-				DWC_ETH_QOS_powerup(pdata->dev, DWC_ETH_QOS_IOCTL_CONTEXT);
-		}
-
-		/* RGMII/SMII interrupt */
-		if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_RGMIIIS)) {
-			varMAC_PCS = DWC_REG_RD(MAC_PHY_CSR);
-			printk(KERN_ALERT "RGMII/SMII interrupt: MAC_PCS = 0x%08x\n", varMAC_PCS);
-			if ((varMAC_PCS & 0x80000) == 0x80000) {
-				pdata->pcs_link = 1;
-				netif_carrier_on(dev);
-				if ((varMAC_PCS & 0x10000) == 0x10000) {
-					pdata->pcs_duplex = 1;
-					hw_if->set_full_duplex();
-				} else {
-					pdata->pcs_duplex = 0;
-					hw_if->set_half_duplex();
-				}
-
-				if ((varMAC_PCS & 0x60000) == 0x0) {
-					hw_if->set_speed(pdata, 10);
-				} else if ((varMAC_PCS & 0x60000) == 0x20000) {
-					hw_if->set_speed(pdata, 100);
-				} else if ((varMAC_PCS & 0x60000) == 0x40000) {
-					hw_if->set_speed(pdata, 1000);
-				}
-				printk(KERN_ALERT "Link is UP:%dMbps & %s duplex\n",
-					pdata->pcs_speed, pdata->pcs_duplex ? "Full" : "Half");
-			} else {
-				printk(KERN_ALERT "Link is Down\n");
-				pdata->pcs_link = 0;
-				netif_carrier_off(dev);
-			}
-		}
-
-		/* PCS Link Status interrupt */
-		if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_PCSLCHGIS)) {
-			printk(KERN_ALERT "PCS Link Status interrupt\n");
-			if (DWC_REG_RD_BIT(MAC_ANSR, MAC_ANSR_LS)) {
-				printk(KERN_ALERT "Link: Up\n");
-				netif_carrier_on(dev);
-				pdata->pcs_link = 1;
-			} else {
-				printk(KERN_ALERT "Link: Down\n");
-				netif_carrier_off(dev);
-				pdata->pcs_link = 0;
-			}
-		}
-
-		/* PCS Auto-Negotiation Complete interrupt */
-		if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_PCSANCIS)) {
-			printk(KERN_ALERT "PCS Auto-Negotiation Complete interrupt\n");
-			varMAC_ANS = DWC_REG_RD(MAC_ANSR);
-		}
-
-		/* EEE interrupts */
-		if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_LPIIS)) {
-			DWC_ETH_QOS_handle_eee_interrupt(pdata);
-		}
-	}
-	netss_interrupt_ack(NETSS_INTERUPT_GBE);
-	DBGPR("<--DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS\n");
-
-	return IRQ_HANDLED;
+         pdata->rx_napi_pending = true;
+         spin_unlock(&pdata->lock);
+         if (sched_rx_napi & HI_PRIORITY_INT) // || itr_mode == NONE
+            /* Schedule NAPI now */
+            napi_schedule(&pdata->rx_napi);
+         else
+            /* Delay schedule of NAPI */
+            hrtimer_start(&pdata->rx_itr_timer,
+               ns_to_ktime(pdata->itr_latency), HRTIMER_MODE_REL);
+      }
+   }
+
+   /* Handle MAC interrupts */
+   if (VAR32_GET_BIT(varDMA_ISR, DMA_ISR_MACIS)) {
+      /* handle only those MAC interrupts which are enabled */
+      varMAC_ISR &= hw_cfg->mac_ier;
+
+      /* PMT interrupt */
+      if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_PMTIS)) {
+         pdata->xstats.pmt_irq_n++;
+         varMAC_PMTCSR = DWC_REG_RD(MAC_PMT_CSR);
+         DBGPR("PMT interrupt: varMAC_PMTCSR = 0x%08x\n", varMAC_PMTCSR);
+         if (pdata->power_state &
+             (DWC_ETH_QOS_MAGIC_WAKEUP | DWC_ETH_QOS_REMOTE_WAKEUP))
+            DWC_ETH_QOS_powerup(pdata->dev);
+      }
+
+      /* RGMII/SMII interrupt */
+      if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_RGMIIIS)) {
+         varMAC_PCS = DWC_REG_RD(MAC_PHY_CSR);
+         printk(KERN_ALERT "RGMII/SMII interrupt: MAC_PCS = 0x%08x\n", varMAC_PCS);
+         if ((varMAC_PCS & 0x80000) == 0x80000) {
+            pdata->pcs_link = 1;
+            netif_carrier_on(dev);
+            if ((varMAC_PCS & 0x10000) == 0x10000) {
+               pdata->pcs_duplex = 1;
+               hw_if->set_full_duplex();
+            } else {
+               pdata->pcs_duplex = 0;
+               hw_if->set_half_duplex();
+            }
+
+            if ((varMAC_PCS & 0x60000) == 0x0) {
+               hw_if->set_speed(pdata, 10);
+            } else if ((varMAC_PCS & 0x60000) == 0x20000) {
+               hw_if->set_speed(pdata, 100);
+            } else if ((varMAC_PCS & 0x60000) == 0x40000) {
+               hw_if->set_speed(pdata, 1000);
+            }
+            printk(KERN_ALERT "Link is UP:%dMbps & %s duplex\n",
+               pdata->pcs_speed, pdata->pcs_duplex ? "Full" : "Half");
+         } else {
+            printk(KERN_ALERT "Link is Down\n");
+            pdata->pcs_link = 0;
+            netif_carrier_off(dev);
+         }
+      }
+
+      /* PCS Link Status interrupt */
+      if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_PCSLCHGIS)) {
+         printk(KERN_ALERT "PCS Link Status interrupt\n");
+         if (DWC_REG_RD_BIT(MAC_ANSR, MAC_ANSR_LS)) {
+            printk(KERN_ALERT "Link: Up\n");
+            netif_carrier_on(dev);
+            pdata->pcs_link = 1;
+         } else {
+            printk(KERN_ALERT "Link: Down\n");
+            netif_carrier_off(dev);
+            pdata->pcs_link = 0;
+         }
+      }
+
+      /* PCS Auto-Negotiation Complete interrupt */
+      if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_PCSANCIS)) {
+         printk(KERN_ALERT "PCS Auto-Negotiation Complete interrupt\n");
+         varMAC_ANS = DWC_REG_RD(MAC_ANSR);
+      }
+
+      /* EEE interrupts */
+      if (VAR32_GET_BIT(varMAC_ISR, MAC_ISR_LPIIS)) {
+         DWC_ETH_QOS_handle_eee_interrupt(pdata);
+      }
+   }
+   netss_interrupt_ack(NETSS_INTERUPT_GBE);
+   DBGPR("<--DWC_ETH_QOS_ISR\n");
+
+   return IRQ_HANDLED;
 }
 
 /*!
@@ -677,57 +734,56 @@ irqreturn_t DWC_ETH_QOS_ISR_SW_DWC_ETH_Q
 */
 void DWC_ETH_QOS_get_all_hw_features(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	uint32_t varMAC_HF0R = DWC_REG_RD(MAC_HF0R);
-	uint32_t varMAC_HF1R = DWC_REG_RD(MAC_HF1R);
-	uint32_t varMAC_HF2R = DWC_REG_RD(MAC_HF2R);
-
-	DBGPR("-->DWC_ETH_QOS_get_all_hw_features\n");
-
-	memset(&pdata->hw_feat, 0, sizeof(pdata->hw_feat));
-	pdata->hw_feat.mii_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MIISEL);
-	pdata->hw_feat.gmii_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_GMIISEL);
-	pdata->hw_feat.hd_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_HDSEL);
-	pdata->hw_feat.pcs_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_PCSSEL);
-	pdata->hw_feat.vlan_hash_en = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_VLHASH);
-	pdata->hw_feat.sma_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_SMASEL);
-	pdata->hw_feat.rwk_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_RWKSEL);
-	pdata->hw_feat.mgk_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MGKSEL);
-	pdata->hw_feat.mmc_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MMCSEL);
-	pdata->hw_feat.arp_offld_en = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_ARPOFFSEL);
-	pdata->hw_feat.ts_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_TSSEL);
-	pdata->hw_feat.eee_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_EEESEL);
-	pdata->hw_feat.tx_coe_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_TXCOESEL);
-	pdata->hw_feat.rx_coe_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_RXCOESEL);
-	pdata->hw_feat.mac_addr16_sel = VAR32_GET_FIELD(varMAC_HF0R, MAC_HF0R_ADDMACADRSEL);
-	pdata->hw_feat.mac_addr32_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MACADR32SEL);
-	pdata->hw_feat.mac_addr64_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MACADR64SEL);
-	pdata->hw_feat.tsstssel = VAR32_GET_FIELD(varMAC_HF0R, MAC_HF0R_TSSTSSEL);
-	pdata->hw_feat.sa_vlan_ins = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_SAVLANINS);
-	pdata->hw_feat.act_phy_sel = VAR32_GET_FIELD(varMAC_HF0R, MAC_HF0R_ACTPHYSEL);
-
-	pdata->hw_feat.rx_fifo_size = VAR32_GET_FIELD(varMAC_HF1R, MAC_HF1R_RXFIFOSIZE);
-	pdata->hw_feat.tx_fifo_size = VAR32_GET_FIELD(varMAC_HF1R, MAC_HF1R_TXFIFOSIZE);
-	pdata->hw_feat.adv_ts_hword = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_ADVTHWORD);
-	pdata->hw_feat.dcb_en = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_DCBEN);
-	pdata->hw_feat.sph_en = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_SPHEN);
-	pdata->hw_feat.tso_en = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_TSOEN);
-	pdata->hw_feat.dma_debug_gen = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_DBGMEMA);
-	pdata->hw_feat.av_sel = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_AVSEL);
-	pdata->hw_feat.lp_mode_en = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_LPMODEEN);
-	pdata->hw_feat.hash_tbl_sz = VAR32_GET_FIELD(varMAC_HF1R, MAC_HF1R_HASHTBLSZ);
-	pdata->hw_feat.l3l4_filter_num = VAR32_GET_FIELD(varMAC_HF1R, MAC_HF1R_L3L4FNUM);
-
-	pdata->hw_feat.rx_q_cnt = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_RXQCNT);
-	pdata->hw_feat.tx_q_cnt = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_TXQCNT);
-	pdata->hw_feat.rx_ch_cnt = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_RXCHCNT);
-	pdata->hw_feat.tx_ch_cnt = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_TXCHCNT);
-	pdata->hw_feat.pps_out_num = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_PPSOUTNUM);
-	pdata->hw_feat.aux_snap_num = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_AUXSNAPNUM);
-
-	DBGPR("<--DWC_ETH_QOS_get_all_hw_features\n");
+   uint32_t varMAC_HF0R = DWC_REG_RD(MAC_HF0R);
+   uint32_t varMAC_HF1R = DWC_REG_RD(MAC_HF1R);
+   uint32_t varMAC_HF2R = DWC_REG_RD(MAC_HF2R);
+
+   DBGPR("-->DWC_ETH_QOS_get_all_hw_features\n");
+
+   memset(&pdata->hw_feat, 0, sizeof(pdata->hw_feat));
+   pdata->hw_feat.mii_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MIISEL);
+   pdata->hw_feat.gmii_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_GMIISEL);
+   pdata->hw_feat.hd_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_HDSEL);
+   pdata->hw_feat.pcs_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_PCSSEL);
+   pdata->hw_feat.vlan_hash_en = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_VLHASH);
+   pdata->hw_feat.sma_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_SMASEL);
+   pdata->hw_feat.rwk_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_RWKSEL);
+   pdata->hw_feat.mgk_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MGKSEL);
+   pdata->hw_feat.mmc_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MMCSEL);
+   pdata->hw_feat.arp_offld_en = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_ARPOFFSEL);
+   pdata->hw_feat.ts_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_TSSEL);
+   pdata->hw_feat.eee_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_EEESEL);
+   pdata->hw_feat.tx_coe_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_TXCOESEL);
+   pdata->hw_feat.rx_coe_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_RXCOESEL);
+   pdata->hw_feat.mac_addr16_sel = VAR32_GET_FIELD(varMAC_HF0R, MAC_HF0R_ADDMACADRSEL);
+   pdata->hw_feat.mac_addr32_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MACADR32SEL);
+   pdata->hw_feat.mac_addr64_sel = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_MACADR64SEL);
+   pdata->hw_feat.tsstssel = VAR32_GET_FIELD(varMAC_HF0R, MAC_HF0R_TSSTSSEL);
+   pdata->hw_feat.sa_vlan_ins = VAR32_GET_BIT(varMAC_HF0R, MAC_HF0R_SAVLANINS);
+   pdata->hw_feat.act_phy_sel = VAR32_GET_FIELD(varMAC_HF0R, MAC_HF0R_ACTPHYSEL);
+
+   pdata->hw_feat.rx_fifo_size = VAR32_GET_FIELD(varMAC_HF1R, MAC_HF1R_RXFIFOSIZE);
+   pdata->hw_feat.tx_fifo_size = VAR32_GET_FIELD(varMAC_HF1R, MAC_HF1R_TXFIFOSIZE);
+   pdata->hw_feat.adv_ts_hword = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_ADVTHWORD);
+   pdata->hw_feat.dcb_en = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_DCBEN);
+   pdata->hw_feat.sph_en = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_SPHEN);
+   pdata->hw_feat.tso_en = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_TSOEN);
+   pdata->hw_feat.dma_debug_gen = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_DBGMEMA);
+   pdata->hw_feat.av_sel = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_AVSEL);
+   pdata->hw_feat.lp_mode_en = VAR32_GET_BIT(varMAC_HF1R, MAC_HF1R_LPMODEEN);
+   pdata->hw_feat.hash_tbl_sz = VAR32_GET_FIELD(varMAC_HF1R, MAC_HF1R_HASHTBLSZ);
+   pdata->hw_feat.l3l4_filter_num = VAR32_GET_FIELD(varMAC_HF1R, MAC_HF1R_L3L4FNUM);
+
+   pdata->hw_feat.rx_q_cnt = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_RXQCNT);
+   pdata->hw_feat.tx_q_cnt = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_TXQCNT);
+   pdata->hw_feat.rx_ch_cnt = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_RXCHCNT);
+   pdata->hw_feat.tx_ch_cnt = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_TXCHCNT);
+   pdata->hw_feat.pps_out_num = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_PPSOUTNUM);
+   pdata->hw_feat.aux_snap_num = VAR32_GET_FIELD(varMAC_HF2R, MAC_HF2R_AUXSNAPNUM);
+
+   DBGPR("<--DWC_ETH_QOS_get_all_hw_features\n");
 }
 
-
 /*!
 * \brief API to print all hw features.
 *
@@ -739,306 +795,305 @@ void DWC_ETH_QOS_get_all_hw_features(str
 */
 void DWC_ETH_QOS_print_all_hw_features(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	char *str = NULL;
-
-	DBGPR("-->DWC_ETH_QOS_print_all_hw_features\n");
-
-	CFG_PRINT("\n");
-	CFG_PRINT("=====================================================/\n");
-	CFG_PRINT("\n");
-	CFG_PRINT("10/100 Mbps Support                         : %s\n",
-		pdata->hw_feat.mii_sel ? "YES" : "NO");
-	CFG_PRINT("1000 Mbps Support                           : %s\n",
-		pdata->hw_feat.gmii_sel ? "YES" : "NO");
-	CFG_PRINT("Half-duplex Support                         : %s\n",
-		pdata->hw_feat.hd_sel ? "YES" : "NO");
-	CFG_PRINT("PCS Registers(TBI/SGMII/RTBI PHY interface) : %s\n",
-		pdata->hw_feat.pcs_sel ? "YES" : "NO");
-	CFG_PRINT("VLAN Hash Filter Selected                   : %s\n",
-		pdata->hw_feat.vlan_hash_en ? "YES" : "NO");
-	pdata->vlan_hash_filtering = pdata->hw_feat.vlan_hash_en;
-	CFG_PRINT("SMA (MDIO) Interface                        : %s\n",
-		pdata->hw_feat.sma_sel ? "YES" : "NO");
-	CFG_PRINT("PMT Remote Wake-up Packet Enable            : %s\n",
-		pdata->hw_feat.rwk_sel ? "YES" : "NO");
-	CFG_PRINT("PMT Magic Packet Enable                     : %s\n",
-		pdata->hw_feat.mgk_sel ? "YES" : "NO");
-	CFG_PRINT("RMON/MMC Module Enable                      : %s\n",
-		pdata->hw_feat.mmc_sel ? "YES" : "NO");
-	CFG_PRINT("ARP Offload Enabled                         : %s\n",
-		pdata->hw_feat.arp_offld_en ? "YES" : "NO");
-	CFG_PRINT("IEEE 1588-2008 Timestamp Enabled            : %s\n",
-		pdata->hw_feat.ts_sel ? "YES" : "NO");
-	CFG_PRINT("Energy Efficient Ethernet Enabled           : %s\n",
-		pdata->hw_feat.eee_sel ? "YES" : "NO");
-	CFG_PRINT("Transmit Checksum Offload Enabled           : %s\n",
-		pdata->hw_feat.tx_coe_sel ? "YES" : "NO");
-	CFG_PRINT("Receive Checksum Offload Enabled            : %s\n",
-		pdata->hw_feat.rx_coe_sel ? "YES" : "NO");
-	CFG_PRINT("MAC Addresses 1631 Selected                : %s\n",
-		pdata->hw_feat.mac_addr16_sel ? "YES" : "NO");
-	CFG_PRINT("MAC Addresses 3263 Selected                : %s\n",
-		pdata->hw_feat.mac_addr32_sel ? "YES" : "NO");
-	CFG_PRINT("MAC Addresses 64127 Selected               : %s\n",
-		pdata->hw_feat.mac_addr64_sel ? "YES" : "NO");
-
-	if (pdata->hw_feat.mac_addr64_sel)
-		pdata->max_addr_reg_cnt = 128;
-	else if (pdata->hw_feat.mac_addr32_sel)
-		pdata->max_addr_reg_cnt = 64;
-	else if (pdata->hw_feat.mac_addr16_sel)
-		pdata->max_addr_reg_cnt = 32;
-	else
-		pdata->max_addr_reg_cnt = 1;
-
-	switch(pdata->hw_feat.tsstssel) {
-	case 0:
-		str = "RESERVED";
-		break;
-	case 1:
-		str = "INTERNAL";
-		break;
-	case 2:
-		str = "EXTERNAL";
-		break;
-	case 3:
-		str = "BOTH";
-		break;
-	}
-	CFG_PRINT("Timestamp System Time Source                : %s\n",
-		str);
-	CFG_PRINT("Source Address or VLAN Insertion Enable     : %s\n",
-		pdata->hw_feat.sa_vlan_ins ? "YES" : "NO");
-
-	switch (pdata->hw_feat.act_phy_sel) {
-	case 0:
-		str = "GMII/MII";
-		break;
-	case 1:
-		str = "RGMII";
-		break;
-	case 2:
-		str = "SGMII";
-		break;
-	case 3:
-		str = "TBI";
-		break;
-	case 4:
-		str = "RMII";
-		break;
-	case 5:
-		str = "RTBI";
-		break;
-	case 6:
-		str = "SMII";
-		break;
-	case 7:
-		str = "RevMII";
-		break;
-	default:
-		str = "RESERVED";
-	}
-	CFG_PRINT("Active PHY Selected                         : %s\n", str);
-
-	switch(pdata->hw_feat.rx_fifo_size) {
-	case 0:
-		str = "128 bytes";
-		break;
-	case 1:
-		str = "256 bytes";
-		break;
-	case 2:
-		str = "512 bytes";
-		break;
-	case 3:
-		str = "1 KBytes";
-		break;
-	case 4:
-		str = "2 KBytes";
-		break;
-	case 5:
-		str = "4 KBytes";
-		break;
-	case 6:
-		str = "8 KBytes";
-		break;
-	case 7:
-		str = "16 KBytes";
-		break;
-	case 8:
-		str = "32 kBytes";
-		break;
-	case 9:
-		str = "64 KBytes";
-		break;
-	case 10:
-		str = "128 KBytes";
-		break;
-	case 11:
-		str = "256 KBytes";
-		break;
-	default:
-		str = "RESERVED";
-	}
-	CFG_PRINT("MTL Receive FIFO Size                       : %s\n", str);
-
-	switch(pdata->hw_feat.tx_fifo_size) {
-	case 0:
-		str = "128 bytes";
-		break;
-	case 1:
-		str = "256 bytes";
-		break;
-	case 2:
-		str = "512 bytes";
-		break;
-	case 3:
-		str = "1 KBytes";
-		break;
-	case 4:
-		str = "2 KBytes";
-		break;
-	case 5:
-		str = "4 KBytes";
-		break;
-	case 6:
-		str = "8 KBytes";
-		break;
-	case 7:
-		str = "16 KBytes";
-		break;
-	case 8:
-		str = "32 kBytes";
-		break;
-	case 9:
-		str = "64 KBytes";
-		break;
-	case 10:
-		str = "128 KBytes";
-		break;
-	case 11:
-		str = "256 KBytes";
-		break;
-	default:
-		str = "RESERVED";
-	}
-	CFG_PRINT("MTL Transmit FIFO Size                       : %s\n", str);
-	CFG_PRINT("IEEE 1588 High Word Register Enable          : %s\n",
-		pdata->hw_feat.adv_ts_hword ? "YES" : "NO");
-	CFG_PRINT("DCB Feature Enable                           : %s\n",
-		pdata->hw_feat.dcb_en ? "YES" : "NO");
-	CFG_PRINT("Split Header Feature Enable                  : %s\n",
-		pdata->hw_feat.sph_en ? "YES" : "NO");
-	CFG_PRINT("TCP Segmentation Offload Enable              : %s\n",
-		pdata->hw_feat.tso_en ? "YES" : "NO");
-	CFG_PRINT("DMA Debug Registers Enabled                  : %s\n",
-		pdata->hw_feat.dma_debug_gen ? "YES" : "NO");
-	CFG_PRINT("AV Feature Enabled                           : %s\n",
-		pdata->hw_feat.av_sel ? "YES" : "NO");
-	CFG_PRINT("Low Power Mode Enabled                       : %s\n",
-		pdata->hw_feat.lp_mode_en ? "YES" : "NO");
-
-	switch(pdata->hw_feat.hash_tbl_sz) {
-	case 0:
-		str = "No hash table selected";
-		pdata->max_hash_table_size = 0;
-		break;
-	case 1:
-		str = "64";
-		pdata->max_hash_table_size = 64;
-		break;
-	case 2:
-		str = "128";
-		pdata->max_hash_table_size = 128;
-		break;
-	case 3:
-		str = "256";
-		pdata->max_hash_table_size = 256;
-		break;
-	}
-	CFG_PRINT("Hash Table Size                              : %s\n", str);
-	CFG_PRINT("Total number of L3 or L4 Filters             : %d L3/L4 Filter\n",
-		pdata->hw_feat.l3l4_filter_num);
-	CFG_PRINT("Number of MTL Receive Queues                 : %d\n",
-		(pdata->hw_feat.rx_q_cnt + 1));
-	CFG_PRINT("Number of MTL Transmit Queues                : %d\n",
-		(pdata->hw_feat.tx_q_cnt + 1));
-	CFG_PRINT("Number of DMA Receive Channels               : %d\n",
-		(pdata->hw_feat.rx_ch_cnt + 1));
-	CFG_PRINT("Number of DMA Transmit Channels              : %d\n",
-		(pdata->hw_feat.tx_ch_cnt + 1));
-
-	switch(pdata->hw_feat.pps_out_num) {
-	case 0:
-		str = "No PPS output";
-		break;
-	case 1:
-		str = "1 PPS output";
-		break;
-	case 2:
-		str = "2 PPS output";
-		break;
-	case 3:
-		str = "3 PPS output";
-		break;
-	case 4:
-		str = "4 PPS output";
-		break;
-	default:
-		str = "RESERVED";
-	}
-	CFG_PRINT("Number of PPS Outputs                        : %s\n", str);
-
-	switch(pdata->hw_feat.aux_snap_num) {
-	case 0:
-		str = "No auxillary input";
-		break;
-	case 1:
-		str = "1 auxillary input";
-		break;
-	case 2:
-		str = "2 auxillary input";
-		break;
-	case 3:
-		str = "3 auxillary input";
-		break;
-	case 4:
-		str = "4 auxillary input";
-		break;
-	default:
-		str = "RESERVED";
-	}
-	CFG_PRINT("Number of Auxiliary Snapshot Inputs          : %s\n", str);
-
-	CFG_PRINT("=====================================================/\n");
-
-	DBGPR("<--DWC_ETH_QOS_print_all_hw_features\n");
+   char *str = NULL;
+
+   DBGPR("-->DWC_ETH_QOS_print_all_hw_features\n");
+
+   CFG_PRINT("\n");
+   CFG_PRINT("=====================================================/\n");
+   CFG_PRINT("\n");
+   CFG_PRINT("10/100 Mbps Support                         : %s\n",
+      pdata->hw_feat.mii_sel ? "YES" : "NO");
+   CFG_PRINT("1000 Mbps Support                           : %s\n",
+      pdata->hw_feat.gmii_sel ? "YES" : "NO");
+   CFG_PRINT("Half-duplex Support                         : %s\n",
+      pdata->hw_feat.hd_sel ? "YES" : "NO");
+   CFG_PRINT("PCS Registers(TBI/SGMII/RTBI PHY interface) : %s\n",
+      pdata->hw_feat.pcs_sel ? "YES" : "NO");
+   CFG_PRINT("VLAN Hash Filter Selected                   : %s\n",
+      pdata->hw_feat.vlan_hash_en ? "YES" : "NO");
+   pdata->vlan_hash_filtering = pdata->hw_feat.vlan_hash_en;
+   CFG_PRINT("SMA (MDIO) Interface                        : %s\n",
+      pdata->hw_feat.sma_sel ? "YES" : "NO");
+   CFG_PRINT("PMT Remote Wake-up Packet Enable            : %s\n",
+      pdata->hw_feat.rwk_sel ? "YES" : "NO");
+   CFG_PRINT("PMT Magic Packet Enable                     : %s\n",
+      pdata->hw_feat.mgk_sel ? "YES" : "NO");
+   CFG_PRINT("RMON/MMC Module Enable                      : %s\n",
+      pdata->hw_feat.mmc_sel ? "YES" : "NO");
+   CFG_PRINT("ARP Offload Enabled                         : %s\n",
+      pdata->hw_feat.arp_offld_en ? "YES" : "NO");
+   CFG_PRINT("IEEE 1588-2008 Timestamp Enabled            : %s\n",
+      pdata->hw_feat.ts_sel ? "YES" : "NO");
+   CFG_PRINT("Energy Efficient Ethernet Enabled           : %s\n",
+      pdata->hw_feat.eee_sel ? "YES" : "NO");
+   CFG_PRINT("Transmit Checksum Offload Enabled           : %s\n",
+      pdata->hw_feat.tx_coe_sel ? "YES" : "NO");
+   CFG_PRINT("Receive Checksum Offload Enabled            : %s\n",
+      pdata->hw_feat.rx_coe_sel ? "YES" : "NO");
+   CFG_PRINT("MAC Addresses 1631 Selected                : %s\n",
+      pdata->hw_feat.mac_addr16_sel ? "YES" : "NO");
+   CFG_PRINT("MAC Addresses 3263 Selected                : %s\n",
+      pdata->hw_feat.mac_addr32_sel ? "YES" : "NO");
+   CFG_PRINT("MAC Addresses 64127 Selected               : %s\n",
+      pdata->hw_feat.mac_addr64_sel ? "YES" : "NO");
+
+   if (pdata->hw_feat.mac_addr64_sel)
+      pdata->max_addr_reg_cnt = 128;
+   else if (pdata->hw_feat.mac_addr32_sel)
+      pdata->max_addr_reg_cnt = 64;
+   else if (pdata->hw_feat.mac_addr16_sel)
+      pdata->max_addr_reg_cnt = 32;
+   else
+      pdata->max_addr_reg_cnt = 1;
+
+   switch(pdata->hw_feat.tsstssel) {
+   case 0:
+      str = "RESERVED";
+      break;
+   case 1:
+      str = "INTERNAL";
+      break;
+   case 2:
+      str = "EXTERNAL";
+      break;
+   case 3:
+      str = "BOTH";
+      break;
+   }
+   CFG_PRINT("Timestamp System Time Source                : %s\n",
+      str);
+   CFG_PRINT("Source Address or VLAN Insertion Enable     : %s\n",
+      pdata->hw_feat.sa_vlan_ins ? "YES" : "NO");
+
+   switch (pdata->hw_feat.act_phy_sel) {
+   case 0:
+      str = "GMII/MII";
+      break;
+   case 1:
+      str = "RGMII";
+      break;
+   case 2:
+      str = "SGMII";
+      break;
+   case 3:
+      str = "TBI";
+      break;
+   case 4:
+      str = "RMII";
+      break;
+   case 5:
+      str = "RTBI";
+      break;
+   case 6:
+      str = "SMII";
+      break;
+   case 7:
+      str = "RevMII";
+      break;
+   default:
+      str = "RESERVED";
+   }
+   CFG_PRINT("Active PHY Selected                         : %s\n", str);
+
+   switch(pdata->hw_feat.rx_fifo_size) {
+   case 0:
+      str = "128 bytes";
+      break;
+   case 1:
+      str = "256 bytes";
+      break;
+   case 2:
+      str = "512 bytes";
+      break;
+   case 3:
+      str = "1 KBytes";
+      break;
+   case 4:
+      str = "2 KBytes";
+      break;
+   case 5:
+      str = "4 KBytes";
+      break;
+   case 6:
+      str = "8 KBytes";
+      break;
+   case 7:
+      str = "16 KBytes";
+      break;
+   case 8:
+      str = "32 kBytes";
+      break;
+   case 9:
+      str = "64 KBytes";
+      break;
+   case 10:
+      str = "128 KBytes";
+      break;
+   case 11:
+      str = "256 KBytes";
+      break;
+   default:
+      str = "RESERVED";
+   }
+   CFG_PRINT("MTL Receive FIFO Size                       : %s\n", str);
+
+   switch(pdata->hw_feat.tx_fifo_size) {
+   case 0:
+      str = "128 bytes";
+      break;
+   case 1:
+      str = "256 bytes";
+      break;
+   case 2:
+      str = "512 bytes";
+      break;
+   case 3:
+      str = "1 KBytes";
+      break;
+   case 4:
+      str = "2 KBytes";
+      break;
+   case 5:
+      str = "4 KBytes";
+      break;
+   case 6:
+      str = "8 KBytes";
+      break;
+   case 7:
+      str = "16 KBytes";
+      break;
+   case 8:
+      str = "32 kBytes";
+      break;
+   case 9:
+      str = "64 KBytes";
+      break;
+   case 10:
+      str = "128 KBytes";
+      break;
+   case 11:
+      str = "256 KBytes";
+      break;
+   default:
+      str = "RESERVED";
+   }
+   CFG_PRINT("MTL Transmit FIFO Size                       : %s\n", str);
+   CFG_PRINT("IEEE 1588 High Word Register Enable          : %s\n",
+      pdata->hw_feat.adv_ts_hword ? "YES" : "NO");
+   CFG_PRINT("DCB Feature Enable                           : %s\n",
+      pdata->hw_feat.dcb_en ? "YES" : "NO");
+   CFG_PRINT("Split Header Feature Enable                  : %s\n",
+      pdata->hw_feat.sph_en ? "YES" : "NO");
+   CFG_PRINT("TCP Segmentation Offload Enable              : %s\n",
+      pdata->hw_feat.tso_en ? "YES" : "NO");
+   CFG_PRINT("DMA Debug Registers Enabled                  : %s\n",
+      pdata->hw_feat.dma_debug_gen ? "YES" : "NO");
+   CFG_PRINT("AV Feature Enabled                           : %s\n",
+      pdata->hw_feat.av_sel ? "YES" : "NO");
+   CFG_PRINT("Low Power Mode Enabled                       : %s\n",
+      pdata->hw_feat.lp_mode_en ? "YES" : "NO");
+
+   switch(pdata->hw_feat.hash_tbl_sz) {
+   case 0:
+      str = "No hash table selected";
+      pdata->max_hash_table_size = 0;
+      break;
+   case 1:
+      str = "64";
+      pdata->max_hash_table_size = 64;
+      break;
+   case 2:
+      str = "128";
+      pdata->max_hash_table_size = 128;
+      break;
+   case 3:
+      str = "256";
+      pdata->max_hash_table_size = 256;
+      break;
+   }
+   CFG_PRINT("Hash Table Size                              : %s\n", str);
+   CFG_PRINT("Total number of L3 or L4 Filters             : %d L3/L4 Filter\n",
+      pdata->hw_feat.l3l4_filter_num);
+   CFG_PRINT("Number of MTL Receive Queues                 : %d\n",
+      (pdata->hw_feat.rx_q_cnt + 1));
+   CFG_PRINT("Number of MTL Transmit Queues                : %d\n",
+      (pdata->hw_feat.tx_q_cnt + 1));
+   CFG_PRINT("Number of DMA Receive Channels               : %d\n",
+      (pdata->hw_feat.rx_ch_cnt + 1));
+   CFG_PRINT("Number of DMA Transmit Channels              : %d\n",
+      (pdata->hw_feat.tx_ch_cnt + 1));
+
+   switch(pdata->hw_feat.pps_out_num) {
+   case 0:
+      str = "No PPS output";
+      break;
+   case 1:
+      str = "1 PPS output";
+      break;
+   case 2:
+      str = "2 PPS output";
+      break;
+   case 3:
+      str = "3 PPS output";
+      break;
+   case 4:
+      str = "4 PPS output";
+      break;
+   default:
+      str = "RESERVED";
+   }
+   CFG_PRINT("Number of PPS Outputs                        : %s\n", str);
+
+   switch(pdata->hw_feat.aux_snap_num) {
+   case 0:
+      str = "No auxillary input";
+      break;
+   case 1:
+      str = "1 auxillary input";
+      break;
+   case 2:
+      str = "2 auxillary input";
+      break;
+   case 3:
+      str = "3 auxillary input";
+      break;
+   case 4:
+      str = "4 auxillary input";
+      break;
+   default:
+      str = "RESERVED";
+   }
+   CFG_PRINT("Number of Auxiliary Snapshot Inputs          : %s\n", str);
+
+   CFG_PRINT("=====================================================/\n");
+
+   DBGPR("<--DWC_ETH_QOS_print_all_hw_features\n");
 }
 
-
 static const struct net_device_ops DWC_ETH_QOS_netdev_ops = {
-	.ndo_open = DWC_ETH_QOS_open,
-	.ndo_stop = DWC_ETH_QOS_close,
-	.ndo_start_xmit = DWC_ETH_QOS_start_xmit,
-	.ndo_get_stats = DWC_ETH_QOS_get_stats,
-	.ndo_set_rx_mode = DWC_ETH_QOS_set_rx_mode,
+   .ndo_open = DWC_ETH_QOS_open,
+   .ndo_stop = DWC_ETH_QOS_close,
+   .ndo_start_xmit = DWC_ETH_QOS_start_xmit,
+   .ndo_get_stats = DWC_ETH_QOS_get_stats,
+   .ndo_set_rx_mode = DWC_ETH_QOS_set_rx_mode,
 #ifdef CONFIG_NET_POLL_CONTROLLER
-	.ndo_poll_controller = DWC_ETH_QOS_poll_controller,
-#endif				/*end of CONFIG_NET_POLL_CONTROLLER */
-	.ndo_set_features = DWC_ETH_QOS_set_features,
-	.ndo_fix_features = DWC_ETH_QOS_fix_features,
-	.ndo_do_ioctl = DWC_ETH_QOS_ioctl,
-	.ndo_change_mtu = DWC_ETH_QOS_change_mtu,
+   .ndo_poll_controller = DWC_ETH_QOS_poll_controller,
+#endif            /*end of CONFIG_NET_POLL_CONTROLLER */
+   .ndo_set_features = DWC_ETH_QOS_set_features,
+   .ndo_fix_features = DWC_ETH_QOS_fix_features,
+   .ndo_do_ioctl = DWC_ETH_QOS_ioctl,
+   .ndo_change_mtu = DWC_ETH_QOS_change_mtu,
 #ifdef DWC_ETH_QOS_QUEUE_SELECT_ALGO
-	.ndo_select_queue = DWC_ETH_QOS_select_queue,
+   .ndo_select_queue = DWC_ETH_QOS_select_queue,
 #endif
-	.ndo_vlan_rx_add_vid = DWC_ETH_QOS_vlan_rx_add_vid,
-	.ndo_vlan_rx_kill_vid = DWC_ETH_QOS_vlan_rx_kill_vid,
+   .ndo_vlan_rx_add_vid = DWC_ETH_QOS_vlan_rx_add_vid,
+   .ndo_vlan_rx_kill_vid = DWC_ETH_QOS_vlan_rx_kill_vid,
 };
 
 struct net_device_ops *DWC_ETH_QOS_get_netdev_ops(void)
 {
-	return (struct net_device_ops *)&DWC_ETH_QOS_netdev_ops;
+   return (struct net_device_ops *)&DWC_ETH_QOS_netdev_ops;
 }
 
 /*!
@@ -1055,60 +1110,58 @@ struct net_device_ops *DWC_ETH_QOS_get_n
  *
  * \retval 0 on success and -ve number on failure.
  */
-
 static int DWC_ETH_QOS_alloc_split_hdr_rx_buf(
-		struct DWC_ETH_QOS_prv_data *pdata,
-		struct DWC_ETH_QOS_rx_buffer *buffer,
-		gfp_t gfp)
+      struct DWC_ETH_QOS_prv_data *pdata,
+      struct DWC_ETH_QOS_rx_buffer *buffer,
+      gfp_t gfp)
 {
-	struct sk_buff *skb = buffer->skb;
-
-	DBGPR("-->DWC_ETH_QOS_alloc_split_hdr_rx_buf\n");
-
-	if (skb) {
-		skb_trim(skb, 0);
-		goto check_page;
-	}
-
-	buffer->rx_hdr_size = DWC_ETH_QOS_MAX_HDR_SIZE;
-	/* allocate twice the maximum header size */
-	skb = __netdev_alloc_skb_ip_align(pdata->dev,
-			(2*buffer->rx_hdr_size),
-			gfp);
-	if (skb == NULL) {
-		printk(KERN_ALERT "Failed to allocate skb\n");
-		return -ENOMEM;
-	}
-	buffer->skb = skb;
-	DBGPR("Maximum header buffer size allocated = %d\n",
-		buffer->rx_hdr_size);
- check_page:
-	if (!buffer->dma)
-		buffer->dma = dma_map_single(&pdata->pdev->dev,
-					buffer->skb->data,
-					(2*buffer->rx_hdr_size),
-					DMA_FROM_DEVICE);
-	buffer->len = buffer->rx_hdr_size;
-
-	/* allocate a new page if necessary */
-	if (buffer->page2 == NULL) {
-		buffer->page2 = alloc_page(gfp);
-		if (unlikely(!buffer->page2)) {
-			printk(KERN_ALERT
-			"Failed to allocate page for second buffer\n");
-			return -ENOMEM;
-		}
-	}
-	if (!buffer->dma2)
-		buffer->dma2 = dma_map_page(&pdata->pdev->dev,
-				    buffer->page2, 0,
-				    PAGE_SIZE, DMA_FROM_DEVICE);
-	buffer->len2 = PAGE_SIZE;
-	buffer->mapped_as_page = Y_TRUE;
-
-	DBGPR("<--DWC_ETH_QOS_alloc_split_hdr_rx_buf\n");
-
-	return 0;
+   struct sk_buff *skb = buffer->skb;
+
+   DBGPR("-->DWC_ETH_QOS_alloc_split_hdr_rx_buf\n");
+
+   if (skb) {
+      skb_trim(skb, 0);
+      goto check_page;
+   }
+
+   buffer->rx_hdr_size = DWC_ETH_QOS_MAX_HDR_SIZE;
+   /* allocate twice the maximum header size */
+   skb = __netdev_alloc_skb_ip_align(pdata->dev,
+         (2*buffer->rx_hdr_size),
+         gfp);
+   if (skb == NULL) {
+      printk(KERN_ALERT "Failed to allocate skb\n");
+      return -ENOMEM;
+   }
+   buffer->skb = skb;
+   DBGPR("Maximum header buffer size allocated = %d\n", buffer->rx_hdr_size);
+check_page:
+   if (!buffer->dma)
+      buffer->dma = dma_map_single(&pdata->pdev->dev,
+               buffer->skb->data,
+               (2*buffer->rx_hdr_size),
+               DMA_FROM_DEVICE);
+   buffer->len = buffer->rx_hdr_size;
+
+   /* allocate a new page if necessary */
+   if (buffer->page2 == NULL) {
+      buffer->page2 = alloc_page(gfp);
+      if (unlikely(!buffer->page2)) {
+         printk(KERN_ALERT
+         "Failed to allocate page for second buffer\n");
+         return -ENOMEM;
+      }
+   }
+   if (!buffer->dma2)
+      buffer->dma2 = dma_map_page(&pdata->pdev->dev,
+                buffer->page2, 0,
+                PAGE_SIZE, DMA_FROM_DEVICE);
+   buffer->len2 = PAGE_SIZE;
+   buffer->mapped_as_page = Y_TRUE;
+
+   DBGPR("<--DWC_ETH_QOS_alloc_split_hdr_rx_buf\n");
+
+   return 0;
 }
 
 /*!
@@ -1125,61 +1178,60 @@ static int DWC_ETH_QOS_alloc_split_hdr_r
  *
  * \retval 0 on success and -ve number on failure.
  */
-
 static int DWC_ETH_QOS_alloc_jumbo_rx_buf(struct DWC_ETH_QOS_prv_data *pdata,
-					  struct DWC_ETH_QOS_rx_buffer *buffer,
-					  gfp_t gfp)
+                 struct DWC_ETH_QOS_rx_buffer *buffer,
+                 gfp_t gfp)
 {
-	struct sk_buff *skb = buffer->skb;
-	unsigned int bufsz = (256 - 16);	/* for skb_reserve */
-
-	DBGPR("-->DWC_ETH_QOS_alloc_jumbo_rx_buf\n");
-
-	if (skb) {
-		skb_trim(skb, 0);
-		goto check_page;
-	}
-
-	skb = __netdev_alloc_skb_ip_align(pdata->dev, bufsz, gfp);
-	if (skb == NULL) {
-		printk(KERN_ALERT "Failed to allocate skb\n");
-		return -ENOMEM;
-	}
-	buffer->skb = skb;
- check_page:
-	/* allocate a new page if necessary */
-	if (buffer->page == NULL) {
-		buffer->page = alloc_page(gfp);
-		if (unlikely(!buffer->page)) {
-			printk(KERN_ALERT "Failed to allocate page\n");
-			return -ENOMEM;
-		}
-	}
-	if (!buffer->dma)
-		buffer->dma = dma_map_page(&pdata->pdev->dev,
-					   buffer->page, 0,
-					   PAGE_SIZE, DMA_FROM_DEVICE);
-	buffer->len = PAGE_SIZE;
-
-	if (buffer->page2 == NULL) {
-		buffer->page2 = alloc_page(gfp);
-		if (unlikely(!buffer->page2)) {
-			printk(KERN_ALERT
-			       "Failed to allocate page for second buffer\n");
-			return -ENOMEM;
-		}
-	}
-	if (!buffer->dma2)
-		buffer->dma2 = dma_map_page(&pdata->pdev->dev,
-					    buffer->page2, 0,
-					    PAGE_SIZE, DMA_FROM_DEVICE);
-	buffer->len2 = PAGE_SIZE;
-
-	buffer->mapped_as_page = Y_TRUE;
-
-	DBGPR("<--DWC_ETH_QOS_alloc_jumbo_rx_buf\n");
-
-	return 0;
+   struct sk_buff *skb = buffer->skb;
+   unsigned int bufsz = (256 - 16);   /* for skb_reserve */
+
+   DBGPR("-->DWC_ETH_QOS_alloc_jumbo_rx_buf\n");
+
+   if (skb) {
+      skb_trim(skb, 0);
+      goto check_page;
+   }
+
+   skb = __netdev_alloc_skb_ip_align(pdata->dev, bufsz, gfp);
+   if (skb == NULL) {
+      printk(KERN_ALERT "Failed to allocate skb\n");
+      return -ENOMEM;
+   }
+   buffer->skb = skb;
+check_page:
+   /* allocate a new page if necessary */
+   if (buffer->page == NULL) {
+      buffer->page = alloc_page(gfp);
+      if (unlikely(!buffer->page)) {
+         printk(KERN_ALERT "Failed to allocate page\n");
+         return -ENOMEM;
+      }
+   }
+   if (!buffer->dma)
+      buffer->dma = dma_map_page(&pdata->pdev->dev,
+                  buffer->page, 0,
+                  PAGE_SIZE, DMA_FROM_DEVICE);
+   buffer->len = PAGE_SIZE;
+
+   if (buffer->page2 == NULL) {
+      buffer->page2 = alloc_page(gfp);
+      if (unlikely(!buffer->page2)) {
+         printk(KERN_ALERT
+                "Failed to allocate page for second buffer\n");
+         return -ENOMEM;
+      }
+   }
+   if (!buffer->dma2)
+      buffer->dma2 = dma_map_page(&pdata->pdev->dev,
+                   buffer->page2, 0,
+                   PAGE_SIZE, DMA_FROM_DEVICE);
+   buffer->len2 = PAGE_SIZE;
+
+   buffer->mapped_as_page = Y_TRUE;
+
+   DBGPR("<--DWC_ETH_QOS_alloc_jumbo_rx_buf\n");
+
+   return 0;
 }
 
 /*!
@@ -1197,41 +1249,39 @@ static int DWC_ETH_QOS_alloc_jumbo_rx_bu
  *
  * \retval 0 on success and -ve number on failure.
  */
-
 static int DWC_ETH_QOS_alloc_rx_buf(struct DWC_ETH_QOS_prv_data *pdata,
-				    struct DWC_ETH_QOS_rx_buffer *buffer,
-				    gfp_t gfp)
+                struct DWC_ETH_QOS_rx_buffer *buffer,
+                gfp_t gfp)
 {
-	struct sk_buff *skb = buffer->skb;
-
-	DBGPR("-->DWC_ETH_QOS_alloc_rx_buf\n");
-
-	if (skb) {
-		skb_trim(skb, 0);
-		goto map_skb;
-	}
-
-	skb = __netdev_alloc_skb_ip_align(pdata->dev, pdata->rx_buffer_len, gfp);
-	if (skb == NULL) {
-		printk(KERN_ALERT "Failed to allocate skb\n");
-		return -ENOMEM;
-	}
-	buffer->skb = skb;
-	buffer->len = pdata->rx_buffer_len;
+   struct sk_buff *skb = buffer->skb;
+
+   DBGPR("-->DWC_ETH_QOS_alloc_rx_buf\n");
+
+   if (skb) {
+      skb_trim(skb, 0);
+      goto map_skb;
+   }
+
+   skb = __netdev_alloc_skb_ip_align(pdata->dev, pdata->rx_buffer_len, gfp);
+   if (skb == NULL) {
+      printk(KERN_ALERT "Failed to allocate skb\n");
+      return -ENOMEM;
+   }
+   buffer->skb = skb;
+   buffer->len = pdata->rx_buffer_len;
  map_skb:
-	buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
-				     pdata->rx_buffer_len, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
-		printk(KERN_ALERT "failed to do the RX dma map\n");
-
-	buffer->mapped_as_page = Y_FALSE;
-
-	DBGPR("<--DWC_ETH_QOS_alloc_rx_buf\n");
-
-	return 0;
+   buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
+                 pdata->rx_buffer_len, DMA_FROM_DEVICE);
+   if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
+      printk(KERN_ALERT "failed to do the RX dma map\n");
+
+   buffer->mapped_as_page = Y_FALSE;
+
+   DBGPR("<--DWC_ETH_QOS_alloc_rx_buf\n");
+
+   return 0;
 }
 
-
 /*!
  * \brief api to configure Rx function pointer after reset.
  *
@@ -1243,28 +1293,26 @@ static int DWC_ETH_QOS_alloc_rx_buf(stru
  *
  * \return void
  */
-
 static void DWC_ETH_QOS_configure_rx_fun_ptr(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	DBGPR("-->DWC_ETH_QOS_configure_rx_fun_ptr\n");
-
-	if (pdata->rx_split_hdr) {
-		pdata->clean_rx = DWC_ETH_QOS_clean_split_hdr_rx_irq;
-		pdata->alloc_rx_buf = DWC_ETH_QOS_alloc_split_hdr_rx_buf;
-	}
-	else if (pdata->dev->mtu > DWC_ETH_QOS_ETH_FRAME_LEN) {
-		pdata->clean_rx = DWC_ETH_QOS_clean_jumbo_rx_irq;
-		pdata->alloc_rx_buf = DWC_ETH_QOS_alloc_jumbo_rx_buf;
-	} else {
-		pdata->rx_buffer_len = DWC_ETH_QOS_ETH_FRAME_LEN;
-		pdata->clean_rx = DWC_ETH_QOS_clean_rx_irq;
-		pdata->alloc_rx_buf = DWC_ETH_QOS_alloc_rx_buf;
-	}
-
-	DBGPR("<--DWC_ETH_QOS_configure_rx_fun_ptr\n");
+   DBGPR("-->DWC_ETH_QOS_configure_rx_fun_ptr\n");
+
+   if (pdata->rx_split_hdr) {
+      pdata->clean_rx = DWC_ETH_QOS_clean_split_hdr_rx_irq;
+      pdata->alloc_rx_buf = DWC_ETH_QOS_alloc_split_hdr_rx_buf;
+   }
+   else if (pdata->dev->mtu > DWC_ETH_QOS_ETH_FRAME_LEN) {
+      pdata->clean_rx = DWC_ETH_QOS_clean_jumbo_rx_irq;
+      pdata->alloc_rx_buf = DWC_ETH_QOS_alloc_jumbo_rx_buf;
+   } else {
+      pdata->rx_buffer_len = DWC_ETH_QOS_ETH_FRAME_LEN;
+      pdata->clean_rx = DWC_ETH_QOS_clean_rx_irq;
+      pdata->alloc_rx_buf = DWC_ETH_QOS_alloc_rx_buf;
+   }
+
+   DBGPR("<--DWC_ETH_QOS_configure_rx_fun_ptr\n");
 }
 
-
 /*!
  * \brief api to initialize default values.
  *
@@ -1278,30 +1326,29 @@ static void DWC_ETH_QOS_configure_rx_fun
 
 static void DWC_ETH_QOS_default_common_confs(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	DBGPR("-->DWC_ETH_QOS_default_common_confs\n");
-
-	pdata->drop_tx_pktburstcnt = 1;
-	pdata->mac_enable_count = 0;
-	pdata->incr_incrx = DWC_ETH_QOS_INCR_ENABLE;
-	pdata->flow_ctrl = DWC_ETH_QOS_FLOW_CTRL_TX_RX;
-	pdata->oldflow_ctrl = DWC_ETH_QOS_FLOW_CTRL_TX_RX;
-	pdata->power_down = 0;
-	pdata->tx_sa_ctrl_via_desc = DWC_ETH_QOS_SA0_NONE;
-	pdata->tx_sa_ctrl_via_reg = DWC_ETH_QOS_SA0_NONE;
-	pdata->hwts_tx_en = 0;
-	pdata->hwts_rx_en = 0;
-	pdata->l3_l4_filter = 0;
-	pdata->l2_filtering_mode = !!pdata->hw_feat.hash_tbl_sz;
-	pdata->tx_path_in_lpi_mode = 0;
-	pdata->use_lpi_tx_automate = true;
-	pdata->eee_active = 0;
-	pdata->one_nsec_accuracy = 1;
-	pdata->rx_napi_pending = false;
-
-	DBGPR("<--DWC_ETH_QOS_default_common_confs\n");
+   DBGPR("-->DWC_ETH_QOS_default_common_confs\n");
+
+   pdata->drop_tx_pktburstcnt = 1;
+   pdata->mac_enable_count = 0;
+   pdata->incr_incrx = DWC_ETH_QOS_INCR_ENABLE;
+   pdata->flow_ctrl = DWC_ETH_QOS_FLOW_CTRL_TX_RX;
+   pdata->oldflow_ctrl = DWC_ETH_QOS_FLOW_CTRL_TX_RX;
+   pdata->power_state = DWC_ETH_QOS_POWER_ON;
+   pdata->tx_sa_ctrl_via_desc = DWC_ETH_QOS_SA0_NONE;
+   pdata->tx_sa_ctrl_via_reg = DWC_ETH_QOS_SA0_NONE;
+   pdata->hwts_tx_en = 0;
+   pdata->hwts_rx_en = 0;
+   pdata->l3_l4_filter = 0;
+   pdata->l2_filtering_mode = !!pdata->hw_feat.hash_tbl_sz;
+   pdata->tx_path_in_lpi_mode = 0;
+   pdata->use_lpi_tx_automate = true;
+   pdata->eee_active = 0;
+   pdata->one_nsec_accuracy = 1;
+   pdata->rx_napi_pending = false;
+
+   DBGPR("<--DWC_ETH_QOS_default_common_confs\n");
 }
 
-
 /*!
  * \brief api to initialize Tx parameters.
  *
@@ -1313,33 +1360,31 @@ static void DWC_ETH_QOS_default_common_c
  *
  * \return void
  */
-
 static void DWC_ETH_QOS_default_tx_confs_single_q(
-		struct DWC_ETH_QOS_prv_data *pdata,
-		uint32_t qInx)
+      struct DWC_ETH_QOS_prv_data *pdata,
+      uint32_t qInx)
 {
-	struct DWC_ETH_QOS_tx_queue *queue_data = GET_TX_QUEUE_PTR(qInx);
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
-		GET_TX_WRAPPER_DESC(qInx);
-
-	DBGPR("-->DWC_ETH_QOS_default_tx_confs_single_q\n");
-
-	queue_data->q_op_mode = q_op_mode[qInx];
-
-	desc_data->tx_threshold_val = DWC_ETH_QOS_TX_THRESHOLD_32;
-	desc_data->tsf_on = DWC_ETH_QOS_TSF_ENABLE;
-	desc_data->osf_on = DWC_ETH_QOS_OSF_ENABLE;
-	desc_data->tx_pbl = DWC_ETH_QOS_PBL_16;
-	desc_data->tx_vlan_tag_via_reg = Y_FALSE;
-	desc_data->tx_vlan_tag_ctrl = DWC_ETH_QOS_TX_VLAN_TAG_INSERT;
-	desc_data->vlan_tag_present = 0;
-	desc_data->context_setup = 0;
-	desc_data->default_mss = 0;
-
-	DBGPR("<--DWC_ETH_QOS_default_tx_confs_single_q\n");
+   struct DWC_ETH_QOS_tx_queue *queue_data = GET_TX_QUEUE_PTR(qInx);
+   struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
+      GET_TX_WRAPPER_DESC(qInx);
+
+   DBGPR("-->DWC_ETH_QOS_default_tx_confs_single_q\n");
+
+   queue_data->q_op_mode = q_op_mode[qInx];
+
+   desc_data->tx_threshold_val = DWC_ETH_QOS_TX_THRESHOLD_32;
+   desc_data->tsf_on = DWC_ETH_QOS_TSF_ENABLE;
+   desc_data->osf_on = DWC_ETH_QOS_OSF_ENABLE;
+   desc_data->tx_pbl = DWC_ETH_QOS_PBL_16;
+   desc_data->tx_vlan_tag_via_reg = Y_FALSE;
+   desc_data->tx_vlan_tag_ctrl = DWC_ETH_QOS_TX_VLAN_TAG_INSERT;
+   desc_data->vlan_tag_present = 0;
+   desc_data->context_setup = 0;
+   desc_data->default_mss = 0;
+
+   DBGPR("<--DWC_ETH_QOS_default_tx_confs_single_q\n");
 }
 
-
 /*!
  * \brief api to initialize Rx parameters.
  *
@@ -1351,76 +1396,75 @@ static void DWC_ETH_QOS_default_tx_confs
  *
  * \return void
  */
-
 static void DWC_ETH_QOS_default_rx_confs_single_q(
-		struct DWC_ETH_QOS_prv_data *pdata,
-		uint32_t qInx)
+      struct DWC_ETH_QOS_prv_data *pdata,
+      uint32_t qInx)
 {
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
-		GET_RX_WRAPPER_DESC(qInx);
-
-	DBGPR("-->DWC_ETH_QOS_default_rx_confs_single_q\n");
-
-	desc_data->rx_threshold_val = DWC_ETH_QOS_RX_THRESHOLD_64;
-	desc_data->rsf_on = DWC_ETH_QOS_RSF_DISABLE;
-	desc_data->rx_pbl = DWC_ETH_QOS_PBL_16;
-	desc_data->rx_outer_vlan_strip = DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS;
-	desc_data->rx_inner_vlan_strip = DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS;
-
-	DBGPR("<--DWC_ETH_QOS_default_rx_confs_single_q\n");
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
+      GET_RX_WRAPPER_DESC(qInx);
+
+   DBGPR("-->DWC_ETH_QOS_default_rx_confs_single_q\n");
+
+   desc_data->rx_threshold_val = DWC_ETH_QOS_RX_THRESHOLD_64;
+   desc_data->rsf_on = DWC_ETH_QOS_RSF_DISABLE;
+   desc_data->rx_pbl = DWC_ETH_QOS_PBL_16;
+   desc_data->rx_outer_vlan_strip = DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS;
+   desc_data->rx_inner_vlan_strip = DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS;
+
+   DBGPR("<--DWC_ETH_QOS_default_rx_confs_single_q\n");
 }
 
 static void DWC_ETH_QOS_default_tx_confs(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	uint32_t qInx;
-
-	DBGPR("-->DWC_ETH_QOS_default_tx_confs\n");
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		DWC_ETH_QOS_default_tx_confs_single_q(pdata, qInx);
-	}
-
-	DBGPR("<--DWC_ETH_QOS_default_tx_confs\n");
+   uint32_t qInx;
+
+   DBGPR("-->DWC_ETH_QOS_default_tx_confs\n");
+
+   for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
+      DWC_ETH_QOS_default_tx_confs_single_q(pdata, qInx);
+   }
+
+   DBGPR("<--DWC_ETH_QOS_default_tx_confs\n");
 }
 
 static void DWC_ETH_QOS_default_rx_confs(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	uint32_t qInx;
-
-	DBGPR("-->DWC_ETH_QOS_default_rx_confs\n");
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
-		DWC_ETH_QOS_default_rx_confs_single_q(pdata, qInx);
-	}
-
-	DBGPR("<--DWC_ETH_QOS_default_rx_confs\n");
+   uint32_t qInx;
+
+   DBGPR("-->DWC_ETH_QOS_default_rx_confs\n");
+
+   for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
+      DWC_ETH_QOS_default_rx_confs_single_q(pdata, qInx);
+   }
+
+   DBGPR("<--DWC_ETH_QOS_default_rx_confs\n");
 }
 
 enum hrtimer_restart rx_itr_timeout(struct hrtimer *timer)
 {
-	struct DWC_ETH_QOS_prv_data *pdata;
-	pdata = container_of(timer, struct DWC_ETH_QOS_prv_data, rx_itr_timer);
-	DBGPR("-->rx_itr_timeout\n");
-	/* Schedule TX NAPI to start polling */
-	if (likely(napi_schedule_prep(&pdata->rx_napi))) {
-		__napi_schedule(&pdata->rx_napi);
-	}
-	DBGPR("<--rx_itr_timeout\n");
-	return HRTIMER_NORESTART;
+   struct DWC_ETH_QOS_prv_data *pdata;
+   pdata = container_of(timer, struct DWC_ETH_QOS_prv_data, rx_itr_timer);
+   DBGPR("-->rx_itr_timeout\n");
+   /* Schedule TX NAPI to start polling */
+   if (likely(napi_schedule_prep(&pdata->rx_napi))) {
+      __napi_schedule(&pdata->rx_napi);
+   }
+   DBGPR("<--rx_itr_timeout\n");
+   return HRTIMER_NORESTART;
 }
 
 #ifdef GBE_POLLING
 enum hrtimer_restart gbe_timeout(struct hrtimer *timer)
 {
-	struct DWC_ETH_QOS_prv_data *pdata;
-	pdata = container_of(timer, struct DWC_ETH_QOS_prv_data, gbe_timer);
-	DBGPR("-->gbe_timeout irq(%d)\n", pdata->irq_number);
-	disable_irq(pdata->irq_number);
-	DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS(pdata->irq_number, pdata);
-	hrtimer_start(&pdata->gbe_timer, ktime_set(0, 100000), HRTIMER_MODE_REL);
-	enable_irq(pdata->irq_number);
-	DBGPR("<--gbe_timeout\n");
-	return HRTIMER_NORESTART;
+   struct DWC_ETH_QOS_prv_data *pdata;
+   pdata = container_of(timer, struct DWC_ETH_QOS_prv_data, gbe_timer);
+   DBGPR("-->gbe_timeout irq(%d)\n", pdata->irq_number);
+   disable_irq(pdata->irq_number);
+   DWC_ETH_QOS_ISR(pdata->irq_number, pdata);
+   hrtimer_start(&pdata->gbe_timer, ktime_set(0, 100000), HRTIMER_MODE_REL);
+   enable_irq(pdata->irq_number);
+   DBGPR("<--gbe_timeout\n");
+   return HRTIMER_NORESTART;
 }
 #endif
 
@@ -1438,110 +1482,99 @@ enum hrtimer_restart gbe_timeout(struct 
 *
 * \retval 0 on success & negative number on failure.
 */
-
 static int DWC_ETH_QOS_open(struct net_device *dev)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	int ret = Y_SUCCESS;
-	struct hw_if_struct *hw_if = &pdata->hw_if;
-	struct desc_if_struct *desc_if = &pdata->desc_if;
-
-	DBGPR("-->DWC_ETH_QOS_open (%d)\n", dev->irq);
-
-	pdata->irq_number = dev->irq;
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	ret = request_irq(pdata->irq_number, DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS_pg,
-			  IRQF_SHARED, DEV_NAME, pdata);
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   int ret = Y_SUCCESS;
+   hw_interface_t *hw_if = &pdata->hw_if;
+   struct desc_if_struct *desc_if = &pdata->desc_if;
+
+   CFG_PRINT("-->DWC_ETH_QOS_open (%d)\n", dev->irq);
+
+   if (pdata->power_state & DWC_ETH_QOS_NETIP_WAKEUP) {
+      WRN_PRINT("Atom GMAC is powered down!\n");
+      ret = -EBUSY;
+      goto err_irq_0;
+   }
+
+   pdata->irq_number = dev->irq;
+   ret = request_irq(pdata->irq_number, DWC_ETH_QOS_ISR,
+           0, DEV_NAME, pdata);
+
+   if (ret != 0) {
+      printk(KERN_ALERT "Unable to register IRQ %d\n", pdata->irq_number);
+      ret = -EBUSY;
+      goto err_irq_0;
+   }
+
+   ret = desc_if->alloc_buff_and_desc(pdata);
+   if (ret < 0) {
+      printk(KERN_ALERT
+             "failed to allocate buffer/descriptor memory\n");
+      ret = -ENOMEM;
+      goto err_out_desc_buf_alloc_failed;
+   }
+
+   /* default configuration */
+   DWC_ETH_QOS_default_common_confs(pdata);
+   DWC_ETH_QOS_default_tx_confs(pdata);
+   DWC_ETH_QOS_default_rx_confs(pdata);
+   DWC_ETH_QOS_configure_rx_fun_ptr(pdata);
+
+   DWC_ETH_QOS_napi_enable(pdata);
+
+   DWC_ETH_QOS_set_rx_mode(dev);
+   desc_if->wrapper_tx_desc_init(pdata);
+   desc_if->wrapper_rx_desc_init(pdata);
+
+#ifdef YDEBUG
+   DWC_ETH_QOS_tx_desc_mang_ds_dump(pdata);
+   DWC_ETH_QOS_rx_desc_mang_ds_dump(pdata);
+#endif
+
+   DWC_ETH_QOS_mmc_setup(pdata);
+
+   /* initializes MAC and DMA */
+   hw_if->init(pdata);
+
+   if (pdata->hw_feat.pcs_sel)
+      hw_if->control_an(1, 0);
+
+   if (pdata->phydev) {
+      phy_start(pdata->phydev);
+      pdata->eee_enabled = DWC_ETH_QOS_eee_init(pdata);
+   } else
+      pdata->eee_enabled = false;
+
+   if (pdata->mux_cfg == GMCR_GMAC5_TO_GMAC4) {
+      hw_if->set_full_duplex();
+      hw_if->set_speed(pdata, 5000);
+      netif_tx_start_all_queues(dev);
+   } else if (pdata->phydev) {
+      netif_tx_start_all_queues(dev);
+   }
+   hrtimer_init(&pdata->rx_itr_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
+   pdata->rx_itr_timer.function = rx_itr_timeout;
+
+#ifdef GBE_POLLING
+   hrtimer_init(&pdata->gbe_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
+   pdata->gbe_timer.function = gbe_timeout;
+   hrtimer_start(&pdata->gbe_timer, ktime_set(0, 10000), HRTIMER_MODE_REL);
 #else
-	ret = request_irq(pdata->irq_number, DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS,
-			  0, DEV_NAME, pdata);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-	if (ret != 0) {
-		printk(KERN_ALERT "Unable to register IRQ %d\n",
-		       pdata->irq_number);
-		ret = -EBUSY;
-		goto err_irq_0;
-	}
-
-	ret = desc_if->alloc_buff_and_desc(pdata);
-	if (ret < 0) {
-		printk(KERN_ALERT
-		       "failed to allocate buffer/descriptor memory\n");
-		ret = -ENOMEM;
-		goto err_out_desc_buf_alloc_failed;
-	}
-
-	/* default configuration */
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	DWC_ETH_QOS_default_confs(pdata);
-#else
-	DWC_ETH_QOS_default_common_confs(pdata);
-	DWC_ETH_QOS_default_tx_confs(pdata);
-	DWC_ETH_QOS_default_rx_confs(pdata);
-	DWC_ETH_QOS_configure_rx_fun_ptr(pdata);
-
-	DWC_ETH_QOS_napi_enable(pdata);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
-	DWC_ETH_QOS_set_rx_mode(dev);
-	desc_if->wrapper_tx_desc_init(pdata);
-	desc_if->wrapper_rx_desc_init(pdata);
-
-#ifdef YDEBUG
-	DWC_ETH_QOS_tx_desc_mang_ds_dump(pdata);
-	DWC_ETH_QOS_rx_desc_mang_ds_dump(pdata);
+   netss_interrupt_enable(NETSS_INTERUPT_GBE);
 #endif
 
-	DWC_ETH_QOS_mmc_setup(pdata);
-
-	/* initializes MAC and DMA */
-	hw_if->init(pdata);
-
-	if (pdata->hw_feat.pcs_sel)
-		hw_if->control_an(1, 0);
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	hw_if->prepare_dev_pktgen(pdata);
-#endif
-
-	if (pdata->phydev) {
-		phy_start(pdata->phydev);
-		pdata->eee_enabled = DWC_ETH_QOS_eee_init(pdata);
-	} else
-		pdata->eee_enabled = false;
-
-#ifndef DWC_ETH_QOS_CONFIG_PGTEST
-	if (pdata->mux_cfg == GMCR_GMAC5_TO_GMAC4) {
-		hw_if->set_full_duplex();
-		hw_if->set_speed(pdata, 5000);
-		netif_tx_start_all_queues(dev);
-	} else if (pdata->phydev) {
-		netif_tx_start_all_queues(dev);
-	}
-	hrtimer_init(&pdata->rx_itr_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
-	pdata->rx_itr_timer.function = rx_itr_timeout;
-#ifdef GBE_POLLING
-	hrtimer_init(&pdata->gbe_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
-	pdata->gbe_timer.function = gbe_timeout;
-	hrtimer_start(&pdata->gbe_timer, ktime_set(0, 10000), HRTIMER_MODE_REL);
-#else
-	netss_interrupt_enable(NETSS_INTERUPT_GBE);
-#endif
-#else
-	netif_tx_disable(dev);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
-	DBGPR("<--DWC_ETH_QOS_open\n");
-
-	return ret;
+   CFG_PRINT("<--DWC_ETH_QOS_open\n");
+
+   return ret;
 
  err_out_desc_buf_alloc_failed:
-	free_irq(pdata->irq_number, pdata);
-	pdata->irq_number = 0;
+   free_irq(pdata->irq_number, pdata);
+   pdata->irq_number = 0;
 
  err_irq_0:
-	DBGPR("<--DWC_ETH_QOS_open\n");
-	return ret;
+   CFG_PRINT("<--DWC_ETH_QOS_open\n");
+   return ret;
 }
 
 /*!
@@ -1556,48 +1589,55 @@ static int DWC_ETH_QOS_open(struct net_d
 *
 * \retval 0 on success & negative number on failure.
 */
-
 static int DWC_ETH_QOS_close(struct net_device *dev)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &pdata->hw_if;
-	struct desc_if_struct *desc_if = &pdata->desc_if;
-
-	DBGPR("-->DWC_ETH_QOS_close\n");
-	netss_interrupt_disable(NETSS_INTERUPT_GBE);
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &pdata->hw_if;
+   struct desc_if_struct *desc_if = &pdata->desc_if;
+
+   CFG_PRINT("-->DWC_ETH_QOS_close\n");
+
+   if (pdata->power_state & DWC_ETH_QOS_NETIP_WAKEUP) {
+      WRN_PRINT("Atom GMAC is powered down!\n");
+      /* Attach net device before stop so it can be
+         restarted when power is up */
+      netif_device_attach(dev);
+   } else {
+      netss_interrupt_disable(NETSS_INTERUPT_GBE);
 #ifdef GBE_POLLING
-	hrtimer_cancel(&pdata->gbe_timer);
+      hrtimer_cancel(&pdata->gbe_timer);
 #endif
 
-	if (pdata->eee_enabled)
-		del_timer_sync(&pdata->eee_ctrl_timer);
-
-	if (pdata->phydev)
-		phy_stop(pdata->phydev);
-
-#ifndef DWC_ETH_QOS_CONFIG_PGTEST
-	netif_tx_disable(dev);
-	DWC_ETH_QOS_napi_disable(pdata);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
-	/* issue software reset to device */
-	hw_if->exit();
-	desc_if->tx_free_mem(pdata);
-	desc_if->rx_free_mem(pdata);
-	if (pdata->irq_number != 0) {
-		free_irq(pdata->irq_number, pdata);
-		pdata->irq_number = 0;
-	}
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	del_timer(&pdata->pg_timer);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
-	DBGPR("<--DWC_ETH_QOS_close\n");
-
-	return Y_SUCCESS;
+      if (pdata->phydev)
+         phy_stop(pdata->phydev);
+
+      hrtimer_cancel(&pdata->rx_itr_timer);
+      netif_tx_disable(dev);
+      DWC_ETH_QOS_napi_disable(pdata);
+
+      /* Stop DMA TX/RX */
+      DWC_ETH_QOS_stop_all_ch_tx_dma(pdata);
+      DWC_ETH_QOS_stop_all_ch_rx_dma(pdata);
+
+      /* issue software reset to device */
+      hw_if->sw_reset();
+   }
+
+   if (pdata->eee_enabled)
+      del_timer_sync(&pdata->eee_ctrl_timer);
+
+   desc_if->tx_free_mem(pdata);
+   desc_if->rx_free_mem(pdata);
+   if (pdata->irq_number != 0) {
+      free_irq(pdata->irq_number, pdata);
+      pdata->irq_number = 0;
+   }
+
+   CFG_PRINT("<--DWC_ETH_QOS_close\n");
+
+   return Y_SUCCESS;
 }
 
-
 /*!
 * \brief API to configure the multicast address in device.
 *
@@ -1611,98 +1651,98 @@ static int DWC_ETH_QOS_close(struct net_
 */
 static int DWC_ETH_QOS_prepare_mc_list(struct net_device *dev)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t mc_filter[DWC_ETH_QOS_HTR_CNT];
-	struct netdev_hw_addr *ha = NULL;
-	int crc32_val = 0;
-	int ret = 0, i = 1;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_prepare_mc_list\n");
-
-	if (pdata->l2_filtering_mode) {
-		DBGPR_FILTER("select HASH FILTERING for mc addresses: mc_count = %d\n",
-				netdev_mc_count(dev));
-		ret = 1;
-		memset(mc_filter, 0, sizeof(mc_filter));
-
-		if (pdata->max_hash_table_size == 64) {
-			netdev_for_each_mc_addr(ha, dev) {
-				DBGPR_FILTER("mc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
-						ha->addr[0], ha->addr[1], ha->addr[2],
-						ha->addr[3], ha->addr[4], ha->addr[5]);
-				/* The upper 6 bits of the calculated CRC are used to
-				 * index the content of the Hash Table Reg 0 and 1.
-				 * */
-				crc32_val =
-					(bitrev32(~crc32_le(~0, ha->addr, 6)) >> 26);
-				/* The most significant bit determines the register
-				 * to use (Hash Table Reg X, X = 0 and 1) while the
-				 * other 5(0x1F) bits determines the bit within the
-				 * selected register
-				 * */
-				mc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-			}
-		} else if (pdata->max_hash_table_size == 128) {
-			netdev_for_each_mc_addr(ha, dev) {
-				DBGPR_FILTER("mc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
-						ha->addr[0], ha->addr[1], ha->addr[2],
-						ha->addr[3], ha->addr[4], ha->addr[5]);
-				/* The upper 7 bits of the calculated CRC are used to
-				 * index the content of the Hash Table Reg 0,1,2 and 3.
-				 * */
-				crc32_val =
-					(bitrev32(~crc32_le(~0, ha->addr, 6)) >> 25);
-
-				printk(KERN_ALERT "crc_le = %#x, crc_be = %#x\n",
-						bitrev32(~crc32_le(~0, ha->addr, 6)),
-						bitrev32(~crc32_be(~0, ha->addr, 6)));
-
-				/* The most significant 2 bits determines the register
-				 * to use (Hash Table Reg X, X = 0,1,2 and 3) while the
-				 * other 5(0x1F) bits determines the bit within the
-				 * selected register
-				 * */
-				mc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-			}
-		} else if (pdata->max_hash_table_size == 256) {
-			netdev_for_each_mc_addr(ha, dev) {
-				DBGPR_FILTER("mc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
-						ha->addr[0], ha->addr[1], ha->addr[2],
-						ha->addr[3], ha->addr[4], ha->addr[5]);
-				/* The upper 8 bits of the calculated CRC are used to
-				 * index the content of the Hash Table Reg 0,1,2,3,4,
-				 * 5,6, and 7.
-				 * */
-				crc32_val =
-					(bitrev32(~crc32_le(~0, ha->addr, 6)) >> 24);
-				/* The most significant 3 bits determines the register
-				 * to use (Hash Table Reg X, X = 0,1,2,3,4,5,6 and 7) while
-				 * the other 5(0x1F) bits determines the bit within the
-				 * selected register
-				 * */
-				mc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-			}
-		}
-
-		for (i = 0; i < DWC_ETH_QOS_HTR_CNT; i++)
-			hw_if->update_hash_table_reg(i, mc_filter[i]);
-
-	} else {
-		DBGPR_FILTER("select PERFECT FILTERING for mc addresses, mc_count = %d, max_addr_reg_cnt = %d\n",
-				netdev_mc_count(dev), pdata->max_addr_reg_cnt);
-		i  = 0;
-		netdev_for_each_mc_addr(ha, dev) {
-			DBGPR_FILTER("mc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n", i + 1,
-					ha->addr[0], ha->addr[1], ha->addr[2],
-					ha->addr[3], ha->addr[4], ha->addr[5]);
-			hw_if->update_mac_addr(i++, ha->addr);
-		}
-	}
-
-	DBGPR_FILTER("<--DWC_ETH_QOS_prepare_mc_list\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t mc_filter[DWC_ETH_QOS_HTR_CNT];
+   struct netdev_hw_addr *ha = NULL;
+   int crc32_val = 0;
+   int ret = 0, i = 1;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_prepare_mc_list\n");
+
+   if (pdata->l2_filtering_mode) {
+      DBGPR_FILTER("select HASH FILTERING for mc addresses: mc_count = %d\n",
+            netdev_mc_count(dev));
+      ret = 1;
+      memset(mc_filter, 0, sizeof(mc_filter));
+
+      if (pdata->max_hash_table_size == 64) {
+         netdev_for_each_mc_addr(ha, dev) {
+            DBGPR_FILTER("mc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
+                  ha->addr[0], ha->addr[1], ha->addr[2],
+                  ha->addr[3], ha->addr[4], ha->addr[5]);
+            /* The upper 6 bits of the calculated CRC are used to
+             * index the content of the Hash Table Reg 0 and 1.
+             * */
+            crc32_val =
+               (bitrev32(~crc32_le(~0, ha->addr, 6)) >> 26);
+            /* The most significant bit determines the register
+             * to use (Hash Table Reg X, X = 0 and 1) while the
+             * other 5(0x1F) bits determines the bit within the
+             * selected register
+             * */
+            mc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+         }
+      } else if (pdata->max_hash_table_size == 128) {
+         netdev_for_each_mc_addr(ha, dev) {
+            DBGPR_FILTER("mc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
+                  ha->addr[0], ha->addr[1], ha->addr[2],
+                  ha->addr[3], ha->addr[4], ha->addr[5]);
+            /* The upper 7 bits of the calculated CRC are used to
+             * index the content of the Hash Table Reg 0,1,2 and 3.
+             * */
+            crc32_val =
+               (bitrev32(~crc32_le(~0, ha->addr, 6)) >> 25);
+
+            printk(KERN_ALERT "crc_le = %#x, crc_be = %#x\n",
+                  bitrev32(~crc32_le(~0, ha->addr, 6)),
+                  bitrev32(~crc32_be(~0, ha->addr, 6)));
+
+            /* The most significant 2 bits determines the register
+             * to use (Hash Table Reg X, X = 0,1,2 and 3) while the
+             * other 5(0x1F) bits determines the bit within the
+             * selected register
+             * */
+            mc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+         }
+      } else if (pdata->max_hash_table_size == 256) {
+         netdev_for_each_mc_addr(ha, dev) {
+            DBGPR_FILTER("mc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
+                  ha->addr[0], ha->addr[1], ha->addr[2],
+                  ha->addr[3], ha->addr[4], ha->addr[5]);
+            /* The upper 8 bits of the calculated CRC are used to
+             * index the content of the Hash Table Reg 0,1,2,3,4,
+             * 5,6, and 7.
+             * */
+            crc32_val =
+               (bitrev32(~crc32_le(~0, ha->addr, 6)) >> 24);
+            /* The most significant 3 bits determines the register
+             * to use (Hash Table Reg X, X = 0,1,2,3,4,5,6 and 7) while
+             * the other 5(0x1F) bits determines the bit within the
+             * selected register
+             * */
+            mc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+         }
+      }
+
+      for (i = 0; i < DWC_ETH_QOS_HTR_CNT; i++)
+         hw_if->update_hash_table_reg(i, mc_filter[i]);
+
+   } else {
+      DBGPR_FILTER("select PERFECT FILTERING for mc addresses, mc_count = %d, max_addr_reg_cnt = %d\n",
+            netdev_mc_count(dev), pdata->max_addr_reg_cnt);
+      i  = 0;
+      netdev_for_each_mc_addr(ha, dev) {
+         DBGPR_FILTER("mc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n", i + 1,
+               ha->addr[0], ha->addr[1], ha->addr[2],
+               ha->addr[3], ha->addr[4], ha->addr[5]);
+         hw_if->update_mac_addr(i++, ha->addr);
+      }
+   }
+
+   DBGPR_FILTER("<--DWC_ETH_QOS_prepare_mc_list\n");
+
+   return ret;
 }
 
 /*!
@@ -1718,88 +1758,88 @@ static int DWC_ETH_QOS_prepare_mc_list(s
 */
 static int DWC_ETH_QOS_prepare_uc_list(struct net_device *dev)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t uc_filter[DWC_ETH_QOS_HTR_CNT];
-	struct netdev_hw_addr *ha = NULL;
-	int crc32_val = 0;
-	int ret = 0, i = 1;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_prepare_uc_list\n");
-
-	if (pdata->l2_filtering_mode) {
-		DBGPR_FILTER("select HASH FILTERING for uc addresses: uc_count = %d\n",
-				netdev_uc_count(dev));
-		ret = 1;
-		memset(uc_filter, 0, sizeof(uc_filter));
-
-		if (pdata->max_hash_table_size == 64) {
-			netdev_for_each_uc_addr(ha, dev) {
-				DBGPR_FILTER("uc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
-						ha->addr[0], ha->addr[1], ha->addr[2],
-						ha->addr[3], ha->addr[4], ha->addr[5]);
-				crc32_val =
-					(bitrev32(~crc32_le(~0, ha->addr, 6)) >> 26);
-				uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-			}
-		} else if (pdata->max_hash_table_size == 128) {
-			netdev_for_each_uc_addr(ha, dev) {
-				DBGPR_FILTER("uc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
-						ha->addr[0], ha->addr[1], ha->addr[2],
-						ha->addr[3], ha->addr[4], ha->addr[5]);
-				crc32_val =
-					(bitrev32(~crc32_le(~0, ha->addr, 6)) >> 25);
-				uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-			}
-		} else if (pdata->max_hash_table_size == 256) {
-			netdev_for_each_uc_addr(ha, dev) {
-				DBGPR_FILTER("uc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
-						ha->addr[0], ha->addr[1], ha->addr[2],
-						ha->addr[3], ha->addr[4], ha->addr[5]);
-				crc32_val =
-					(bitrev32(~crc32_le(~0, ha->addr, 6)) >> 24);
-				uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-			}
-		}
-
-		/* configure hash value of real/default interface also */
-		DBGPR_FILTER("real/default dev_addr = %#x:%#x:%#x:%#x:%#x:%#x\n",
-				dev->dev_addr[0], dev->dev_addr[1], dev->dev_addr[2],
-				dev->dev_addr[3], dev->dev_addr[4], dev->dev_addr[5]);
-
-		if (pdata->max_hash_table_size == 64) {
-			crc32_val =
-				(bitrev32(~crc32_le(~0, dev->dev_addr, 6)) >> 26);
-			uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-		} else if (pdata->max_hash_table_size == 128) {
-			crc32_val =
-				(bitrev32(~crc32_le(~0, dev->dev_addr, 6)) >> 25);
-			uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-
-		} else if (pdata->max_hash_table_size == 256) {
-			crc32_val =
-				(bitrev32(~crc32_le(~0, dev->dev_addr, 6)) >> 24);
-			uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
-		}
-
-		for (i = 0; i < DWC_ETH_QOS_HTR_CNT; i++)
-			hw_if->update_hash_table_reg(i, uc_filter[i]);
-
-	} else {
-		DBGPR_FILTER("select PERFECT FILTERING for uc addresses: uc_count = %d\n",
-				netdev_uc_count(dev));
-		i = 0;
-		netdev_for_each_uc_addr(ha, dev) {
-			DBGPR_FILTER("uc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n", i,
-					ha->addr[0], ha->addr[1], ha->addr[2],
-					ha->addr[3], ha->addr[4], ha->addr[5]);
-			hw_if->update_mac_addr(i++, ha->addr);
-		}
-	}
-
-	DBGPR_FILTER("<--DWC_ETH_QOS_prepare_uc_list\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t uc_filter[DWC_ETH_QOS_HTR_CNT];
+   struct netdev_hw_addr *ha = NULL;
+   int crc32_val = 0;
+   int ret = 0, i = 1;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_prepare_uc_list\n");
+
+   if (pdata->l2_filtering_mode) {
+      DBGPR_FILTER("select HASH FILTERING for uc addresses: uc_count = %d\n",
+            netdev_uc_count(dev));
+      ret = 1;
+      memset(uc_filter, 0, sizeof(uc_filter));
+
+      if (pdata->max_hash_table_size == 64) {
+         netdev_for_each_uc_addr(ha, dev) {
+            DBGPR_FILTER("uc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
+                  ha->addr[0], ha->addr[1], ha->addr[2],
+                  ha->addr[3], ha->addr[4], ha->addr[5]);
+            crc32_val =
+               (bitrev32(~crc32_le(~0, ha->addr, 6)) >> 26);
+            uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+         }
+      } else if (pdata->max_hash_table_size == 128) {
+         netdev_for_each_uc_addr(ha, dev) {
+            DBGPR_FILTER("uc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
+                  ha->addr[0], ha->addr[1], ha->addr[2],
+                  ha->addr[3], ha->addr[4], ha->addr[5]);
+            crc32_val =
+               (bitrev32(~crc32_le(~0, ha->addr, 6)) >> 25);
+            uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+         }
+      } else if (pdata->max_hash_table_size == 256) {
+         netdev_for_each_uc_addr(ha, dev) {
+            DBGPR_FILTER("uc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n",i++,
+                  ha->addr[0], ha->addr[1], ha->addr[2],
+                  ha->addr[3], ha->addr[4], ha->addr[5]);
+            crc32_val =
+               (bitrev32(~crc32_le(~0, ha->addr, 6)) >> 24);
+            uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+         }
+      }
+
+      /* configure hash value of real/default interface also */
+      DBGPR_FILTER("real/default dev_addr = %#x:%#x:%#x:%#x:%#x:%#x\n",
+            dev->dev_addr[0], dev->dev_addr[1], dev->dev_addr[2],
+            dev->dev_addr[3], dev->dev_addr[4], dev->dev_addr[5]);
+
+      if (pdata->max_hash_table_size == 64) {
+         crc32_val =
+            (bitrev32(~crc32_le(~0, dev->dev_addr, 6)) >> 26);
+         uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+      } else if (pdata->max_hash_table_size == 128) {
+         crc32_val =
+            (bitrev32(~crc32_le(~0, dev->dev_addr, 6)) >> 25);
+         uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+
+      } else if (pdata->max_hash_table_size == 256) {
+         crc32_val =
+            (bitrev32(~crc32_le(~0, dev->dev_addr, 6)) >> 24);
+         uc_filter[crc32_val >> 5] |= (1 << (crc32_val & 0x1F));
+      }
+
+      for (i = 0; i < DWC_ETH_QOS_HTR_CNT; i++)
+         hw_if->update_hash_table_reg(i, uc_filter[i]);
+
+   } else {
+      DBGPR_FILTER("select PERFECT FILTERING for uc addresses: uc_count = %d\n",
+            netdev_uc_count(dev));
+      i = 0;
+      netdev_for_each_uc_addr(ha, dev) {
+         DBGPR_FILTER("uc addr[%d] = %#x:%#x:%#x:%#x:%#x:%#x\n", i,
+               ha->addr[0], ha->addr[1], ha->addr[2],
+               ha->addr[3], ha->addr[4], ha->addr[5]);
+         hw_if->update_mac_addr(i++, ha->addr);
+      }
+   }
+
+   DBGPR_FILTER("<--DWC_ETH_QOS_prepare_uc_list\n");
+
+   return ret;
 }
 
 /*!
@@ -1814,79 +1854,73 @@ static int DWC_ETH_QOS_prepare_uc_list(s
 */
 static void DWC_ETH_QOS_set_rx_mode(struct net_device *dev)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	unsigned long flags;
-	unsigned char pr_mode = 0;
-	unsigned char huc_mode = 0;
-	unsigned char hmc_mode = 0;
-	unsigned char pm_mode = 0;
-	unsigned char hpf_mode = 0;
-	int mode, i;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_set_rx_mode\n");
-
-	spin_lock_irqsave(&pdata->lock, flags);
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	DBGPR("PG Test running, no parameters will be changed\n");
-	spin_unlock_irqrestore(&pdata->lock, flags);
-	return;
-#endif
-
-	if (dev->flags & IFF_PROMISC) {
-		DBGPR_FILTER("PROMISCUOUS MODE (Accept all packets irrespective of DA)\n");
-		pr_mode = 1;
-	} else if ((dev->flags & IFF_ALLMULTI) ||
-			(netdev_mc_count(dev) > (pdata->max_hash_table_size))) {
-		DBGPR_FILTER("pass all multicast pkt\n");
-		pm_mode = 1;
-		if (pdata->max_hash_table_size) {
-			for (i = 0; i < DWC_ETH_QOS_HTR_CNT; i++)
-				hw_if->update_hash_table_reg(i, 0xffffffff);
-		}
-	} else if (!netdev_mc_empty(dev)) {
-		DBGPR_FILTER("pass list of multicast pkt\n");
-		if ((netdev_mc_count(dev) > (pdata->max_addr_reg_cnt - 1)) &&
-			(!pdata->max_hash_table_size)) {
-			/* switch to PROMISCUOUS mode */
-			pr_mode = 1;
-		} else {
-			mode = DWC_ETH_QOS_prepare_mc_list(dev);
-			if (mode) {
-				/* Hash filtering for multicast */
-				hmc_mode = 1;
-			} else {
-				/* Perfect filtering for multicast */
-				hmc_mode = 0;
-				hpf_mode = 1;
-			}
-		}
-	}
-
-	/* Handle multiple unicast addresses */
-	if ((netdev_uc_count(dev) > (pdata->max_addr_reg_cnt - 1)) &&
-			(!pdata->max_hash_table_size)) {
-		/* switch to PROMISCUOUS mode */
-		pr_mode = 1;
-	} else if (!netdev_uc_empty(dev)) {
-		mode = DWC_ETH_QOS_prepare_uc_list(dev);
-		if (mode) {
-			/* Hash filtering for unicast */
-			huc_mode = 1;
-		} else {
-			/* Perfect filtering for unicast */
-			huc_mode = 0;
-			hpf_mode = 1;
-		}
-	}
-
-	hw_if->config_mac_pkt_filter_reg(pr_mode, huc_mode,
-		hmc_mode, pm_mode, hpf_mode);
-
-	spin_unlock_irqrestore(&pdata->lock, flags);
-
-	DBGPR("<--DWC_ETH_QOS_set_rx_mode\n");
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   unsigned long flags;
+   unsigned char pr_mode = 0;
+   unsigned char huc_mode = 0;
+   unsigned char hmc_mode = 0;
+   unsigned char pm_mode = 0;
+   unsigned char hpf_mode = 0;
+   int mode, i;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_set_rx_mode\n");
+
+   spin_lock_irqsave(&pdata->lock, flags);
+
+   if (dev->flags & IFF_PROMISC) {
+      DBGPR_FILTER("PROMISCUOUS MODE (Accept all packets irrespective of DA)\n");
+      pr_mode = 1;
+   } else if ((dev->flags & IFF_ALLMULTI) ||
+         (netdev_mc_count(dev) > (pdata->max_hash_table_size))) {
+      DBGPR_FILTER("pass all multicast pkt\n");
+      pm_mode = 1;
+      if (pdata->max_hash_table_size) {
+         for (i = 0; i < DWC_ETH_QOS_HTR_CNT; i++)
+            hw_if->update_hash_table_reg(i, 0xffffffff);
+      }
+   } else if (!netdev_mc_empty(dev)) {
+      DBGPR_FILTER("pass list of multicast pkt\n");
+      if ((netdev_mc_count(dev) > (pdata->max_addr_reg_cnt - 1)) &&
+         (!pdata->max_hash_table_size)) {
+         /* switch to PROMISCUOUS mode */
+         pr_mode = 1;
+      } else {
+         mode = DWC_ETH_QOS_prepare_mc_list(dev);
+         if (mode) {
+            /* Hash filtering for multicast */
+            hmc_mode = 1;
+         } else {
+            /* Perfect filtering for multicast */
+            hmc_mode = 0;
+            hpf_mode = 1;
+         }
+      }
+   }
+
+   /* Handle multiple unicast addresses */
+   if ((netdev_uc_count(dev) > (pdata->max_addr_reg_cnt - 1)) &&
+         (!pdata->max_hash_table_size)) {
+      /* switch to PROMISCUOUS mode */
+      pr_mode = 1;
+   } else if (!netdev_uc_empty(dev)) {
+      mode = DWC_ETH_QOS_prepare_uc_list(dev);
+      if (mode) {
+         /* Hash filtering for unicast */
+         huc_mode = 1;
+      } else {
+         /* Perfect filtering for unicast */
+         huc_mode = 0;
+         hpf_mode = 1;
+      }
+   }
+
+   hw_if->config_mac_pkt_filter_reg(pr_mode, huc_mode,
+      hmc_mode, pm_mode, hpf_mode);
+
+   spin_unlock_irqrestore(&pdata->lock, flags);
+
+   DBGPR("<--DWC_ETH_QOS_set_rx_mode\n");
 }
 
 /*!
@@ -1903,64 +1937,63 @@ static void DWC_ETH_QOS_set_rx_mode(stru
 *
 * \retval number of descriptor required.
 */
-
 uint32_t DWC_ETH_QOS_get_total_desc_cnt(struct DWC_ETH_QOS_prv_data *pdata,
-		struct sk_buff *skb, uint32_t qInx)
+      struct sk_buff *skb, uint32_t qInx)
 {
-	uint32_t count = 0, size = 0;
-	int length = 0;
-	struct hw_if_struct *hw_if = &pdata->hw_if;
-	tx_pkt_features_t *tx_pkt_features = &pdata->tx_pkt_features;
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
-	    GET_TX_WRAPPER_DESC(qInx);
-
-	/* SG fragment count */
-	count += skb_shinfo(skb)->nr_frags;
-
-	/* descriptors required based on data limit per descriptor */
-	length = (skb->len - skb->data_len);
-	while (length) {
-		size = min(length, DWC_ETH_QOS_MAX_DATA_PER_TXD);
-		count++;
-		length = length - size;
-	}
-
-	/* we need one context descriptor to carry tso details */
-	if (skb_shinfo(skb)->gso_size != 0)
-		count++;
+   uint32_t count = 0, size = 0;
+   int length = 0;
+   hw_interface_t *hw_if = &pdata->hw_if;
+   tx_pkt_features_t *tx_pkt_features = &pdata->tx_pkt_features;
+   struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
+       GET_TX_WRAPPER_DESC(qInx);
+
+   /* SG fragment count */
+   count += skb_shinfo(skb)->nr_frags;
+
+   /* descriptors required based on data limit per descriptor */
+   length = (skb->len - skb->data_len);
+   while (length) {
+      size = min(length, DWC_ETH_QOS_MAX_DATA_PER_TXD);
+      count++;
+      length = length - size;
+   }
+
+   /* we need one context descriptor to carry tso details */
+   if (skb_shinfo(skb)->gso_size != 0)
+      count++;
 
 #ifdef DWC_ETH_QOS_ENABLE_VLAN_TAG
-	desc_data->vlan_tag_present = 0;
-	if (vlan_tx_tag_present(skb)) {
-		uint16_t vlan_tag = vlan_tx_tag_get(skb);
-		vlan_tag |= (qInx << 13);
-		desc_data->vlan_tag_present = 1;
-		if (vlan_tag != desc_data->vlan_tag_id ||
-				desc_data->context_setup == 1) {
-			desc_data->vlan_tag_id = vlan_tag;
-			if (Y_TRUE == desc_data->tx_vlan_tag_via_reg) {
-				printk(KERN_ALERT "VLAN control info update via register\n\n");
-				hw_if->enable_vlan_reg_control(desc_data);
-			} else {
-				hw_if->enable_vlan_desc_control(pdata);
-				VAR32_SET_BIT(tx_pkt_features->pkt_attributes,
-					TX_PKT_FEATURES_ATTR_VLAN_PKT, 1);
-				tx_pkt_features->vlan_tag = vlan_tag;
-				/* we need one context descriptor to carry vlan tag info */
-				count++;
-			}
-		}
-		pdata->xstats.tx_vlan_pkt_n++;
-	}
+   desc_data->vlan_tag_present = 0;
+   if (vlan_tx_tag_present(skb)) {
+      uint16_t vlan_tag = vlan_tx_tag_get(skb);
+      vlan_tag |= (qInx << 13);
+      desc_data->vlan_tag_present = 1;
+      if (vlan_tag != desc_data->vlan_tag_id ||
+            desc_data->context_setup == 1) {
+         desc_data->vlan_tag_id = vlan_tag;
+         if (Y_TRUE == desc_data->tx_vlan_tag_via_reg) {
+            printk(KERN_ALERT "VLAN control info update via register\n\n");
+            hw_if->enable_vlan_reg_control(desc_data);
+         } else {
+            hw_if->enable_vlan_desc_control(pdata);
+            VAR32_SET_BIT(tx_pkt_features->pkt_attributes,
+               TX_PKT_FEATURES_ATTR_VLAN_PKT, 1);
+            tx_pkt_features->vlan_tag = vlan_tag;
+            /* we need one context descriptor to carry vlan tag info */
+            count++;
+         }
+      }
+      pdata->xstats.tx_vlan_pkt_n++;
+   }
 #endif
 #ifdef DWC_ETH_QOS_ENABLE_DVLAN
-	if (pdata->via_reg_or_desc == DWC_ETH_QOS_VIA_DESC) {
-		/* we need one context descriptor to carry vlan tag info */
-		count++;
-	}
+   if (pdata->via_reg_or_desc == DWC_ETH_QOS_VIA_DESC) {
+      /* we need one context descriptor to carry vlan tag info */
+      count++;
+   }
 #endif /* End of DWC_ETH_QOS_ENABLE_DVLAN */
 
-	return count;
+   return count;
 }
 
 /*!
@@ -1979,201 +2012,196 @@ uint32_t DWC_ETH_QOS_get_total_desc_cnt(
 */
 static int DWC_ETH_QOS_start_xmit(struct sk_buff *skb, struct net_device *dev)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	uint32_t qInx = skb_get_queue_mapping(skb);
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
-	    GET_TX_WRAPPER_DESC(qInx);
-	tx_pkt_features_t *tx_pkt_features = &pdata->tx_pkt_features;
-	unsigned long flags;
-	unsigned int desc_count = 0;
-	unsigned int count = 0;
-	struct hw_if_struct *hw_if = &pdata->hw_if;
-	struct desc_if_struct *desc_if = &pdata->desc_if;
-	int retval = NETDEV_TX_OK;
-	int tso;
-
-	DBGPR("-->DWC_ETH_QOS_start_xmit: skb->len = %d, qInx = %u, tx_pkt_queued(%d)\n",
-		skb->len, qInx, desc_data->tx_pkt_queued);
-
-	spin_lock_irqsave(&pdata->tx_lock, flags);
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	retval = NETDEV_TX_BUSY;
-	goto tx_netdev_return;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   uint32_t qInx = skb_get_queue_mapping(skb);
+   struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
+       GET_TX_WRAPPER_DESC(qInx);
+   tx_pkt_features_t *tx_pkt_features = &pdata->tx_pkt_features;
+   unsigned long flags;
+   unsigned int desc_count = 0;
+   unsigned int count = 0;
+   hw_interface_t *hw_if = &pdata->hw_if;
+   struct desc_if_struct *desc_if = &pdata->desc_if;
+   int retval = NETDEV_TX_OK;
+   int tso;
+
+   DBGPR("-->DWC_ETH_QOS_start_xmit: skb->len = %d, qInx = %u, tx_pkt_queued(%d)\n",
+      skb->len, qInx, desc_data->tx_pkt_queued);
+
+   spin_lock_irqsave(&pdata->tx_lock, flags);
+
+   if (skb->len <= 0) {
+      dev_kfree_skb_any(skb);
+      printk(KERN_ERR "%s : Empty skb received from stack\n",
+         dev->name);
+      goto tx_netdev_return;
+   } else if ((skb_shinfo(skb)->gso_size == 0) &&
+      (skb->len > DWC_ETH_QOS_MAX_SUPPORTED_MTU)) {
+      printk(KERN_ERR "%s : big packet = %d\n", dev->name, skb->len);
+      dev_kfree_skb_any(skb);
+      dev->stats.tx_dropped++;
+      goto tx_netdev_return;
+   }
+#ifdef GBE_DEBUG
+   if (metadata_on_crc) {
+      if (replace_crc(skb)) {
+         printk(KERN_ALERT "Failed replacing CRC on SKB!\n");
+         goto tx_netdev_return;
+      }
+   }
+   if (print_tx_pkts)
+      print_skb(skb, false);
 #endif
 
-	if (skb->len <= 0) {
-		dev_kfree_skb_any(skb);
-		printk(KERN_ERR "%s : Empty skb received from stack\n",
-			dev->name);
-		goto tx_netdev_return;
-	} else if ((skb_shinfo(skb)->gso_size == 0) &&
-		(skb->len > DWC_ETH_QOS_MAX_SUPPORTED_MTU)) {
-		printk(KERN_ERR "%s : big packet = %d\n", dev->name, skb->len);
-		dev_kfree_skb_any(skb);
-		dev->stats.tx_dropped++;
-		goto tx_netdev_return;
-	}
-#ifdef GBE_DEBUG
-	if (metadata_on_crc) {
-		if (replace_crc(skb)) {
-			printk(KERN_ALERT "Failed replacing CRC on SKB!\n");
-			goto tx_netdev_return;
-		}
-	}
-	if (print_tx_pkts)
-		print_skb(skb, false);
-#endif
-
-	if ((pdata->eee_enabled) && (pdata->tx_path_in_lpi_mode) &&
-		(!pdata->use_lpi_tx_automate))
-		DWC_ETH_QOS_disable_eee_mode(pdata);
-
-	memset(&pdata->tx_pkt_features, 0, sizeof(pdata->tx_pkt_features));
-
-	/* check total number of desc required for current xfer */
-	desc_count = DWC_ETH_QOS_get_total_desc_cnt(pdata, skb, qInx);
-	if (desc_data->free_desc_cnt < desc_count) {
-		desc_data->queue_stopped = 1;
-		netif_stop_subqueue(dev, qInx);
-		DBGPR("Stopped TX queue(%d) no enough space in queue\n", qInx);
-		retval = NETDEV_TX_BUSY;
-		goto tx_netdev_return;
-	}
-
-	/* check for hw tstamping */
-	if (pdata->hw_feat.tsstssel && pdata->hwts_tx_en) {
-		if(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP) {
-			/* declare that device is doing timestamping */
-			skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
-			VAR32_SET_BIT(tx_pkt_features->pkt_attributes,
-				TX_PKT_FEATURES_ATTR_PTP_ENABLE, 1);
-			DBGPR_PTP("Got PTP pkt to transmit [qInx = %d, cur_tx = %d]\n",
-				qInx, desc_data->cur_tx);
-		}
-	}
-
-	tso = desc_if->handle_tso(dev, skb);
-	if (tso < 0) {
-		printk(KERN_ALERT "Unable to handle TSO\n");
-		dev_kfree_skb_any(skb);
-		retval = NETDEV_TX_OK;
-		goto tx_netdev_return;
-	} else if (tso) {
-		pdata->xstats.tx_tso_pkt_n++;
-		VAR32_SET_BIT(tx_pkt_features->pkt_attributes,
-			TX_PKT_FEATURES_ATTR_TSO_ENABLE, 1);
-	} else if (skb->ip_summed == CHECKSUM_PARTIAL) {
-		VAR32_SET_BIT(tx_pkt_features->pkt_attributes,
-			TX_PKT_FEATURES_ATTR_CSUM_ENABLE, 1);
-	}
-
-	count = desc_if->map_tx_skb(dev, skb);
-	if (count == 0) {
-		dev_kfree_skb_any(skb);
-		retval = NETDEV_TX_OK;
-		goto tx_netdev_return;
-	}
-
-	dev->trans_start = jiffies;
-	desc_data->free_desc_cnt -= count;
-	desc_data->tx_pkt_queued += count;
-
-	/* fallback to software time stamping if core doesn't
-	 * support hardware time stamping */
-	if ((pdata->hw_feat.tsstssel == 0) || (pdata->hwts_tx_en == 0))
-		skb_tx_timestamp(skb);
-
-	/* configure required descriptor fields for transmission */
-	hw_if->pre_xmit(pdata, qInx);
+   if ((pdata->eee_enabled) && (pdata->tx_path_in_lpi_mode) &&
+      (!pdata->use_lpi_tx_automate))
+      DWC_ETH_QOS_disable_eee_mode(pdata);
+
+   memset(&pdata->tx_pkt_features, 0, sizeof(pdata->tx_pkt_features));
+
+   /* check total number of desc required for current xfer */
+   desc_count = DWC_ETH_QOS_get_total_desc_cnt(pdata, skb, qInx);
+   if (desc_data->free_desc_cnt < desc_count) {
+      desc_data->queue_stopped = 1;
+      netif_stop_subqueue(dev, qInx);
+      DBGPR("Stopped TX queue(%d) no enough space in queue\n", qInx);
+      retval = NETDEV_TX_BUSY;
+      goto tx_netdev_return;
+   }
+
+   /* check for hw tstamping */
+   if (pdata->hw_feat.tsstssel && pdata->hwts_tx_en) {
+      if(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP) {
+         /* declare that device is doing timestamping */
+         skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
+         VAR32_SET_BIT(tx_pkt_features->pkt_attributes,
+            TX_PKT_FEATURES_ATTR_PTP_ENABLE, 1);
+         DBGPR_PTP("Got PTP pkt to transmit [qInx = %d, cur_tx = %d]\n",
+            qInx, desc_data->cur_tx);
+      }
+   }
+
+   tso = desc_if->handle_tso(dev, skb);
+   if (tso < 0) {
+      printk(KERN_ALERT "Unable to handle TSO\n");
+      dev_kfree_skb_any(skb);
+      retval = NETDEV_TX_OK;
+      goto tx_netdev_return;
+   } else if (tso) {
+      pdata->xstats.tx_tso_pkt_n++;
+      VAR32_SET_BIT(tx_pkt_features->pkt_attributes,
+         TX_PKT_FEATURES_ATTR_TSO_ENABLE, 1);
+   } else if (skb->ip_summed == CHECKSUM_PARTIAL) {
+      VAR32_SET_BIT(tx_pkt_features->pkt_attributes,
+         TX_PKT_FEATURES_ATTR_CSUM_ENABLE, 1);
+   }
+
+   count = desc_if->map_tx_skb(dev, skb);
+   if (count == 0) {
+      dev_kfree_skb_any(skb);
+      retval = NETDEV_TX_OK;
+      goto tx_netdev_return;
+   }
+
+   dev->trans_start = jiffies;
+   desc_data->free_desc_cnt -= count;
+   desc_data->tx_pkt_queued += count;
+
+   /* fallback to software time stamping if core doesn't
+    * support hardware time stamping */
+   if ((pdata->hw_feat.tsstssel == 0) || (pdata->hwts_tx_en == 0))
+      skb_tx_timestamp(skb);
+
+   /* configure required descriptor fields for transmission */
+   hw_if->pre_xmit(pdata, qInx);
 
 tx_netdev_return:
-	spin_unlock_irqrestore(&pdata->tx_lock, flags);
-
-	DBGPR("<--DWC_ETH_QOS_start_xmit\n");
-
-	return retval;
+   spin_unlock_irqrestore(&pdata->tx_lock, flags);
+
+   DBGPR("<--DWC_ETH_QOS_start_xmit\n");
+
+   return retval;
 }
 
 static void DWC_ETH_QOS_print_rx_tstamp_info(rx_descriptor_t *rxdesc,
-	unsigned int qInx)
+   unsigned int qInx)
 {
-	uint32_t ptp_status = 0;
-	uint32_t pkt_type = 0;
-	char *tstamp_dropped = NULL;
-	char *tstamp_available = NULL;
-	char *ptp_version = NULL;
-	char *ptp_pkt_type = NULL;
-	char *ptp_msg_type = NULL;
-
-	DBGPR_PTP("-->DWC_ETH_QOS_print_rx_tstamp_info\n");
-
-	/* status in RDES1 is not valid */
-	if (!(rxdesc->RDES3 & DWC_ETH_QOS_RDESC3_RS1V))
-		return;
-
-	ptp_status = rxdesc->RDES1;
-	tstamp_dropped = ((ptp_status & 0x8000) ? "YES" : "NO");
-	tstamp_available = ((ptp_status & 0x4000) ? "YES" : "NO");
-	ptp_version = ((ptp_status & 0x2000) ? "v2 (1588-2008)" : "v1 (1588-2002)");
-	ptp_pkt_type = ((ptp_status & 0x1000) ? "ptp over Eth" : "ptp over IPv4/6");
-
-	pkt_type = ((ptp_status & 0xF00) > 8);
-	switch (pkt_type) {
-	case 0:
-		ptp_msg_type = "NO PTP msg received";
-		break;
-	case 1:
-		ptp_msg_type = "SYNC";
-		break;
-	case 2:
-		ptp_msg_type = "Follow_Up";
-		break;
-	case 3:
-		ptp_msg_type = "Delay_Req";
-		break;
-	case 4:
-		ptp_msg_type = "Delay_Resp";
-		break;
-	case 5:
-		ptp_msg_type = "Pdelay_Req";
-		break;
-	case 6:
-		ptp_msg_type = "Pdelay_Resp";
-		break;
-	case 7:
-		ptp_msg_type = "Pdelay_Resp_Follow_up";
-		break;
-	case 8:
-		ptp_msg_type = "Announce";
-		break;
-	case 9:
-		ptp_msg_type = "Management";
-		break;
-	case 10:
-		ptp_msg_type = "Signaling";
-		break;
-	case 11:
-	case 12:
-	case 13:
-	case 14:
-		ptp_msg_type = "Reserved";
-		break;
-	case 15:
-		ptp_msg_type = "PTP pkr with Reserved Msg Type";
-		break;
-	}
-
-	DBGPR_PTP("Rx timestamp detail for queue %d\n"
-			"tstamp dropped    = %s\n"
-			"tstamp available  = %s\n"
-			"PTP version       = %s\n"
-			"PTP Pkt Type      = %s\n"
-			"PTP Msg Type      = %s\n",
-			qInx, tstamp_dropped, tstamp_available,
-			ptp_version, ptp_pkt_type, ptp_msg_type);
-
-	DBGPR_PTP("<--DWC_ETH_QOS_print_rx_tstamp_info\n");
+   uint32_t ptp_status = 0;
+   uint32_t pkt_type = 0;
+   char *tstamp_dropped = NULL;
+   char *tstamp_available = NULL;
+   char *ptp_version = NULL;
+   char *ptp_pkt_type = NULL;
+   char *ptp_msg_type = NULL;
+
+   DBGPR_PTP("-->DWC_ETH_QOS_print_rx_tstamp_info\n");
+
+   /* status in RDES1 is not valid */
+   if (!(rxdesc->RDES3 & DWC_ETH_QOS_RDESC3_RS1V))
+      return;
+
+   ptp_status = rxdesc->RDES1;
+   tstamp_dropped = ((ptp_status & 0x8000) ? "YES" : "NO");
+   tstamp_available = ((ptp_status & 0x4000) ? "YES" : "NO");
+   ptp_version = ((ptp_status & 0x2000) ? "v2 (1588-2008)" : "v1 (1588-2002)");
+   ptp_pkt_type = ((ptp_status & 0x1000) ? "ptp over Eth" : "ptp over IPv4/6");
+
+   pkt_type = ((ptp_status & 0xF00) > 8);
+   switch (pkt_type) {
+   case 0:
+      ptp_msg_type = "NO PTP msg received";
+      break;
+   case 1:
+      ptp_msg_type = "SYNC";
+      break;
+   case 2:
+      ptp_msg_type = "Follow_Up";
+      break;
+   case 3:
+      ptp_msg_type = "Delay_Req";
+      break;
+   case 4:
+      ptp_msg_type = "Delay_Resp";
+      break;
+   case 5:
+      ptp_msg_type = "Pdelay_Req";
+      break;
+   case 6:
+      ptp_msg_type = "Pdelay_Resp";
+      break;
+   case 7:
+      ptp_msg_type = "Pdelay_Resp_Follow_up";
+      break;
+   case 8:
+      ptp_msg_type = "Announce";
+      break;
+   case 9:
+      ptp_msg_type = "Management";
+      break;
+   case 10:
+      ptp_msg_type = "Signaling";
+      break;
+   case 11:
+   case 12:
+   case 13:
+   case 14:
+      ptp_msg_type = "Reserved";
+      break;
+   case 15:
+      ptp_msg_type = "PTP pkr with Reserved Msg Type";
+      break;
+   }
+
+   DBGPR_PTP("Rx timestamp detail for queue %d\n"
+         "tstamp dropped    = %s\n"
+         "tstamp available  = %s\n"
+         "PTP version       = %s\n"
+         "PTP Pkt Type      = %s\n"
+         "PTP Msg Type      = %s\n",
+         qInx, tstamp_dropped, tstamp_available,
+         ptp_version, ptp_pkt_type, ptp_msg_type);
+
+   DBGPR_PTP("<--DWC_ETH_QOS_print_rx_tstamp_info\n");
 }
 
 /*!
@@ -2194,70 +2222,69 @@ static void DWC_ETH_QOS_print_rx_tstamp_
 * \retval 2 if time stamp is corrupted
 */
 static unsigned char DWC_ETH_QOS_get_rx_hwtstamp(
-	struct DWC_ETH_QOS_prv_data *pdata,
-	struct sk_buff *skb,
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data,
-	unsigned int qInx)
+   struct DWC_ETH_QOS_prv_data *pdata,
+   struct sk_buff *skb,
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data,
+   unsigned int qInx)
 {
-	rx_descriptor_t *rx_normal_desc =
-		GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
-	rx_descriptor_t *rx_context_desc = NULL;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct skb_shared_hwtstamps *shhwtstamp = NULL;
-	uint64_t ns;
-	int retry, ret;
-
-	DBGPR_PTP("-->DWC_ETH_QOS_get_rx_hwtstamp\n");
-
-	DWC_ETH_QOS_print_rx_tstamp_info(rx_normal_desc, qInx);
-
-	desc_data->dirty_rx++;
-	INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
-	rx_context_desc = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
-
-	DBGPR_PTP("\nRX_CONTEX_DESC[%d %4p %d RECEIVED FROM DEVICE]"\
-			" = %#x:%#x:%#x:%#x",
-			qInx, rx_context_desc, desc_data->cur_rx, rx_context_desc->RDES0,
-			rx_context_desc->RDES1,
-			rx_context_desc->RDES2, rx_context_desc->RDES3);
-
-	/* check rx tsatmp */
-	for (retry = 0; retry < 10; retry++) {
-		ret = hw_if->get_rx_tstamp_status(rx_context_desc);
-		if (ret == 1) {
-			/* time stamp is valid */
-			break;
-		} else if (ret == 0) {
-			printk(KERN_ALERT "Device has not yet updated the context "
-				"desc to hold Rx time stamp(retry = %d)\n", retry);
-		} else {
-			printk(KERN_ALERT "Error: Rx time stamp is corrupted(retry = %d)\n", retry);
-			return 2;
-		}
-	}
-
-	if (retry == 10) {
-			printk(KERN_ALERT "Device has not yet updated the context "
-				"desc to hold Rx time stamp(retry = %d)\n", retry);
-			desc_data->dirty_rx--;
-			DECR_RX_DESC_INDEX(desc_data->cur_rx);
-			return 0;
-	}
-
-	pdata->xstats.rx_timestamp_captured_n++;
-	/* get valid tstamp */
-	ns = hw_if->get_rx_tstamp(rx_context_desc);
-
-	shhwtstamp = skb_hwtstamps(skb);
-	memset(shhwtstamp, 0, sizeof(struct skb_shared_hwtstamps));
-	shhwtstamp->hwtstamp = ns_to_ktime(ns);
-
-	DBGPR_PTP("<--DWC_ETH_QOS_get_rx_hwtstamp\n");
-
-	return 1;
+   rx_descriptor_t *rx_normal_desc =
+      GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
+   rx_descriptor_t *rx_context_desc = NULL;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct skb_shared_hwtstamps *shhwtstamp = NULL;
+   uint64_t ns;
+   int retry, ret;
+
+   DBGPR_PTP("-->DWC_ETH_QOS_get_rx_hwtstamp\n");
+
+   DWC_ETH_QOS_print_rx_tstamp_info(rx_normal_desc, qInx);
+
+   desc_data->dirty_rx++;
+   INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
+   rx_context_desc = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
+
+   DBGPR_PTP("\nRX_CONTEX_DESC[%d %4p %d RECEIVED FROM DEVICE]"\
+         " = %#x:%#x:%#x:%#x",
+         qInx, rx_context_desc, desc_data->cur_rx, rx_context_desc->RDES0,
+         rx_context_desc->RDES1,
+         rx_context_desc->RDES2, rx_context_desc->RDES3);
+
+   /* check rx tsatmp */
+   for (retry = 0; retry < 10; retry++) {
+      ret = hw_if->get_rx_tstamp_status(rx_context_desc);
+      if (ret == 1) {
+         /* time stamp is valid */
+         break;
+      } else if (ret == 0) {
+         printk(KERN_ALERT "Device has not yet updated the context "
+            "desc to hold Rx time stamp(retry = %d)\n", retry);
+      } else {
+         printk(KERN_ALERT "Error: Rx time stamp is corrupted(retry = %d)\n", retry);
+         return 2;
+      }
+   }
+
+   if (retry == 10) {
+         printk(KERN_ALERT "Device has not yet updated the context "
+            "desc to hold Rx time stamp(retry = %d)\n", retry);
+         desc_data->dirty_rx--;
+         DECR_RX_DESC_INDEX(desc_data->cur_rx);
+         return 0;
+   }
+
+   pdata->xstats.rx_timestamp_captured_n++;
+   /* get valid tstamp */
+   ns = hw_if->get_rx_tstamp(rx_context_desc);
+
+   shhwtstamp = skb_hwtstamps(skb);
+   memset(shhwtstamp, 0, sizeof(struct skb_shared_hwtstamps));
+   shhwtstamp->hwtstamp = ns_to_ktime(ns);
+
+   DBGPR_PTP("<--DWC_ETH_QOS_get_rx_hwtstamp\n");
+
+   return 1;
 }
 
-
 /*!
 * \brief API to get tx time stamp value.
 *
@@ -2274,48 +2301,48 @@ static unsigned char DWC_ETH_QOS_get_rx_
 * \retval 0 if time stamp in not taken/valid
 */
 static unsigned int DWC_ETH_QOS_get_tx_hwtstamp(
-	struct DWC_ETH_QOS_prv_data *pdata,
-	tx_descriptor_t *txdesc,
-	struct sk_buff *skb)
+   struct DWC_ETH_QOS_prv_data *pdata,
+   tx_descriptor_t *txdesc,
+   struct sk_buff *skb)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct skb_shared_hwtstamps shhwtstamp;
-	uint64_t ns;
-
-	DBGPR_PTP("-->DWC_ETH_QOS_get_tx_hwtstamp\n");
-
-	if (hw_if->drop_tx_status_enabled() == 0) {
-		/* check tx tstamp status */
-		if (!hw_if->get_tx_tstamp_status(txdesc)) {
-			printk(KERN_ALERT "tx timestamp is not captured for this packet\n");
-			return 0;
-		}
-
-		/* get the valid tstamp */
-		ns = hw_if->get_tx_tstamp(txdesc);
-	} else {
-		/* drop tx status mode is enabled, hence read time
-		 * stamp from register instead of descriptor */
-
-		/* check tx tstamp status */
-		if (!hw_if->get_tx_tstamp_status_via_reg()) {
-			printk(KERN_ALERT "tx timestamp is not captured for this packet\n");
-			return 0;
-		}
-
-		/* get the valid tstamp */
-		ns = hw_if->get_tx_tstamp_via_reg();
-	}
-
-	pdata->xstats.tx_timestamp_captured_n++;
-	memset(&shhwtstamp, 0, sizeof(struct skb_shared_hwtstamps));
-	shhwtstamp.hwtstamp = ns_to_ktime(ns);
-	/* pass tstamp to stack */
-	skb_tstamp_tx(skb, &shhwtstamp);
-
-	DBGPR_PTP("<--DWC_ETH_QOS_get_tx_hwtstamp\n");
-
-	return 1;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct skb_shared_hwtstamps shhwtstamp;
+   uint64_t ns;
+
+   DBGPR_PTP("-->DWC_ETH_QOS_get_tx_hwtstamp\n");
+
+   if (hw_if->drop_tx_status_enabled() == 0) {
+      /* check tx tstamp status */
+      if (!hw_if->get_tx_tstamp_status(txdesc)) {
+         printk(KERN_ALERT "tx timestamp is not captured for this packet\n");
+         return 0;
+      }
+
+      /* get the valid tstamp */
+      ns = hw_if->get_tx_tstamp(txdesc);
+   } else {
+      /* drop tx status mode is enabled, hence read time
+       * stamp from register instead of descriptor */
+
+      /* check tx tstamp status */
+      if (!hw_if->get_tx_tstamp_status_via_reg()) {
+         printk(KERN_ALERT "tx timestamp is not captured for this packet\n");
+         return 0;
+      }
+
+      /* get the valid tstamp */
+      ns = hw_if->get_tx_tstamp_via_reg();
+   }
+
+   pdata->xstats.tx_timestamp_captured_n++;
+   memset(&shhwtstamp, 0, sizeof(struct skb_shared_hwtstamps));
+   shhwtstamp.hwtstamp = ns_to_ktime(ns);
+   /* pass tstamp to stack */
+   skb_tstamp_tx(skb, &shhwtstamp);
+
+   DBGPR_PTP("<--DWC_ETH_QOS_get_tx_hwtstamp\n");
+
+   return 1;
 }
 
 /*!
@@ -2332,256 +2359,256 @@ static unsigned int DWC_ETH_QOS_get_tx_h
 * \return void
 */
 static void DWC_ETH_QOS_tx_interrupt(struct net_device *dev,
-				     struct DWC_ETH_QOS_prv_data *pdata,
-				     uint32_t qInx)
+                 struct DWC_ETH_QOS_prv_data *pdata,
+                 uint32_t qInx)
 {
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
-	    GET_TX_WRAPPER_DESC(qInx);
-	tx_descriptor_t *txptr = NULL;
-	struct DWC_ETH_QOS_tx_buffer *buffer = NULL;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct desc_if_struct *desc_if = &(pdata->desc_if);
+   struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
+       GET_TX_WRAPPER_DESC(qInx);
+   tx_descriptor_t *txptr = NULL;
+   struct DWC_ETH_QOS_tx_buffer *buffer = NULL;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct desc_if_struct *desc_if = &(pdata->desc_if);
 #ifndef DWC_ETH_QOS_CERTIFICATION_PKTBURSTCNT
-	int err_incremented;
+   int err_incremented;
 #endif
-	unsigned int tstamp_taken = 0;
-	unsigned long flags;
-
-	DBGPR("-->DWC_ETH_QOS_tx_interrupt: desc_data->tx_pkt_queued = %d"
-		" dirty_tx = %d, qInx = %u\n",
-		desc_data->tx_pkt_queued, desc_data->dirty_tx, qInx);
-
-	spin_lock_irqsave(&pdata->tx_lock, flags);
-
-	pdata->xstats.tx_clean_n[qInx]++;
-	while (desc_data->tx_pkt_queued > 0) {
-		txptr = GET_TX_DESC_PTR(qInx, desc_data->dirty_tx);
-		buffer = GET_TX_BUF_PTR(qInx, desc_data->dirty_tx);
-		tstamp_taken = 0;
-
-		if (!hw_if->tx_complete(txptr))
-			break;
+   unsigned int tstamp_taken = 0;
+   unsigned long flags;
+
+   DBGPR("-->DWC_ETH_QOS_tx_interrupt: desc_data->tx_pkt_queued = %d"
+      " dirty_tx = %d, qInx = %u\n",
+      desc_data->tx_pkt_queued, desc_data->dirty_tx, qInx);
+
+   spin_lock_irqsave(&pdata->tx_lock, flags);
+
+   pdata->xstats.tx_clean_n[qInx]++;
+   while (desc_data->tx_pkt_queued > 0) {
+      txptr = GET_TX_DESC_PTR(qInx, desc_data->dirty_tx);
+      buffer = GET_TX_BUF_PTR(qInx, desc_data->dirty_tx);
+      tstamp_taken = 0;
+
+      if (!hw_if->tx_complete(txptr))
+         break;
 
 #ifdef GBE_DEBUG
-		PRINT_TX_DESC(txptr, NORMAL_WB);
+      PRINT_TX_DESC(txptr, NORMAL_WB);
 #endif
 
 #ifndef DWC_ETH_QOS_CERTIFICATION_PKTBURSTCNT
-		/* update the tx error if any by looking at last segment
-		 * for NORMAL descriptors
-		 * */
-		if ((hw_if->get_tx_desc_ls(txptr)) && !(hw_if->get_tx_desc_ctxt(txptr))) {
-			/* check whether skb support hw tstamp */
-			if (pdata->hw_feat.tsstssel && buffer->skb &&
-				(skb_shinfo(buffer->skb)->tx_flags & SKBTX_IN_PROGRESS)) {
-				tstamp_taken = DWC_ETH_QOS_get_tx_hwtstamp(pdata, txptr, buffer->skb);
-				if (tstamp_taken) {
-					DBGPR_PTP("passed tx timestamp to stack[qInx = %d, dirty_tx = %d]\n",
-						qInx, desc_data->dirty_tx);
-				}
-			}
-
-			err_incremented = 0;
-			if (hw_if->tx_window_error) {
-				if (hw_if->tx_window_error(txptr)) {
-					err_incremented = 1;
-					dev->stats.tx_window_errors++;
-				}
-			}
-			if (hw_if->tx_aborted_error) {
-				if (hw_if->tx_aborted_error(txptr)) {
-					err_incremented = 1;
-					dev->stats.tx_aborted_errors++;
-					if (hw_if->tx_handle_aborted_error)
-						hw_if->tx_handle_aborted_error(txptr);
-				}
-			}
-			if (hw_if->tx_carrier_lost_error) {
-				if (hw_if->tx_carrier_lost_error(txptr)) {
-					err_incremented = 1;
-					dev->stats.tx_carrier_errors++;
-				}
-			}
-			if (hw_if->tx_fifo_underrun) {
-				if (hw_if->tx_fifo_underrun(txptr)) {
-					err_incremented = 1;
-					dev->stats.tx_fifo_errors++;
-					if (hw_if->tx_update_fifo_threshold)
-						hw_if->tx_update_fifo_threshold(txptr);
-				}
-			}
-			if (hw_if->tx_get_collision_count)
-				dev->stats.collisions +=
-				    hw_if->tx_get_collision_count(txptr);
-
-			if (err_incremented == 1)
-				dev->stats.tx_errors++;
-
-			pdata->xstats.q_tx_pkt_n[qInx]++;
-			pdata->xstats.tx_pkt_n++;
-			dev->stats.tx_packets++;
-		}
+      /* update the tx error if any by looking at last segment
+       * for NORMAL descriptors
+       * */
+      if ((hw_if->get_tx_desc_ls(txptr)) && !(hw_if->get_tx_desc_ctxt(txptr))) {
+         /* check whether skb support hw tstamp */
+         if (pdata->hw_feat.tsstssel && buffer->skb &&
+            (skb_shinfo(buffer->skb)->tx_flags & SKBTX_IN_PROGRESS)) {
+            tstamp_taken = DWC_ETH_QOS_get_tx_hwtstamp(pdata, txptr, buffer->skb);
+            if (tstamp_taken) {
+               DBGPR_PTP("passed tx timestamp to stack[qInx = %d, dirty_tx = %d]\n",
+                  qInx, desc_data->dirty_tx);
+            }
+         }
+
+         err_incremented = 0;
+         if (hw_if->tx_window_error) {
+            if (hw_if->tx_window_error(txptr)) {
+               err_incremented = 1;
+               dev->stats.tx_window_errors++;
+            }
+         }
+         if (hw_if->tx_aborted_error) {
+            if (hw_if->tx_aborted_error(txptr)) {
+               err_incremented = 1;
+               dev->stats.tx_aborted_errors++;
+               if (hw_if->tx_handle_aborted_error)
+                  hw_if->tx_handle_aborted_error(txptr);
+            }
+         }
+         if (hw_if->tx_carrier_lost_error) {
+            if (hw_if->tx_carrier_lost_error(txptr)) {
+               err_incremented = 1;
+               dev->stats.tx_carrier_errors++;
+            }
+         }
+         if (hw_if->tx_fifo_underrun) {
+            if (hw_if->tx_fifo_underrun(txptr)) {
+               err_incremented = 1;
+               dev->stats.tx_fifo_errors++;
+               if (hw_if->tx_update_fifo_threshold)
+                  hw_if->tx_update_fifo_threshold(txptr);
+            }
+         }
+         if (hw_if->tx_get_collision_count)
+            dev->stats.collisions +=
+                hw_if->tx_get_collision_count(txptr);
+
+         if (err_incremented == 1)
+            dev->stats.tx_errors++;
+
+         pdata->xstats.q_tx_pkt_n[qInx]++;
+         pdata->xstats.tx_pkt_n++;
+         dev->stats.tx_packets++;
+      }
 #else
-		if ((hw_if->get_tx_desc_ls(txptr)) && !(hw_if->get_tx_desc_ctxt(txptr))) {
-			/* check whether skb support hw tstamp */
-			if (pdata->hw_feat.tsstssel && buffer->skb &&
-				(skb_shinfo(buffer->skb)->tx_flags & SKBTX_IN_PROGRESS)) {
-				tstamp_taken = DWC_ETH_QOS_get_tx_hwtstamp(pdata,
-					txptr, buffer->skb);
-				if (tstamp_taken) {
-					DBGPR_PTP("passed tx timestamp to stack[qInx = %d, dirty_tx = %d]\n",
-						qInx, desc_data->dirty_tx);
-				}
-			}
-		}
+      if ((hw_if->get_tx_desc_ls(txptr)) && !(hw_if->get_tx_desc_ctxt(txptr))) {
+         /* check whether skb support hw tstamp */
+         if (pdata->hw_feat.tsstssel && buffer->skb &&
+            (skb_shinfo(buffer->skb)->tx_flags & SKBTX_IN_PROGRESS)) {
+            tstamp_taken = DWC_ETH_QOS_get_tx_hwtstamp(pdata,
+               txptr, buffer->skb);
+            if (tstamp_taken) {
+               DBGPR_PTP("passed tx timestamp to stack[qInx = %d, dirty_tx = %d]\n",
+                  qInx, desc_data->dirty_tx);
+            }
+         }
+      }
 #endif
-		dev->stats.tx_bytes += buffer->len;
-		dev->stats.tx_bytes += buffer->len2;
-		desc_if->unmap_tx_skb(pdata, buffer);
-
-		/* reset the descriptor so that driver/host can reuse it */
-		hw_if->tx_desc_reset(desc_data->dirty_tx, pdata, qInx);
-
-		INCR_TX_DESC_INDEX(desc_data->dirty_tx, 1);
-		desc_data->free_desc_cnt++;
-		desc_data->tx_pkt_queued--;
-	}
-
-	if ((desc_data->queue_stopped == 1) && (desc_data->free_desc_cnt > 0)) {
-		desc_data->queue_stopped = 0;
-		netif_wake_subqueue(dev, qInx);
-	}
+      dev->stats.tx_bytes += buffer->len;
+      dev->stats.tx_bytes += buffer->len2;
+      desc_if->unmap_tx_skb(pdata, buffer);
+
+      /* reset the descriptor so that driver/host can reuse it */
+      hw_if->tx_desc_reset(desc_data->dirty_tx, pdata, qInx);
+
+      INCR_TX_DESC_INDEX(desc_data->dirty_tx, 1);
+      desc_data->free_desc_cnt++;
+      desc_data->tx_pkt_queued--;
+   }
+
+   if ((desc_data->queue_stopped == 1) && (desc_data->free_desc_cnt > 0)) {
+      desc_data->queue_stopped = 0;
+      netif_wake_subqueue(dev, qInx);
+   }
 #ifdef DWC_ETH_QOS_CERTIFICATION_PKTBURSTCNT
-	/* DMA has finished Transmitting data to MAC Tx-Fifo */
-	MAC_MCR_TE_UdfWr(1);
+   /* DMA has finished Transmitting data to MAC Tx-Fifo */
+   MAC_MCR_TE_UdfWr(1);
 #endif
 
-	if ((pdata->eee_enabled) && (!pdata->tx_path_in_lpi_mode) &&
-		(!pdata->use_lpi_tx_automate)) {
-		DWC_ETH_QOS_enable_eee_mode(pdata);
-		mod_timer(&pdata->eee_ctrl_timer,
-			DWC_ETH_QOS_LPI_TIMER(DWC_ETH_QOS_DEFAULT_LPI_TIMER));
-	}
-
-	spin_unlock_irqrestore(&pdata->tx_lock, flags);
-
-	DBGPR("<--DWC_ETH_QOS_tx_interrupt: desc_data->tx_pkt_queued = %d\n",
-	      desc_data->tx_pkt_queued);
+   if ((pdata->eee_enabled) && (!pdata->tx_path_in_lpi_mode) &&
+      (!pdata->use_lpi_tx_automate)) {
+      DWC_ETH_QOS_enable_eee_mode(pdata);
+      mod_timer(&pdata->eee_ctrl_timer,
+         DWC_ETH_QOS_LPI_TIMER(DWC_ETH_QOS_DEFAULT_LPI_TIMER));
+   }
+
+   spin_unlock_irqrestore(&pdata->tx_lock, flags);
+
+   DBGPR("<--DWC_ETH_QOS_tx_interrupt: desc_data->tx_pkt_queued = %d\n",
+         desc_data->tx_pkt_queued);
 }
 
 #ifdef YDEBUG_FILTER
 static void DWC_ETH_QOS_check_rx_filter_status(rx_descriptor_t *RX_NORMAL_DESC)
 {
-	uint32_t rdes2 = RX_NORMAL_DESC->RDES2;
-	uint32_t rdes3 = RX_NORMAL_DESC->RDES3;
-
-	/* Receive Status RDES2 Valid ? */
-	if ((rdes3 & 0x8000000) == 0x8000000) {
-		if ((rdes2 & 0x400) == 0x400)
-			printk(KERN_ALERT "ARP pkt received\n");
-		if ((rdes2 & 0x800) == 0x800)
-			printk(KERN_ALERT "ARP reply not generated\n");
-		if ((rdes2 & 0x8000) == 0x8000)
-			printk(KERN_ALERT "VLAN pkt passed VLAN filter\n");
-		if ((rdes2 & 0x10000) == 0x10000)
-			printk(KERN_ALERT "SA Address filter fail\n");
-		if ((rdes2 & 0x20000) == 0x20000)
-			printk(KERN_ALERT "DA Addess filter fail\n");
-		if ((rdes2 & 0x40000) == 0x40000)
-			printk(KERN_ALERT "pkt passed the HASH filter in MAC and HASH value = %#x\n",
-					(rdes2 >> 19) & 0xff);
-		if ((rdes2 & 0x8000000) == 0x8000000)
-			printk(KERN_ALERT "L3 filter(%d) Match\n", ((rdes2 >> 29) & 0x7));
-		if ((rdes2 & 0x10000000) == 0x10000000)
-			printk(KERN_ALERT "L4 filter(%d) Match\n", ((rdes2 >> 29) & 0x7));
-	}
+   uint32_t rdes2 = RX_NORMAL_DESC->RDES2;
+   uint32_t rdes3 = RX_NORMAL_DESC->RDES3;
+
+   /* Receive Status RDES2 Valid ? */
+   if ((rdes3 & 0x8000000) == 0x8000000) {
+      if ((rdes2 & 0x400) == 0x400)
+         printk(KERN_ALERT "ARP pkt received\n");
+      if ((rdes2 & 0x800) == 0x800)
+         printk(KERN_ALERT "ARP reply not generated\n");
+      if ((rdes2 & 0x8000) == 0x8000)
+         printk(KERN_ALERT "VLAN pkt passed VLAN filter\n");
+      if ((rdes2 & 0x10000) == 0x10000)
+         printk(KERN_ALERT "SA Address filter fail\n");
+      if ((rdes2 & 0x20000) == 0x20000)
+         printk(KERN_ALERT "DA Addess filter fail\n");
+      if ((rdes2 & 0x40000) == 0x40000)
+         printk(KERN_ALERT "pkt passed the HASH filter in MAC and HASH value = %#x\n",
+               (rdes2 >> 19) & 0xff);
+      if ((rdes2 & 0x8000000) == 0x8000000)
+         printk(KERN_ALERT "L3 filter(%d) Match\n", ((rdes2 >> 29) & 0x7));
+      if ((rdes2 & 0x10000000) == 0x10000000)
+         printk(KERN_ALERT "L4 filter(%d) Match\n", ((rdes2 >> 29) & 0x7));
+   }
 }
 #endif /* YDEBUG_FILTER */
 
 /* pass skb to upper layer */
 static void DWC_ETH_QOS_receive_skb(struct DWC_ETH_QOS_prv_data *pdata,
-				    struct net_device *dev, struct sk_buff *skb,
-				    uint32_t qInx)
+                struct net_device *dev, struct sk_buff *skb,
+                uint32_t qInx)
 {
-	struct DWC_ETH_QOS_rx_queue *rx_queue = GET_RX_QUEUE_PTR(qInx);
-
-	skb_record_rx_queue(skb, qInx);
-	skb->dev = dev;
-	skb->protocol = eth_type_trans(skb, dev);
-
-	if (dev->features & NETIF_F_GRO) {
-		napi_gro_receive(&pdata->rx_napi, skb);
-	} else if ((dev->features & NETIF_F_LRO) &&
-		(skb->ip_summed == CHECKSUM_UNNECESSARY)) {
-		lro_receive_skb(&rx_queue->lro_mgr, skb, (void *)pdata);
-		rx_queue->lro_flush_needed = 1;
-	} else {
-		netif_receive_skb(skb);
-	}
+   struct DWC_ETH_QOS_rx_queue *rx_queue = GET_RX_QUEUE_PTR(qInx);
+
+   skb_record_rx_queue(skb, qInx);
+   skb->dev = dev;
+   skb->protocol = eth_type_trans(skb, dev);
+
+   if (dev->features & NETIF_F_GRO) {
+      napi_gro_receive(&pdata->rx_napi, skb);
+   } else if ((dev->features & NETIF_F_LRO) &&
+      (skb->ip_summed == CHECKSUM_UNNECESSARY)) {
+      lro_receive_skb(&rx_queue->lro_mgr, skb, (void *)pdata);
+      rx_queue->lro_flush_needed = 1;
+   } else {
+      netif_receive_skb(skb);
+   }
 }
 
 static void DWC_ETH_QOS_consume_page(struct DWC_ETH_QOS_rx_buffer *buffer,
-				     struct sk_buff *skb,
-				     u16 length, u16 buf2_used)
+                 struct sk_buff *skb,
+                 u16 length, u16 buf2_used)
 {
-	buffer->page = NULL;
-	if (buf2_used)
-		buffer->page2 = NULL;
-	skb->len += length;
-	skb->data_len += length;
-	skb->truesize += length;
+   buffer->page = NULL;
+   if (buf2_used)
+      buffer->page2 = NULL;
+   skb->len += length;
+   skb->data_len += length;
+   skb->truesize += length;
 }
 
 static void DWC_ETH_QOS_consume_page_split_hdr(
-				struct DWC_ETH_QOS_rx_buffer *buffer,
-				struct sk_buff *skb,
-				u16 length,
-				uint16_t page2_used)
+            struct DWC_ETH_QOS_rx_buffer *buffer,
+            struct sk_buff *skb,
+            u16 length,
+            uint16_t page2_used)
 {
-	if (page2_used)
-		buffer->page2 = NULL;
-
-	skb->len += length;
-	skb->data_len += length;
-	skb->truesize += length;
+   if (page2_used)
+      buffer->page2 = NULL;
+
+   skb->len += length;
+   skb->data_len += length;
+   skb->truesize += length;
 }
 
 /* Receive Checksum Offload configuration */
 static inline void DWC_ETH_QOS_config_rx_csum(struct DWC_ETH_QOS_prv_data *pdata,
-		struct sk_buff *skb,
-		rx_descriptor_t *rx_normal_desc)
+      struct sk_buff *skb,
+      rx_descriptor_t *rx_normal_desc)
 {
-	skb->ip_summed = CHECKSUM_NONE;
-	if ((pdata->dev_state & NETIF_F_RXCSUM) == NETIF_F_RXCSUM) {
-		/* Receive Status RDES1 Valid ? */
-		if ((rx_normal_desc->RDES3 & DWC_ETH_QOS_RDESC3_RS1V)) {
-			/* check(RDES1.IPCE bit) whether device has done csum correctly or not */
-			if ((rx_normal_desc->RDES1 & 0xC8) == 0x0)
-				skb->ip_summed = CHECKSUM_UNNECESSARY;	/* csum done by device */
-		}
-	}
+   skb->ip_summed = CHECKSUM_NONE;
+   if ((pdata->dev_state & NETIF_F_RXCSUM) == NETIF_F_RXCSUM) {
+      /* Receive Status RDES1 Valid ? */
+      if ((rx_normal_desc->RDES3 & DWC_ETH_QOS_RDESC3_RS1V)) {
+         /* check(RDES1.IPCE bit) whether device has done csum correctly or not */
+         if ((rx_normal_desc->RDES1 & 0xC8) == 0x0)
+            skb->ip_summed = CHECKSUM_UNNECESSARY;   /* csum done by device */
+      }
+   }
 }
 
 static inline void DWC_ETH_QOS_get_rx_vlan(struct DWC_ETH_QOS_prv_data *pdata,
-			struct sk_buff *skb,
-			rx_descriptor_t *rx_normal_desc)
+         struct sk_buff *skb,
+         rx_descriptor_t *rx_normal_desc)
 {
-	uint16_t vlan_tag = 0;
-
-	if ((pdata->dev_state & NETIF_F_HW_VLAN_CTAG_RX) == NETIF_F_HW_VLAN_CTAG_RX) {
-		/* Receive Status RDES0 Valid ? */
-		if ((rx_normal_desc->RDES3 & DWC_ETH_QOS_RDESC3_RS0V)) {
-			/* device received frame with VLAN Tag or
-			 * double VLAN Tag ? */
-			if (((rx_normal_desc->RDES3 & DWC_ETH_QOS_RDESC3_LT) == 0x40000)
-				|| ((rx_normal_desc->RDES3 & DWC_ETH_QOS_RDESC3_LT) == 0x50000)) {
-				vlan_tag = rx_normal_desc->RDES0 & 0xffff;
-				/* insert VLAN tag into skb */
-				__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tag);
-				pdata->xstats.rx_vlan_pkt_n++;
-			}
-		}
-	}
+   uint16_t vlan_tag = 0;
+
+   if ((pdata->dev_state & NETIF_F_HW_VLAN_CTAG_RX) == NETIF_F_HW_VLAN_CTAG_RX) {
+      /* Receive Status RDES0 Valid ? */
+      if ((rx_normal_desc->RDES3 & DWC_ETH_QOS_RDESC3_RS0V)) {
+         /* device received frame with VLAN Tag or
+          * double VLAN Tag ? */
+         if (((rx_normal_desc->RDES3 & DWC_ETH_QOS_RDESC3_LT) == 0x40000)
+            || ((rx_normal_desc->RDES3 & DWC_ETH_QOS_RDESC3_LT) == 0x50000)) {
+            vlan_tag = rx_normal_desc->RDES0 & 0xffff;
+            /* insert VLAN tag into skb */
+            __vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tag);
+            pdata->xstats.rx_vlan_pkt_n++;
+         }
+      }
+   }
 }
 
 /* This api check for payload type and returns
@@ -2589,16 +2616,16 @@ static inline void DWC_ETH_QOS_get_rx_vl
  * */
 static int DWC_ETH_QOS_check_for_tcp_payload(rx_descriptor_t *rxdesc)
 {
-		uint32_t pt_type = 0;
-		int ret = 0;
-
-		if (rxdesc->RDES3 & DWC_ETH_QOS_RDESC3_RS1V) {
-				pt_type = rxdesc->RDES1 & DWC_ETH_QOS_RDESC1_PT;
-				if (pt_type == DWC_ETH_QOS_RDESC1_PT_TCP)
-						ret = 1;
-		}
-
-		return ret;
+      uint32_t pt_type = 0;
+      int ret = 0;
+
+      if (rxdesc->RDES3 & DWC_ETH_QOS_RDESC3_RS1V) {
+            pt_type = rxdesc->RDES1 & DWC_ETH_QOS_RDESC1_PT;
+            if (pt_type == DWC_ETH_QOS_RDESC1_PT_TCP)
+                  ret = 1;
+      }
+
+      return ret;
 }
 
 /*!
@@ -2620,266 +2647,266 @@ static int DWC_ETH_QOS_check_for_tcp_pay
 * \retval number of packets received.
 */
 static int DWC_ETH_QOS_clean_split_hdr_rx_irq(
-			struct DWC_ETH_QOS_prv_data *pdata,
-			int quota,
-			uint32_t qInx)
+         struct DWC_ETH_QOS_prv_data *pdata,
+         int quota,
+         uint32_t qInx)
 {
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
-	    GET_RX_WRAPPER_DESC(qInx);
-	struct net_device *dev = pdata->dev;
-	struct desc_if_struct *desc_if = &pdata->desc_if;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct sk_buff *skb = NULL;
-	int received = 0;
-	struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
-	rx_descriptor_t *RX_NORMAL_DESC = NULL;
-	u16 pkt_len;
-	unsigned short hdr_len = 0;
-	unsigned short payload_len = 0;
-	unsigned char intermediate_desc_cnt = 0;
-	unsigned char buf2_used = 0;
-	int ret;
-
-	DBGPR("-->DWC_ETH_QOS_clean_split_hdr_rx_irq: qInx = %u, quota = %d\n",
-		qInx, quota);
-
-	while (received < quota) {
-		buffer = GET_RX_BUF_PTR(qInx, desc_data->cur_rx);
-		RX_NORMAL_DESC = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
-
-		/* check for data availability */
-		if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_OWN)) {
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
+       GET_RX_WRAPPER_DESC(qInx);
+   struct net_device *dev = pdata->dev;
+   struct desc_if_struct *desc_if = &pdata->desc_if;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct sk_buff *skb = NULL;
+   int received = 0;
+   struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
+   rx_descriptor_t *RX_NORMAL_DESC = NULL;
+   u16 pkt_len;
+   unsigned short hdr_len = 0;
+   unsigned short payload_len = 0;
+   unsigned char intermediate_desc_cnt = 0;
+   unsigned char buf2_used = 0;
+   int ret;
+
+   DBGPR("-->DWC_ETH_QOS_clean_split_hdr_rx_irq: qInx = %u, quota = %d\n",
+      qInx, quota);
+
+   while (received < quota) {
+      buffer = GET_RX_BUF_PTR(qInx, desc_data->cur_rx);
+      RX_NORMAL_DESC = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
+
+      /* check for data availability */
+      if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_OWN)) {
 #ifdef DWC_ETH_QOS_ENABLE_RX_DESC_DUMP
-			dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
+         dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
 #endif
-			/* assign it to new skb */
-			skb = buffer->skb;
-			buffer->skb = NULL;
-
-			/* first buffer pointer */
-			dma_unmap_single(&pdata->pdev->dev, buffer->dma,
-				       (2*buffer->rx_hdr_size), DMA_FROM_DEVICE);
-			buffer->dma = 0;
-
-			/* second buffer pointer */
-			dma_unmap_page(&pdata->pdev->dev, buffer->dma2,
-				       PAGE_SIZE, DMA_FROM_DEVICE);
-			buffer->dma2 = 0;
-
-			/* get the packet length */
-			pkt_len =
-			    (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_PL);
-
-			/* FIRST desc and Receive Status RDES2 Valid ? */
-			if ((RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD) &&
-				(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_RS2V)) {
-				/* get header length */
-				hdr_len = (RX_NORMAL_DESC->RDES2 & DWC_ETH_QOS_RDESC2_HL);
-				DBGPR("Device has %s HEADER SPLIT: hdr_len = %d\n",
-						(hdr_len ? "done" : "not done"), hdr_len);
-				if (hdr_len)
-					pdata->xstats.rx_split_hdr_pkt_n++;
-			}
-
-			/* check for bad packet,
-			 * error is valid only for last descriptor(OWN + LD bit set).
-			 * */
-			if ((RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_ES) &&
-			    (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
-				DBGPR("Error in rcved pkt, failed to pass it to upper layer\n");
+         /* assign it to new skb */
+         skb = buffer->skb;
+         buffer->skb = NULL;
+
+         /* first buffer pointer */
+         dma_unmap_single(&pdata->pdev->dev, buffer->dma,
+                   (2*buffer->rx_hdr_size), DMA_FROM_DEVICE);
+         buffer->dma = 0;
+
+         /* second buffer pointer */
+         dma_unmap_page(&pdata->pdev->dev, buffer->dma2,
+                   PAGE_SIZE, DMA_FROM_DEVICE);
+         buffer->dma2 = 0;
+
+         /* get the packet length */
+         pkt_len =
+             (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_PL);
+
+         /* FIRST desc and Receive Status RDES2 Valid ? */
+         if ((RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD) &&
+            (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_RS2V)) {
+            /* get header length */
+            hdr_len = (RX_NORMAL_DESC->RDES2 & DWC_ETH_QOS_RDESC2_HL);
+            DBGPR("Device has %s HEADER SPLIT: hdr_len = %d\n",
+                  (hdr_len ? "done" : "not done"), hdr_len);
+            if (hdr_len)
+               pdata->xstats.rx_split_hdr_pkt_n++;
+         }
+
+         /* check for bad packet,
+          * error is valid only for last descriptor(OWN + LD bit set).
+          * */
+         if ((RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_ES) &&
+             (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
+            DBGPR("Error in rcved pkt, failed to pass it to upper layer\n");
 #ifdef DWC_ETH_QOS_ENABLE_RX_DESC_DUMP
-				dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
+            dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
 #endif
-				dev->stats.rx_errors++;
-				DWC_ETH_QOS_update_rx_errors(dev,
-					RX_NORMAL_DESC->RDES3);
-
-				/* recycle both page/buff and skb */
-				buffer->skb = skb;
-				if (desc_data->skb_top)
-					dev_kfree_skb_any(desc_data->skb_top);
-
-				desc_data->skb_top = NULL;
-				goto next_desc;
-			}
-
-			if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
-				intermediate_desc_cnt++;
-				buf2_used = 1;
-				/* this descriptor is only the beginning/middle */
-				if (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD) {
-					/* this is the beginning of a chain */
-
-					/* here skb/skb_top may contain
-					 * if (device done split header)
-					 *	only header
-					 * else
-					 *	header/(header + payload)
-					 * */
-					desc_data->skb_top = skb;
-					/* page2 always contain only payload */
-					if (hdr_len) {
-						/* add header len to first skb->len */
-						skb_put(skb, hdr_len);
-						payload_len = pdata->rx_buffer_len;
-						skb_fill_page_desc(skb, 0,
-							buffer->page2, 0,
-							payload_len);
-					} else {
-						/* add header len to first skb->len */
-						skb_put(skb, buffer->rx_hdr_size);
-						/* No split header, hence
-						 * pkt_len = (payload + hdr_len)
-						 * */
-						payload_len = (pkt_len - buffer->rx_hdr_size);
-						skb_fill_page_desc(skb, 0,
-							buffer->page2, 0,
-							payload_len);
-					}
-				} else {
-					/* this is the middle of a chain */
-					payload_len = pdata->rx_buffer_len;
-					skb_fill_page_desc(desc_data->skb_top,
-						skb_shinfo(desc_data->skb_top)->nr_frags,
-						buffer->page2, 0,
-						payload_len);
-
-					/* re-use this skb, as consumed only the page */
-					buffer->skb = skb;
-				}
-				DWC_ETH_QOS_consume_page_split_hdr(buffer,
-							 desc_data->skb_top,
-							 payload_len, buf2_used);
-				goto next_desc;
-			} else {
-				if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD)) {
-					buf2_used = 1;
-					/* end of the chain */
-					if (hdr_len) {
-						payload_len = (pkt_len -
-							(pdata->rx_buffer_len * intermediate_desc_cnt) -
-							hdr_len);
-					} else {
-						payload_len = (pkt_len -
-							(pdata->rx_buffer_len * intermediate_desc_cnt) -
-							buffer->rx_hdr_size);
-					}
-
-					skb_fill_page_desc(desc_data->skb_top,
-						skb_shinfo(desc_data->skb_top)->nr_frags,
-						buffer->page2, 0,
-						payload_len);
-
-					/* re-use this skb, as consumed only the page */
-					buffer->skb = skb;
-					skb = desc_data->skb_top;
-					desc_data->skb_top = NULL;
-					DWC_ETH_QOS_consume_page_split_hdr(buffer, skb,
-								 payload_len, buf2_used);
-				} else {
-					/* no chain, got both FD + LD together */
-					if (hdr_len) {
-						buf2_used = 1;
-						/* add header len to first skb->len */
-						skb_put(skb, hdr_len);
-
-						payload_len = pkt_len - hdr_len;
-						skb_fill_page_desc(skb, 0,
-							buffer->page2, 0,
-							payload_len);
-					} else {
-						/* No split header, hence
-						 * payload_len = (payload + hdr_len)
-						 * */
-						if (pkt_len > buffer->rx_hdr_size) {
-							buf2_used = 1;
-							/* add header len to first skb->len */
-							skb_put(skb, buffer->rx_hdr_size);
-
-							payload_len = (pkt_len - buffer->rx_hdr_size);
-							skb_fill_page_desc(skb, 0,
-								buffer->page2, 0,
-								payload_len);
-						} else {
-							buf2_used = 0;
-							/* add header len to first skb->len */
-							skb_put(skb, pkt_len);
-							payload_len = 0; /* no data in page2 */
-						}
-					}
-					DWC_ETH_QOS_consume_page_split_hdr(buffer,
-							skb, payload_len,
-							buf2_used);
-				}
-				/* reset for next new packet/frame */
-				intermediate_desc_cnt = 0;
-				hdr_len = 0;
-			}
-
-			DWC_ETH_QOS_config_rx_csum(pdata, skb, RX_NORMAL_DESC);
+            dev->stats.rx_errors++;
+            DWC_ETH_QOS_update_rx_errors(dev,
+               RX_NORMAL_DESC->RDES3);
+
+            /* recycle both page/buff and skb */
+            buffer->skb = skb;
+            if (desc_data->skb_top)
+               dev_kfree_skb_any(desc_data->skb_top);
+
+            desc_data->skb_top = NULL;
+            goto next_desc;
+         }
+
+         if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
+            intermediate_desc_cnt++;
+            buf2_used = 1;
+            /* this descriptor is only the beginning/middle */
+            if (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD) {
+               /* this is the beginning of a chain */
+
+               /* here skb/skb_top may contain
+                * if (device done split header)
+                *   only header
+                * else
+                *   header/(header + payload)
+                * */
+               desc_data->skb_top = skb;
+               /* page2 always contain only payload */
+               if (hdr_len) {
+                  /* add header len to first skb->len */
+                  skb_put(skb, hdr_len);
+                  payload_len = pdata->rx_buffer_len;
+                  skb_fill_page_desc(skb, 0,
+                     buffer->page2, 0,
+                     payload_len);
+               } else {
+                  /* add header len to first skb->len */
+                  skb_put(skb, buffer->rx_hdr_size);
+                  /* No split header, hence
+                   * pkt_len = (payload + hdr_len)
+                   * */
+                  payload_len = (pkt_len - buffer->rx_hdr_size);
+                  skb_fill_page_desc(skb, 0,
+                     buffer->page2, 0,
+                     payload_len);
+               }
+            } else {
+               /* this is the middle of a chain */
+               payload_len = pdata->rx_buffer_len;
+               skb_fill_page_desc(desc_data->skb_top,
+                  skb_shinfo(desc_data->skb_top)->nr_frags,
+                  buffer->page2, 0,
+                  payload_len);
+
+               /* re-use this skb, as consumed only the page */
+               buffer->skb = skb;
+            }
+            DWC_ETH_QOS_consume_page_split_hdr(buffer,
+                      desc_data->skb_top,
+                      payload_len, buf2_used);
+            goto next_desc;
+         } else {
+            if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD)) {
+               buf2_used = 1;
+               /* end of the chain */
+               if (hdr_len) {
+                  payload_len = (pkt_len -
+                     (pdata->rx_buffer_len * intermediate_desc_cnt) -
+                     hdr_len);
+               } else {
+                  payload_len = (pkt_len -
+                     (pdata->rx_buffer_len * intermediate_desc_cnt) -
+                     buffer->rx_hdr_size);
+               }
+
+               skb_fill_page_desc(desc_data->skb_top,
+                  skb_shinfo(desc_data->skb_top)->nr_frags,
+                  buffer->page2, 0,
+                  payload_len);
+
+               /* re-use this skb, as consumed only the page */
+               buffer->skb = skb;
+               skb = desc_data->skb_top;
+               desc_data->skb_top = NULL;
+               DWC_ETH_QOS_consume_page_split_hdr(buffer, skb,
+                         payload_len, buf2_used);
+            } else {
+               /* no chain, got both FD + LD together */
+               if (hdr_len) {
+                  buf2_used = 1;
+                  /* add header len to first skb->len */
+                  skb_put(skb, hdr_len);
+
+                  payload_len = pkt_len - hdr_len;
+                  skb_fill_page_desc(skb, 0,
+                     buffer->page2, 0,
+                     payload_len);
+               } else {
+                  /* No split header, hence
+                   * payload_len = (payload + hdr_len)
+                   * */
+                  if (pkt_len > buffer->rx_hdr_size) {
+                     buf2_used = 1;
+                     /* add header len to first skb->len */
+                     skb_put(skb, buffer->rx_hdr_size);
+
+                     payload_len = (pkt_len - buffer->rx_hdr_size);
+                     skb_fill_page_desc(skb, 0,
+                        buffer->page2, 0,
+                        payload_len);
+                  } else {
+                     buf2_used = 0;
+                     /* add header len to first skb->len */
+                     skb_put(skb, pkt_len);
+                     payload_len = 0; /* no data in page2 */
+                  }
+               }
+               DWC_ETH_QOS_consume_page_split_hdr(buffer,
+                     skb, payload_len,
+                     buf2_used);
+            }
+            /* reset for next new packet/frame */
+            intermediate_desc_cnt = 0;
+            hdr_len = 0;
+         }
+
+         DWC_ETH_QOS_config_rx_csum(pdata, skb, RX_NORMAL_DESC);
 
 #ifdef DWC_ETH_QOS_ENABLE_VLAN_TAG
-			DWC_ETH_QOS_get_rx_vlan(pdata, skb, RX_NORMAL_DESC);
+         DWC_ETH_QOS_get_rx_vlan(pdata, skb, RX_NORMAL_DESC);
 #endif
 
 #ifdef YDEBUG_FILTER
-			DWC_ETH_QOS_check_rx_filter_status(RX_NORMAL_DESC);
+         DWC_ETH_QOS_check_rx_filter_status(RX_NORMAL_DESC);
 #endif
 
-			if ((pdata->hw_feat.tsstssel) && (pdata->hwts_rx_en)) {
-				/* get rx tstamp if available */
-				if (hw_if->rx_tstamp_available(RX_NORMAL_DESC)) {
-					ret = DWC_ETH_QOS_get_rx_hwtstamp(pdata,
-							skb, desc_data, qInx);
-					if (ret == 0) {
-						/* device has not yet updated the CONTEXT desc to hold the
-						 * time stamp, hence delay the packet reception
-						 * */
-						buffer->skb = skb;
-						buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
-								pdata->rx_buffer_len, DMA_FROM_DEVICE);
-						if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
-							printk(KERN_ALERT "failed to do the RX dma map\n");
-
-						goto rx_tstmp_failed;
-					}
-				}
-			}
-
-			if (!(dev->features & NETIF_F_GRO) &&
-						(dev->features & NETIF_F_LRO)) {
-					pdata->tcp_pkt =
-							DWC_ETH_QOS_check_for_tcp_payload(RX_NORMAL_DESC);
-			}
-
-			dev->last_rx = jiffies;
-			/* update the statistics */
-			dev->stats.rx_packets++;
-			dev->stats.rx_bytes += skb->len;
-			DWC_ETH_QOS_receive_skb(pdata, dev, skb, qInx);
-			received++;
+         if ((pdata->hw_feat.tsstssel) && (pdata->hwts_rx_en)) {
+            /* get rx tstamp if available */
+            if (hw_if->rx_tstamp_available(RX_NORMAL_DESC)) {
+               ret = DWC_ETH_QOS_get_rx_hwtstamp(pdata,
+                     skb, desc_data, qInx);
+               if (ret == 0) {
+                  /* device has not yet updated the CONTEXT desc to hold the
+                   * time stamp, hence delay the packet reception
+                   * */
+                  buffer->skb = skb;
+                  buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
+                        pdata->rx_buffer_len, DMA_FROM_DEVICE);
+                  if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
+                     printk(KERN_ALERT "failed to do the RX dma map\n");
+
+                  goto rx_tstmp_failed;
+               }
+            }
+         }
+
+         if (!(dev->features & NETIF_F_GRO) &&
+                  (dev->features & NETIF_F_LRO)) {
+               pdata->tcp_pkt =
+                     DWC_ETH_QOS_check_for_tcp_payload(RX_NORMAL_DESC);
+         }
+
+         dev->last_rx = jiffies;
+         /* update the statistics */
+         dev->stats.rx_packets++;
+         dev->stats.rx_bytes += skb->len;
+         DWC_ETH_QOS_receive_skb(pdata, dev, skb, qInx);
+         received++;
  next_desc:
-			desc_data->dirty_rx++;
-			if (desc_data->dirty_rx >= desc_data->skb_realloc_threshold)
-				desc_if->realloc_skb(pdata, qInx);
-
-			INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
-			buf2_used = 0;
-		} else {
-			/* no more data to read */
-			break;
-		}
-	}
+         desc_data->dirty_rx++;
+         if (desc_data->dirty_rx >= desc_data->skb_realloc_threshold)
+            desc_if->realloc_skb(pdata, qInx);
+
+         INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
+         buf2_used = 0;
+      } else {
+         /* no more data to read */
+         break;
+      }
+   }
 
 rx_tstmp_failed:
 
-	if (desc_data->dirty_rx)
-		desc_if->realloc_skb(pdata, qInx);
-
-	DBGPR("<--DWC_ETH_QOS_clean_split_hdr_rx_irq: received = %d\n",
-		received);
-
-	return received;
+   if (desc_data->dirty_rx)
+      desc_if->realloc_skb(pdata, qInx);
+
+   DBGPR("<--DWC_ETH_QOS_clean_split_hdr_rx_irq: received = %d\n",
+      received);
+
+   return received;
 }
 
 /*!
@@ -2901,259 +2928,259 @@ rx_tstmp_failed:
 * \retval number of packets received.
 */
 static int DWC_ETH_QOS_clean_jumbo_rx_irq(struct DWC_ETH_QOS_prv_data *pdata,
-					  int quota,
-					  uint32_t qInx)
+                 int quota,
+                 uint32_t qInx)
 {
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
-	    GET_RX_WRAPPER_DESC(qInx);
-	struct net_device *dev = pdata->dev;
-	struct desc_if_struct *desc_if = &pdata->desc_if;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct sk_buff *skb = NULL;
-	int received = 0;
-	struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
-	rx_descriptor_t *RX_NORMAL_DESC = NULL;
-	u16 pkt_len;
-	uint8_t intermediate_desc_cnt = 0;
-	unsigned int buf2_used;
-	int ret;
-
-	DBGPR("-->DWC_ETH_QOS_clean_jumbo_rx_irq: qInx = %u, quota = %d\n",
-		qInx, quota);
-
-	while (received < quota) {
-		buffer = GET_RX_BUF_PTR(qInx, desc_data->cur_rx);
-		RX_NORMAL_DESC = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
-
-		/* check for data availability */
-		if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_OWN)) {
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
+       GET_RX_WRAPPER_DESC(qInx);
+   struct net_device *dev = pdata->dev;
+   struct desc_if_struct *desc_if = &pdata->desc_if;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct sk_buff *skb = NULL;
+   int received = 0;
+   struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
+   rx_descriptor_t *RX_NORMAL_DESC = NULL;
+   u16 pkt_len;
+   uint8_t intermediate_desc_cnt = 0;
+   unsigned int buf2_used;
+   int ret;
+
+   DBGPR("-->DWC_ETH_QOS_clean_jumbo_rx_irq: qInx = %u, quota = %d\n",
+      qInx, quota);
+
+   while (received < quota) {
+      buffer = GET_RX_BUF_PTR(qInx, desc_data->cur_rx);
+      RX_NORMAL_DESC = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
+
+      /* check for data availability */
+      if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_OWN)) {
 #ifdef DWC_ETH_QOS_ENABLE_RX_DESC_DUMP
-			dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
+         dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
 #endif
-			/* assign it to new skb */
-			skb = buffer->skb;
-			buffer->skb = NULL;
-
-			/* first buffer pointer */
-			dma_unmap_page(&pdata->pdev->dev, buffer->dma,
-				       PAGE_SIZE, DMA_FROM_DEVICE);
-			buffer->dma = 0;
-
-			/* second buffer pointer */
-			dma_unmap_page(&pdata->pdev->dev, buffer->dma2,
-				       PAGE_SIZE, DMA_FROM_DEVICE);
-			buffer->dma2 = 0;
-
-			/* get the packet length */
-			pkt_len =
-				(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_PL);
-
-			/* check for bad packet,
-			 * error is valid only for last descriptor (OWN + LD bit set).
-			 * */
-			if ((RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_ES) &&
-			    (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
-				DBGPR("Error in rcved pkt, failed to pass it to upper layer\n");
+         /* assign it to new skb */
+         skb = buffer->skb;
+         buffer->skb = NULL;
+
+         /* first buffer pointer */
+         dma_unmap_page(&pdata->pdev->dev, buffer->dma,
+                   PAGE_SIZE, DMA_FROM_DEVICE);
+         buffer->dma = 0;
+
+         /* second buffer pointer */
+         dma_unmap_page(&pdata->pdev->dev, buffer->dma2,
+                   PAGE_SIZE, DMA_FROM_DEVICE);
+         buffer->dma2 = 0;
+
+         /* get the packet length */
+         pkt_len =
+            (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_PL);
+
+         /* check for bad packet,
+          * error is valid only for last descriptor (OWN + LD bit set).
+          * */
+         if ((RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_ES) &&
+             (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
+            DBGPR("Error in rcved pkt, failed to pass it to upper layer\n");
 #ifdef DWC_ETH_QOS_ENABLE_RX_DESC_DUMP
-				dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
+            dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
 #endif
-				dev->stats.rx_errors++;
-				DWC_ETH_QOS_update_rx_errors(dev,
-					RX_NORMAL_DESC->RDES3);
-
-				/* recycle both page and skb */
-				buffer->skb = skb;
-				if (desc_data->skb_top)
-					dev_kfree_skb_any(desc_data->skb_top);
-
-				desc_data->skb_top = NULL;
-				goto next_desc;
-			}
-
-			if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
-				intermediate_desc_cnt++;
-				buf2_used = 1;
-				/* this descriptor is only the beginning/middle */
-				if (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD) {
-					/* this is the beginning of a chain */
-					desc_data->skb_top = skb;
-					skb_fill_page_desc(skb, 0,
-						buffer->page, 0,
-						pdata->rx_buffer_len);
-
-					DBGPR("RX: pkt in second buffer pointer\n");
-					skb_fill_page_desc(
-						desc_data->skb_top,
-						skb_shinfo(desc_data->skb_top)->nr_frags,
-						buffer->page2, 0,
-						pdata->rx_buffer_len);
-				} else {
-					/* this is the middle of a chain */
-					skb_fill_page_desc(desc_data->skb_top,
-						skb_shinfo(desc_data->skb_top)->nr_frags,
-						buffer->page, 0,
-						pdata->rx_buffer_len);
-
-					DBGPR("RX: pkt in second buffer pointer\n");
-					skb_fill_page_desc(desc_data->skb_top,
-						skb_shinfo(desc_data->skb_top)->nr_frags,
-						buffer->page2, 0,
-						pdata->rx_buffer_len);
-					/* re-use this skb, as consumed only the page */
-					buffer->skb = skb;
-				}
-				DWC_ETH_QOS_consume_page(buffer,
-							 desc_data->skb_top,
-							 (pdata->rx_buffer_len * 2),
-							 buf2_used);
-				goto next_desc;
-			} else {
-				if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD)) {
-					/* end of the chain */
-					pkt_len =
-						(pkt_len - (pdata->rx_buffer_len * intermediate_desc_cnt));
-					if (pkt_len > pdata->rx_buffer_len) {
-						skb_fill_page_desc(desc_data->skb_top,
-							skb_shinfo(desc_data->skb_top)->nr_frags,
-							buffer->page, 0,
-							pdata->rx_buffer_len);
-
-						DBGPR("RX: pkt in second buffer pointer\n");
-						skb_fill_page_desc(desc_data->skb_top,
-							skb_shinfo(desc_data->skb_top)->nr_frags,
-							buffer->page2, 0,
-							(pkt_len - pdata->rx_buffer_len));
-						buf2_used = 1;
-					} else {
-						skb_fill_page_desc(desc_data->skb_top,
-							skb_shinfo(desc_data->skb_top)->nr_frags,
-							buffer->page, 0,
-							pkt_len);
-						buf2_used = 0;
-					}
-					/* re-use this skb, as consumed only the page */
-					buffer->skb = skb;
-					skb = desc_data->skb_top;
-					desc_data->skb_top = NULL;
-					DWC_ETH_QOS_consume_page(buffer, skb,
-								 pkt_len,
-								 buf2_used);
-				} else {
-					/* no chain, got both FD + LD together */
-
-					/* code added for copybreak, this should improve
-					 * performance for small pkts with large amount
-					 * of reassembly being done in the stack
-					 * */
-					if ((pkt_len <= DWC_ETH_QOS_COPYBREAK_DEFAULT)
-					    && (skb_tailroom(skb) >= pkt_len)) {
-						u8 *vaddr;
-						vaddr =
-						    kmap_atomic(buffer->page);
-						memcpy(skb_tail_pointer(skb),
-						       vaddr, pkt_len);
-						kunmap_atomic(vaddr);
-						/* re-use the page, so don't erase buffer->page/page2 */
-						skb_put(skb, pkt_len);
-					} else {
-						if (pkt_len > pdata->rx_buffer_len) {
-							skb_fill_page_desc(skb,
-								0, buffer->page,
-								0,
-								pdata->rx_buffer_len);
-
-							DBGPR ("RX: pkt in second buffer pointer\n");
-							skb_fill_page_desc(skb,
-								skb_shinfo(skb)->nr_frags, buffer->page2,
-								0,
-								(pkt_len - pdata->rx_buffer_len));
-							buf2_used = 1;
-						} else {
-							skb_fill_page_desc(skb,
-								0, buffer->page,
-								0,
-								pkt_len);
-							buf2_used = 0;
-						}
-						DWC_ETH_QOS_consume_page(buffer,
-								skb,
-								pkt_len,
-								buf2_used);
-					}
-				}
-				intermediate_desc_cnt = 0;
-			}
-
-			DWC_ETH_QOS_config_rx_csum(pdata, skb, RX_NORMAL_DESC);
+            dev->stats.rx_errors++;
+            DWC_ETH_QOS_update_rx_errors(dev,
+               RX_NORMAL_DESC->RDES3);
+
+            /* recycle both page and skb */
+            buffer->skb = skb;
+            if (desc_data->skb_top)
+               dev_kfree_skb_any(desc_data->skb_top);
+
+            desc_data->skb_top = NULL;
+            goto next_desc;
+         }
+
+         if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
+            intermediate_desc_cnt++;
+            buf2_used = 1;
+            /* this descriptor is only the beginning/middle */
+            if (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD) {
+               /* this is the beginning of a chain */
+               desc_data->skb_top = skb;
+               skb_fill_page_desc(skb, 0,
+                  buffer->page, 0,
+                  pdata->rx_buffer_len);
+
+               DBGPR("RX: pkt in second buffer pointer\n");
+               skb_fill_page_desc(
+                  desc_data->skb_top,
+                  skb_shinfo(desc_data->skb_top)->nr_frags,
+                  buffer->page2, 0,
+                  pdata->rx_buffer_len);
+            } else {
+               /* this is the middle of a chain */
+               skb_fill_page_desc(desc_data->skb_top,
+                  skb_shinfo(desc_data->skb_top)->nr_frags,
+                  buffer->page, 0,
+                  pdata->rx_buffer_len);
+
+               DBGPR("RX: pkt in second buffer pointer\n");
+               skb_fill_page_desc(desc_data->skb_top,
+                  skb_shinfo(desc_data->skb_top)->nr_frags,
+                  buffer->page2, 0,
+                  pdata->rx_buffer_len);
+               /* re-use this skb, as consumed only the page */
+               buffer->skb = skb;
+            }
+            DWC_ETH_QOS_consume_page(buffer,
+                      desc_data->skb_top,
+                      (pdata->rx_buffer_len * 2),
+                      buf2_used);
+            goto next_desc;
+         } else {
+            if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_FD)) {
+               /* end of the chain */
+               pkt_len =
+                  (pkt_len - (pdata->rx_buffer_len * intermediate_desc_cnt));
+               if (pkt_len > pdata->rx_buffer_len) {
+                  skb_fill_page_desc(desc_data->skb_top,
+                     skb_shinfo(desc_data->skb_top)->nr_frags,
+                     buffer->page, 0,
+                     pdata->rx_buffer_len);
+
+                  DBGPR("RX: pkt in second buffer pointer\n");
+                  skb_fill_page_desc(desc_data->skb_top,
+                     skb_shinfo(desc_data->skb_top)->nr_frags,
+                     buffer->page2, 0,
+                     (pkt_len - pdata->rx_buffer_len));
+                  buf2_used = 1;
+               } else {
+                  skb_fill_page_desc(desc_data->skb_top,
+                     skb_shinfo(desc_data->skb_top)->nr_frags,
+                     buffer->page, 0,
+                     pkt_len);
+                  buf2_used = 0;
+               }
+               /* re-use this skb, as consumed only the page */
+               buffer->skb = skb;
+               skb = desc_data->skb_top;
+               desc_data->skb_top = NULL;
+               DWC_ETH_QOS_consume_page(buffer, skb,
+                         pkt_len,
+                         buf2_used);
+            } else {
+               /* no chain, got both FD + LD together */
+
+               /* code added for copybreak, this should improve
+                * performance for small pkts with large amount
+                * of reassembly being done in the stack
+                * */
+               if ((pkt_len <= DWC_ETH_QOS_COPYBREAK_DEFAULT)
+                   && (skb_tailroom(skb) >= pkt_len)) {
+                  u8 *vaddr;
+                  vaddr =
+                      kmap_atomic(buffer->page);
+                  memcpy(skb_tail_pointer(skb),
+                         vaddr, pkt_len);
+                  kunmap_atomic(vaddr);
+                  /* re-use the page, so don't erase buffer->page/page2 */
+                  skb_put(skb, pkt_len);
+               } else {
+                  if (pkt_len > pdata->rx_buffer_len) {
+                     skb_fill_page_desc(skb,
+                        0, buffer->page,
+                        0,
+                        pdata->rx_buffer_len);
+
+                     DBGPR ("RX: pkt in second buffer pointer\n");
+                     skb_fill_page_desc(skb,
+                        skb_shinfo(skb)->nr_frags, buffer->page2,
+                        0,
+                        (pkt_len - pdata->rx_buffer_len));
+                     buf2_used = 1;
+                  } else {
+                     skb_fill_page_desc(skb,
+                        0, buffer->page,
+                        0,
+                        pkt_len);
+                     buf2_used = 0;
+                  }
+                  DWC_ETH_QOS_consume_page(buffer,
+                        skb,
+                        pkt_len,
+                        buf2_used);
+               }
+            }
+            intermediate_desc_cnt = 0;
+         }
+
+         DWC_ETH_QOS_config_rx_csum(pdata, skb, RX_NORMAL_DESC);
 
 #ifdef DWC_ETH_QOS_ENABLE_VLAN_TAG
-			DWC_ETH_QOS_get_rx_vlan(pdata, skb, RX_NORMAL_DESC);
+         DWC_ETH_QOS_get_rx_vlan(pdata, skb, RX_NORMAL_DESC);
 #endif
 
 #ifdef YDEBUG_FILTER
-			DWC_ETH_QOS_check_rx_filter_status(RX_NORMAL_DESC);
+         DWC_ETH_QOS_check_rx_filter_status(RX_NORMAL_DESC);
 #endif
 
-			if ((pdata->hw_feat.tsstssel) && (pdata->hwts_rx_en)) {
-				/* get rx tstamp if available */
-				if (hw_if->rx_tstamp_available(RX_NORMAL_DESC)) {
-					ret = DWC_ETH_QOS_get_rx_hwtstamp(pdata,
-							skb, desc_data, qInx);
-					if (ret == 0) {
-						/* device has not yet updated the CONTEXT desc to hold the
-						 * time stamp, hence delay the packet reception
-						 * */
-						buffer->skb = skb;
-						buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
-								pdata->rx_buffer_len, DMA_FROM_DEVICE);
-						if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
-							printk(KERN_ALERT "failed to do the RX dma map\n");
-
-						goto rx_tstmp_failed;
-					}
-				}
-			}
-
-			if (!(dev->features & NETIF_F_GRO) &&
-						(dev->features & NETIF_F_LRO)) {
-					pdata->tcp_pkt =
-							DWC_ETH_QOS_check_for_tcp_payload(RX_NORMAL_DESC);
-			}
-
-			dev->last_rx = jiffies;
-			/* update the statistics */
-			dev->stats.rx_packets++;
-			dev->stats.rx_bytes += skb->len;
-
-			/* eth type trans needs skb->data to point to something */
-			if (!pskb_may_pull(skb, ETH_HLEN)) {
-				printk(KERN_ALERT "pskb_may_pull failed\n");
-				dev_kfree_skb_any(skb);
-				goto next_desc;
-			}
-
-			DWC_ETH_QOS_receive_skb(pdata, dev, skb, qInx);
-			received++;
+         if ((pdata->hw_feat.tsstssel) && (pdata->hwts_rx_en)) {
+            /* get rx tstamp if available */
+            if (hw_if->rx_tstamp_available(RX_NORMAL_DESC)) {
+               ret = DWC_ETH_QOS_get_rx_hwtstamp(pdata,
+                     skb, desc_data, qInx);
+               if (ret == 0) {
+                  /* device has not yet updated the CONTEXT desc to hold the
+                   * time stamp, hence delay the packet reception
+                   * */
+                  buffer->skb = skb;
+                  buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
+                        pdata->rx_buffer_len, DMA_FROM_DEVICE);
+                  if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
+                     printk(KERN_ALERT "failed to do the RX dma map\n");
+
+                  goto rx_tstmp_failed;
+               }
+            }
+         }
+
+         if (!(dev->features & NETIF_F_GRO) &&
+                  (dev->features & NETIF_F_LRO)) {
+               pdata->tcp_pkt =
+                     DWC_ETH_QOS_check_for_tcp_payload(RX_NORMAL_DESC);
+         }
+
+         dev->last_rx = jiffies;
+         /* update the statistics */
+         dev->stats.rx_packets++;
+         dev->stats.rx_bytes += skb->len;
+
+         /* eth type trans needs skb->data to point to something */
+         if (!pskb_may_pull(skb, ETH_HLEN)) {
+            printk(KERN_ALERT "pskb_may_pull failed\n");
+            dev_kfree_skb_any(skb);
+            goto next_desc;
+         }
+
+         DWC_ETH_QOS_receive_skb(pdata, dev, skb, qInx);
+         received++;
  next_desc:
-			desc_data->dirty_rx++;
-			if (desc_data->dirty_rx >= desc_data->skb_realloc_threshold)
-				desc_if->realloc_skb(pdata, qInx);
-
-			INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
-		} else {
-			/* no more data to read */
-			break;
-		}
-	}
+         desc_data->dirty_rx++;
+         if (desc_data->dirty_rx >= desc_data->skb_realloc_threshold)
+            desc_if->realloc_skb(pdata, qInx);
+
+         INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
+      } else {
+         /* no more data to read */
+         break;
+      }
+   }
 
 rx_tstmp_failed:
 
-	if (desc_data->dirty_rx)
-		desc_if->realloc_skb(pdata, qInx);
-
-	DBGPR("<--DWC_ETH_QOS_clean_jumbo_rx_irq: received = %d\n", received);
-
-	return received;
+   if (desc_data->dirty_rx)
+      desc_if->realloc_skb(pdata, qInx);
+
+   DBGPR("<--DWC_ETH_QOS_clean_jumbo_rx_irq: received = %d\n", received);
+
+   return received;
 }
 
 /*!
@@ -3175,151 +3202,151 @@ rx_tstmp_failed:
 * \retval number of packets received.
 */
 static int DWC_ETH_QOS_clean_rx_irq(struct DWC_ETH_QOS_prv_data *pdata,
-				    int quota,
-				    uint32_t qInx)
+                int quota,
+                uint32_t qInx)
 {
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
-	    GET_RX_WRAPPER_DESC(qInx);
-	struct net_device *dev = pdata->dev;
-	struct desc_if_struct *desc_if = &pdata->desc_if;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct sk_buff *skb = NULL;
-	int received = 0;
-	struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
-	rx_descriptor_t *RX_NORMAL_DESC = NULL;
-	uint32_t pkt_len;
-	int ret;
-
-	DBGPR("-->DWC_ETH_QOS_clean_rx_irq: qInx = %u, quota = %d\n",
-		qInx, quota);
-
-	while (received < quota) {
-		buffer = GET_RX_BUF_PTR(qInx, desc_data->cur_rx);
-		RX_NORMAL_DESC = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
-
-		/* check for data availability */
-		if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_OWN)) {
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
+       GET_RX_WRAPPER_DESC(qInx);
+   struct net_device *dev = pdata->dev;
+   struct desc_if_struct *desc_if = &pdata->desc_if;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct sk_buff *skb = NULL;
+   int received = 0;
+   struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
+   rx_descriptor_t *RX_NORMAL_DESC = NULL;
+   uint32_t pkt_len;
+   int ret;
+
+   DBGPR("-->DWC_ETH_QOS_clean_rx_irq: qInx = %u, quota = %d\n",
+      qInx, quota);
+
+   while (received < quota) {
+      buffer = GET_RX_BUF_PTR(qInx, desc_data->cur_rx);
+      RX_NORMAL_DESC = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
+
+      /* check for data availability */
+      if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_OWN)) {
 #ifdef DWC_ETH_QOS_ENABLE_RX_DESC_DUMP
-			dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
+         dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
 #endif
-			/* assign it to new skb */
-			skb = buffer->skb;
-			buffer->skb = NULL;
-			dma_unmap_single(&pdata->pdev->dev, buffer->dma,
-					 pdata->rx_buffer_len, DMA_FROM_DEVICE);
-			buffer->dma = 0;
-
-			/* get the packet length */
-			pkt_len = (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_PL);
-
-			/* check for bad/oversized packet,
-			 * error is valid only for last descriptor (OWN + LD bit set).
-			 * */
-			if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_ES) &&
-			    (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
-				/* pkt_len = pkt_len - 4; */ /* CRC stripping */
-				/* code added for copybreak, this should improve
-				 * performance for small pkts with large amount
-				 * of reassembly being done in the stack
-				 * */
+         /* assign it to new skb */
+         skb = buffer->skb;
+         buffer->skb = NULL;
+         dma_unmap_single(&pdata->pdev->dev, buffer->dma,
+                pdata->rx_buffer_len, DMA_FROM_DEVICE);
+         buffer->dma = 0;
+
+         /* get the packet length */
+         pkt_len = (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_PL);
+
+         /* check for bad/oversized packet,
+          * error is valid only for last descriptor (OWN + LD bit set).
+          * */
+         if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_ES) &&
+             (RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD)) {
+            /* pkt_len = pkt_len - 4; */ /* CRC stripping */
+            /* code added for copybreak, this should improve
+             * performance for small pkts with large amount
+             * of reassembly being done in the stack
+             * */
 // Disable this logic to avoid conflict with not updated timestamp logic below
 #if 0
-				if (pkt_len < DWC_ETH_QOS_COPYBREAK_DEFAULT) {
-					struct sk_buff *new_skb =
-					    netdev_alloc_skb_ip_align(dev, pkt_len);
-					if (new_skb) {
-						skb_copy_to_linear_data_offset(new_skb,
-							-NET_IP_ALIGN,
-							(skb->data - NET_IP_ALIGN),
-							(pkt_len + NET_IP_ALIGN));
-						/* recycle actual desc skb */
-						buffer->skb = skb;
-						skb = new_skb;
-					} else {
-						/* just continue with the old skb */
-					}
-				}
+            if (pkt_len < DWC_ETH_QOS_COPYBREAK_DEFAULT) {
+               struct sk_buff *new_skb =
+                   netdev_alloc_skb_ip_align(dev, pkt_len);
+               if (new_skb) {
+                  skb_copy_to_linear_data_offset(new_skb,
+                     -NET_IP_ALIGN,
+                     (skb->data - NET_IP_ALIGN),
+                     (pkt_len + NET_IP_ALIGN));
+                  /* recycle actual desc skb */
+                  buffer->skb = skb;
+                  skb = new_skb;
+               } else {
+                  /* just continue with the old skb */
+               }
+            }
 #endif
-				skb_put(skb, pkt_len);
+            skb_put(skb, pkt_len);
 #ifdef GBE_DEBUG
-				if(print_rx_pkts)
-					print_skb(skb, true);
+            if(print_rx_pkts)
+               print_skb(skb, true);
 #endif
-				DWC_ETH_QOS_config_rx_csum(pdata, skb, RX_NORMAL_DESC);
+            DWC_ETH_QOS_config_rx_csum(pdata, skb, RX_NORMAL_DESC);
 
 #ifdef DWC_ETH_QOS_ENABLE_VLAN_TAG
-				DWC_ETH_QOS_get_rx_vlan(pdata, skb, RX_NORMAL_DESC);
+            DWC_ETH_QOS_get_rx_vlan(pdata, skb, RX_NORMAL_DESC);
 #endif
 
 #ifdef YDEBUG_FILTER
-				DWC_ETH_QOS_check_rx_filter_status(RX_NORMAL_DESC);
+            DWC_ETH_QOS_check_rx_filter_status(RX_NORMAL_DESC);
 #endif
 
-				if ((pdata->hw_feat.tsstssel) && (pdata->hwts_rx_en)) {
-					/* get rx tstamp if available */
-					if (hw_if->rx_tstamp_available(RX_NORMAL_DESC)) {
-						ret = DWC_ETH_QOS_get_rx_hwtstamp(pdata,
-								skb, desc_data, qInx);
-						if (ret == 0) {
-							/* device has not yet updated the CONTEXT desc to hold the
-							 * time stamp, hence delay the packet reception
-							 * */
-							buffer->skb = skb; //Potential conflict when above COPYBREAK logic is enabled!!!
-							buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
-									pdata->rx_buffer_len, DMA_FROM_DEVICE);
-							if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
-								printk(KERN_ALERT "failed to do the RX dma map\n");
-
-							goto rx_tstmp_failed;
-						}
-					}
-				}
-
-				if (!(dev->features & NETIF_F_GRO) &&
-						(dev->features & NETIF_F_LRO)) {
-						pdata->tcp_pkt =
-								DWC_ETH_QOS_check_for_tcp_payload(RX_NORMAL_DESC);
-				}
-
-				dev->last_rx = jiffies;
-				/* update the statistics */
-				dev->stats.rx_packets++;
-				dev->stats.rx_bytes += skb->len;
-				DWC_ETH_QOS_receive_skb(pdata, dev, skb, qInx);
-				received++;
-			} else {
+            if ((pdata->hw_feat.tsstssel) && (pdata->hwts_rx_en)) {
+               /* get rx tstamp if available */
+               if (hw_if->rx_tstamp_available(RX_NORMAL_DESC)) {
+                  ret = DWC_ETH_QOS_get_rx_hwtstamp(pdata,
+                        skb, desc_data, qInx);
+                  if (ret == 0) {
+                     /* device has not yet updated the CONTEXT desc to hold the
+                      * time stamp, hence delay the packet reception
+                      * */
+                     buffer->skb = skb; //Potential conflict when above COPYBREAK logic is enabled!!!
+                     buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
+                           pdata->rx_buffer_len, DMA_FROM_DEVICE);
+                     if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
+                        printk(KERN_ALERT "failed to do the RX dma map\n");
+
+                     goto rx_tstmp_failed;
+                  }
+               }
+            }
+
+            if (!(dev->features & NETIF_F_GRO) &&
+                  (dev->features & NETIF_F_LRO)) {
+                  pdata->tcp_pkt =
+                        DWC_ETH_QOS_check_for_tcp_payload(RX_NORMAL_DESC);
+            }
+
+            dev->last_rx = jiffies;
+            /* update the statistics */
+            dev->stats.rx_packets++;
+            dev->stats.rx_bytes += skb->len;
+            DWC_ETH_QOS_receive_skb(pdata, dev, skb, qInx);
+            received++;
+         } else {
 #ifdef DWC_ETH_QOS_ENABLE_RX_DESC_DUMP
-				dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
+            dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
 #endif
-				if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD))
-					DBGPR("Received oversized pkt, spanned across multiple desc\n");
-
-				/* recycle skb */
-				buffer->skb = skb;
-				dev->stats.rx_errors++;
-				DWC_ETH_QOS_update_rx_errors(dev,
-					RX_NORMAL_DESC->RDES3);
-			}
-
-			desc_data->dirty_rx++;
-			if (desc_data->dirty_rx >= desc_data->skb_realloc_threshold)
-				desc_if->realloc_skb(pdata, qInx);
-
-			INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
-		} else {
-			/* no more data to read */
-			break;
-		}
-	}
+            if (!(RX_NORMAL_DESC->RDES3 & DWC_ETH_QOS_RDESC3_LD))
+               DBGPR("Received oversized pkt, spanned across multiple desc\n");
+
+            /* recycle skb */
+            buffer->skb = skb;
+            dev->stats.rx_errors++;
+            DWC_ETH_QOS_update_rx_errors(dev,
+               RX_NORMAL_DESC->RDES3);
+         }
+
+         desc_data->dirty_rx++;
+         if (desc_data->dirty_rx >= desc_data->skb_realloc_threshold)
+            desc_if->realloc_skb(pdata, qInx);
+
+         INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
+      } else {
+         /* no more data to read */
+         break;
+      }
+   }
 
 rx_tstmp_failed:
 
-	if (desc_data->dirty_rx)
-		desc_if->realloc_skb(pdata, qInx);
-
-	DBGPR("<--DWC_ETH_QOS_clean_rx_irq: received = %d\n", received);
-
-	return received;
+   if (desc_data->dirty_rx)
+      desc_if->realloc_skb(pdata, qInx);
+
+   DBGPR("<--DWC_ETH_QOS_clean_rx_irq: received = %d\n", received);
+
+   return received;
 }
 
 /*!
@@ -3334,23 +3361,23 @@ rx_tstmp_failed:
 * \return void.
 */
 void DWC_ETH_QOS_update_rx_errors(struct net_device *dev,
-				 unsigned int rx_status)
+             unsigned int rx_status)
 {
-	DBGPR("-->DWC_ETH_QOS_update_rx_errors\n");
-
-	/* received pkt with crc error */
-	if ((rx_status & 0x1000000))
-		dev->stats.rx_crc_errors++;
-
-	/* received frame alignment */
-	if ((rx_status & 0x100000))
-		dev->stats.rx_frame_errors++;
-
-	/* receiver fifo overrun */
-	if ((rx_status & 0x200000))
-		dev->stats.rx_fifo_errors++;
-
-	DBGPR("<--DWC_ETH_QOS_update_rx_errors\n");
+   DBGPR("-->DWC_ETH_QOS_update_rx_errors\n");
+
+   /* received pkt with crc error */
+   if ((rx_status & 0x1000000))
+      dev->stats.rx_crc_errors++;
+
+   /* received frame alignment */
+   if ((rx_status & 0x100000))
+      dev->stats.rx_frame_errors++;
+
+   /* receiver fifo overrun */
+   if ((rx_status & 0x200000))
+      dev->stats.rx_fifo_errors++;
+
+   DBGPR("<--DWC_ETH_QOS_update_rx_errors\n");
 }
 
 /*!
@@ -3369,62 +3396,62 @@ void DWC_ETH_QOS_update_rx_errors(struct
 */
 int DWC_ETH_QOS_poll_rx(struct napi_struct *napi, int budget)
 {
-	struct DWC_ETH_QOS_prv_data *pdata =
-		container_of(napi, struct DWC_ETH_QOS_prv_data, rx_napi);
-	struct DWC_ETH_QOS_rx_queue *rx_queue = NULL;
-	/* divide the budget evenly among all the queues */
-	int per_q_budget = budget / DWC_ETH_QOS_RX_QUEUE_CNT;
-	int qInx = 0;
-	int received = 0, per_q_received = 0;
-
-	DBGPR("-->DWC_ETH_QOS_poll_mq: budget = %d\n", budget);
-
-	pdata->xstats.napi_poll_n++;
-	for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
-		rx_queue = GET_RX_QUEUE_PTR(qInx);
+   struct DWC_ETH_QOS_prv_data *pdata =
+      container_of(napi, struct DWC_ETH_QOS_prv_data, rx_napi);
+   struct DWC_ETH_QOS_rx_queue *rx_queue = NULL;
+   /* divide the budget evenly among all the queues */
+   int per_q_budget = budget / DWC_ETH_QOS_RX_QUEUE_CNT;
+   int qInx = 0;
+   int received = 0, per_q_received = 0;
+
+   DBGPR("-->DWC_ETH_QOS_poll_mq: budget = %d\n", budget);
+
+   pdata->xstats.napi_poll_n++;
+   for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
+      rx_queue = GET_RX_QUEUE_PTR(qInx);
 
 #ifdef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-		/* check for tx descriptor status */
-		DWC_ETH_QOS_tx_interrupt(pdata->dev, pdata, qInx);
+      /* check for tx descriptor status */
+      DWC_ETH_QOS_tx_interrupt(pdata->dev, pdata, qInx);
 #endif
-		rx_queue->lro_flush_needed = 0;
+      rx_queue->lro_flush_needed = 0;
 
 #ifdef RX_OLD_CODE
-		per_q_received = DWC_ETH_QOS_poll(pdata, per_q_budget, qInx);
+      per_q_received = DWC_ETH_QOS_poll(pdata, per_q_budget, qInx);
 #else
-		per_q_received = pdata->clean_rx(pdata, per_q_budget, qInx);
+      per_q_received = pdata->clean_rx(pdata, per_q_budget, qInx);
 #endif
-		received += per_q_received;
-		pdata->xstats.rx_pkt_n += per_q_received;
-		pdata->xstats.q_rx_pkt_n[qInx] += per_q_received;
-
-		if (rx_queue->lro_flush_needed)
-			lro_flush_all(&rx_queue->lro_mgr);
-	}
-
-	/* If we processed all pkts, we are done;
-	 * tell the kernel & re-enable interrupt */
-	if (received < budget) {
-		unsigned long flags;
-		/* Turn off polling */
-		if (pdata->dev->features & NETIF_F_GRO)
-			napi_complete(napi);
-		else
-			__napi_complete(napi);
-		spin_lock_irqsave(&pdata->lock, flags);
-		/* Enable Rx interrupts */
-		DWC_ETH_QOS_enable_rx_interrupts(pdata);
+      received += per_q_received;
+      pdata->xstats.rx_pkt_n += per_q_received;
+      pdata->xstats.q_rx_pkt_n[qInx] += per_q_received;
+
+      if (rx_queue->lro_flush_needed)
+         lro_flush_all(&rx_queue->lro_mgr);
+   }
+
+   /* If we processed all pkts, we are done;
+    * tell the kernel & re-enable interrupt */
+   if (received < budget) {
+      unsigned long flags;
+      /* Turn off polling */
+      if (pdata->dev->features & NETIF_F_GRO)
+         napi_complete(napi);
+      else
+         __napi_complete(napi);
+      spin_lock_irqsave(&pdata->lock, flags);
+      /* Enable Rx interrupts */
+      DWC_ETH_QOS_enable_rx_interrupts(pdata);
 #ifdef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-		/* Enable Tx interrupts */
-		DWC_ETH_QOS_enable_tx_interrupts(pdata);
+      /* Enable Tx interrupts */
+      DWC_ETH_QOS_enable_tx_interrupts(pdata);
 #endif
-		pdata->rx_napi_pending = false;
-		spin_unlock_irqrestore(&pdata->lock, flags);
-	}
-
-	DBGPR("<--DWC_ETH_QOS_poll_mq\n");
-
-	return received;
+      pdata->rx_napi_pending = false;
+      spin_unlock_irqrestore(&pdata->lock, flags);
+   }
+
+   DBGPR("<--DWC_ETH_QOS_poll_mq\n");
+
+   return received;
 }
 
 /*!
@@ -3440,11 +3467,9 @@ int DWC_ETH_QOS_poll_rx(struct napi_stru
 *
 * \retval net_device_stats - returns pointer to net_device_stats structure.
 */
-
 static struct net_device_stats *DWC_ETH_QOS_get_stats(struct net_device *dev)
 {
-
-	return &dev->stats;
+   return &dev->stats;
 }
 
 #ifdef CONFIG_NET_POLL_CONTROLLER
@@ -3461,18 +3486,18 @@ static struct net_device_stats *DWC_ETH_
 */
 static void DWC_ETH_QOS_poll_controller(struct net_device *dev)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-
-	DBGPR("-->DWC_ETH_QOS_poll_controller\n");
-
-	disable_irq(pdata->irq_number);
-	DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS(pdata->irq_number, pdata);
-	enable_irq(pdata->irq_number);
-
-	DBGPR("<--DWC_ETH_QOS_poll_controller\n");
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+
+   DBGPR("-->DWC_ETH_QOS_poll_controller\n");
+
+   disable_irq(pdata->irq_number);
+   DWC_ETH_QOS_ISR(pdata->irq_number, pdata);
+   enable_irq(pdata->irq_number);
+
+   DBGPR("<--DWC_ETH_QOS_poll_controller\n");
 }
 
-#endif	/*end of CONFIG_NET_POLL_CONTROLLER */
+#endif   /*end of CONFIG_NET_POLL_CONTROLLER */
 
 /*!
  * \brief User defined parameter setting API
@@ -3490,55 +3515,55 @@ static void DWC_ETH_QOS_poll_controller(
  */
 static int DWC_ETH_QOS_set_features(struct net_device *dev, netdev_features_t features)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t dev_rxcsum_enable;
-	uint32_t dev_rxvlan_enable, dev_txvlan_enable;
-
-	if (pdata->hw_feat.rx_coe_sel) {
-		dev_rxcsum_enable = !!(pdata->dev_state & NETIF_F_RXCSUM);
-
-		if (((features & NETIF_F_RXCSUM) == NETIF_F_RXCSUM)
-		    && !dev_rxcsum_enable) {
-			hw_if->enable_rx_csum();
-			pdata->dev_state |= NETIF_F_RXCSUM;
-			printk(KERN_ALERT "State change - rxcsum enable\n");
-		} else if (((features & NETIF_F_RXCSUM) == 0)
-			   && dev_rxcsum_enable) {
-			hw_if->disable_rx_csum();
-			pdata->dev_state &= ~NETIF_F_RXCSUM;
-			printk(KERN_ALERT "State change - rxcsum disable\n");
-		}
-	}
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t dev_rxcsum_enable;
+   uint32_t dev_rxvlan_enable, dev_txvlan_enable;
+
+   if (pdata->hw_feat.rx_coe_sel) {
+      dev_rxcsum_enable = !!(pdata->dev_state & NETIF_F_RXCSUM);
+
+      if (((features & NETIF_F_RXCSUM) == NETIF_F_RXCSUM)
+          && !dev_rxcsum_enable) {
+         hw_if->enable_rx_csum();
+         pdata->dev_state |= NETIF_F_RXCSUM;
+         printk(KERN_ALERT "State change - rxcsum enable\n");
+      } else if (((features & NETIF_F_RXCSUM) == 0)
+            && dev_rxcsum_enable) {
+         hw_if->disable_rx_csum();
+         pdata->dev_state &= ~NETIF_F_RXCSUM;
+         printk(KERN_ALERT "State change - rxcsum disable\n");
+      }
+   }
 #ifdef DWC_ETH_QOS_ENABLE_VLAN_TAG
-	dev_rxvlan_enable = !!(pdata->dev_state & NETIF_F_HW_VLAN_CTAG_RX);
-	if (((features & NETIF_F_HW_VLAN_CTAG_RX) == NETIF_F_HW_VLAN_CTAG_RX)
-	    && !dev_rxvlan_enable) {
-		pdata->dev_state |= NETIF_F_HW_VLAN_CTAG_RX;
-		hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
-		printk(KERN_ALERT "State change - rxvlan enable\n");
-	} else if (((features & NETIF_F_HW_VLAN_CTAG_RX) == 0) &&
-			dev_rxvlan_enable) {
-		pdata->dev_state &= ~NETIF_F_HW_VLAN_CTAG_RX;
-		hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
-		printk(KERN_ALERT "State change - rxvlan disable\n");
-	}
-
-	dev_txvlan_enable = !!(pdata->dev_state & NETIF_F_HW_VLAN_CTAG_TX);
-	if (((features & NETIF_F_HW_VLAN_CTAG_TX) == NETIF_F_HW_VLAN_CTAG_TX)
-	    && !dev_txvlan_enable) {
-		pdata->dev_state |= NETIF_F_HW_VLAN_CTAG_TX;
-		printk(KERN_ALERT "State change - txvlan enable\n");
-	} else if (((features & NETIF_F_HW_VLAN_CTAG_TX) == 0) &&
-			dev_txvlan_enable) {
-		pdata->dev_state &= ~NETIF_F_HW_VLAN_CTAG_TX;
-		printk(KERN_ALERT "State change - txvlan disable\n");
-	}
-#endif	/* DWC_ETH_QOS_ENABLE_VLAN_TAG */
-
-	DBGPR("<--DWC_ETH_QOS_set_features\n");
-
-	return 0;
+   dev_rxvlan_enable = !!(pdata->dev_state & NETIF_F_HW_VLAN_CTAG_RX);
+   if (((features & NETIF_F_HW_VLAN_CTAG_RX) == NETIF_F_HW_VLAN_CTAG_RX)
+       && !dev_rxvlan_enable) {
+      pdata->dev_state |= NETIF_F_HW_VLAN_CTAG_RX;
+      hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
+      printk(KERN_ALERT "State change - rxvlan enable\n");
+   } else if (((features & NETIF_F_HW_VLAN_CTAG_RX) == 0) &&
+         dev_rxvlan_enable) {
+      pdata->dev_state &= ~NETIF_F_HW_VLAN_CTAG_RX;
+      hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
+      printk(KERN_ALERT "State change - rxvlan disable\n");
+   }
+
+   dev_txvlan_enable = !!(pdata->dev_state & NETIF_F_HW_VLAN_CTAG_TX);
+   if (((features & NETIF_F_HW_VLAN_CTAG_TX) == NETIF_F_HW_VLAN_CTAG_TX)
+       && !dev_txvlan_enable) {
+      pdata->dev_state |= NETIF_F_HW_VLAN_CTAG_TX;
+      printk(KERN_ALERT "State change - txvlan enable\n");
+   } else if (((features & NETIF_F_HW_VLAN_CTAG_TX) == 0) &&
+         dev_txvlan_enable) {
+      pdata->dev_state &= ~NETIF_F_HW_VLAN_CTAG_TX;
+      printk(KERN_ALERT "State change - txvlan disable\n");
+   }
+#endif   /* DWC_ETH_QOS_ENABLE_VLAN_TAG */
+
+   DBGPR("<--DWC_ETH_QOS_set_features\n");
+
+   return 0;
 }
 
 /*!
@@ -3555,29 +3580,28 @@ static int DWC_ETH_QOS_set_features(stru
  *
  * \retval modified flag
  */
-
 static netdev_features_t DWC_ETH_QOS_fix_features(struct net_device *dev,
       netdev_features_t features)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-
-	DBGPR("-->DWC_ETH_QOS_fix_features: %#llx\n", features);
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+
+   DBGPR("-->DWC_ETH_QOS_fix_features: %#llx\n", features);
 
 #ifdef DWC_ETH_QOS_ENABLE_VLAN_TAG
-	if (pdata->rx_split_hdr) {
-		/* The VLAN tag stripping must be set for the split function.
-		 * For instance, the DMA separates the header and payload of
-		 * an untagged packet only. Hence, when a tagged packet is
-		 * received, the QOS must be programmed such that the VLAN
-		 * tags are deleted/stripped from the received packets.
-		 * */
-		features |= NETIF_F_HW_VLAN_CTAG_RX;
-	}
+   if (pdata->rx_split_hdr) {
+      /* The VLAN tag stripping must be set for the split function.
+       * For instance, the DMA separates the header and payload of
+       * an untagged packet only. Hence, when a tagged packet is
+       * received, the QOS must be programmed such that the VLAN
+       * tags are deleted/stripped from the received packets.
+       * */
+      features |= NETIF_F_HW_VLAN_CTAG_RX;
+   }
 #endif /* end of DWC_ETH_QOS_ENABLE_VLAN_TAG */
 
-	DBGPR("<--DWC_ETH_QOS_fix_features: %#llx\n", features);
-
-	return features;
+   DBGPR("<--DWC_ETH_QOS_fix_features: %#llx\n", features);
+
+   return features;
 }
 
 /*!
@@ -3593,47 +3617,44 @@ static netdev_features_t DWC_ETH_QOS_fix
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_rx_split_hdr_mode(struct net_device *dev,
-		unsigned int flags)
+      unsigned int flags)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	unsigned int qInx;
-	int ret = 0;
-
-	DBGPR("-->DWC_ETH_QOS_config_rx_split_hdr_mode\n");
-
-	if (flags && pdata->rx_split_hdr) {
-		printk(KERN_ALERT
-			"Rx Split header mode is already enabled\n");
-		return -EINVAL;
-	}
-
-	if (!flags && !pdata->rx_split_hdr) {
-		printk(KERN_ALERT
-			"Rx Split header mode is already disabled\n");
-		return -EINVAL;
-	}
-
-	DWC_ETH_QOS_stop_dev(pdata);
-
-	/* If split header mode is disabled(ie flags == 0)
-	 * then RX will be in default/jumbo mode based on MTU
-	 * */
-	pdata->rx_split_hdr = !!flags;
-
-	DWC_ETH_QOS_start_dev(pdata);
-
-	hw_if->config_header_size(DWC_ETH_QOS_MAX_HDR_SIZE);
-	/* enable/disable split header for all RX DMA channel */
-	for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
-		hw_if->config_split_header_mode(qInx, pdata->rx_split_hdr);
-
-	printk(KERN_ALERT "Succesfully %s Rx Split header mode\n",
-		(flags ? "enabled" : "disabled"));
-
-	DBGPR("<--DWC_ETH_QOS_config_rx_split_hdr_mode\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   unsigned int qInx;
+   gbe_power_state_t state;
+
+   DBGPR("-->DWC_ETH_QOS_config_rx_split_hdr_mode\n");
+
+   if (flags && pdata->rx_split_hdr) {
+      WRN_PRINT("Rx Split header mode is already enabled\n");
+      return 0;
+   }
+   if (!flags && !pdata->rx_split_hdr) {
+      WRN_PRINT("Rx Split header mode is already disabled\n");
+      return 0;
+   }
+
+   state = DWC_ETH_QOS_stop_dev(pdata);
+   /* If split header mode is disabled(ie flags == 0)
+    * then RX will be in default/jumbo mode based on MTU
+    * */
+   pdata->rx_split_hdr = !!flags;
+   CFG_PRINT("Rx Split header mode set(%d)!\n", flags);
+
+   if (state == GBE_RUN_STATE) {
+      hw_if->config_header_size(DWC_ETH_QOS_MAX_HDR_SIZE);
+      /* Enable/disable split header for all RX DMA channel */
+      for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
+         hw_if->config_split_header_mode(qInx, pdata->rx_split_hdr);
+      DWC_ETH_QOS_start_dev(pdata);
+   } else if (state == GBE_STANDBY_STATE) {
+      /* Save request to apply it when device is powered up */
+      pdata->power_state |= DWC_ETH_QOS_NETIP_SPLHDR_REQ;
+   }
+
+   DBGPR("<--DWC_ETH_QOS_config_rx_split_hdr_mode\n");
+   return 0;
 }
 
 /*!
@@ -3649,35 +3670,35 @@ static int DWC_ETH_QOS_config_rx_split_h
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_l3_l4_filtering(struct net_device *dev,
-		unsigned int flags)
+      unsigned int flags)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	int ret = 0;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_config_l3_l4_filtering\n");
-
-	if (flags && pdata->l3_l4_filter) {
-		printk(KERN_ALERT
-			"L3/L4 filtering is already enabled\n");
-		return -EINVAL;
-	}
-
-	if (!flags && !pdata->l3_l4_filter) {
-		printk(KERN_ALERT
-			"L3/L4 filtering is already disabled\n");
-		return -EINVAL;
-	}
-
-	pdata->l3_l4_filter = !!flags;
-	hw_if->config_l3_l4_filter_enable(pdata->l3_l4_filter);
-
-	DBGPR_FILTER("Succesfully %s L3/L4 filtering\n",
-		(flags ? "ENABLED" : "DISABLED"));
-
-	DBGPR_FILTER("<--DWC_ETH_QOS_config_l3_l4_filtering\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   int ret = 0;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_config_l3_l4_filtering\n");
+
+   if (flags && pdata->l3_l4_filter) {
+      printk(KERN_ALERT
+         "L3/L4 filtering is already enabled\n");
+      return -EINVAL;
+   }
+
+   if (!flags && !pdata->l3_l4_filter) {
+      printk(KERN_ALERT
+         "L3/L4 filtering is already disabled\n");
+      return -EINVAL;
+   }
+
+   pdata->l3_l4_filter = !!flags;
+   hw_if->config_l3_l4_filter_enable(pdata->l3_l4_filter);
+
+   DBGPR_FILTER("Succesfully %s L3/L4 filtering\n",
+      (flags ? "ENABLED" : "DISABLED"));
+
+   DBGPR_FILTER("<--DWC_ETH_QOS_config_l3_l4_filtering\n");
+
+   return ret;
 }
 
 /*!
@@ -3696,57 +3717,57 @@ static int DWC_ETH_QOS_config_l3_l4_filt
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_ip4_filters(struct net_device *dev,
-		struct ifr_data_struct *req)
+      struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct DWC_ETH_QOS_l3_l4_filter *u_l3_filter =
-		(struct DWC_ETH_QOS_l3_l4_filter *)req->ptr;
-	struct DWC_ETH_QOS_l3_l4_filter l_l3_filter;
-	int ret = 0;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_config_ip4_filters\n");
-
-	if (pdata->hw_feat.l3l4_filter_num == 0)
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-
-	if (copy_from_user(&l_l3_filter, u_l3_filter,
-		sizeof(struct DWC_ETH_QOS_l3_l4_filter)))
-		return -EFAULT;
-
-	if ((l_l3_filter.filter_no + 1) > pdata->hw_feat.l3l4_filter_num) {
-		printk(KERN_ALERT "%d filter is not supported in the HW\n",
-			l_l3_filter.filter_no);
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-	}
-
-	if (!pdata->l3_l4_filter) {
-		hw_if->config_l3_l4_filter_enable(1);
-		pdata->l3_l4_filter = 1;
-	}
-
-	/* configure the L3 filters */
-	hw_if->config_l3_filters(l_l3_filter.filter_no,
-			l_l3_filter.filter_enb_dis, 0,
-			l_l3_filter.src_dst_addr_match,
-			l_l3_filter.perfect_inverse_match);
-
-	if (!l_l3_filter.src_dst_addr_match)
-		hw_if->update_ip4_addr0(l_l3_filter.filter_no,
-				l_l3_filter.ip4_addr);
-	else
-		hw_if->update_ip4_addr1(l_l3_filter.filter_no,
-				l_l3_filter.ip4_addr);
-
-	DBGPR_FILTER("Successfully %s IPv4 %s %s addressing filtering on %d filter\n",
-		(l_l3_filter.filter_enb_dis ? "ENABLED" : "DISABLED"),
-		(l_l3_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"),
-		(l_l3_filter.src_dst_addr_match ? "DESTINATION" : "SOURCE"),
-		l_l3_filter.filter_no);
-
-	DBGPR_FILTER("<--DWC_ETH_QOS_config_ip4_filters\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct DWC_ETH_QOS_l3_l4_filter *u_l3_filter =
+      (struct DWC_ETH_QOS_l3_l4_filter *)req->ptr;
+   struct DWC_ETH_QOS_l3_l4_filter l_l3_filter;
+   int ret = 0;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_config_ip4_filters\n");
+
+   if (pdata->hw_feat.l3l4_filter_num == 0)
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+
+   if (copy_from_user(&l_l3_filter, u_l3_filter,
+      sizeof(struct DWC_ETH_QOS_l3_l4_filter)))
+      return -EFAULT;
+
+   if ((l_l3_filter.filter_no + 1) > pdata->hw_feat.l3l4_filter_num) {
+      printk(KERN_ALERT "%d filter is not supported in the HW\n",
+         l_l3_filter.filter_no);
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+   }
+
+   if (!pdata->l3_l4_filter) {
+      hw_if->config_l3_l4_filter_enable(1);
+      pdata->l3_l4_filter = 1;
+   }
+
+   /* configure the L3 filters */
+   hw_if->config_l3_filters(l_l3_filter.filter_no,
+         l_l3_filter.filter_enb_dis, 0,
+         l_l3_filter.src_dst_addr_match,
+         l_l3_filter.perfect_inverse_match);
+
+   if (!l_l3_filter.src_dst_addr_match)
+      hw_if->update_ip4_addr0(l_l3_filter.filter_no,
+            l_l3_filter.ip4_addr);
+   else
+      hw_if->update_ip4_addr1(l_l3_filter.filter_no,
+            l_l3_filter.ip4_addr);
+
+   DBGPR_FILTER("Successfully %s IPv4 %s %s addressing filtering on %d filter\n",
+      (l_l3_filter.filter_enb_dis ? "ENABLED" : "DISABLED"),
+      (l_l3_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"),
+      (l_l3_filter.src_dst_addr_match ? "DESTINATION" : "SOURCE"),
+      l_l3_filter.filter_no);
+
+   DBGPR_FILTER("<--DWC_ETH_QOS_config_ip4_filters\n");
+
+   return ret;
 }
 
 /*!
@@ -3765,53 +3786,53 @@ static int DWC_ETH_QOS_config_ip4_filter
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_ip6_filters(struct net_device *dev,
-		struct ifr_data_struct *req)
+      struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct DWC_ETH_QOS_l3_l4_filter *u_l3_filter =
-		(struct DWC_ETH_QOS_l3_l4_filter *)req->ptr;
-	struct DWC_ETH_QOS_l3_l4_filter l_l3_filter;
-	int ret = 0;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_config_ip6_filters\n");
-
-	if (pdata->hw_feat.l3l4_filter_num == 0)
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-
-	if (copy_from_user(&l_l3_filter, u_l3_filter,
-		sizeof(struct DWC_ETH_QOS_l3_l4_filter)))
-		return -EFAULT;
-
-	if ((l_l3_filter.filter_no + 1) > pdata->hw_feat.l3l4_filter_num) {
-		printk(KERN_ALERT "%d filter is not supported in the HW\n",
-			l_l3_filter.filter_no);
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-	}
-
-	if (!pdata->l3_l4_filter) {
-		hw_if->config_l3_l4_filter_enable(1);
-		pdata->l3_l4_filter = 1;
-	}
-
-	/* configure the L3 filters */
-	hw_if->config_l3_filters(l_l3_filter.filter_no,
-			l_l3_filter.filter_enb_dis, 1,
-			l_l3_filter.src_dst_addr_match,
-			l_l3_filter.perfect_inverse_match);
-
-	hw_if->update_ip6_addr(l_l3_filter.filter_no,
-			l_l3_filter.ip6_addr);
-
-	DBGPR_FILTER("Successfully %s IPv6 %s %s addressing filtering on %d filter\n",
-		(l_l3_filter.filter_enb_dis ? "ENABLED" : "DISABLED"),
-		(l_l3_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"),
-		(l_l3_filter.src_dst_addr_match ? "DESTINATION" : "SOURCE"),
-		l_l3_filter.filter_no);
-
-	DBGPR_FILTER("<--DWC_ETH_QOS_config_ip6_filters\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct DWC_ETH_QOS_l3_l4_filter *u_l3_filter =
+      (struct DWC_ETH_QOS_l3_l4_filter *)req->ptr;
+   struct DWC_ETH_QOS_l3_l4_filter l_l3_filter;
+   int ret = 0;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_config_ip6_filters\n");
+
+   if (pdata->hw_feat.l3l4_filter_num == 0)
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+
+   if (copy_from_user(&l_l3_filter, u_l3_filter,
+      sizeof(struct DWC_ETH_QOS_l3_l4_filter)))
+      return -EFAULT;
+
+   if ((l_l3_filter.filter_no + 1) > pdata->hw_feat.l3l4_filter_num) {
+      printk(KERN_ALERT "%d filter is not supported in the HW\n",
+         l_l3_filter.filter_no);
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+   }
+
+   if (!pdata->l3_l4_filter) {
+      hw_if->config_l3_l4_filter_enable(1);
+      pdata->l3_l4_filter = 1;
+   }
+
+   /* configure the L3 filters */
+   hw_if->config_l3_filters(l_l3_filter.filter_no,
+         l_l3_filter.filter_enb_dis, 1,
+         l_l3_filter.src_dst_addr_match,
+         l_l3_filter.perfect_inverse_match);
+
+   hw_if->update_ip6_addr(l_l3_filter.filter_no,
+         l_l3_filter.ip6_addr);
+
+   DBGPR_FILTER("Successfully %s IPv6 %s %s addressing filtering on %d filter\n",
+      (l_l3_filter.filter_enb_dis ? "ENABLED" : "DISABLED"),
+      (l_l3_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"),
+      (l_l3_filter.src_dst_addr_match ? "DESTINATION" : "SOURCE"),
+      l_l3_filter.filter_no);
+
+   DBGPR_FILTER("<--DWC_ETH_QOS_config_ip6_filters\n");
+
+   return ret;
 }
 
 /*!
@@ -3832,60 +3853,60 @@ static int DWC_ETH_QOS_config_ip6_filter
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_tcp_udp_filters(struct net_device *dev,
-		struct ifr_data_struct *req,
-		int tcp_udp)
+      struct ifr_data_struct *req,
+      int tcp_udp)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct DWC_ETH_QOS_l3_l4_filter *u_l4_filter =
-		(struct DWC_ETH_QOS_l3_l4_filter *)req->ptr;
-	struct DWC_ETH_QOS_l3_l4_filter l_l4_filter;
-	int ret = 0;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_config_tcp_udp_filters\n");
-
-	if (pdata->hw_feat.l3l4_filter_num == 0)
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-
-	if (copy_from_user(&l_l4_filter, u_l4_filter,
-		sizeof(struct DWC_ETH_QOS_l3_l4_filter)))
-		return -EFAULT;
-
-	if ((l_l4_filter.filter_no + 1) > pdata->hw_feat.l3l4_filter_num) {
-		printk(KERN_ALERT "%d filter is not supported in the HW\n",
-			l_l4_filter.filter_no);
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-	}
-
-	if (!pdata->l3_l4_filter) {
-		hw_if->config_l3_l4_filter_enable(1);
-		pdata->l3_l4_filter = 1;
-	}
-
-	/* configure the L4 filters */
-	hw_if->config_l4_filters(l_l4_filter.filter_no,
-			l_l4_filter.filter_enb_dis,
-			tcp_udp,
-			l_l4_filter.src_dst_addr_match,
-			l_l4_filter.perfect_inverse_match);
-
-	if (l_l4_filter.src_dst_addr_match)
-		hw_if->update_l4_da_port_no(l_l4_filter.filter_no,
-				l_l4_filter.port_no);
-	else
-		hw_if->update_l4_sa_port_no(l_l4_filter.filter_no,
-				l_l4_filter.port_no);
-
-	DBGPR_FILTER("Successfully %s %s %s %s Port number filtering on %d filter\n",
-		(l_l4_filter.filter_enb_dis ? "ENABLED" : "DISABLED"),
-		(tcp_udp ? "UDP" : "TCP"),
-		(l_l4_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"),
-		(l_l4_filter.src_dst_addr_match ? "DESTINATION" : "SOURCE"),
-		l_l4_filter.filter_no);
-
-	DBGPR_FILTER("<--DWC_ETH_QOS_config_tcp_udp_filters\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct DWC_ETH_QOS_l3_l4_filter *u_l4_filter =
+      (struct DWC_ETH_QOS_l3_l4_filter *)req->ptr;
+   struct DWC_ETH_QOS_l3_l4_filter l_l4_filter;
+   int ret = 0;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_config_tcp_udp_filters\n");
+
+   if (pdata->hw_feat.l3l4_filter_num == 0)
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+
+   if (copy_from_user(&l_l4_filter, u_l4_filter,
+      sizeof(struct DWC_ETH_QOS_l3_l4_filter)))
+      return -EFAULT;
+
+   if ((l_l4_filter.filter_no + 1) > pdata->hw_feat.l3l4_filter_num) {
+      printk(KERN_ALERT "%d filter is not supported in the HW\n",
+         l_l4_filter.filter_no);
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+   }
+
+   if (!pdata->l3_l4_filter) {
+      hw_if->config_l3_l4_filter_enable(1);
+      pdata->l3_l4_filter = 1;
+   }
+
+   /* configure the L4 filters */
+   hw_if->config_l4_filters(l_l4_filter.filter_no,
+         l_l4_filter.filter_enb_dis,
+         tcp_udp,
+         l_l4_filter.src_dst_addr_match,
+         l_l4_filter.perfect_inverse_match);
+
+   if (l_l4_filter.src_dst_addr_match)
+      hw_if->update_l4_da_port_no(l_l4_filter.filter_no,
+            l_l4_filter.port_no);
+   else
+      hw_if->update_l4_sa_port_no(l_l4_filter.filter_no,
+            l_l4_filter.port_no);
+
+   DBGPR_FILTER("Successfully %s %s %s %s Port number filtering on %d filter\n",
+      (l_l4_filter.filter_enb_dis ? "ENABLED" : "DISABLED"),
+      (tcp_udp ? "UDP" : "TCP"),
+      (l_l4_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"),
+      (l_l4_filter.src_dst_addr_match ? "DESTINATION" : "SOURCE"),
+      l_l4_filter.filter_no);
+
+   DBGPR_FILTER("<--DWC_ETH_QOS_config_tcp_udp_filters\n");
+
+   return ret;
 }
 
 /*!
@@ -3902,41 +3923,41 @@ static int DWC_ETH_QOS_config_tcp_udp_fi
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_vlan_filter(struct net_device *dev,
-		struct ifr_data_struct *req)
+      struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct DWC_ETH_QOS_vlan_filter *u_vlan_filter =
-		(struct DWC_ETH_QOS_vlan_filter *)req->ptr;
-	struct DWC_ETH_QOS_vlan_filter l_vlan_filter;
-	int ret = 0;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_config_vlan_filter\n");
-
-	if (copy_from_user(&l_vlan_filter, u_vlan_filter,
-		sizeof(struct DWC_ETH_QOS_vlan_filter)))
-		return -EFAULT;
-
-	if ((l_vlan_filter.perfect_hash) &&
-		(pdata->hw_feat.vlan_hash_en == 0)) {
-		printk(KERN_ALERT "VLAN HASH filtering is not supported\n");
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-	}
-
-	/* configure the vlan filter */
-	hw_if->config_vlan_filtering(l_vlan_filter.filter_enb_dis,
-					l_vlan_filter.perfect_hash,
-					l_vlan_filter.perfect_inverse_match);
-	pdata->vlan_hash_filtering = l_vlan_filter.perfect_hash;
-
-	DBGPR_FILTER("Successfully %s VLAN %s filtering and %s matching\n",
-		(l_vlan_filter.filter_enb_dis ? "ENABLED" : "DISABLED"),
-		(l_vlan_filter.perfect_hash ? "HASH" : "PERFECT"),
-		(l_vlan_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"));
-
-	DBGPR_FILTER("<--DWC_ETH_QOS_config_vlan_filter\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct DWC_ETH_QOS_vlan_filter *u_vlan_filter =
+      (struct DWC_ETH_QOS_vlan_filter *)req->ptr;
+   struct DWC_ETH_QOS_vlan_filter l_vlan_filter;
+   int ret = 0;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_config_vlan_filter\n");
+
+   if (copy_from_user(&l_vlan_filter, u_vlan_filter,
+      sizeof(struct DWC_ETH_QOS_vlan_filter)))
+      return -EFAULT;
+
+   if ((l_vlan_filter.perfect_hash) &&
+      (pdata->hw_feat.vlan_hash_en == 0)) {
+      printk(KERN_ALERT "VLAN HASH filtering is not supported\n");
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+   }
+
+   /* configure the vlan filter */
+   hw_if->config_vlan_filtering(l_vlan_filter.filter_enb_dis,
+               l_vlan_filter.perfect_hash,
+               l_vlan_filter.perfect_inverse_match);
+   pdata->vlan_hash_filtering = l_vlan_filter.perfect_hash;
+
+   DBGPR_FILTER("Successfully %s VLAN %s filtering and %s matching\n",
+      (l_vlan_filter.filter_enb_dis ? "ENABLED" : "DISABLED"),
+      (l_vlan_filter.perfect_hash ? "HASH" : "PERFECT"),
+      (l_vlan_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"));
+
+   DBGPR_FILTER("<--DWC_ETH_QOS_config_vlan_filter\n");
+
+   return ret;
 }
 
 /*!
@@ -3951,38 +3972,37 @@ static int DWC_ETH_QOS_config_vlan_filte
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_arp_offload(struct net_device *dev,
-		struct ifr_data_struct *req)
+      struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct DWC_ETH_QOS_arp_offload *u_arp_offload =
-		(struct DWC_ETH_QOS_arp_offload *)req->ptr;
-	struct DWC_ETH_QOS_arp_offload l_arp_offload;
-	int ret = 0;
-
-	printk(KERN_ALERT "-->DWC_ETH_QOS_config_arp_offload\n");
-
-	if (pdata->hw_feat.arp_offld_en == 0)
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-
-	if (copy_from_user(&l_arp_offload, u_arp_offload,
-		sizeof(struct DWC_ETH_QOS_arp_offload)))
-		return -EFAULT;
-
-	/* configure the L3 filters */
-	hw_if->config_arp_offload(req->flags);
-	hw_if->update_arp_offload_ip_addr(l_arp_offload.ip_addr, pdata->version);
-	pdata->arp_offload = req->flags;
-
-	printk(KERN_ALERT "Successfully %s arp Offload\n",
-		(req->flags ? "ENABLED" : "DISABLED"));
-
-	printk(KERN_ALERT "<--DWC_ETH_QOS_config_arp_offload\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct DWC_ETH_QOS_arp_offload *u_arp_offload =
+      (struct DWC_ETH_QOS_arp_offload *)req->ptr;
+   struct DWC_ETH_QOS_arp_offload l_arp_offload;
+   int ret = 0;
+
+   printk(KERN_ALERT "-->DWC_ETH_QOS_config_arp_offload\n");
+
+   if (pdata->hw_feat.arp_offld_en == 0)
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+
+   if (copy_from_user(&l_arp_offload, u_arp_offload,
+      sizeof(struct DWC_ETH_QOS_arp_offload)))
+      return -EFAULT;
+
+   /* configure the L3 filters */
+   hw_if->config_arp_offload(req->flags);
+   hw_if->update_arp_offload_ip_addr(l_arp_offload.ip_addr, pdata->version);
+   pdata->arp_offload = req->flags;
+
+   printk(KERN_ALERT "Successfully %s arp Offload\n",
+      (req->flags ? "ENABLED" : "DISABLED"));
+
+   printk(KERN_ALERT "<--DWC_ETH_QOS_config_arp_offload\n");
+
+   return ret;
 }
 
-
 /*!
  * \details This function is invoked by ioctl function when user issues an
  * ioctl command to configure L2 destination addressing filtering mode. This
@@ -3998,43 +4018,43 @@ static int DWC_ETH_QOS_config_arp_offloa
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_confing_l2_da_filter(struct net_device *dev,
-		struct ifr_data_struct *req)
+      struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct DWC_ETH_QOS_l2_da_filter *u_l2_da_filter =
-	  (struct DWC_ETH_QOS_l2_da_filter *)req->ptr;
-	struct DWC_ETH_QOS_l2_da_filter l_l2_da_filter;
-	int ret = 0;
-
-	DBGPR_FILTER("-->DWC_ETH_QOS_confing_l2_da_filter\n");
-
-	if (copy_from_user(&l_l2_da_filter, u_l2_da_filter,
-	      sizeof(struct DWC_ETH_QOS_l2_da_filter)))
-		return - EFAULT;
-
-	if (l_l2_da_filter.perfect_hash) {
-		if (pdata->hw_feat.hash_tbl_sz > 0)
-			pdata->l2_filtering_mode = 1;
-		else
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-	} else {
-		if (pdata->max_addr_reg_cnt > 1)
-			pdata->l2_filtering_mode = 0;
-		else
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-	}
-
-	/* configure L2 DA perfect/inverse_matching */
-	hw_if->config_l2_da_perfect_inverse_match(l_l2_da_filter.perfect_inverse_match);
-
-	DBGPR_FILTER("Successfully selected L2 %s filtering and %s DA matching\n",
-		(l_l2_da_filter.perfect_hash ? "HASH" : "PERFECT"),
-		(l_l2_da_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"));
-
-	DBGPR_FILTER("<--DWC_ETH_QOS_confing_l2_da_filter\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct DWC_ETH_QOS_l2_da_filter *u_l2_da_filter =
+     (struct DWC_ETH_QOS_l2_da_filter *)req->ptr;
+   struct DWC_ETH_QOS_l2_da_filter l_l2_da_filter;
+   int ret = 0;
+
+   DBGPR_FILTER("-->DWC_ETH_QOS_confing_l2_da_filter\n");
+
+   if (copy_from_user(&l_l2_da_filter, u_l2_da_filter,
+         sizeof(struct DWC_ETH_QOS_l2_da_filter)))
+      return - EFAULT;
+
+   if (l_l2_da_filter.perfect_hash) {
+      if (pdata->hw_feat.hash_tbl_sz > 0)
+         pdata->l2_filtering_mode = 1;
+      else
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+   } else {
+      if (pdata->max_addr_reg_cnt > 1)
+         pdata->l2_filtering_mode = 0;
+      else
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+   }
+
+   /* configure L2 DA perfect/inverse_matching */
+   hw_if->config_l2_da_perfect_inverse_match(l_l2_da_filter.perfect_inverse_match);
+
+   DBGPR_FILTER("Successfully selected L2 %s filtering and %s DA matching\n",
+      (l_l2_da_filter.perfect_hash ? "HASH" : "PERFECT"),
+      (l_l2_da_filter.perfect_inverse_match ? "INVERSE" : "PERFECT"));
+
+   DBGPR_FILTER("<--DWC_ETH_QOS_confing_l2_da_filter\n");
+
+   return ret;
 }
 
 /*!
@@ -4050,84 +4070,84 @@ static int DWC_ETH_QOS_confing_l2_da_fil
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_mac_loopback_mode(struct net_device *dev,
-		unsigned int flags)
+      unsigned int flags)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	int ret = 0;
-
-	DBGPR("-->DWC_ETH_QOS_config_mac_loopback_mode\n");
-
-	if (flags && pdata->mac_loopback_mode) {
-		printk(KERN_ALERT
-			"MAC loopback mode is already enabled\n");
-		return -EINVAL;
-	}
-	if (!flags && !pdata->mac_loopback_mode) {
-		printk(KERN_ALERT
-			"MAC loopback mode is already disabled\n");
-		return -EINVAL;
-	}
-	pdata->mac_loopback_mode = !!flags;
-	hw_if->config_mac_loopback_mode(flags);
-
-	printk(KERN_ALERT "Succesfully %s MAC loopback mode\n",
-		(flags ? "enabled" : "disabled"));
-
-	DBGPR("<--DWC_ETH_QOS_config_mac_loopback_mode\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   int ret = 0;
+
+   DBGPR("-->DWC_ETH_QOS_config_mac_loopback_mode\n");
+
+   if (flags && pdata->mac_loopback_mode) {
+      printk(KERN_ALERT
+         "MAC loopback mode is already enabled\n");
+      return -EINVAL;
+   }
+   if (!flags && !pdata->mac_loopback_mode) {
+      printk(KERN_ALERT
+         "MAC loopback mode is already disabled\n");
+      return -EINVAL;
+   }
+   pdata->mac_loopback_mode = !!flags;
+   hw_if->config_mac_loopback_mode(flags);
+
+   printk(KERN_ALERT "Succesfully %s MAC loopback mode\n",
+      (flags ? "enabled" : "disabled"));
+
+   DBGPR("<--DWC_ETH_QOS_config_mac_loopback_mode\n");
+
+   return ret;
 }
 
 #ifdef DWC_ETH_QOS_ENABLE_DVLAN
 static int config_tx_dvlan_processing_via_reg(struct DWC_ETH_QOS_prv_data *pdata,
-						uint32_t flags)
+                  uint32_t flags)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-
-	printk(KERN_ALERT "--> config_tx_dvlan_processing_via_reg()\n");
-
-	if (pdata->in_out & DWC_ETH_QOS_DVLAN_OUTER)
-		hw_if->config_tx_outer_vlan(pdata->op_type,
-					pdata->outer_vlan_tag);
-
-	if (pdata->in_out & DWC_ETH_QOS_DVLAN_INNER)
-		hw_if->config_tx_inner_vlan(pdata->op_type,
-					pdata->inner_vlan_tag);
-
-	if (flags == DWC_ETH_QOS_DVLAN_DISABLE)
-		hw_if->config_mac_for_vlan_pkt(); /* restore default configurations */
-	else
-		hw_if->config_dvlan(1);
-
-	printk(KERN_ALERT "<-- config_tx_dvlan_processing_via_reg()\n");
-
-	return Y_SUCCESS;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+
+   printk(KERN_ALERT "--> config_tx_dvlan_processing_via_reg()\n");
+
+   if (pdata->in_out & DWC_ETH_QOS_DVLAN_OUTER)
+      hw_if->config_tx_outer_vlan(pdata->op_type,
+               pdata->outer_vlan_tag);
+
+   if (pdata->in_out & DWC_ETH_QOS_DVLAN_INNER)
+      hw_if->config_tx_inner_vlan(pdata->op_type,
+               pdata->inner_vlan_tag);
+
+   if (flags == DWC_ETH_QOS_DVLAN_DISABLE)
+      hw_if->config_mac_for_vlan_pkt(); /* restore default configurations */
+   else
+      hw_if->config_dvlan(1);
+
+   printk(KERN_ALERT "<-- config_tx_dvlan_processing_via_reg()\n");
+
+   return Y_SUCCESS;
 }
 
 static int config_tx_dvlan_processing_via_desc(struct DWC_ETH_QOS_prv_data *pdata,
-						uint32_t flags)
+                  uint32_t flags)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-
-	printk(KERN_ALERT "-->config_tx_dvlan_processing_via_desc\n");
-
-	if (flags == DWC_ETH_QOS_DVLAN_DISABLE) {
-		hw_if->config_mac_for_vlan_pkt(); /* restore default configurations */
-		pdata->via_reg_or_desc = 0;
-	} else {
-		hw_if->config_dvlan(1);
-	}
-
-	if (pdata->in_out & DWC_ETH_QOS_DVLAN_INNER)
-			MAC_IVLANTIRR_VLTI_UdfWr(1);
-
-	if (pdata->in_out & DWC_ETH_QOS_DVLAN_OUTER)
-			MAC_VLANTIRR_VLTI_UdfWr(1);
-
-	printk(KERN_ALERT "<--config_tx_dvlan_processing_via_desc\n");
-
-	return Y_SUCCESS;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+
+   printk(KERN_ALERT "-->config_tx_dvlan_processing_via_desc\n");
+
+   if (flags == DWC_ETH_QOS_DVLAN_DISABLE) {
+      hw_if->config_mac_for_vlan_pkt(); /* restore default configurations */
+      pdata->via_reg_or_desc = 0;
+   } else {
+      hw_if->config_dvlan(1);
+   }
+
+   if (pdata->in_out & DWC_ETH_QOS_DVLAN_INNER)
+         MAC_IVLANTIRR_VLTI_UdfWr(1);
+
+   if (pdata->in_out & DWC_ETH_QOS_DVLAN_OUTER)
+         MAC_VLANTIRR_VLTI_UdfWr(1);
+
+   printk(KERN_ALERT "<--config_tx_dvlan_processing_via_desc\n");
+
+   return Y_SUCCESS;
 }
 
 /*!
@@ -4136,42 +4156,42 @@ static int config_tx_dvlan_processing_vi
  *
  * \param[in] pdata - pointer to private data structure.
  * \param[in] flags  Each bit in this variable carry some information related
- *		      double vlan processing.
+ *            double vlan processing.
  *
  * \return integer
  *
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_tx_dvlan_processing(
-		struct DWC_ETH_QOS_prv_data *pdata,
-		struct ifr_data_struct *req)
+      struct DWC_ETH_QOS_prv_data *pdata,
+      struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_config_dvlan l_config_doubule_vlan,
-					  *u_config_doubule_vlan = req->ptr;
-	int ret = 0;
-
-	DBGPR("-->DWC_ETH_QOS_config_tx_dvlan_processing\n");
-
-	if(copy_from_user(&l_config_doubule_vlan, u_config_doubule_vlan,
-				sizeof(struct DWC_ETH_QOS_config_dvlan))) {
-		printk(KERN_ALERT "Failed to fetch Double vlan Struct info from user\n");
-		return DWC_ETH_QOS_CONFIG_FAIL;
-	}
-
-	pdata->inner_vlan_tag = l_config_doubule_vlan.inner_vlan_tag;
-	pdata->outer_vlan_tag = l_config_doubule_vlan.outer_vlan_tag;
-	pdata->op_type = l_config_doubule_vlan.op_type;
-	pdata->in_out = l_config_doubule_vlan.in_out;
-	pdata->via_reg_or_desc = l_config_doubule_vlan.via_reg_or_desc;
-
-	if (pdata->via_reg_or_desc == DWC_ETH_QOS_VIA_REG)
-		ret = config_tx_dvlan_processing_via_reg(pdata, req->flags);
-	else
-		ret = config_tx_dvlan_processing_via_desc(pdata, req->flags);
-
-	DBGPR("<--DWC_ETH_QOS_config_tx_dvlan_processing\n");
-
-	return ret;
+   struct DWC_ETH_QOS_config_dvlan l_config_doubule_vlan,
+                 *u_config_doubule_vlan = req->ptr;
+   int ret = 0;
+
+   DBGPR("-->DWC_ETH_QOS_config_tx_dvlan_processing\n");
+
+   if(copy_from_user(&l_config_doubule_vlan, u_config_doubule_vlan,
+            sizeof(struct DWC_ETH_QOS_config_dvlan))) {
+      printk(KERN_ALERT "Failed to fetch Double vlan Struct info from user\n");
+      return DWC_ETH_QOS_CONFIG_FAIL;
+   }
+
+   pdata->inner_vlan_tag = l_config_doubule_vlan.inner_vlan_tag;
+   pdata->outer_vlan_tag = l_config_doubule_vlan.outer_vlan_tag;
+   pdata->op_type = l_config_doubule_vlan.op_type;
+   pdata->in_out = l_config_doubule_vlan.in_out;
+   pdata->via_reg_or_desc = l_config_doubule_vlan.via_reg_or_desc;
+
+   if (pdata->via_reg_or_desc == DWC_ETH_QOS_VIA_REG)
+      ret = config_tx_dvlan_processing_via_reg(pdata, req->flags);
+   else
+      ret = config_tx_dvlan_processing_via_desc(pdata, req->flags);
+
+   DBGPR("<--DWC_ETH_QOS_config_tx_dvlan_processing\n");
+
+   return ret;
 }
 
 /*!
@@ -4180,42 +4200,42 @@ static int DWC_ETH_QOS_config_tx_dvlan_p
  *
  * \param[in] pdata - pointer to private data structure.
  * \param[in] flags  Each bit in this variable carry some information related
- *		      double vlan processing.
+ *            double vlan processing.
  *
  * \return integer
  *
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_rx_dvlan_processing(
-		struct DWC_ETH_QOS_prv_data *pdata, unsigned int flags)
+      struct DWC_ETH_QOS_prv_data *pdata, unsigned int flags)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	int ret = 0;
-
-	DBGPR("-->DWC_ETH_QOS_config_rx_dvlan_processing\n");
-
-	hw_if->config_dvlan(1);
-	if (flags == DWC_ETH_QOS_DVLAN_NONE) {
-		hw_if->config_dvlan(0);
-		hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
-		hw_if->config_rx_inner_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
-	} else if (flags == DWC_ETH_QOS_DVLAN_INNER) {
-		hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
-		hw_if->config_rx_inner_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
-	} else if (flags == DWC_ETH_QOS_DVLAN_OUTER) {
-		hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
-		hw_if->config_rx_inner_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
-	} else if (flags == DWC_ETH_QOS_DVLAN_BOTH) {
-		hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
-		hw_if->config_rx_inner_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
-	} else {
-		printk(KERN_ALERT "ERROR : double VLAN Rx configuration - Invalid argument");
-		ret = DWC_ETH_QOS_CONFIG_FAIL;
-	}
-
-	DBGPR("<--DWC_ETH_QOS_config_rx_dvlan_processing\n");
-
-	return ret;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   int ret = 0;
+
+   DBGPR("-->DWC_ETH_QOS_config_rx_dvlan_processing\n");
+
+   hw_if->config_dvlan(1);
+   if (flags == DWC_ETH_QOS_DVLAN_NONE) {
+      hw_if->config_dvlan(0);
+      hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
+      hw_if->config_rx_inner_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
+   } else if (flags == DWC_ETH_QOS_DVLAN_INNER) {
+      hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
+      hw_if->config_rx_inner_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
+   } else if (flags == DWC_ETH_QOS_DVLAN_OUTER) {
+      hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
+      hw_if->config_rx_inner_vlan_stripping(DWC_ETH_QOS_RX_NO_VLAN_STRIP);
+   } else if (flags == DWC_ETH_QOS_DVLAN_BOTH) {
+      hw_if->config_rx_outer_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
+      hw_if->config_rx_inner_vlan_stripping(DWC_ETH_QOS_RX_VLAN_STRIP_ALWAYS);
+   } else {
+      printk(KERN_ALERT "ERROR : double VLAN Rx configuration - Invalid argument");
+      ret = DWC_ETH_QOS_CONFIG_FAIL;
+   }
+
+   DBGPR("<--DWC_ETH_QOS_config_rx_dvlan_processing\n");
+
+   return ret;
 }
 
 /*!
@@ -4224,65 +4244,65 @@ static int DWC_ETH_QOS_config_rx_dvlan_p
  *
  * \param[in] pdata - pointer to private data structure.
  * \param[in] flags  Each bit in this variable carry some information related
- *		      double vlan processing.
+ *            double vlan processing.
  *
  * \return integer
  *
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_svlan(struct DWC_ETH_QOS_prv_data *pdata,
-					unsigned int flags)
+               unsigned int flags)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	int ret = 0;
-
-	DBGPR("-->DWC_ETH_QOS_config_svlan\n");
-
-	ret = hw_if->config_svlan(flags);
-	if (ret == Y_FAILURE)
-		ret = DWC_ETH_QOS_CONFIG_FAIL;
-
-	DBGPR("<--DWC_ETH_QOS_config_svlan\n");
-
-	return ret;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   int ret = 0;
+
+   DBGPR("-->DWC_ETH_QOS_config_svlan\n");
+
+   ret = hw_if->config_svlan(flags);
+   if (ret == Y_FAILURE)
+      ret = DWC_ETH_QOS_CONFIG_FAIL;
+
+   DBGPR("<--DWC_ETH_QOS_config_svlan\n");
+
+   return ret;
 }
 #endif /* end of DWC_ETH_QOS_ENABLE_DVLAN */
 
 static void DWC_ETH_QOS_config_timer_registers(
-				struct DWC_ETH_QOS_prv_data *pdata)
+            struct DWC_ETH_QOS_prv_data *pdata)
 {
-		struct timespec now;
-		struct hw_if_struct *hw_if = &(pdata->hw_if);
-		uint64_t temp;
-
-		DBGPR("-->DWC_ETH_QOS_config_timer_registers\n");
-
-		/* program Sub Second Increment Reg */
-		hw_if->config_sub_second_increment(DWC_ETH_QOS_SYSCLOCK);
-
-		/* formula is :
-		 * addend = 2^32/freq_div_ratio;
-		 *
-		 * where, freq_div_ratio = DWC_ETH_QOS_SYSCLOCK/50MHz
-		 *
-		 * hence, addend = ((2^32) * 50MHz)/DWC_ETH_QOS_SYSCLOCK;
-		 *
-		 * NOTE: DWC_ETH_QOS_SYSCLOCK should be >= 50MHz to
-		 *       achive 20ns accuracy.
-		 *
-		 * 2^x * y == (y << x), hence
-		 * 2^32 * 50000000 ==> (50000000 << 32)
-		 * */
-		temp = (uint64_t)(50000000ULL << 32);
-		pdata->default_addend = div_u64(temp, 62500000);
-
-		hw_if->config_addend(pdata->default_addend);
-
-		/* initialize system time */
-		getnstimeofday(&now);
-		hw_if->init_systime(now.tv_sec, now.tv_nsec);
-
-		DBGPR("-->DWC_ETH_QOS_config_timer_registers\n");
+      struct timespec now;
+      hw_interface_t *hw_if = &(pdata->hw_if);
+      uint64_t temp;
+
+      DBGPR("-->DWC_ETH_QOS_config_timer_registers\n");
+
+      /* program Sub Second Increment Reg */
+      hw_if->config_sub_second_increment(DWC_ETH_QOS_SYSCLOCK);
+
+      /* formula is :
+       * addend = 2^32/freq_div_ratio;
+       *
+       * where, freq_div_ratio = DWC_ETH_QOS_SYSCLOCK/50MHz
+       *
+       * hence, addend = ((2^32) * 50MHz)/DWC_ETH_QOS_SYSCLOCK;
+       *
+       * NOTE: DWC_ETH_QOS_SYSCLOCK should be >= 50MHz to
+       *       achive 20ns accuracy.
+       *
+       * 2^x * y == (y << x), hence
+       * 2^32 * 50000000 ==> (50000000 << 32)
+       * */
+      temp = (uint64_t)(50000000ULL << 32);
+      pdata->default_addend = div_u64(temp, 62500000);
+
+      hw_if->config_addend(pdata->default_addend);
+
+      /* initialize system time */
+      getnstimeofday(&now);
+      hw_if->init_systime(now.tv_sec, now.tv_nsec);
+
+      DBGPR("-->DWC_ETH_QOS_config_timer_registers\n");
 }
 
 /*!
@@ -4291,85 +4311,84 @@ static void DWC_ETH_QOS_config_timer_reg
  *
  * \param[in] pdata - pointer to private data structure.
  * \param[in] flags  Each bit in this variable carry some information related
- *		      double vlan processing.
+ *            double vlan processing.
  *
  * \return integer
  *
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_ptpoffload(
-		struct DWC_ETH_QOS_prv_data *pdata,
-		struct DWC_ETH_QOS_config_ptpoffloading *u_conf_ptp)
+      struct DWC_ETH_QOS_prv_data *pdata,
+      struct DWC_ETH_QOS_config_ptpoffloading *u_conf_ptp)
 {
-	uint32_t pto_cntrl;
-	uint32_t varMAC_TCR;
-	struct DWC_ETH_QOS_config_ptpoffloading l_conf_ptp;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-
-
-	if(copy_from_user(&l_conf_ptp, u_conf_ptp,
-				sizeof(struct DWC_ETH_QOS_config_ptpoffloading))) {
-		printk(KERN_ALERT "Failed to fetch Double vlan Struct info from user\n");
-		return DWC_ETH_QOS_CONFIG_FAIL;
-	}
-
-	printk(KERN_ALERT"-->DWC_ETH_QOS_config_ptpoffload - %d\n",l_conf_ptp.mode);
-
-	pto_cntrl = MAC_PTOCR_PTOEN; /* enable ptp offloading */
-	varMAC_TCR = MAC_TCR_TSENA | MAC_TCR_TSIPENA | MAC_TCR_TSVER2ENA
-			| MAC_TCR_TSCFUPDT | MAC_TCR_TSCTRLSSR;
-	if (l_conf_ptp.mode == DWC_ETH_QOS_PTP_ORDINARY_SLAVE) {
-
-		varMAC_TCR |= MAC_TCR_TSEVENTENA;
-		pdata->ptp_offloading_mode = DWC_ETH_QOS_PTP_ORDINARY_SLAVE;
-
-	} else if (l_conf_ptp.mode == DWC_ETH_QOS_PTP_TRASPARENT_SLAVE) {
-
-		pto_cntrl |= MAC_PTOCR_APDREQEN;
-		varMAC_TCR |= MAC_TCR_TSEVENTENA;
-		varMAC_TCR |= MAC_TCR_SNAPTYPSEL_1;
-		pdata->ptp_offloading_mode =
-			DWC_ETH_QOS_PTP_TRASPARENT_SLAVE;
-
-	} else if (l_conf_ptp.mode == DWC_ETH_QOS_PTP_ORDINARY_MASTER) {
-
-		pto_cntrl |= MAC_PTOCR_ASYNCEN;
-		varMAC_TCR |= MAC_TCR_TSEVENTENA;
-		varMAC_TCR |= MAC_TCR_TSMASTERENA;
-		pdata->ptp_offloading_mode = DWC_ETH_QOS_PTP_ORDINARY_MASTER;
-
-	} else if(l_conf_ptp.mode == DWC_ETH_QOS_PTP_TRASPARENT_MASTER) {
-
-		pto_cntrl |= MAC_PTOCR_ASYNCEN | MAC_PTOCR_APDREQEN;
-		varMAC_TCR |= MAC_TCR_SNAPTYPSEL_1;
-		varMAC_TCR |= MAC_TCR_TSEVENTENA;
-		varMAC_TCR |= MAC_TCR_TSMASTERENA;
-		pdata->ptp_offloading_mode =
-			DWC_ETH_QOS_PTP_TRASPARENT_MASTER;
-
-	} else if (l_conf_ptp.mode == DWC_ETH_QOS_PTP_PEER_TO_PEER_TRANSPARENT) {
-
-		pto_cntrl |= MAC_PTOCR_APDREQEN;
-		varMAC_TCR |= MAC_TCR_SNAPTYPSEL_3;
-		pdata->ptp_offloading_mode =
-			DWC_ETH_QOS_PTP_PEER_TO_PEER_TRANSPARENT;
-	}
-
-	pdata->ptp_offload = 1;
-	if (l_conf_ptp.en_dis == DWC_ETH_QOS_PTP_OFFLOADING_DISABLE) {
-		pto_cntrl = 0;
-		varMAC_TCR = 0;
-		pdata->ptp_offload = 0;
-	}
-
-	pto_cntrl |= (l_conf_ptp.domain_num << 8);
-	hw_if->config_hw_time_stamping(varMAC_TCR);
-	DWC_ETH_QOS_config_timer_registers(pdata);
-	hw_if->config_ptpoffload_engine(pto_cntrl, l_conf_ptp.mc_uc);
-
-	printk(KERN_ALERT"<--DWC_ETH_QOS_config_ptpoffload\n");
-
-	return Y_SUCCESS;
+   uint32_t pto_cntrl;
+   uint32_t varMAC_TCR;
+   struct DWC_ETH_QOS_config_ptpoffloading l_conf_ptp;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+
+   if(copy_from_user(&l_conf_ptp, u_conf_ptp,
+            sizeof(struct DWC_ETH_QOS_config_ptpoffloading))) {
+      printk(KERN_ALERT "Failed to fetch Double vlan Struct info from user\n");
+      return DWC_ETH_QOS_CONFIG_FAIL;
+   }
+
+   printk(KERN_ALERT"-->DWC_ETH_QOS_config_ptpoffload - %d\n",l_conf_ptp.mode);
+
+   pto_cntrl = MAC_PTOCR_PTOEN; /* enable ptp offloading */
+   varMAC_TCR = MAC_TCR_TSENA | MAC_TCR_TSIPENA | MAC_TCR_TSVER2ENA
+         | MAC_TCR_TSCFUPDT | MAC_TCR_TSCTRLSSR;
+   if (l_conf_ptp.mode == DWC_ETH_QOS_PTP_ORDINARY_SLAVE) {
+
+      varMAC_TCR |= MAC_TCR_TSEVENTENA;
+      pdata->ptp_offloading_mode = DWC_ETH_QOS_PTP_ORDINARY_SLAVE;
+
+   } else if (l_conf_ptp.mode == DWC_ETH_QOS_PTP_TRASPARENT_SLAVE) {
+
+      pto_cntrl |= MAC_PTOCR_APDREQEN;
+      varMAC_TCR |= MAC_TCR_TSEVENTENA;
+      varMAC_TCR |= MAC_TCR_SNAPTYPSEL_1;
+      pdata->ptp_offloading_mode =
+         DWC_ETH_QOS_PTP_TRASPARENT_SLAVE;
+
+   } else if (l_conf_ptp.mode == DWC_ETH_QOS_PTP_ORDINARY_MASTER) {
+
+      pto_cntrl |= MAC_PTOCR_ASYNCEN;
+      varMAC_TCR |= MAC_TCR_TSEVENTENA;
+      varMAC_TCR |= MAC_TCR_TSMASTERENA;
+      pdata->ptp_offloading_mode = DWC_ETH_QOS_PTP_ORDINARY_MASTER;
+
+   } else if(l_conf_ptp.mode == DWC_ETH_QOS_PTP_TRASPARENT_MASTER) {
+
+      pto_cntrl |= MAC_PTOCR_ASYNCEN | MAC_PTOCR_APDREQEN;
+      varMAC_TCR |= MAC_TCR_SNAPTYPSEL_1;
+      varMAC_TCR |= MAC_TCR_TSEVENTENA;
+      varMAC_TCR |= MAC_TCR_TSMASTERENA;
+      pdata->ptp_offloading_mode =
+         DWC_ETH_QOS_PTP_TRASPARENT_MASTER;
+
+   } else if (l_conf_ptp.mode == DWC_ETH_QOS_PTP_PEER_TO_PEER_TRANSPARENT) {
+
+      pto_cntrl |= MAC_PTOCR_APDREQEN;
+      varMAC_TCR |= MAC_TCR_SNAPTYPSEL_3;
+      pdata->ptp_offloading_mode =
+         DWC_ETH_QOS_PTP_PEER_TO_PEER_TRANSPARENT;
+   }
+
+   pdata->ptp_offload = 1;
+   if (l_conf_ptp.en_dis == DWC_ETH_QOS_PTP_OFFLOADING_DISABLE) {
+      pto_cntrl = 0;
+      varMAC_TCR = 0;
+      pdata->ptp_offload = 0;
+   }
+
+   pto_cntrl |= (l_conf_ptp.domain_num << 8);
+   hw_if->config_hw_time_stamping(varMAC_TCR);
+   DWC_ETH_QOS_config_timer_registers(pdata);
+   hw_if->config_ptpoffload_engine(pto_cntrl, l_conf_ptp.mc_uc);
+
+   printk(KERN_ALERT"<--DWC_ETH_QOS_config_ptpoffload\n");
+
+   return Y_SUCCESS;
 }
 
 /*!
@@ -4384,27 +4403,27 @@ static int DWC_ETH_QOS_config_ptpoffload
  * \retval zero on success and -ve number on failure.
  */
 static int DWC_ETH_QOS_config_pfc(struct net_device *dev,
-		unsigned int flags)
+      unsigned int flags)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	int ret = 0;
-
-	DBGPR("-->DWC_ETH_QOS_config_pfc\n");
-
-	if (!pdata->hw_feat.dcb_en) {
-		printk(KERN_ALERT "PFC is not supported\n");
-		return DWC_ETH_QOS_NO_HW_SUPPORT;
-	}
-
-	hw_if->config_pfc(flags);
-
-	printk(KERN_ALERT "Succesfully %s PFC(Priority Based Flow Control)\n",
-		(flags ? "enabled" : "disabled"));
-
-	DBGPR("<--DWC_ETH_QOS_config_pfc\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   int ret = 0;
+
+   DBGPR("-->DWC_ETH_QOS_config_pfc\n");
+
+   if (!pdata->hw_feat.dcb_en) {
+      printk(KERN_ALERT "PFC is not supported\n");
+      return DWC_ETH_QOS_NO_HW_SUPPORT;
+   }
+
+   hw_if->config_pfc(flags);
+
+   printk(KERN_ALERT "Succesfully %s PFC(Priority Based Flow Control)\n",
+      (flags ? "enabled" : "disabled"));
+
+   DBGPR("<--DWC_ETH_QOS_config_pfc\n");
+
+   return ret;
 }
 
 /*!
@@ -4424,386 +4443,378 @@ static int DWC_ETH_QOS_config_pfc(struct
  * \retval 0 - success
  * \retval negative - failure
  */
-
 static int DWC_ETH_QOS_handle_prv_ioctl(struct DWC_ETH_QOS_prv_data *pdata,
-					struct ifr_data_struct *req)
+               struct ifr_data_struct *req)
 {
-	unsigned int qInx = req->qInx;
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data =
-	    GET_TX_WRAPPER_DESC(qInx);
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data =
-	    GET_RX_WRAPPER_DESC(qInx);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct net_device *dev = pdata->dev;
-	int ret = 0;
-
-	DBGPR("-->DWC_ETH_QOS_handle_prv_ioctl\n");
-
-	if (qInx > DWC_ETH_QOS_QUEUE_CNT) {
-		printk(KERN_ALERT "Queue number %d is invalid\n" \
-				"Hardware has only %d Tx/Rx Queues\n",
-				qInx, DWC_ETH_QOS_QUEUE_CNT);
-		ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		return ret;
-	}
-
-	switch (req->cmd) {
-	case DWC_ETH_QOS_POWERUP_MAGIC_CMD:
-		if (pdata->hw_feat.mgk_sel) {
-			ret = DWC_ETH_QOS_powerup(dev, DWC_ETH_QOS_IOCTL_CONTEXT);
-			if (ret == 0)
-				ret = DWC_ETH_QOS_CONFIG_SUCCESS;
-			else
-				ret = DWC_ETH_QOS_CONFIG_FAIL;
-		} else {
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_POWERDOWN_MAGIC_CMD:
-		if (pdata->hw_feat.mgk_sel) {
-			ret =
-			  DWC_ETH_QOS_powerdown(dev,
-			    DWC_ETH_QOS_MAGIC_WAKEUP, DWC_ETH_QOS_IOCTL_CONTEXT);
-			if (ret == 0)
-				ret = DWC_ETH_QOS_CONFIG_SUCCESS;
-			else
-				ret = DWC_ETH_QOS_CONFIG_FAIL;
-		} else {
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_POWERUP_REMOTE_WAKEUP_CMD:
-		if (pdata->hw_feat.rwk_sel) {
-			ret = DWC_ETH_QOS_powerup(dev, DWC_ETH_QOS_IOCTL_CONTEXT);
-			if (ret == 0)
-				ret = DWC_ETH_QOS_CONFIG_SUCCESS;
-			else
-				ret = DWC_ETH_QOS_CONFIG_FAIL;
-		} else {
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_POWERDOWN_REMOTE_WAKEUP_CMD:
-		if (pdata->hw_feat.rwk_sel) {
-			ret = DWC_ETH_QOS_configure_remotewakeup(dev, req);
-			if (ret == 0)
-				ret = DWC_ETH_QOS_CONFIG_SUCCESS;
-			else
-				ret = DWC_ETH_QOS_CONFIG_FAIL;
-		} else {
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_RX_THRESHOLD_CMD:
-		rx_desc_data->rx_threshold_val = req->flags;
-		hw_if->config_rx_threshold(qInx,
-					rx_desc_data->rx_threshold_val);
-		printk(KERN_ALERT "Configured Rx threshold with %d\n",
-		       rx_desc_data->rx_threshold_val);
-		break;
-
-	case DWC_ETH_QOS_TX_THRESHOLD_CMD:
-		tx_desc_data->tx_threshold_val = req->flags;
-		hw_if->config_tx_threshold(qInx,
-					tx_desc_data->tx_threshold_val);
-		printk(KERN_ALERT "Configured Tx threshold with %d\n",
-		       tx_desc_data->tx_threshold_val);
-		break;
-
-	case DWC_ETH_QOS_RSF_CMD:
-		rx_desc_data->rsf_on = req->flags;
-		hw_if->config_rsf_mode(qInx, rx_desc_data->rsf_on);
-		printk(KERN_ALERT "Receive store and forward mode %s\n",
-		       (rx_desc_data->rsf_on) ? "enabled" : "disabled");
-		break;
-
-	case DWC_ETH_QOS_TSF_CMD:
-		tx_desc_data->tsf_on = req->flags;
-		hw_if->config_tsf_mode(qInx, tx_desc_data->tsf_on);
-		printk(KERN_ALERT "Transmit store and forward mode %s\n",
-		       (tx_desc_data->tsf_on) ? "enabled" : "disabled");
-		break;
-
-	case DWC_ETH_QOS_OSF_CMD:
-		tx_desc_data->osf_on = req->flags;
-		hw_if->config_osf_mode(qInx, tx_desc_data->osf_on);
-		printk(KERN_ALERT "Transmit DMA OSF mode is %s\n",
-		       (tx_desc_data->osf_on) ? "enabled" : "disabled");
-		break;
-
-	case DWC_ETH_QOS_INCR_INCRX_CMD:
-		pdata->incr_incrx = req->flags;
-		hw_if->config_incr_incrx_mode(pdata->incr_incrx);
-		printk(KERN_ALERT "%s mode is enabled\n",
-		       (pdata->incr_incrx) ? "INCRX" : "INCR");
-		break;
-
-	case DWC_ETH_QOS_RX_PBL_CMD:
-		rx_desc_data->rx_pbl = req->flags;
-		DWC_ETH_QOS_config_rx_pbl(pdata, rx_desc_data->rx_pbl, qInx);
-		break;
-
-	case DWC_ETH_QOS_TX_PBL_CMD:
-		tx_desc_data->tx_pbl = req->flags;
-		DWC_ETH_QOS_config_tx_pbl(pdata, tx_desc_data->tx_pbl, qInx);
-		break;
+   unsigned int qInx = req->qInx;
+   struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data =
+       GET_TX_WRAPPER_DESC(qInx);
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data =
+       GET_RX_WRAPPER_DESC(qInx);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct net_device *dev = pdata->dev;
+   int ret = 0;
+
+   DBGPR("-->DWC_ETH_QOS_handle_prv_ioctl\n");
+
+   if (qInx > DWC_ETH_QOS_QUEUE_CNT) {
+      printk(KERN_ALERT "Queue number %d is invalid\n" \
+            "Hardware has only %d Tx/Rx Queues\n",
+            qInx, DWC_ETH_QOS_QUEUE_CNT);
+      ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      return ret;
+   }
+
+   switch (req->cmd) {
+   case DWC_ETH_QOS_POWERUP_MAGIC_CMD:
+      if (pdata->hw_feat.mgk_sel) {
+         ret = DWC_ETH_QOS_powerup(dev);
+         if (ret == 0)
+            ret = DWC_ETH_QOS_CONFIG_SUCCESS;
+         else
+            ret = DWC_ETH_QOS_CONFIG_FAIL;
+      } else {
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_POWERDOWN_MAGIC_CMD:
+      if (pdata->hw_feat.mgk_sel) {
+         ret =
+           DWC_ETH_QOS_powerdown(dev, DWC_ETH_QOS_MAGIC_WAKEUP);
+         if (ret == 0)
+            ret = DWC_ETH_QOS_CONFIG_SUCCESS;
+         else
+            ret = DWC_ETH_QOS_CONFIG_FAIL;
+      } else {
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_POWERUP_REMOTE_WAKEUP_CMD:
+      if (pdata->hw_feat.rwk_sel) {
+         ret = DWC_ETH_QOS_powerup(dev);
+         if (ret == 0)
+            ret = DWC_ETH_QOS_CONFIG_SUCCESS;
+         else
+            ret = DWC_ETH_QOS_CONFIG_FAIL;
+      } else {
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_POWERDOWN_REMOTE_WAKEUP_CMD:
+      if (pdata->hw_feat.rwk_sel) {
+         ret = DWC_ETH_QOS_configure_remotewakeup(dev, req);
+         if (ret == 0)
+            ret = DWC_ETH_QOS_CONFIG_SUCCESS;
+         else
+            ret = DWC_ETH_QOS_CONFIG_FAIL;
+      } else {
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_RX_THRESHOLD_CMD:
+      rx_desc_data->rx_threshold_val = req->flags;
+      hw_if->config_rx_threshold(qInx,
+               rx_desc_data->rx_threshold_val);
+      printk(KERN_ALERT "Configured Rx threshold with %d\n",
+             rx_desc_data->rx_threshold_val);
+      break;
+
+   case DWC_ETH_QOS_TX_THRESHOLD_CMD:
+      tx_desc_data->tx_threshold_val = req->flags;
+      hw_if->config_tx_threshold(qInx,
+               tx_desc_data->tx_threshold_val);
+      printk(KERN_ALERT "Configured Tx threshold with %d\n",
+             tx_desc_data->tx_threshold_val);
+      break;
+
+   case DWC_ETH_QOS_RSF_CMD:
+      rx_desc_data->rsf_on = req->flags;
+      hw_if->config_rsf_mode(qInx, rx_desc_data->rsf_on);
+      printk(KERN_ALERT "Receive store and forward mode %s\n",
+             (rx_desc_data->rsf_on) ? "enabled" : "disabled");
+      break;
+
+   case DWC_ETH_QOS_TSF_CMD:
+      tx_desc_data->tsf_on = req->flags;
+      hw_if->config_tsf_mode(qInx, tx_desc_data->tsf_on);
+      printk(KERN_ALERT "Transmit store and forward mode %s\n",
+             (tx_desc_data->tsf_on) ? "enabled" : "disabled");
+      break;
+
+   case DWC_ETH_QOS_OSF_CMD:
+      tx_desc_data->osf_on = req->flags;
+      hw_if->config_osf_mode(qInx, tx_desc_data->osf_on);
+      printk(KERN_ALERT "Transmit DMA OSF mode is %s\n",
+             (tx_desc_data->osf_on) ? "enabled" : "disabled");
+      break;
+
+   case DWC_ETH_QOS_INCR_INCRX_CMD:
+      pdata->incr_incrx = req->flags;
+      hw_if->config_incr_incrx_mode(pdata->incr_incrx);
+      printk(KERN_ALERT "%s mode is enabled\n",
+             (pdata->incr_incrx) ? "INCRX" : "INCR");
+      break;
+
+   case DWC_ETH_QOS_RX_PBL_CMD:
+      rx_desc_data->rx_pbl = req->flags;
+      DWC_ETH_QOS_config_rx_pbl(pdata, rx_desc_data->rx_pbl, qInx);
+      break;
+
+   case DWC_ETH_QOS_TX_PBL_CMD:
+      tx_desc_data->tx_pbl = req->flags;
+      DWC_ETH_QOS_config_tx_pbl(pdata, tx_desc_data->tx_pbl, qInx);
+      break;
 
 #ifdef DWC_ETH_QOS_ENABLE_DVLAN
-	case DWC_ETH_QOS_DVLAN_TX_PROCESSING_CMD:
-		if (pdata->hw_feat.sa_vlan_ins) {
-			ret = DWC_ETH_QOS_config_tx_dvlan_processing(pdata, req);
-		} else {
-			printk(KERN_ALERT "No HW support for Single/Double VLAN\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-	case DWC_ETH_QOS_DVLAN_RX_PROCESSING_CMD:
-		if (pdata->hw_feat.sa_vlan_ins) {
-			ret = DWC_ETH_QOS_config_rx_dvlan_processing(pdata, req->flags);
-		} else {
-			printk(KERN_ALERT "No HW support for Single/Double VLAN\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-	case DWC_ETH_QOS_SVLAN_CMD:
-		if (pdata->hw_feat.sa_vlan_ins) {
-			ret = DWC_ETH_QOS_config_svlan(pdata, req->flags);
-		} else {
-			printk(KERN_ALERT "No HW support for Single/Double VLAN\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
+   case DWC_ETH_QOS_DVLAN_TX_PROCESSING_CMD:
+      if (pdata->hw_feat.sa_vlan_ins) {
+         ret = DWC_ETH_QOS_config_tx_dvlan_processing(pdata, req);
+      } else {
+         printk(KERN_ALERT "No HW support for Single/Double VLAN\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+   case DWC_ETH_QOS_DVLAN_RX_PROCESSING_CMD:
+      if (pdata->hw_feat.sa_vlan_ins) {
+         ret = DWC_ETH_QOS_config_rx_dvlan_processing(pdata, req->flags);
+      } else {
+         printk(KERN_ALERT "No HW support for Single/Double VLAN\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+   case DWC_ETH_QOS_SVLAN_CMD:
+      if (pdata->hw_feat.sa_vlan_ins) {
+         ret = DWC_ETH_QOS_config_svlan(pdata, req->flags);
+      } else {
+         printk(KERN_ALERT "No HW support for Single/Double VLAN\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
 #endif /* end of DWC_ETH_QOS_ENABLE_DVLAN */
-	case DWC_ETH_QOS_PTPOFFLOADING_CMD:
-		if (pdata->hw_feat.tsstssel) {
-			ret = DWC_ETH_QOS_config_ptpoffload(pdata,
-					req->ptr);
-		} else {
-			printk(KERN_ALERT "No HW support for PTP\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_SA0_DESC_CMD:
-		if (pdata->hw_feat.sa_vlan_ins) {
-			pdata->tx_sa_ctrl_via_desc = req->flags;
-			pdata->tx_sa_ctrl_via_reg = DWC_ETH_QOS_SA0_NONE;
-			if (req->flags == DWC_ETH_QOS_SA0_NONE) {
-				memcpy(pdata->mac_addr, pdata->dev->dev_addr,
-				       DWC_ETH_QOS_MAC_ADDR_LEN);
-			} else {
-				memcpy(pdata->mac_addr, mac_addr0,
-				       DWC_ETH_QOS_MAC_ADDR_LEN);
-			}
-			hw_if->update_mac_addr(0, pdata->mac_addr);
-			hw_if->configure_sa_via_reg(pdata->tx_sa_ctrl_via_reg);
-			printk(KERN_ALERT
-			       "SA will use MAC0 with descriptor for configuration %d\n",
-			       pdata->tx_sa_ctrl_via_desc);
-		} else {
-			printk(KERN_ALERT
-			       "Device doesn't supports SA Insertion/Replacement\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_SA1_DESC_CMD:
-		if (pdata->hw_feat.sa_vlan_ins) {
-			pdata->tx_sa_ctrl_via_desc = req->flags;
-			pdata->tx_sa_ctrl_via_reg = DWC_ETH_QOS_SA1_NONE;
-			if (req->flags == DWC_ETH_QOS_SA1_NONE) {
-				memcpy(pdata->mac_addr, pdata->dev->dev_addr,
-				       DWC_ETH_QOS_MAC_ADDR_LEN);
-			} else {
-				memcpy(pdata->mac_addr, mac_addr1,
-				       DWC_ETH_QOS_MAC_ADDR_LEN);
-			}
-			hw_if->update_mac_addr(1, pdata->mac_addr);
-			hw_if->configure_sa_via_reg(pdata->tx_sa_ctrl_via_reg);
-			printk(KERN_ALERT
-			       "SA will use MAC1 with descriptor for configuration %d\n",
-			       pdata->tx_sa_ctrl_via_desc);
-		} else {
-			printk(KERN_ALERT
-			       "Device doesn't supports SA Insertion/Replacement\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_SA0_REG_CMD:
-		if (pdata->hw_feat.sa_vlan_ins) {
-			pdata->tx_sa_ctrl_via_reg = req->flags;
-			pdata->tx_sa_ctrl_via_desc = DWC_ETH_QOS_SA0_NONE;
-			if (req->flags == DWC_ETH_QOS_SA0_NONE) {
-				memcpy(pdata->mac_addr, pdata->dev->dev_addr,
-				       DWC_ETH_QOS_MAC_ADDR_LEN);
-			} else {
-				memcpy(pdata->mac_addr, mac_addr0,
-				       DWC_ETH_QOS_MAC_ADDR_LEN);
-			}
-			hw_if->update_mac_addr(0, pdata->mac_addr);
-			hw_if->configure_sa_via_reg(pdata->tx_sa_ctrl_via_reg);
-			printk(KERN_ALERT
-			       "SA will use MAC0 with register for configuration %d\n",
-			       pdata->tx_sa_ctrl_via_desc);
-		} else {
-			printk(KERN_ALERT
-			       "Device doesn't supports SA Insertion/Replacement\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_SA1_REG_CMD:
-		if (pdata->hw_feat.sa_vlan_ins) {
-			pdata->tx_sa_ctrl_via_reg = req->flags;
-			pdata->tx_sa_ctrl_via_desc = DWC_ETH_QOS_SA1_NONE;
-			if (req->flags == DWC_ETH_QOS_SA1_NONE) {
-				memcpy(pdata->mac_addr, pdata->dev->dev_addr,
-				       DWC_ETH_QOS_MAC_ADDR_LEN);
-			} else {
-				memcpy(pdata->mac_addr, mac_addr1,
-				       DWC_ETH_QOS_MAC_ADDR_LEN);
-			}
-			hw_if->update_mac_addr(1, pdata->mac_addr);
-			hw_if->configure_sa_via_reg(pdata->tx_sa_ctrl_via_reg);
-			printk(KERN_ALERT
-			       "SA will use MAC1 with register for configuration %d\n",
-			       pdata->tx_sa_ctrl_via_desc);
-		} else {
-			printk(KERN_ALERT
-			       "Device doesn't supports SA Insertion/Replacement\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_SETUP_CONTEXT_DESCRIPTOR:
-		if (pdata->hw_feat.sa_vlan_ins) {
-			tx_desc_data->context_setup = req->context_setup;
-			if (tx_desc_data->context_setup == 1) {
-				printk(KERN_ALERT "Context descriptor will be transmitted"\
-						" with every normal descriptor on %d DMA Channel\n",
-						qInx);
-			}
-			else {
-				printk(KERN_ALERT "Context descriptor will be setup"\
-						" only if VLAN id changes %d\n", qInx);
-			}
-		}
-		else {
-			printk(KERN_ALERT
-			       "Device doesn't support VLAN operations\n");
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-
-	case DWC_ETH_QOS_GET_RX_QCNT:
-		req->qInx = DWC_ETH_QOS_RX_QUEUE_CNT;
-		break;
-
-	case DWC_ETH_QOS_GET_TX_QCNT:
-		req->qInx = DWC_ETH_QOS_TX_QUEUE_CNT;
-		break;
-
-	case DWC_ETH_QOS_GET_CONNECTED_SPEED:
-		req->connected_speed = pdata->speed;
-		break;
-
-	case DWC_ETH_QOS_DCB_ALGORITHM:
-		DWC_ETH_QOS_program_dcb_algorithm(pdata, req);
-		break;
-
-	case DWC_ETH_QOS_AVB_ALGORITHM:
-		DWC_ETH_QOS_program_avb_algorithm(pdata, req);
-		break;
-
-	case DWC_ETH_QOS_RX_SPLIT_HDR_CMD:
-		if (pdata->hw_feat.sph_en) {
-			ret = DWC_ETH_QOS_config_rx_split_hdr_mode(dev, req->flags);
-			if (ret == 0)
-				ret = DWC_ETH_QOS_CONFIG_SUCCESS;
-			else
-				ret = DWC_ETH_QOS_CONFIG_FAIL;
-		} else {
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-	case DWC_ETH_QOS_L3_L4_FILTER_CMD:
-		if (pdata->hw_feat.l3l4_filter_num > 0) {
-			ret = DWC_ETH_QOS_config_l3_l4_filtering(dev, req->flags);
-			if (ret == 0)
-				ret = DWC_ETH_QOS_CONFIG_SUCCESS;
-			else
-				ret = DWC_ETH_QOS_CONFIG_FAIL;
-		} else {
-			ret = DWC_ETH_QOS_NO_HW_SUPPORT;
-		}
-		break;
-	case DWC_ETH_QOS_IPV4_FILTERING_CMD:
-		ret = DWC_ETH_QOS_config_ip4_filters(dev, req);
-		break;
-	case DWC_ETH_QOS_IPV6_FILTERING_CMD:
-		ret = DWC_ETH_QOS_config_ip6_filters(dev, req);
-		break;
-	case DWC_ETH_QOS_UDP_FILTERING_CMD:
-		ret = DWC_ETH_QOS_config_tcp_udp_filters(dev, req, 1);
-		break;
-	case DWC_ETH_QOS_TCP_FILTERING_CMD:
-		ret = DWC_ETH_QOS_config_tcp_udp_filters(dev, req, 0);
-		break;
-	case DWC_ETH_QOS_VLAN_FILTERING_CMD:
-		ret = DWC_ETH_QOS_config_vlan_filter(dev, req);
-		break;
-	case DWC_ETH_QOS_L2_DA_FILTERING_CMD:
-		ret = DWC_ETH_QOS_confing_l2_da_filter(dev, req);
-		break;
-	case DWC_ETH_QOS_ARP_OFFLOAD_CMD:
-		ret = DWC_ETH_QOS_config_arp_offload(dev, req);
-		break;
-	case DWC_ETH_QOS_AXI_PBL_CMD:
-		pdata->axi_pbl = req->flags;
-		hw_if->config_axi_pbl_val(pdata->axi_pbl);
-		printk(KERN_ALERT "AXI PBL value: %d\n", pdata->axi_pbl);
-		break;
-	case DWC_ETH_QOS_AXI_WORL_CMD:
-		pdata->axi_worl = req->flags;
-		hw_if->config_axi_worl_val(pdata->axi_worl);
-		printk(KERN_ALERT "AXI WORL value: %d\n", pdata->axi_worl);
-		break;
-	case DWC_ETH_QOS_AXI_RORL_CMD:
-		pdata->axi_rorl = req->flags;
-		hw_if->config_axi_rorl_val(pdata->axi_rorl);
-		printk(KERN_ALERT "AXI RORL value: %d\n", pdata->axi_rorl);
-		break;
-	case DWC_ETH_QOS_MAC_LOOPBACK_MODE_CMD:
-		ret = DWC_ETH_QOS_config_mac_loopback_mode(dev, req->flags);
-		if (ret == 0)
-			ret = DWC_ETH_QOS_CONFIG_SUCCESS;
-		else
-			ret = DWC_ETH_QOS_CONFIG_FAIL;
-		break;
-	case DWC_ETH_QOS_PFC_CMD:
-		ret = DWC_ETH_QOS_config_pfc(dev, req->flags);
-		break;
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	case DWC_ETH_QOS_PG_TEST:
-		ret = DWC_ETH_QOS_handle_pg_ioctl(pdata, (void *)req);
-		break;
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-	default:
-		ret = -EOPNOTSUPP;
-		printk(KERN_ALERT "Unsupported command call\n");
-	}
-
-	DBGPR("<--DWC_ETH_QOS_handle_prv_ioctl\n");
-
-	return ret;
+   case DWC_ETH_QOS_PTPOFFLOADING_CMD:
+      if (pdata->hw_feat.tsstssel) {
+         ret = DWC_ETH_QOS_config_ptpoffload(pdata,
+               req->ptr);
+      } else {
+         printk(KERN_ALERT "No HW support for PTP\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_SA0_DESC_CMD:
+      if (pdata->hw_feat.sa_vlan_ins) {
+         pdata->tx_sa_ctrl_via_desc = req->flags;
+         pdata->tx_sa_ctrl_via_reg = DWC_ETH_QOS_SA0_NONE;
+         if (req->flags == DWC_ETH_QOS_SA0_NONE) {
+            memcpy(pdata->mac_addr, pdata->dev->dev_addr,
+                   DWC_ETH_QOS_MAC_ADDR_LEN);
+         } else {
+            memcpy(pdata->mac_addr, mac_addr0,
+                   DWC_ETH_QOS_MAC_ADDR_LEN);
+         }
+         hw_if->update_mac_addr(0, pdata->mac_addr);
+         hw_if->configure_sa_via_reg(pdata->tx_sa_ctrl_via_reg);
+         printk(KERN_ALERT
+                "SA will use MAC0 with descriptor for configuration %d\n",
+                pdata->tx_sa_ctrl_via_desc);
+      } else {
+         printk(KERN_ALERT
+                "Device doesn't supports SA Insertion/Replacement\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_SA1_DESC_CMD:
+      if (pdata->hw_feat.sa_vlan_ins) {
+         pdata->tx_sa_ctrl_via_desc = req->flags;
+         pdata->tx_sa_ctrl_via_reg = DWC_ETH_QOS_SA1_NONE;
+         if (req->flags == DWC_ETH_QOS_SA1_NONE) {
+            memcpy(pdata->mac_addr, pdata->dev->dev_addr,
+                   DWC_ETH_QOS_MAC_ADDR_LEN);
+         } else {
+            memcpy(pdata->mac_addr, mac_addr1,
+                   DWC_ETH_QOS_MAC_ADDR_LEN);
+         }
+         hw_if->update_mac_addr(1, pdata->mac_addr);
+         hw_if->configure_sa_via_reg(pdata->tx_sa_ctrl_via_reg);
+         printk(KERN_ALERT
+                "SA will use MAC1 with descriptor for configuration %d\n",
+                pdata->tx_sa_ctrl_via_desc);
+      } else {
+         printk(KERN_ALERT
+                "Device doesn't supports SA Insertion/Replacement\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_SA0_REG_CMD:
+      if (pdata->hw_feat.sa_vlan_ins) {
+         pdata->tx_sa_ctrl_via_reg = req->flags;
+         pdata->tx_sa_ctrl_via_desc = DWC_ETH_QOS_SA0_NONE;
+         if (req->flags == DWC_ETH_QOS_SA0_NONE) {
+            memcpy(pdata->mac_addr, pdata->dev->dev_addr,
+                   DWC_ETH_QOS_MAC_ADDR_LEN);
+         } else {
+            memcpy(pdata->mac_addr, mac_addr0,
+                   DWC_ETH_QOS_MAC_ADDR_LEN);
+         }
+         hw_if->update_mac_addr(0, pdata->mac_addr);
+         hw_if->configure_sa_via_reg(pdata->tx_sa_ctrl_via_reg);
+         printk(KERN_ALERT
+                "SA will use MAC0 with register for configuration %d\n",
+                pdata->tx_sa_ctrl_via_desc);
+      } else {
+         printk(KERN_ALERT
+                "Device doesn't supports SA Insertion/Replacement\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_SA1_REG_CMD:
+      if (pdata->hw_feat.sa_vlan_ins) {
+         pdata->tx_sa_ctrl_via_reg = req->flags;
+         pdata->tx_sa_ctrl_via_desc = DWC_ETH_QOS_SA1_NONE;
+         if (req->flags == DWC_ETH_QOS_SA1_NONE) {
+            memcpy(pdata->mac_addr, pdata->dev->dev_addr,
+                   DWC_ETH_QOS_MAC_ADDR_LEN);
+         } else {
+            memcpy(pdata->mac_addr, mac_addr1,
+                   DWC_ETH_QOS_MAC_ADDR_LEN);
+         }
+         hw_if->update_mac_addr(1, pdata->mac_addr);
+         hw_if->configure_sa_via_reg(pdata->tx_sa_ctrl_via_reg);
+         printk(KERN_ALERT
+                "SA will use MAC1 with register for configuration %d\n",
+                pdata->tx_sa_ctrl_via_desc);
+      } else {
+         printk(KERN_ALERT
+                "Device doesn't supports SA Insertion/Replacement\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_SETUP_CONTEXT_DESCRIPTOR:
+      if (pdata->hw_feat.sa_vlan_ins) {
+         tx_desc_data->context_setup = req->context_setup;
+         if (tx_desc_data->context_setup == 1) {
+            printk(KERN_ALERT "Context descriptor will be transmitted"\
+                  " with every normal descriptor on %d DMA Channel\n",
+                  qInx);
+         }
+         else {
+            printk(KERN_ALERT "Context descriptor will be setup"\
+                  " only if VLAN id changes %d\n", qInx);
+         }
+      }
+      else {
+         printk(KERN_ALERT
+                "Device doesn't support VLAN operations\n");
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+
+   case DWC_ETH_QOS_GET_RX_QCNT:
+      req->qInx = DWC_ETH_QOS_RX_QUEUE_CNT;
+      break;
+
+   case DWC_ETH_QOS_GET_TX_QCNT:
+      req->qInx = DWC_ETH_QOS_TX_QUEUE_CNT;
+      break;
+
+   case DWC_ETH_QOS_GET_CONNECTED_SPEED:
+      req->connected_speed = pdata->speed;
+      break;
+
+   case DWC_ETH_QOS_DCB_ALGORITHM:
+      DWC_ETH_QOS_program_dcb_algorithm(pdata, req);
+      break;
+
+   case DWC_ETH_QOS_AVB_ALGORITHM:
+      DWC_ETH_QOS_program_avb_algorithm(pdata, req);
+      break;
+
+   case DWC_ETH_QOS_RX_SPLIT_HDR_CMD:
+      if (pdata->hw_feat.sph_en) {
+         ret = DWC_ETH_QOS_config_rx_split_hdr_mode(dev, req->flags);
+         if (ret == 0)
+            ret = DWC_ETH_QOS_CONFIG_SUCCESS;
+         else
+            ret = DWC_ETH_QOS_CONFIG_FAIL;
+      } else {
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+   case DWC_ETH_QOS_L3_L4_FILTER_CMD:
+      if (pdata->hw_feat.l3l4_filter_num > 0) {
+         ret = DWC_ETH_QOS_config_l3_l4_filtering(dev, req->flags);
+         if (ret == 0)
+            ret = DWC_ETH_QOS_CONFIG_SUCCESS;
+         else
+            ret = DWC_ETH_QOS_CONFIG_FAIL;
+      } else {
+         ret = DWC_ETH_QOS_NO_HW_SUPPORT;
+      }
+      break;
+   case DWC_ETH_QOS_IPV4_FILTERING_CMD:
+      ret = DWC_ETH_QOS_config_ip4_filters(dev, req);
+      break;
+   case DWC_ETH_QOS_IPV6_FILTERING_CMD:
+      ret = DWC_ETH_QOS_config_ip6_filters(dev, req);
+      break;
+   case DWC_ETH_QOS_UDP_FILTERING_CMD:
+      ret = DWC_ETH_QOS_config_tcp_udp_filters(dev, req, 1);
+      break;
+   case DWC_ETH_QOS_TCP_FILTERING_CMD:
+      ret = DWC_ETH_QOS_config_tcp_udp_filters(dev, req, 0);
+      break;
+   case DWC_ETH_QOS_VLAN_FILTERING_CMD:
+      ret = DWC_ETH_QOS_config_vlan_filter(dev, req);
+      break;
+   case DWC_ETH_QOS_L2_DA_FILTERING_CMD:
+      ret = DWC_ETH_QOS_confing_l2_da_filter(dev, req);
+      break;
+   case DWC_ETH_QOS_ARP_OFFLOAD_CMD:
+      ret = DWC_ETH_QOS_config_arp_offload(dev, req);
+      break;
+   case DWC_ETH_QOS_AXI_PBL_CMD:
+      pdata->axi_pbl = req->flags;
+      hw_if->config_axi_pbl_val(pdata->axi_pbl);
+      printk(KERN_ALERT "AXI PBL value: %d\n", pdata->axi_pbl);
+      break;
+   case DWC_ETH_QOS_AXI_WORL_CMD:
+      pdata->axi_worl = req->flags;
+      hw_if->config_axi_worl_val(pdata->axi_worl);
+      printk(KERN_ALERT "AXI WORL value: %d\n", pdata->axi_worl);
+      break;
+   case DWC_ETH_QOS_AXI_RORL_CMD:
+      pdata->axi_rorl = req->flags;
+      hw_if->config_axi_rorl_val(pdata->axi_rorl);
+      printk(KERN_ALERT "AXI RORL value: %d\n", pdata->axi_rorl);
+      break;
+   case DWC_ETH_QOS_MAC_LOOPBACK_MODE_CMD:
+      ret = DWC_ETH_QOS_config_mac_loopback_mode(dev, req->flags);
+      if (ret == 0)
+         ret = DWC_ETH_QOS_CONFIG_SUCCESS;
+      else
+         ret = DWC_ETH_QOS_CONFIG_FAIL;
+      break;
+   case DWC_ETH_QOS_PFC_CMD:
+      ret = DWC_ETH_QOS_config_pfc(dev, req->flags);
+      break;
+   default:
+      ret = -EOPNOTSUPP;
+      printk(KERN_ALERT "Unsupported command call\n");
+   }
+
+   DBGPR("<--DWC_ETH_QOS_handle_prv_ioctl\n");
+
+   return ret;
 }
 
-
 /*!
  * \brief control hw timestamping.
  *
@@ -4818,223 +4829,222 @@ static int DWC_ETH_QOS_handle_prv_ioctl(
  * \retval 0 - success
  * \retval negative - failure
  */
-
 static int DWC_ETH_QOS_handle_hwtstamp_ioctl(struct DWC_ETH_QOS_prv_data *pdata,
-	struct ifreq *ifr)
+   struct ifreq *ifr)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct hwtstamp_config config;
-	uint32_t ptp_v2 = 0;
-	uint32_t tstamp_all = 0;
-	uint32_t ptp_over_ipv4_udp = 0;
-	uint32_t ptp_over_ipv6_udp = 0;
-	uint32_t ptp_over_ethernet = 0;
-	uint32_t snap_type_sel = 0;
-	uint32_t ts_master_en = 0;
-	uint32_t ts_event_en = 0;
-	uint32_t av_8021asm_en = 0;
-	uint32_t varMAC_TCR = 0;
-	uint64_t temp = 0;
-	struct timespec now;
-
-	DBGPR_PTP("-->DWC_ETH_QOS_handle_hwtstamp_ioctl\n");
-
-	if (!pdata->hw_feat.tsstssel) {
-		printk(KERN_ALERT "No hw timestamping is available in this core\n");
-		return -EOPNOTSUPP;
-	}
-
-	if (copy_from_user(&config, ifr->ifr_data,
-		sizeof(struct hwtstamp_config)))
-		return -EFAULT;
-
-	DBGPR_PTP("config.flags = %#x, tx_type = %#x, rx_filter = %#x\n",
-		config.flags, config.tx_type, config.rx_filter);
-
-	/* reserved for future extensions */
-	if (config.flags)
-		return -EINVAL;
-
-	switch (config.tx_type) {
-	case HWTSTAMP_TX_OFF:
-		pdata->hwts_tx_en = 0;
-		break;
-	case HWTSTAMP_TX_ON:
-		pdata->hwts_tx_en = 1;
-		break;
-	default:
-		return -ERANGE;
-	}
-
-	switch (config.rx_filter) {
-	/* time stamp no incoming packet at all */
-	case HWTSTAMP_FILTER_NONE:
-		config.rx_filter = HWTSTAMP_FILTER_NONE;
-		break;
-
-	/* PTP v1, UDP, any kind of event packet */
-	case HWTSTAMP_FILTER_PTP_V1_L4_EVENT:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_EVENT;
-		/* take time stamp for all event messages */
-		snap_type_sel = MAC_TCR_SNAPTYPSEL_1;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		break;
-
-	/* PTP v1, UDP, Sync packet */
-	case HWTSTAMP_FILTER_PTP_V1_L4_SYNC:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_SYNC;
-		/* take time stamp for SYNC messages only */
-		ts_event_en = MAC_TCR_TSEVENTENA;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		break;
-
-	/* PTP v1, UDP, Delay_req packet */
-	case HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ;
-		/* take time stamp for Delay_Req messages only */
-		ts_master_en = MAC_TCR_TSMASTERENA;
-		ts_event_en = MAC_TCR_TSEVENTENA;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		break;
-
-	/* PTP v2, UDP, any kind of event packet */
-	case HWTSTAMP_FILTER_PTP_V2_L4_EVENT:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V2_L4_EVENT;
-		ptp_v2 = MAC_TCR_TSVER2ENA;
-		/* take time stamp for all event messages */
-		snap_type_sel = MAC_TCR_SNAPTYPSEL_1;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		break;
-
-	/* PTP v2, UDP, Sync packet */
-	case HWTSTAMP_FILTER_PTP_V2_L4_SYNC:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V2_L4_SYNC;
-		ptp_v2 = MAC_TCR_TSVER2ENA;
-		/* take time stamp for SYNC messages only */
-		ts_event_en = MAC_TCR_TSEVENTENA;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		break;
-
-	/* PTP v2, UDP, Delay_req packet */
-	case HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ;
-		ptp_v2 = MAC_TCR_TSVER2ENA;
-		/* take time stamp for Delay_Req messages only */
-		ts_master_en = MAC_TCR_TSMASTERENA;
-		ts_event_en = MAC_TCR_TSEVENTENA;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		break;
-
-	/* PTP v2/802.AS1, any layer, any kind of event packet */
-	case HWTSTAMP_FILTER_PTP_V2_EVENT:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V2_EVENT;
-		ptp_v2 = MAC_TCR_TSVER2ENA;
-		/* take time stamp for all event messages */
-		snap_type_sel = MAC_TCR_SNAPTYPSEL_1;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		ptp_over_ethernet = MAC_TCR_TSIPENA;
-		av_8021asm_en = MAC_TCR_AV8021ASMEN;
-		break;
-
-	/* PTP v2/802.AS1, any layer, Sync packet */
-	case HWTSTAMP_FILTER_PTP_V2_SYNC:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V2_SYNC;
-		ptp_v2 = MAC_TCR_TSVER2ENA;
-		/* take time stamp for SYNC messages only */
-		ts_event_en = MAC_TCR_TSEVENTENA;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		ptp_over_ethernet = MAC_TCR_TSIPENA;
-		av_8021asm_en = MAC_TCR_AV8021ASMEN;
-		break;
-
-	/* PTP v2/802.AS1, any layer, Delay_req packet */
-	case HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:
-		config.rx_filter = HWTSTAMP_FILTER_PTP_V2_DELAY_REQ;
-		ptp_v2 = MAC_TCR_TSVER2ENA;
-		/* take time stamp for Delay_Req messages only */
-		ts_master_en = MAC_TCR_TSMASTERENA;
-		ts_event_en = MAC_TCR_TSEVENTENA;
-
-		ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
-		ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
-		ptp_over_ethernet = MAC_TCR_TSIPENA;
-		av_8021asm_en = MAC_TCR_AV8021ASMEN;
-		break;
-
-	/* time stamp any incoming packet */
-	case HWTSTAMP_FILTER_ALL:
-		config.rx_filter = HWTSTAMP_FILTER_ALL;
-		tstamp_all = MAC_TCR_TSENALL;
-		break;
-
-	default:
-		return -ERANGE;
-	}
-	pdata->hwts_rx_en = ((config.rx_filter == HWTSTAMP_FILTER_NONE) ? 0 : 1);
-
-	if (!pdata->hwts_tx_en && !pdata->hwts_rx_en) {
-		/* disable hw time stamping */
-		hw_if->config_hw_time_stamping(varMAC_TCR);
-	} else {
-		varMAC_TCR = (MAC_TCR_TSENA | MAC_TCR_TSCFUPDT | MAC_TCR_TSCTRLSSR |
-				tstamp_all | ptp_v2 | ptp_over_ethernet | ptp_over_ipv6_udp |
-				ptp_over_ipv4_udp | ts_event_en | ts_master_en |
-				snap_type_sel | av_8021asm_en);
-
-		if (!pdata->one_nsec_accuracy)
-			varMAC_TCR &= ~MAC_TCR_TSCTRLSSR;
-
-		hw_if->config_hw_time_stamping(varMAC_TCR);
-
-		/* program Sub Second Increment Reg */
-		hw_if->config_sub_second_increment(DWC_ETH_QOS_SYSCLOCK);
-
-		/* formula is :
-		 * addend = 2^32/freq_div_ratio;
-		 *
-		 * where, freq_div_ratio = DWC_ETH_QOS_SYSCLOCK/50MHz
-		 *
-		 * hence, addend = ((2^32) * 50MHz)/DWC_ETH_QOS_SYSCLOCK;
-		 *
-		 * NOTE: DWC_ETH_QOS_SYSCLOCK should be >= 50MHz to
-		 *       achive 20ns accuracy.
-		 *
-		 * 2^x * y == (y << x), hence
-		 * 2^32 * 50000000 ==> (50000000 << 32)
-		 * */
-		temp = (uint64_t)(50000000ULL << 32);
-		pdata->default_addend = div_u64(temp, 62500000);
-
-		hw_if->config_addend(pdata->default_addend);
-
-		/* initialize system time */
-		getnstimeofday(&now);
-		hw_if->init_systime(now.tv_sec, now.tv_nsec);
-	}
-
-	DBGPR_PTP("config.flags = %#x, tx_type = %#x, rx_filter = %#x\n",
-		config.flags, config.tx_type, config.rx_filter);
-
-	DBGPR_PTP("<--DWC_ETH_QOS_handle_hwtstamp_ioctl\n");
-
-	return (copy_to_user(ifr->ifr_data, &config,
-		sizeof(struct hwtstamp_config))) ? -EFAULT : 0;
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   struct hwtstamp_config config;
+   uint32_t ptp_v2 = 0;
+   uint32_t tstamp_all = 0;
+   uint32_t ptp_over_ipv4_udp = 0;
+   uint32_t ptp_over_ipv6_udp = 0;
+   uint32_t ptp_over_ethernet = 0;
+   uint32_t snap_type_sel = 0;
+   uint32_t ts_master_en = 0;
+   uint32_t ts_event_en = 0;
+   uint32_t av_8021asm_en = 0;
+   uint32_t varMAC_TCR = 0;
+   uint64_t temp = 0;
+   struct timespec now;
+
+   DBGPR_PTP("-->DWC_ETH_QOS_handle_hwtstamp_ioctl\n");
+
+   if (!pdata->hw_feat.tsstssel) {
+      printk(KERN_ALERT "No hw timestamping is available in this core\n");
+      return -EOPNOTSUPP;
+   }
+
+   if (copy_from_user(&config, ifr->ifr_data,
+      sizeof(struct hwtstamp_config)))
+      return -EFAULT;
+
+   DBGPR_PTP("config.flags = %#x, tx_type = %#x, rx_filter = %#x\n",
+      config.flags, config.tx_type, config.rx_filter);
+
+   /* reserved for future extensions */
+   if (config.flags)
+      return -EINVAL;
+
+   switch (config.tx_type) {
+   case HWTSTAMP_TX_OFF:
+      pdata->hwts_tx_en = 0;
+      break;
+   case HWTSTAMP_TX_ON:
+      pdata->hwts_tx_en = 1;
+      break;
+   default:
+      return -ERANGE;
+   }
+
+   switch (config.rx_filter) {
+   /* time stamp no incoming packet at all */
+   case HWTSTAMP_FILTER_NONE:
+      config.rx_filter = HWTSTAMP_FILTER_NONE;
+      break;
+
+   /* PTP v1, UDP, any kind of event packet */
+   case HWTSTAMP_FILTER_PTP_V1_L4_EVENT:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_EVENT;
+      /* take time stamp for all event messages */
+      snap_type_sel = MAC_TCR_SNAPTYPSEL_1;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      break;
+
+   /* PTP v1, UDP, Sync packet */
+   case HWTSTAMP_FILTER_PTP_V1_L4_SYNC:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_SYNC;
+      /* take time stamp for SYNC messages only */
+      ts_event_en = MAC_TCR_TSEVENTENA;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      break;
+
+   /* PTP v1, UDP, Delay_req packet */
+   case HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ;
+      /* take time stamp for Delay_Req messages only */
+      ts_master_en = MAC_TCR_TSMASTERENA;
+      ts_event_en = MAC_TCR_TSEVENTENA;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      break;
+
+   /* PTP v2, UDP, any kind of event packet */
+   case HWTSTAMP_FILTER_PTP_V2_L4_EVENT:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V2_L4_EVENT;
+      ptp_v2 = MAC_TCR_TSVER2ENA;
+      /* take time stamp for all event messages */
+      snap_type_sel = MAC_TCR_SNAPTYPSEL_1;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      break;
+
+   /* PTP v2, UDP, Sync packet */
+   case HWTSTAMP_FILTER_PTP_V2_L4_SYNC:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V2_L4_SYNC;
+      ptp_v2 = MAC_TCR_TSVER2ENA;
+      /* take time stamp for SYNC messages only */
+      ts_event_en = MAC_TCR_TSEVENTENA;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      break;
+
+   /* PTP v2, UDP, Delay_req packet */
+   case HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ;
+      ptp_v2 = MAC_TCR_TSVER2ENA;
+      /* take time stamp for Delay_Req messages only */
+      ts_master_en = MAC_TCR_TSMASTERENA;
+      ts_event_en = MAC_TCR_TSEVENTENA;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      break;
+
+   /* PTP v2/802.AS1, any layer, any kind of event packet */
+   case HWTSTAMP_FILTER_PTP_V2_EVENT:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V2_EVENT;
+      ptp_v2 = MAC_TCR_TSVER2ENA;
+      /* take time stamp for all event messages */
+      snap_type_sel = MAC_TCR_SNAPTYPSEL_1;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      ptp_over_ethernet = MAC_TCR_TSIPENA;
+      av_8021asm_en = MAC_TCR_AV8021ASMEN;
+      break;
+
+   /* PTP v2/802.AS1, any layer, Sync packet */
+   case HWTSTAMP_FILTER_PTP_V2_SYNC:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V2_SYNC;
+      ptp_v2 = MAC_TCR_TSVER2ENA;
+      /* take time stamp for SYNC messages only */
+      ts_event_en = MAC_TCR_TSEVENTENA;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      ptp_over_ethernet = MAC_TCR_TSIPENA;
+      av_8021asm_en = MAC_TCR_AV8021ASMEN;
+      break;
+
+   /* PTP v2/802.AS1, any layer, Delay_req packet */
+   case HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:
+      config.rx_filter = HWTSTAMP_FILTER_PTP_V2_DELAY_REQ;
+      ptp_v2 = MAC_TCR_TSVER2ENA;
+      /* take time stamp for Delay_Req messages only */
+      ts_master_en = MAC_TCR_TSMASTERENA;
+      ts_event_en = MAC_TCR_TSEVENTENA;
+
+      ptp_over_ipv4_udp = MAC_TCR_TSIPV4ENA;
+      ptp_over_ipv6_udp = MAC_TCR_TSIPV6ENA;
+      ptp_over_ethernet = MAC_TCR_TSIPENA;
+      av_8021asm_en = MAC_TCR_AV8021ASMEN;
+      break;
+
+   /* time stamp any incoming packet */
+   case HWTSTAMP_FILTER_ALL:
+      config.rx_filter = HWTSTAMP_FILTER_ALL;
+      tstamp_all = MAC_TCR_TSENALL;
+      break;
+
+   default:
+      return -ERANGE;
+   }
+   pdata->hwts_rx_en = ((config.rx_filter == HWTSTAMP_FILTER_NONE) ? 0 : 1);
+
+   if (!pdata->hwts_tx_en && !pdata->hwts_rx_en) {
+      /* disable hw time stamping */
+      hw_if->config_hw_time_stamping(varMAC_TCR);
+   } else {
+      varMAC_TCR = (MAC_TCR_TSENA | MAC_TCR_TSCFUPDT | MAC_TCR_TSCTRLSSR |
+            tstamp_all | ptp_v2 | ptp_over_ethernet | ptp_over_ipv6_udp |
+            ptp_over_ipv4_udp | ts_event_en | ts_master_en |
+            snap_type_sel | av_8021asm_en);
+
+      if (!pdata->one_nsec_accuracy)
+         varMAC_TCR &= ~MAC_TCR_TSCTRLSSR;
+
+      hw_if->config_hw_time_stamping(varMAC_TCR);
+
+      /* program Sub Second Increment Reg */
+      hw_if->config_sub_second_increment(DWC_ETH_QOS_SYSCLOCK);
+
+      /* formula is :
+       * addend = 2^32/freq_div_ratio;
+       *
+       * where, freq_div_ratio = DWC_ETH_QOS_SYSCLOCK/50MHz
+       *
+       * hence, addend = ((2^32) * 50MHz)/DWC_ETH_QOS_SYSCLOCK;
+       *
+       * NOTE: DWC_ETH_QOS_SYSCLOCK should be >= 50MHz to
+       *       achive 20ns accuracy.
+       *
+       * 2^x * y == (y << x), hence
+       * 2^32 * 50000000 ==> (50000000 << 32)
+       * */
+      temp = (uint64_t)(50000000ULL << 32);
+      pdata->default_addend = div_u64(temp, 62500000);
+
+      hw_if->config_addend(pdata->default_addend);
+
+      /* initialize system time */
+      getnstimeofday(&now);
+      hw_if->init_systime(now.tv_sec, now.tv_nsec);
+   }
+
+   DBGPR_PTP("config.flags = %#x, tx_type = %#x, rx_filter = %#x\n",
+      config.flags, config.tx_type, config.rx_filter);
+
+   DBGPR_PTP("<--DWC_ETH_QOS_handle_hwtstamp_ioctl\n");
+
+   return (copy_to_user(ifr->ifr_data, &config,
+      sizeof(struct hwtstamp_config))) ? -EFAULT : 0;
 }
 
 /*!
@@ -5059,62 +5069,60 @@ static int DWC_ETH_QOS_handle_hwtstamp_i
  */
 static int DWC_ETH_QOS_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct ifr_data_struct *req = ifr->ifr_ifru.ifru_data;
-	struct mii_ioctl_data *data = if_mii(ifr);
-	unsigned int reg_val = 0;
-	int ret = 0;
-
-	DBGPR("-->DWC_ETH_QOS_ioctl\n");
-
-#ifndef DWC_ETH_QOS_CONFIG_PGTEST
-	if ((!netif_running(dev)) || (!pdata->phydev)) {
-		DBGPR("<--DWC_ETH_QOS_ioctl - error\n");
-		return -EINVAL;
-	}
-#endif
-
-	spin_lock(&pdata->lock);
-	switch (cmd) {
-	case SIOCGMIIPHY:
-		data->phy_id = pdata->phyaddr;
-		printk(KERN_ALERT "PHY ID: SIOCGMIIPHY\n");
-		break;
-
-	case SIOCGMIIREG:
-		ret =
-		    DWC_ETH_QOS_mdio_read_direct(pdata, pdata->phyaddr,
-				(data->reg_num & 0x1F), &reg_val);
-		if (ret)
-			ret = -EIO;
-
-		data->val_out = reg_val;
-		printk(KERN_ALERT "PHY ID: SIOCGMIIREG reg:%#x reg_val:%#x\n",
-		       (data->reg_num & 0x1F), reg_val);
-		break;
-
-	case SIOCSMIIREG:
-		printk(KERN_ALERT "PHY ID: SIOCSMIIPHY\n");
-		break;
-
-	case DWC_ETH_QOS_PRV_IOCTL:
-		ret = DWC_ETH_QOS_handle_prv_ioctl(pdata, req);
-		req->command_error = ret;
-		break;
-
-	case SIOCSHWTSTAMP:
-		ret = DWC_ETH_QOS_handle_hwtstamp_ioctl(pdata, ifr);
-		break;
-
-	default:
-		ret = -EOPNOTSUPP;
-		printk(KERN_ALERT "Unsupported IOCTL call\n");
-	}
-	spin_unlock(&pdata->lock);
-
-	DBGPR("<--DWC_ETH_QOS_ioctl\n");
-
-	return ret;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   struct ifr_data_struct *req = ifr->ifr_ifru.ifru_data;
+   struct mii_ioctl_data *data = if_mii(ifr);
+   unsigned int reg_val = 0;
+   int ret = 0;
+
+   DBGPR("-->DWC_ETH_QOS_ioctl\n");
+
+   if ((!netif_running(dev)) || (!pdata->phydev)) {
+      DBGPR("<--DWC_ETH_QOS_ioctl - error\n");
+      return -EINVAL;
+   }
+
+   spin_lock(&pdata->lock);
+   switch (cmd) {
+   case SIOCGMIIPHY:
+      data->phy_id = pdata->phyaddr;
+      printk(KERN_ALERT "PHY ID: SIOCGMIIPHY\n");
+      break;
+
+   case SIOCGMIIREG:
+      ret =
+          DWC_ETH_QOS_mdio_read_direct(pdata, pdata->phyaddr,
+            (data->reg_num & 0x1F), &reg_val);
+      if (ret)
+         ret = -EIO;
+
+      data->val_out = reg_val;
+      printk(KERN_ALERT "PHY ID: SIOCGMIIREG reg:%#x reg_val:%#x\n",
+             (data->reg_num & 0x1F), reg_val);
+      break;
+
+   case SIOCSMIIREG:
+      printk(KERN_ALERT "PHY ID: SIOCSMIIPHY\n");
+      break;
+
+   case DWC_ETH_QOS_PRV_IOCTL:
+      ret = DWC_ETH_QOS_handle_prv_ioctl(pdata, req);
+      req->command_error = ret;
+      break;
+
+   case SIOCSHWTSTAMP:
+      ret = DWC_ETH_QOS_handle_hwtstamp_ioctl(pdata, ifr);
+      break;
+
+   default:
+      ret = -EOPNOTSUPP;
+      printk(KERN_ALERT "Unsupported IOCTL call\n");
+   }
+   spin_unlock(&pdata->lock);
+
+   DBGPR("<--DWC_ETH_QOS_ioctl\n");
+
+   return ret;
 }
 
 /*!
@@ -5135,90 +5143,83 @@ static int DWC_ETH_QOS_ioctl(struct net_
 */
 static int DWC_ETH_QOS_change_mtu(struct net_device *dev, int new_mtu)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	int max_frame = (new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN);
-
-	DBGPR("-->DWC_ETH_QOS_change_mtu: new_mtu:%d\n", new_mtu);
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	printk(KERN_ALERT "jumbo frames not supported with PG test\n");
-	return -EOPNOTSUPP;
-#endif
-	if (dev->mtu == new_mtu) {
-		printk(KERN_ALERT "%s: is already configured to %d mtu\n",
-		       dev->name, new_mtu);
-		return 0;
-	}
-
-	/* Supported frame sizes */
-	if ((new_mtu < DWC_ETH_QOS_MIN_SUPPORTED_MTU) ||
-	    (max_frame > DWC_ETH_QOS_MAX_SUPPORTED_MTU)) {
-		printk(KERN_ALERT
-		       "%s: invalid MTU, min %d and max %d MTU are supported\n",
-		       dev->name, DWC_ETH_QOS_MIN_SUPPORTED_MTU,
-		       DWC_ETH_QOS_MAX_SUPPORTED_MTU);
-		return -EINVAL;
-	}
-
-	printk(KERN_ALERT "changing MTU from %d to %d\n", dev->mtu, new_mtu);
-
-	DWC_ETH_QOS_stop_dev(pdata);
-
-	if (max_frame <= 2048)
-		pdata->rx_buffer_len = 2048;
-	else
-		pdata->rx_buffer_len = PAGE_SIZE; /* in case of JUMBO frame,
-						max buffer allocated is
-						PAGE_SIZE */
-
-	if ((max_frame == ETH_FRAME_LEN + ETH_FCS_LEN) ||
-	    (max_frame == ETH_FRAME_LEN + ETH_FCS_LEN + VLAN_HLEN))
-		pdata->rx_buffer_len =
-		    DWC_ETH_QOS_ETH_FRAME_LEN;
-
-	dev->mtu = new_mtu;
-
-	DWC_ETH_QOS_start_dev(pdata);
-
-	DBGPR("<--DWC_ETH_QOS_change_mtu\n");
-
-	return 0;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   int max_frame = (new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN);
+   gbe_power_state_t state;
+
+   CFG_PRINT("-->DWC_ETH_QOS_change_mtu: new_mtu:%d\n", new_mtu);
+
+   if (dev->mtu == new_mtu) {
+      printk(KERN_ALERT "%s: is already configured to %d mtu\n",
+             dev->name, new_mtu);
+      return 0;
+   }
+
+   /* Supported frame sizes */
+   if ((new_mtu < DWC_ETH_QOS_MIN_SUPPORTED_MTU) ||
+       (max_frame > DWC_ETH_QOS_MAX_SUPPORTED_MTU)) {
+      printk(KERN_ALERT
+             "%s: invalid MTU, min %d and max %d MTU are supported\n",
+             dev->name, DWC_ETH_QOS_MIN_SUPPORTED_MTU,
+             DWC_ETH_QOS_MAX_SUPPORTED_MTU);
+      return -EINVAL;
+   }
+
+   state = DWC_ETH_QOS_stop_dev(pdata);
+
+   CFG_PRINT("Changing MTU from %d to %d\n", dev->mtu, new_mtu);
+   /* For JUMBO frame, max buffer allocated is PAGE_SIZE */
+   pdata->rx_buffer_len = (max_frame <= 2048)? 2048 : PAGE_SIZE;
+   if ((max_frame == ETH_FRAME_LEN + ETH_FCS_LEN) ||
+       (max_frame == ETH_FRAME_LEN + ETH_FCS_LEN + VLAN_HLEN))
+      pdata->rx_buffer_len = DWC_ETH_QOS_ETH_FRAME_LEN;
+   dev->mtu = new_mtu;
+
+   if (state == GBE_RUN_STATE) {
+      DWC_ETH_QOS_start_dev(pdata);
+   } else if (state == GBE_STANDBY_STATE) {
+      /* Save request to apply it when device is powered up */
+      pdata->power_state |= DWC_ETH_QOS_NETIP_MTU_REQ;
+   }
+
+   CFG_PRINT("<--DWC_ETH_QOS_change_mtu\n");
+   return 0;
 }
 
 #ifdef DWC_ETH_QOS_QUEUE_SELECT_ALGO
-u16	DWC_ETH_QOS_select_queue(struct net_device *dev,
-			struct sk_buff *skb)
+u16   DWC_ETH_QOS_select_queue(struct net_device *dev,
+         struct sk_buff *skb)
 {
-	static u16 txqueue_select = 0;
-
-	DBGPR("-->DWC_ETH_QOS_select_queue\n");
-
-	txqueue_select = skb_tx_hash(dev, skb);
-
-	DBGPR("<--DWC_ETH_QOS_select_queue txqueue-select:%d\n",
-		txqueue_select);
-
-	return txqueue_select;
+   static u16 txqueue_select = 0;
+
+   DBGPR("-->DWC_ETH_QOS_select_queue\n");
+
+   txqueue_select = skb_tx_hash(dev, skb);
+
+   DBGPR("<--DWC_ETH_QOS_select_queue txqueue-select:%d\n",
+      txqueue_select);
+
+   return txqueue_select;
 }
 #endif
 
 unsigned int crc32_snps_le(unsigned int initval, unsigned char *data, unsigned int size)
 {
-	unsigned int crc = initval;
-	unsigned int poly = 0x04c11db7;
-	unsigned int temp = 0;
-	unsigned char my_data = 0;
-	int bit_count;
-	for(bit_count = 0; bit_count < size; bit_count++) {
-		if((bit_count % 8) == 0) my_data = data[bit_count/8];
-		DBGPR_FILTER("%s my_data = %x crc=%x\n", __func__, my_data,crc);
-		temp = ((crc >> 31) ^  my_data) &  0x1;
-		crc <<= 1;
-		if(temp != 0) crc ^= poly;
-		my_data >>=1;
-	}
-		DBGPR_FILTER("%s my_data = %x crc=%x\n", __func__, my_data,crc);
-	return ~crc;
+   unsigned int crc = initval;
+   unsigned int poly = 0x04c11db7;
+   unsigned int temp = 0;
+   unsigned char my_data = 0;
+   int bit_count;
+   for(bit_count = 0; bit_count < size; bit_count++) {
+      if((bit_count % 8) == 0) my_data = data[bit_count/8];
+      DBGPR_FILTER("%s my_data = %x crc=%x\n", __func__, my_data,crc);
+      temp = ((crc >> 31) ^  my_data) &  0x1;
+      crc <<= 1;
+      if(temp != 0) crc ^= poly;
+      my_data >>=1;
+   }
+      DBGPR_FILTER("%s my_data = %x crc=%x\n", __func__, my_data,crc);
+   return ~crc;
 }
 
 /*!
@@ -5237,37 +5238,37 @@ unsigned int crc32_snps_le(unsigned int 
 static int DWC_ETH_QOS_vlan_rx_kill_vid(struct net_device *dev,
       __always_unused __be16 proto, u16 vid)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	unsigned short new_index, old_index;
-	int crc32_val = 0;
-	unsigned int enb_12bit_vhash;
-
-	DBGPR("-->DWC_ETH_QOS_vlan_rx_kill_vid: vid = %d\n", vid);
-
-	if (pdata->vlan_hash_filtering) {
-		crc32_val = (bitrev32(~crc32_le(~0, (unsigned char *)&vid, 2)) >> 28);
-
-		enb_12bit_vhash = hw_if->get_vlan_tag_comparison();
-		if (enb_12bit_vhash) {
-			/* neget 4-bit crc value for 12-bit VLAN hash comparison */
-			new_index = (1 << (~crc32_val & 0xF));
-		} else {
-			new_index = (1 << (crc32_val & 0xF));
-		}
-
-		old_index = hw_if->get_vlan_hash_table_reg();
-		old_index &= ~new_index;
-		hw_if->update_vlan_hash_table_reg(old_index);
-		pdata->vlan_ht_or_id = old_index;
-	} else {
-		/* By default, receive only VLAN pkt with VID = 1
-		 * becasue writting 0 will pass all VLAN pkt */
-		hw_if->update_vlan_id(1);
-		pdata->vlan_ht_or_id = 1;
-	}
-
-	DBGPR("<--DWC_ETH_QOS_vlan_rx_kill_vid\n");
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   unsigned short new_index, old_index;
+   int crc32_val = 0;
+   unsigned int enb_12bit_vhash;
+
+   DBGPR("-->DWC_ETH_QOS_vlan_rx_kill_vid: vid = %d\n", vid);
+
+   if (pdata->vlan_hash_filtering) {
+      crc32_val = (bitrev32(~crc32_le(~0, (unsigned char *)&vid, 2)) >> 28);
+
+      enb_12bit_vhash = hw_if->get_vlan_tag_comparison();
+      if (enb_12bit_vhash) {
+         /* neget 4-bit crc value for 12-bit VLAN hash comparison */
+         new_index = (1 << (~crc32_val & 0xF));
+      } else {
+         new_index = (1 << (crc32_val & 0xF));
+      }
+
+      old_index = hw_if->get_vlan_hash_table_reg();
+      old_index &= ~new_index;
+      hw_if->update_vlan_hash_table_reg(old_index);
+      pdata->vlan_ht_or_id = old_index;
+   } else {
+      /* By default, receive only VLAN pkt with VID = 1
+       * becasue writting 0 will pass all VLAN pkt */
+      hw_if->update_vlan_id(1);
+      pdata->vlan_ht_or_id = 1;
+   }
+
+   DBGPR("<--DWC_ETH_QOS_vlan_rx_kill_vid\n");
    return 0;
 }
 
@@ -5289,43 +5290,86 @@ static int DWC_ETH_QOS_vlan_rx_kill_vid(
 static int DWC_ETH_QOS_vlan_rx_add_vid(struct net_device *dev,
       __always_unused __be16 proto, u16 vid)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	unsigned short new_index, old_index;
-	int crc32_val = 0;
-	unsigned int enb_12bit_vhash;
-
-	CFG_PRINT("-->DWC_ETH_QOS_vlan_rx_add_vid: vid = %d hash = %d\n",
-			vid, pdata->vlan_hash_filtering);
-
-	if (pdata->vlan_hash_filtering) {
-		/* The upper 4 bits of the calculated CRC are used to
-		 * index the content of the VLAN Hash Table Reg.
-		 * */
-		crc32_val = (bitrev32(~crc32_le(~0, (unsigned char *)&vid, 2)) >> 28);
-
-		/* These 4(0xF) bits determines the bit within the
-		 * VLAN Hash Table Reg 0
-		 * */
-		enb_12bit_vhash = hw_if->get_vlan_tag_comparison();
-		if (enb_12bit_vhash) {
-			/* neget 4-bit crc value for 12-bit VLAN hash comparison */
-			new_index = (1 << (~crc32_val & 0xF));
-		} else {
-			new_index = (1 << (crc32_val & 0xF));
-		}
-
-		old_index = hw_if->get_vlan_hash_table_reg();
-		old_index |= new_index;
-		hw_if->update_vlan_hash_table_reg(old_index);
-		pdata->vlan_ht_or_id = old_index;
-	} else {
-		hw_if->update_vlan_id(vid);
-		pdata->vlan_ht_or_id = vid;
-	}
-
-	CFG_PRINT("<--DWC_ETH_QOS_vlan_rx_add_vid\n");
-	return 0;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   unsigned short new_index, old_index;
+   int crc32_val = 0;
+   unsigned int enb_12bit_vhash;
+
+   CFG_PRINT("-->DWC_ETH_QOS_vlan_rx_add_vid: vid = %d hash = %d\n",
+         vid, pdata->vlan_hash_filtering);
+
+   if (pdata->vlan_hash_filtering) {
+      /* The upper 4 bits of the calculated CRC are used to
+       * index the content of the VLAN Hash Table Reg.
+       * */
+      crc32_val = (bitrev32(~crc32_le(~0, (unsigned char *)&vid, 2)) >> 28);
+
+      /* These 4(0xF) bits determines the bit within the
+       * VLAN Hash Table Reg 0
+       * */
+      enb_12bit_vhash = hw_if->get_vlan_tag_comparison();
+      if (enb_12bit_vhash) {
+         /* neget 4-bit crc value for 12-bit VLAN hash comparison */
+         new_index = (1 << (~crc32_val & 0xF));
+      } else {
+         new_index = (1 << (crc32_val & 0xF));
+      }
+
+      old_index = hw_if->get_vlan_hash_table_reg();
+      old_index |= new_index;
+      hw_if->update_vlan_hash_table_reg(old_index);
+      pdata->vlan_ht_or_id = old_index;
+   } else {
+      hw_if->update_vlan_id(vid);
+      pdata->vlan_ht_or_id = vid;
+   }
+
+   CFG_PRINT("<--DWC_ETH_QOS_vlan_rx_add_vid\n");
+   return 0;
+}
+
+void gbe_enter_standby(struct DWC_ETH_QOS_prv_data *pdata)
+{
+   uint32_t qInx;
+   hw_interface_t *hw_if = &pdata->hw_if;
+#ifdef GBE_POLLING
+   hrtimer_cancel(&pdata->gbe_timer);
+#endif
+   hrtimer_cancel(&pdata->rx_itr_timer);
+   /* Stop MAC */
+   hw_if->stop_mac_tx_rx();
+   /* Disable interrupts in NetSS */
+   netss_interrupt_disable(NETSS_INTERUPT_GBE);
+   /* Disable MAC interrupts */
+   DWC_REG_WR(MAC_IER, 0);
+   /* Disable DMA interrupts */
+   for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
+      DWC_REG_WR(DMA_IER(qInx), 0);
+   }
+   /* Indicate ISR that NetIP is powering down */
+   pdata->power_state = DWC_ETH_QOS_NETIP_PWRDWN;
+   /* Process and clear any pending interrupt */
+   DWC_ETH_QOS_ISR(pdata->irq_number, pdata);
+   /* Update power down status variable */
+   pdata->power_state = DWC_ETH_QOS_NETIP_WAKEUP;
+}
+
+void gbe_exit_standby(struct DWC_ETH_QOS_prv_data *pdata)
+{
+   uint32_t qInx;
+   hw_config_t *hw_cfg = &pdata->hw_cfg;
+   /* Enable interrupts in NetSS */
+   netss_interrupt_enable(NETSS_INTERUPT_GBE);
+   /* Enable MAC interrupts */
+   DWC_REG_WR(MAC_IER, hw_cfg->mac_ier);
+   /* Enable DMA interrupts */
+   for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
+      DWC_REG_WR(DMA_IER(qInx), hw_cfg->dma_ier);
+   }
+#ifdef GBE_POLLING
+   hrtimer_start(&pdata->gbe_timer, ktime_set(0, 100000), HRTIMER_MODE_REL);
+#endif
 }
 
 /*!
@@ -5342,61 +5386,81 @@ static int DWC_ETH_QOS_vlan_rx_add_vid(s
  *
  * \param[in] dev  pointer to net device structure.
  * \param[in] wakeup_type  remote wake-on-lan or magic packet.
- * \param[in] caller  netif_detach gets called conditionally based
- *                     on caller, IOCTL or DRIVER-suspend
  *
  * \return int
  *
  * \retval zero on success and -ve number on failure.
  */
-int DWC_ETH_QOS_powerdown(struct net_device *dev, uint32_t wakeup_type,
-		uint32_t caller)
+int DWC_ETH_QOS_powerdown(struct net_device *dev, uint32_t wakeup_type)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	unsigned long flags;
-
-	DBGPR(KERN_ALERT "-->DWC_ETH_QOS_powerdown\n");
-
-	if (!dev || !netif_running(dev) ||
-	    (caller == DWC_ETH_QOS_IOCTL_CONTEXT && pdata->power_down)) {
-		printk(KERN_ALERT
-		       "Device is already powered down and will powerup for %s\n",
-		       DWC_ETH_QOS_POWER_DOWN_TYPE(pdata));
-		DBGPR("<--DWC_ETH_QOS_powerdown\n");
-		return -EINVAL;
-	}
-
-	if (pdata->phydev)
-		phy_stop(pdata->phydev);
-
-	spin_lock_irqsave(&pdata->pmt_lock, flags);
-
-	if (caller == DWC_ETH_QOS_DRIVER_CONTEXT)
-		netif_device_detach(dev);
-
-	netif_tx_disable(dev);
-	DWC_ETH_QOS_napi_disable(pdata);
-
-	/* stop DMA TX/RX */
-	DWC_ETH_QOS_stop_all_ch_tx_dma(pdata);
-	DWC_ETH_QOS_stop_all_ch_rx_dma(pdata);
-
-	/* enable power down mode by programming the PMT regs */
-	if (wakeup_type & DWC_ETH_QOS_REMOTE_WAKEUP)
-		hw_if->enable_remote_pmt();
-	if (wakeup_type & DWC_ETH_QOS_MAGIC_WAKEUP)
-		hw_if->enable_magic_pmt();
-	pdata->power_down_type = wakeup_type;
-
-	if (caller == DWC_ETH_QOS_IOCTL_CONTEXT)
-		pdata->power_down = 1;
-
-	spin_unlock_irqrestore(&pdata->pmt_lock, flags);
-
-	DBGPR("<--DWC_ETH_QOS_powerdown\n");
-
-	return 0;
+   struct DWC_ETH_QOS_prv_data *pdata = NULL;
+   hw_interface_t *hw_if = NULL;
+   unsigned long flags;
+   int ret = 0;
+
+   CFG_PRINT("-->DWC_ETH_QOS_powerdown (0x%08x)\n", wakeup_type);
+
+   if (!dev) {
+      ERR_PRINT("Invalid parameter!\n");
+      ret = -EINVAL;
+      goto exit_pwr_dwn_err;
+   }
+
+   pdata = netdev_priv(dev);
+   hw_if = &(pdata->hw_if);
+
+   spin_lock_irqsave(&pdata->pmt_lock, flags);
+
+   if (!netif_running(dev)) {
+      WRN_PRINT("Device is not running!\n");
+      pdata->power_state = (wakeup_type & DWC_ETH_QOS_NETIP_WAKEUP);
+      goto exit_pwr_dwn;
+   }
+
+   if (pdata->power_state &&
+     !(pdata->power_state & DWC_ETH_QOS_NETIP_WAKEUP) &&
+      (wakeup_type & DWC_ETH_QOS_NETIP_WAKEUP)) {
+      /* Process request started by the NetIP SS driver. */
+      gbe_enter_standby(pdata);
+      goto exit_pwr_dwn;
+   } else if (pdata->power_state) {
+      WRN_PRINT("Device is already powered down!\n");
+      goto exit_pwr_dwn;
+   }
+
+   /* Stop PHY */
+   if (pdata->phydev)
+      phy_stop(pdata->phydev);
+   /* Detach net device */
+   netif_device_detach(dev);
+   /* Disable NAPI */
+   DWC_ETH_QOS_napi_disable(pdata);
+   /* Stop DMA TX/RX */
+   DWC_ETH_QOS_stop_all_ch_tx_dma(pdata);
+   DWC_ETH_QOS_stop_all_ch_rx_dma(pdata);
+
+   if (wakeup_type & DWC_ETH_QOS_NETIP_WAKEUP) {
+      /* Process request started by NetIP SS driver first */
+      gbe_enter_standby(pdata);
+   } else {
+      /* Enable PMT Interrupt */
+      VAR32_SET_BIT(pdata->hw_cfg.mac_ier, MAC_IER_PMTIE, 0x1);
+      DWC_REG_WR(MAC_IER, pdata->hw_cfg.mac_ier);
+      /* Enable power down mode by programming the PMT regs */
+      if (wakeup_type & DWC_ETH_QOS_REMOTE_WAKEUP)
+         hw_if->enable_remote_pmt();
+      if (wakeup_type & DWC_ETH_QOS_MAGIC_WAKEUP)
+         hw_if->enable_magic_pmt();
+      pdata->power_state = wakeup_type;
+   }
+
+exit_pwr_dwn:
+   spin_unlock_irqrestore(&pdata->pmt_lock, flags);
+
+exit_pwr_dwn_err:
+   CFG_PRINT("<--DWC_ETH_QOS_powerdown\n");
+
+   return ret;
 }
 
 /*!
@@ -5412,64 +5476,98 @@ int DWC_ETH_QOS_powerdown(struct net_dev
  * - Starts the queue.
  *
  * \param[in] dev  pointer to net device structure.
- * \param[in] caller  netif_attach gets called conditionally based
- *                     on caller, IOCTL or DRIVER-suspend
  *
  * \return int
  *
  * \retval zero on success and -ve number on failure.
  */
-int DWC_ETH_QOS_powerup(struct net_device *dev, uint32_t caller)
+int DWC_ETH_QOS_powerup(struct net_device *dev)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	unsigned long flags;
-
-	DBGPR("-->DWC_ETH_QOS_powerup\n");
-
-	if (!dev || !netif_running(dev) ||
-	    (caller == DWC_ETH_QOS_IOCTL_CONTEXT && !pdata->power_down)) {
-		printk(KERN_ALERT "Device is already powered up\n");
-		DBGPR(KERN_ALERT "<--DWC_ETH_QOS_powerup\n");
-		return -EINVAL;
-	}
-
-	spin_lock_irqsave(&pdata->pmt_lock, flags);
-
-	if (pdata->power_down_type & DWC_ETH_QOS_MAGIC_WAKEUP) {
-		hw_if->disable_magic_pmt();
-		pdata->power_down_type &= ~DWC_ETH_QOS_MAGIC_WAKEUP;
-	}
-
-	if (pdata->power_down_type & DWC_ETH_QOS_REMOTE_WAKEUP) {
-		hw_if->disable_remote_pmt();
-		pdata->power_down_type &= ~DWC_ETH_QOS_REMOTE_WAKEUP;
-	}
-
-	pdata->power_down = 0;
-
-	if (pdata->phydev)
-		phy_start(pdata->phydev);
-
-	/* enable MAC TX/RX */
-	hw_if->start_mac_tx_rx();
-
-	/* enable DMA TX/RX */
-	DWC_ETH_QOS_start_all_ch_tx_dma(pdata);
-	DWC_ETH_QOS_start_all_ch_rx_dma(pdata);
-
-	if (caller == DWC_ETH_QOS_DRIVER_CONTEXT)
-		netif_device_attach(dev);
-
-	DWC_ETH_QOS_napi_enable(pdata);
-
-	netif_tx_start_all_queues(dev);
-
-	spin_unlock_irqrestore(&pdata->pmt_lock, flags);
-
-	DBGPR("<--DWC_ETH_QOS_powerup\n");
-
-	return 0;
+   struct DWC_ETH_QOS_prv_data *pdata = NULL;
+   hw_interface_t *hw_if = NULL;
+   unsigned long flags;
+   int ret = 0;
+
+   CFG_PRINT("-->DWC_ETH_QOS_powerup\n");
+
+   if (!dev) {
+      ERR_PRINT("Invalid parameter!\n");
+      ret = -EINVAL;
+      goto exit_pwr_up_err;
+   }
+
+   pdata = netdev_priv(dev);
+   hw_if = &(pdata->hw_if);
+
+   spin_lock_irqsave(&pdata->pmt_lock, flags);
+
+   if(!pdata->power_state) {
+      WRN_PRINT("Device has not been powered down!\n");
+      goto exit_pwr_up;
+   } else if (!netif_running(dev)) {
+      /* Process request if it was started by the NetIP SS driver. */
+      pdata->power_state &= ~DWC_ETH_QOS_NETIP_WAKEUP;
+      WRN_PRINT("Device is not running!\n");
+      goto exit_pwr_up;
+   }
+
+   if (pdata->power_state & DWC_ETH_QOS_NETIP_WAKEUP) {
+      gbe_exit_standby(pdata);
+      pdata->power_state &= ~DWC_ETH_QOS_NETIP_WAKEUP;
+   }
+   if (pdata->power_state & DWC_ETH_QOS_MAGIC_WAKEUP) {
+      hw_if->disable_magic_pmt();
+      pdata->power_state &= ~DWC_ETH_QOS_MAGIC_WAKEUP;
+   }
+   if (pdata->power_state & DWC_ETH_QOS_REMOTE_WAKEUP) {
+      hw_if->disable_remote_pmt();
+      pdata->power_state &= ~DWC_ETH_QOS_REMOTE_WAKEUP;
+   }
+
+   /* Configure pending requests (e.g. Split header or MTU changes) */
+   if (pdata->power_state &
+      (DWC_ETH_QOS_NETIP_SPLHDR_REQ | DWC_ETH_QOS_NETIP_MTU_REQ)) {
+      /* Indicate controller is powering up from StandBy */
+      pdata->power_state |= DWC_ETH_QOS_NETIP_PWRUP;
+      DWC_ETH_QOS_stop_dev(pdata);
+      if (pdata->power_state & DWC_ETH_QOS_NETIP_SPLHDR_REQ) {
+         uint32_t qInx;
+         hw_if->config_header_size(DWC_ETH_QOS_MAX_HDR_SIZE);
+         /* Enable/disable split header for all RX DMA channel */
+         for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++)
+            hw_if->config_split_header_mode(qInx, pdata->rx_split_hdr);
+         }
+      /* Attach net device */
+      netif_device_attach(dev);
+      DWC_ETH_QOS_start_dev(pdata);
+   } else {
+      /* Start PHY */
+      if (pdata->phydev)
+         phy_start(pdata->phydev);
+      /* Enable MAC TX/RX */
+      hw_if->start_mac_tx_rx();
+      /* Enable DMA TX/RX */
+      DWC_ETH_QOS_start_all_ch_tx_dma(pdata);
+      DWC_ETH_QOS_start_all_ch_rx_dma(pdata);
+      /* Attach net device */
+      netif_device_attach(dev);
+      /* Enable NAPI */
+      DWC_ETH_QOS_napi_enable(pdata);
+      /* Start Tx queues */
+      netif_tx_start_all_queues(dev);
+      /* Disable PMT Interrupt */
+      VAR32_SET_BIT(pdata->hw_cfg.mac_ier, MAC_IER_PMTIE, 0x0);
+      DWC_REG_WR(MAC_IER, pdata->hw_cfg.mac_ier);
+   }
+   pdata->power_state = DWC_ETH_QOS_POWER_ON;
+
+exit_pwr_up:
+   spin_unlock_irqrestore(&pdata->pmt_lock, flags);
+
+exit_pwr_up_err:
+   CFG_PRINT("<--DWC_ETH_QOS_powerup\n");
+
+   return ret;
 }
 
 /*!
@@ -5486,26 +5584,22 @@ int DWC_ETH_QOS_powerup(struct net_devic
  * \retval zero on success and -ve number on failure.
  */
 int DWC_ETH_QOS_configure_remotewakeup(struct net_device *dev,
-				       struct ifr_data_struct *req)
+                   struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-
-	if (!dev || !netif_running(dev) || !pdata->hw_feat.rwk_sel
-	    || pdata->power_down) {
-		printk(KERN_ALERT
-		       "Device is already powered down and will powerup for %s\n",
-		       DWC_ETH_QOS_POWER_DOWN_TYPE(pdata));
-		return -EINVAL;
-	}
-
-	hw_if->configure_rwk_filter(req->rwk_filter_values,
-				    req->rwk_filter_length);
-
-	DWC_ETH_QOS_powerdown(dev, DWC_ETH_QOS_REMOTE_WAKEUP,
-			DWC_ETH_QOS_IOCTL_CONTEXT);
-
-	return 0;
+   struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
+   hw_interface_t *hw_if = &(pdata->hw_if);
+
+   if (!dev || !netif_running(dev) ||
+       !pdata->hw_feat.rwk_sel || pdata->power_state) {
+      ERR_PRINT("Device is already powered down!\n");
+      return -EINVAL;
+   }
+
+   hw_if->configure_rwk_filter(req->rwk_filter_values, req->rwk_filter_length);
+
+   DWC_ETH_QOS_powerdown(dev, DWC_ETH_QOS_REMOTE_WAKEUP);
+
+   return 0;
 }
 
 /*!
@@ -5520,51 +5614,50 @@ int DWC_ETH_QOS_configure_remotewakeup(s
  *
  * \retval none
  */
-
 static void DWC_ETH_QOS_config_rx_pbl(struct DWC_ETH_QOS_prv_data *pdata,
-				      uint32_t rx_pbl,
-				      uint32_t qInx)
+                  uint32_t rx_pbl,
+                  uint32_t qInx)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t pblx8_val = 0;
-
-	DBGPR("-->DWC_ETH_QOS_config_rx_pbl: %d\n", rx_pbl);
-
-	switch (rx_pbl) {
-	case DWC_ETH_QOS_PBL_1:
-	case DWC_ETH_QOS_PBL_2:
-	case DWC_ETH_QOS_PBL_4:
-	case DWC_ETH_QOS_PBL_8:
-	case DWC_ETH_QOS_PBL_16:
-	case DWC_ETH_QOS_PBL_32:
-		hw_if->config_rx_pbl_val(qInx, rx_pbl);
-		hw_if->config_pblx8(qInx, 0);
-		break;
-	case DWC_ETH_QOS_PBL_64:
-	case DWC_ETH_QOS_PBL_128:
-	case DWC_ETH_QOS_PBL_256:
-		hw_if->config_rx_pbl_val(qInx, rx_pbl / 8);
-		hw_if->config_pblx8(qInx, 1);
-		pblx8_val = 1;
-		break;
-	}
-
-	switch (pblx8_val) {
-		case 0:
-			printk(KERN_ALERT "Tx PBL[%d] value: %d\n",
-					qInx, hw_if->get_tx_pbl_val(qInx));
-			printk(KERN_ALERT "Rx PBL[%d] value: %d\n",
-					qInx, hw_if->get_rx_pbl_val(qInx));
-			break;
-		case 1:
-			printk(KERN_ALERT "Tx PBL[%d] value: %d\n",
-					qInx, (hw_if->get_tx_pbl_val(qInx) * 8));
-			printk(KERN_ALERT "Rx PBL[%d] value: %d\n",
-					qInx, (hw_if->get_rx_pbl_val(qInx) * 8));
-			break;
-	}
-
-	DBGPR("<--DWC_ETH_QOS_config_rx_pbl\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t pblx8_val = 0;
+
+   DBGPR("-->DWC_ETH_QOS_config_rx_pbl: %d\n", rx_pbl);
+
+   switch (rx_pbl) {
+   case DWC_ETH_QOS_PBL_1:
+   case DWC_ETH_QOS_PBL_2:
+   case DWC_ETH_QOS_PBL_4:
+   case DWC_ETH_QOS_PBL_8:
+   case DWC_ETH_QOS_PBL_16:
+   case DWC_ETH_QOS_PBL_32:
+      hw_if->config_rx_pbl_val(qInx, rx_pbl);
+      hw_if->config_pblx8(qInx, 0);
+      break;
+   case DWC_ETH_QOS_PBL_64:
+   case DWC_ETH_QOS_PBL_128:
+   case DWC_ETH_QOS_PBL_256:
+      hw_if->config_rx_pbl_val(qInx, rx_pbl / 8);
+      hw_if->config_pblx8(qInx, 1);
+      pblx8_val = 1;
+      break;
+   }
+
+   switch (pblx8_val) {
+      case 0:
+         printk(KERN_ALERT "Tx PBL[%d] value: %d\n",
+               qInx, hw_if->get_tx_pbl_val(qInx));
+         printk(KERN_ALERT "Rx PBL[%d] value: %d\n",
+               qInx, hw_if->get_rx_pbl_val(qInx));
+         break;
+      case 1:
+         printk(KERN_ALERT "Tx PBL[%d] value: %d\n",
+               qInx, (hw_if->get_tx_pbl_val(qInx) * 8));
+         printk(KERN_ALERT "Rx PBL[%d] value: %d\n",
+               qInx, (hw_if->get_rx_pbl_val(qInx) * 8));
+         break;
+   }
+
+   DBGPR("<--DWC_ETH_QOS_config_rx_pbl\n");
 }
 
 /*!
@@ -5579,54 +5672,52 @@ static void DWC_ETH_QOS_config_rx_pbl(st
  *
  * \retval none
  */
-
 static void DWC_ETH_QOS_config_tx_pbl(struct DWC_ETH_QOS_prv_data *pdata,
-				      uint32_t tx_pbl,
-				      uint32_t qInx)
+                  uint32_t tx_pbl,
+                  uint32_t qInx)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	uint32_t pblx8_val = 0;
-
-	DBGPR("-->DWC_ETH_QOS_config_tx_pbl: %d\n", tx_pbl);
-
-	switch (tx_pbl) {
-	case DWC_ETH_QOS_PBL_1:
-	case DWC_ETH_QOS_PBL_2:
-	case DWC_ETH_QOS_PBL_4:
-	case DWC_ETH_QOS_PBL_8:
-	case DWC_ETH_QOS_PBL_16:
-	case DWC_ETH_QOS_PBL_32:
-		hw_if->config_tx_pbl_val(qInx, tx_pbl);
-		hw_if->config_pblx8(qInx, 0);
-		break;
-	case DWC_ETH_QOS_PBL_64:
-	case DWC_ETH_QOS_PBL_128:
-	case DWC_ETH_QOS_PBL_256:
-		hw_if->config_tx_pbl_val(qInx, tx_pbl / 8);
-		hw_if->config_pblx8(qInx, 1);
-		pblx8_val = 1;
-		break;
-	}
-
-	switch (pblx8_val) {
-		case 0:
-			printk(KERN_ALERT "Tx PBL[%d] value: %d\n",
-					qInx, hw_if->get_tx_pbl_val(qInx));
-			printk(KERN_ALERT "Rx PBL[%d] value: %d\n",
-					qInx, hw_if->get_rx_pbl_val(qInx));
-			break;
-		case 1:
-			printk(KERN_ALERT "Tx PBL[%d] value: %d\n",
-					qInx, (hw_if->get_tx_pbl_val(qInx) * 8));
-			printk(KERN_ALERT "Rx PBL[%d] value: %d\n",
-					qInx, (hw_if->get_rx_pbl_val(qInx) * 8));
-			break;
-	}
-
-	DBGPR("<--DWC_ETH_QOS_config_tx_pbl\n");
+   hw_interface_t *hw_if = &(pdata->hw_if);
+   uint32_t pblx8_val = 0;
+
+   DBGPR("-->DWC_ETH_QOS_config_tx_pbl: %d\n", tx_pbl);
+
+   switch (tx_pbl) {
+   case DWC_ETH_QOS_PBL_1:
+   case DWC_ETH_QOS_PBL_2:
+   case DWC_ETH_QOS_PBL_4:
+   case DWC_ETH_QOS_PBL_8:
+   case DWC_ETH_QOS_PBL_16:
+   case DWC_ETH_QOS_PBL_32:
+      hw_if->config_tx_pbl_val(qInx, tx_pbl);
+      hw_if->config_pblx8(qInx, 0);
+      break;
+   case DWC_ETH_QOS_PBL_64:
+   case DWC_ETH_QOS_PBL_128:
+   case DWC_ETH_QOS_PBL_256:
+      hw_if->config_tx_pbl_val(qInx, tx_pbl / 8);
+      hw_if->config_pblx8(qInx, 1);
+      pblx8_val = 1;
+      break;
+   }
+
+   switch (pblx8_val) {
+      case 0:
+         printk(KERN_ALERT "Tx PBL[%d] value: %d\n",
+               qInx, hw_if->get_tx_pbl_val(qInx));
+         printk(KERN_ALERT "Rx PBL[%d] value: %d\n",
+               qInx, hw_if->get_rx_pbl_val(qInx));
+         break;
+      case 1:
+         printk(KERN_ALERT "Tx PBL[%d] value: %d\n",
+               qInx, (hw_if->get_tx_pbl_val(qInx) * 8));
+         printk(KERN_ALERT "Rx PBL[%d] value: %d\n",
+               qInx, (hw_if->get_rx_pbl_val(qInx) * 8));
+         break;
+   }
+
+   DBGPR("<--DWC_ETH_QOS_config_tx_pbl\n");
 }
 
-
 /*!
  * \details This function is invoked by ioctl function when the user issues an
  * ioctl command to select the DCB algorithm.
@@ -5638,31 +5729,29 @@ static void DWC_ETH_QOS_config_tx_pbl(st
  *
  * \retval none
  */
-
 static void DWC_ETH_QOS_program_dcb_algorithm(struct DWC_ETH_QOS_prv_data *pdata,
-		struct ifr_data_struct *req)
+      struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_dcb_algorithm l_dcb_struct, *u_dcb_struct =
-		(struct DWC_ETH_QOS_dcb_algorithm *)req->ptr;
-	struct hw_if_struct *hw_if = &pdata->hw_if;
-
-	DBGPR("-->DWC_ETH_QOS_program_dcb_algorithm\n");
-
-	if(copy_from_user(&l_dcb_struct, u_dcb_struct,
-				sizeof(struct DWC_ETH_QOS_dcb_algorithm)))
-		printk(KERN_ALERT "Failed to fetch DCB Struct info from user\n");
-
-	hw_if->set_tx_queue_operating_mode(l_dcb_struct.qInx,
-		(uint32_t)l_dcb_struct.op_mode);
-	hw_if->set_dcb_algorithm(l_dcb_struct.algorithm);
-	hw_if->set_dcb_queue_weight(l_dcb_struct.qInx, l_dcb_struct.weight);
-
-	DBGPR("<--DWC_ETH_QOS_program_dcb_algorithm\n");
-
-	return;
+   struct DWC_ETH_QOS_dcb_algorithm l_dcb_struct, *u_dcb_struct =
+      (struct DWC_ETH_QOS_dcb_algorithm *)req->ptr;
+   hw_interface_t *hw_if = &pdata->hw_if;
+
+   DBGPR("-->DWC_ETH_QOS_program_dcb_algorithm\n");
+
+   if(copy_from_user(&l_dcb_struct, u_dcb_struct,
+            sizeof(struct DWC_ETH_QOS_dcb_algorithm)))
+      printk(KERN_ALERT "Failed to fetch DCB Struct info from user\n");
+
+   hw_if->set_tx_queue_operating_mode(l_dcb_struct.qInx,
+      (uint32_t)l_dcb_struct.op_mode);
+   hw_if->set_dcb_algorithm(l_dcb_struct.algorithm);
+   hw_if->set_dcb_queue_weight(l_dcb_struct.qInx, l_dcb_struct.weight);
+
+   DBGPR("<--DWC_ETH_QOS_program_dcb_algorithm\n");
+
+   return;
 }
 
-
 /*!
  * \details This function is invoked by ioctl function when the user issues an
  * ioctl command to select the AVB algorithm. This function also configures other
@@ -5675,32 +5764,31 @@ static void DWC_ETH_QOS_program_dcb_algo
  *
  * \retval none
  */
-
 static void DWC_ETH_QOS_program_avb_algorithm(struct DWC_ETH_QOS_prv_data *pdata,
-		struct ifr_data_struct *req)
+      struct ifr_data_struct *req)
 {
-	struct DWC_ETH_QOS_avb_algorithm l_avb_struct, *u_avb_struct =
-		(struct DWC_ETH_QOS_avb_algorithm *)req->ptr;
-	struct hw_if_struct *hw_if = &pdata->hw_if;
-
-	DBGPR("-->DWC_ETH_QOS_program_avb_algorithm\n");
-
-	if(copy_from_user(&l_avb_struct, u_avb_struct,
-				sizeof(struct DWC_ETH_QOS_avb_algorithm)))
-		printk(KERN_ALERT "Failed to fetch AVB Struct info from user\n");
-
-	hw_if->set_tx_queue_operating_mode(l_avb_struct.qInx,
-		(uint32_t)l_avb_struct.op_mode);
-	hw_if->set_avb_algorithm(l_avb_struct.qInx, l_avb_struct.algorithm);
-	hw_if->config_credit_control(l_avb_struct.qInx, l_avb_struct.cc);
-	hw_if->config_send_slope(l_avb_struct.qInx, l_avb_struct.send_slope);
-	hw_if->config_idle_slope(l_avb_struct.qInx, l_avb_struct.idle_slope);
-	hw_if->config_high_credit(l_avb_struct.qInx, l_avb_struct.hi_credit);
-	hw_if->config_low_credit(l_avb_struct.qInx, l_avb_struct.low_credit);
-
-	DBGPR("<--DWC_ETH_QOS_program_avb_algorithm\n");
-
-	return;
+   struct DWC_ETH_QOS_avb_algorithm l_avb_struct, *u_avb_struct =
+      (struct DWC_ETH_QOS_avb_algorithm *)req->ptr;
+   hw_interface_t *hw_if = &pdata->hw_if;
+
+   DBGPR("-->DWC_ETH_QOS_program_avb_algorithm\n");
+
+   if(copy_from_user(&l_avb_struct, u_avb_struct,
+            sizeof(struct DWC_ETH_QOS_avb_algorithm)))
+      printk(KERN_ALERT "Failed to fetch AVB Struct info from user\n");
+
+   hw_if->set_tx_queue_operating_mode(l_avb_struct.qInx,
+      (uint32_t)l_avb_struct.op_mode);
+   hw_if->set_avb_algorithm(l_avb_struct.qInx, l_avb_struct.algorithm);
+   hw_if->config_credit_control(l_avb_struct.qInx, l_avb_struct.cc);
+   hw_if->config_send_slope(l_avb_struct.qInx, l_avb_struct.send_slope);
+   hw_if->config_idle_slope(l_avb_struct.qInx, l_avb_struct.idle_slope);
+   hw_if->config_high_credit(l_avb_struct.qInx, l_avb_struct.hi_credit);
+   hw_if->config_low_credit(l_avb_struct.qInx, l_avb_struct.low_credit);
+
+   DBGPR("<--DWC_ETH_QOS_program_avb_algorithm\n");
+
+   return;
 }
 
 /*!
@@ -5713,13 +5801,12 @@ static void DWC_ETH_QOS_program_avb_algo
  *
  * \return void
  */
-
 void dump_rx_desc(uint32_t qInx, rx_descriptor_t *desc, int desc_idx)
 {
-	printk(KERN_ALERT "\nRX_NORMAL_DESC[%02d %4p %03d RECEIVED FROM DEVICE]"\
-		" = %#x:%#x:%#x:%#x",
-		qInx, desc, desc_idx, desc->RDES0, desc->RDES1,
-		desc->RDES2, desc->RDES3);
+   printk(KERN_ALERT "\nRX_NORMAL_DESC[%02d %4p %03d RECEIVED FROM DEVICE]"\
+      " = %#x:%#x:%#x:%#x",
+      qInx, desc, desc_idx, desc->RDES0, desc->RDES1,
+      desc->RDES2, desc->RDES3);
 }
 
 /*!
@@ -5733,21 +5820,21 @@ void dump_rx_desc(uint32_t qInx, rx_desc
  */
 void DWC_ETH_QOS_init_rx_coalesce(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data = NULL;
-	uint32_t i;
-
-	DBGPR("-->DWC_ETH_QOS_init_rx_coalesce\n");
-
-	for (i = 0; i < DWC_ETH_QOS_RX_QUEUE_CNT; i++) {
-		rx_desc_data = GET_RX_WRAPPER_DESC(i);
-
-		rx_desc_data->use_riwt = 1;
-		rx_desc_data->rx_coal_frames = DWC_ETH_QOS_RX_MAX_FRAMES;
-		rx_desc_data->rx_riwt =
-			DWC_ETH_QOS_usec2riwt(DWC_ETH_QOS_OPTIMAL_DMA_RIWT_USEC, pdata);
-	}
-
-	DBGPR("<--DWC_ETH_QOS_init_rx_coalesce\n");
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data = NULL;
+   uint32_t i;
+
+   DBGPR("-->DWC_ETH_QOS_init_rx_coalesce\n");
+
+   for (i = 0; i < DWC_ETH_QOS_RX_QUEUE_CNT; i++) {
+      rx_desc_data = GET_RX_WRAPPER_DESC(i);
+
+      rx_desc_data->use_riwt = 1;
+      rx_desc_data->rx_coal_frames = DWC_ETH_QOS_RX_MAX_FRAMES;
+      rx_desc_data->rx_riwt =
+         DWC_ETH_QOS_usec2riwt(DWC_ETH_QOS_OPTIMAL_DMA_RIWT_USEC, pdata);
+   }
+
+   DBGPR("<--DWC_ETH_QOS_init_rx_coalesce\n");
 }
 
 /*!
@@ -5760,14 +5847,14 @@ void DWC_ETH_QOS_init_rx_coalesce(struct
  */
 static void DWC_ETH_QOS_mmc_setup(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	DBGPR("-->DWC_ETH_QOS_mmc_setup\n");
-
-	if (pdata->hw_feat.mmc_sel) {
-		memset(&pdata->mmc, 0, sizeof(struct DWC_ETH_QOS_mmc_counters));
-	} else
-		printk(KERN_ALERT "No MMC/RMON module available in the HW\n");
-
-	DBGPR("<--DWC_ETH_QOS_mmc_setup\n");
+   DBGPR("-->DWC_ETH_QOS_mmc_setup\n");
+
+   if (pdata->hw_feat.mmc_sel) {
+      memset(&pdata->mmc, 0, sizeof(struct DWC_ETH_QOS_mmc_counters));
+   } else
+      printk(KERN_ALERT "No MMC/RMON module available in the HW\n");
+
+   DBGPR("<--DWC_ETH_QOS_mmc_setup\n");
 }
 
 /*!
@@ -5787,144 +5874,166 @@ static void DWC_ETH_QOS_mmc_setup(struct
  */
 void DWC_ETH_QOS_mmc_read(struct DWC_ETH_QOS_mmc_counters *mmc)
 {
-	DBGPR("-->DWC_ETH_QOS_mmc_read\n");
-
-	/* MMC TX counter registers */
-	mmc->mmc_tx_octetcount_gb += DWC_REG_RD(MMC_TX_OCTETS);
-	mmc->mmc_tx_framecount_gb += DWC_REG_RD(MMC_TX_PKTS);
-	mmc->mmc_tx_broadcastframe_g += DWC_REG_RD(MMC_TX_BROADCAST_GOOD);
-	mmc->mmc_tx_multicastframe_g += DWC_REG_RD(MMC_TX_MULTICAST_GOOD);
-	mmc->mmc_tx_64_octets_gb += DWC_REG_RD(MMC_TX_64_OCTETS);
-	mmc->mmc_tx_65_to_127_octets_gb += DWC_REG_RD(MMC_TX_65TO127_OCTETS);
-	mmc->mmc_tx_128_to_255_octets_gb += DWC_REG_RD(MMC_TX_128TO255_OCTETS);
-	mmc->mmc_tx_256_to_511_octets_gb += DWC_REG_RD(MMC_TX_256TO511_OCTETS);
-	mmc->mmc_tx_512_to_1023_octets_gb += DWC_REG_RD(MMC_TX_512TO1023_OCTETS);
-	mmc->mmc_tx_1024_to_max_octets_gb += DWC_REG_RD(MMC_TX_1024TOMAX_OCTETS);
-	mmc->mmc_tx_unicast_gb += DWC_REG_RD(MMC_TX_UNICAST);
-	mmc->mmc_tx_multicast_gb += DWC_REG_RD(MMC_TX_MULTICAST);
-	mmc->mmc_tx_broadcast_gb += DWC_REG_RD(MMC_TX_BROADCAST);
-	mmc->mmc_tx_underflow_error += DWC_REG_RD(MMC_TX_UNDERFLOW_ERROR);
-	mmc->mmc_tx_singlecol_g += DWC_REG_RD(MMC_TX_SINGLE_COLLISION);
-	mmc->mmc_tx_multicol_g += DWC_REG_RD(MMC_TX_MULTI_COLLISION);
-	mmc->mmc_tx_deferred += DWC_REG_RD(MMC_TX_DEFERRED);
-	mmc->mmc_tx_latecol += DWC_REG_RD(MMC_TX_LATE_COLLISION);
-	mmc->mmc_tx_exesscol += DWC_REG_RD(MMC_TX_EXCESS_COLLISION);
-	mmc->mmc_tx_carrier_error += DWC_REG_RD(MMC_TX_CARRIER_ERROR);
-	mmc->mmc_tx_octetcount_g += DWC_REG_RD(MMC_TX_OCTETS_GOOD);
-	mmc->mmc_tx_framecount_g += DWC_REG_RD(MMC_TX_PKTS_GOOD);
-	mmc->mmc_tx_excessdef += DWC_REG_RD(MMC_TX_EXCESS_DEFERRAL_ERR);
-	mmc->mmc_tx_pause_frame += DWC_REG_RD(MMC_TX_PAUSE_PKTS);
-	mmc->mmc_tx_vlan_frame_g += DWC_REG_RD(MMC_TX_VLAN_PKTS);
-	mmc->mmc_tx_osize_frame_g += DWC_REG_RD(MMC_TX_OVERSIZE_PKTS);
-
-	/* MMC RX counter registers */
-	mmc->mmc_rx_framecount_gb += DWC_REG_RD(MMC_RX_PKTS);
-	mmc->mmc_rx_octetcount_gb += DWC_REG_RD(MMC_RX_OCTETS);
-	mmc->mmc_rx_octetcount_g += DWC_REG_RD(MMC_RX_OCTET_GOOD);
-	mmc->mmc_rx_broadcastframe_g += DWC_REG_RD(MMC_RX_BROADCAST_GOOD);
-	mmc->mmc_rx_multicastframe_g += DWC_REG_RD(MMC_RX_MULTICAST_GOOD);
-	mmc->mmc_rx_crc_errror += DWC_REG_RD(MMC_RX_CRC_ERROR);
-	mmc->mmc_rx_align_error += DWC_REG_RD(MMC_RX_ALIGN_ERROR);
-	mmc->mmc_rx_run_error += DWC_REG_RD(MMC_RX_RUNT_ERROR);
-	mmc->mmc_rx_jabber_error += DWC_REG_RD(MMC_RX_JABBER_ERROR);
-	mmc->mmc_rx_undersize_g += DWC_REG_RD(MMC_RX_UNDERSIZE_PKTS);
-	mmc->mmc_rx_oversize_g += DWC_REG_RD(MMC_RX_OVERSIZE_PKTS);
-	mmc->mmc_rx_64_octets_gb += DWC_REG_RD(MMC_RX_64_OCTETS);
-	mmc->mmc_rx_65_to_127_octets_gb += DWC_REG_RD(MMC_RX_65TO127_OCTETS);
-	mmc->mmc_rx_128_to_255_octets_gb += DWC_REG_RD(MMC_RX_128TO255_OCTETS);
-	mmc->mmc_rx_256_to_511_octets_gb += DWC_REG_RD(MMC_RX_256TO511_OCTETS);
-	mmc->mmc_rx_512_to_1023_octets_gb += DWC_REG_RD(MMC_RX_512TO1023_OCTETS);
-	mmc->mmc_rx_1024_to_max_octets_gb += DWC_REG_RD(MMC_RX_1024TOMAX_OCTETS);
-	mmc->mmc_rx_unicast_g += DWC_REG_RD(MMC_RX_UNICAST_GOOD);
-	mmc->mmc_rx_length_error += DWC_REG_RD(MMC_RX_LENGTH_ERROR);
-	mmc->mmc_rx_outofrangetype += DWC_REG_RD(MMC_RX_OUT_RANGE_TYPE);
-	mmc->mmc_rx_pause_frames += DWC_REG_RD(MMC_RX_PAUSE_PKTS);
-	mmc->mmc_rx_fifo_overflow += DWC_REG_RD(MMC_RX_FIFO_OVERFLOW);
-	mmc->mmc_rx_vlan_frames_gb += DWC_REG_RD(MMC_RX_VLAN_PKTS);
-	mmc->mmc_rx_watchdog_error += DWC_REG_RD(MMC_RX_WATCHDOG_ERROR);
-	mmc->mmc_rx_receive_error += DWC_REG_RD(MMC_RX_RECEIVE_ERROR);
-	mmc->mmc_rx_ctrl_frames_g += DWC_REG_RD(MMC_RX_CONTROL_PKTS);
-
-	/* IPC */
-	mmc->mmc_rx_ipc_intr_mask = DWC_REG_RD(MMC_IPC_RX_IMR);
-	mmc->mmc_rx_ipc_intr = DWC_REG_RD(MMC_IPC_RX_IR);
-
-	/* IPv4 */
-	mmc->mmc_rx_ipv4_gd += DWC_REG_RD(MMC_RX_IPV4_GOOD_PKTS);
-	mmc->mmc_rx_ipv4_hderr += DWC_REG_RD(MMC_RX_IPV4_HEADER_ERROR_PKTS);
-	mmc->mmc_rx_ipv4_nopay += DWC_REG_RD(MMC_RX_IPV4_NO_PAYLOAD_PKTS);
-	mmc->mmc_rx_ipv4_frag += DWC_REG_RD(MMC_RX_IPV4_FRAGMENTED_PKTS);
-	mmc->mmc_rx_ipv4_udsbl += DWC_REG_RD(MMC_RX_IPV4_UDP_CSUM_DIS_PKTS);
-
-	/* IPV6 */
-	mmc->mmc_rx_ipv6_gd += DWC_REG_RD(MMC_RX_IPV6_GOOD_PKTS);
-	mmc->mmc_rx_ipv6_hderr += DWC_REG_RD(MMC_RX_IPV6_HEADER_ERROR_PKTS);
-	mmc->mmc_rx_ipv6_nopay += DWC_REG_RD(MMC_RX_IPV6_NO_PAYLOAD_PKTS);
-
-	/* Protocols */
-	mmc->mmc_rx_udp_gd += DWC_REG_RD(MMC_RX_UDP_GOOD_PKTS);
-	mmc->mmc_rx_udp_err += DWC_REG_RD(MMC_RX_UDP_ERROR_PKTS);
-	mmc->mmc_rx_tcp_gd += DWC_REG_RD(MMC_RX_TCP_GOOD_PKTS);
-	mmc->mmc_rx_tcp_err += DWC_REG_RD(MMC_RX_TCP_ERROR_PKTS);
-	mmc->mmc_rx_icmp_gd += DWC_REG_RD(MMC_RX_ICMP_GOOD_PKTS);
-	mmc->mmc_rx_icmp_err += DWC_REG_RD(MMC_RX_ICMP_ERROR_PKTS);
-
-	/* IPv4 */
-	mmc->mmc_rx_ipv4_gd_octets += DWC_REG_RD(MMC_RX_IPV4_GOOD_OCTETS);
-	mmc->mmc_rx_ipv4_hderr_octets += DWC_REG_RD(MMC_RX_IPV4_ERROR_OCTETS);
-	mmc->mmc_rx_ipv4_nopay_octets += DWC_REG_RD(MMC_RX_IPV4_NO_PAYLOAD_OCTETS);
-	mmc->mmc_rx_ipv4_frag_octets += DWC_REG_RD(MMC_RX_IPV4_FRAGMENTED_OCTETS);
-	mmc->mmc_rx_ipv4_udsbl_octets += DWC_REG_RD(MMC_RX_IPV4_UDP_CSUM_DIS_OCTETS);
-
-	/* IPV6 */
-	mmc->mmc_rx_ipv6_gd_octets += DWC_REG_RD(MMC_RX_IPV6_GOOD_OCTETS);
-	mmc->mmc_rx_ipv6_hderr_octets += DWC_REG_RD(MMC_RX_IPV6_HEADER_ERROR_OCTETS);
-	mmc->mmc_rx_ipv6_nopay_octets += DWC_REG_RD(MMC_RX_IPV6_NO_PAYLOAD_OCTETS);
-
-	/* Protocols */
-	mmc->mmc_rx_udp_gd_octets += DWC_REG_RD(MMC_RX_UDP_GOOD_OCTETS);
-	mmc->mmc_rx_udp_err_octets += DWC_REG_RD(MMC_RX_UDP_ERROR_OCTETS);
-	mmc->mmc_rx_tcp_gd_octets += DWC_REG_RD(MMC_RX_TCP_GOOD_OCTETS);
-	mmc->mmc_rx_tcp_err_octets += DWC_REG_RD(MMC_RX_TCP_ERROR_OCTETS);
-	mmc->mmc_rx_icmp_gd_octets += DWC_REG_RD(MMC_RX_ICMP_GOOD_OCTETS);
-	mmc->mmc_rx_icmp_err_octets += DWC_REG_RD(MMC_RX_ICMP_ERROR_OCTETS);
-
-	DBGPR("<--DWC_ETH_QOS_mmc_read\n");
+   DBGPR("-->DWC_ETH_QOS_mmc_read\n");
+
+   /* MMC TX counter registers */
+   mmc->mmc_tx_octetcount_gb += DWC_REG_RD(MMC_TX_OCTETS);
+   mmc->mmc_tx_framecount_gb += DWC_REG_RD(MMC_TX_PKTS);
+   mmc->mmc_tx_broadcastframe_g += DWC_REG_RD(MMC_TX_BROADCAST_GOOD);
+   mmc->mmc_tx_multicastframe_g += DWC_REG_RD(MMC_TX_MULTICAST_GOOD);
+   mmc->mmc_tx_64_octets_gb += DWC_REG_RD(MMC_TX_64_OCTETS);
+   mmc->mmc_tx_65_to_127_octets_gb += DWC_REG_RD(MMC_TX_65TO127_OCTETS);
+   mmc->mmc_tx_128_to_255_octets_gb += DWC_REG_RD(MMC_TX_128TO255_OCTETS);
+   mmc->mmc_tx_256_to_511_octets_gb += DWC_REG_RD(MMC_TX_256TO511_OCTETS);
+   mmc->mmc_tx_512_to_1023_octets_gb += DWC_REG_RD(MMC_TX_512TO1023_OCTETS);
+   mmc->mmc_tx_1024_to_max_octets_gb += DWC_REG_RD(MMC_TX_1024TOMAX_OCTETS);
+   mmc->mmc_tx_unicast_gb += DWC_REG_RD(MMC_TX_UNICAST);
+   mmc->mmc_tx_multicast_gb += DWC_REG_RD(MMC_TX_MULTICAST);
+   mmc->mmc_tx_broadcast_gb += DWC_REG_RD(MMC_TX_BROADCAST);
+   mmc->mmc_tx_underflow_error += DWC_REG_RD(MMC_TX_UNDERFLOW_ERROR);
+   mmc->mmc_tx_singlecol_g += DWC_REG_RD(MMC_TX_SINGLE_COLLISION);
+   mmc->mmc_tx_multicol_g += DWC_REG_RD(MMC_TX_MULTI_COLLISION);
+   mmc->mmc_tx_deferred += DWC_REG_RD(MMC_TX_DEFERRED);
+   mmc->mmc_tx_latecol += DWC_REG_RD(MMC_TX_LATE_COLLISION);
+   mmc->mmc_tx_exesscol += DWC_REG_RD(MMC_TX_EXCESS_COLLISION);
+   mmc->mmc_tx_carrier_error += DWC_REG_RD(MMC_TX_CARRIER_ERROR);
+   mmc->mmc_tx_octetcount_g += DWC_REG_RD(MMC_TX_OCTETS_GOOD);
+   mmc->mmc_tx_framecount_g += DWC_REG_RD(MMC_TX_PKTS_GOOD);
+   mmc->mmc_tx_excessdef += DWC_REG_RD(MMC_TX_EXCESS_DEFERRAL_ERR);
+   mmc->mmc_tx_pause_frame += DWC_REG_RD(MMC_TX_PAUSE_PKTS);
+   mmc->mmc_tx_vlan_frame_g += DWC_REG_RD(MMC_TX_VLAN_PKTS);
+   mmc->mmc_tx_osize_frame_g += DWC_REG_RD(MMC_TX_OVERSIZE_PKTS);
+
+   /* MMC RX counter registers */
+   mmc->mmc_rx_framecount_gb += DWC_REG_RD(MMC_RX_PKTS);
+   mmc->mmc_rx_octetcount_gb += DWC_REG_RD(MMC_RX_OCTETS);
+   mmc->mmc_rx_octetcount_g += DWC_REG_RD(MMC_RX_OCTET_GOOD);
+   mmc->mmc_rx_broadcastframe_g += DWC_REG_RD(MMC_RX_BROADCAST_GOOD);
+   mmc->mmc_rx_multicastframe_g += DWC_REG_RD(MMC_RX_MULTICAST_GOOD);
+   mmc->mmc_rx_crc_errror += DWC_REG_RD(MMC_RX_CRC_ERROR);
+   mmc->mmc_rx_align_error += DWC_REG_RD(MMC_RX_ALIGN_ERROR);
+   mmc->mmc_rx_run_error += DWC_REG_RD(MMC_RX_RUNT_ERROR);
+   mmc->mmc_rx_jabber_error += DWC_REG_RD(MMC_RX_JABBER_ERROR);
+   mmc->mmc_rx_undersize_g += DWC_REG_RD(MMC_RX_UNDERSIZE_PKTS);
+   mmc->mmc_rx_oversize_g += DWC_REG_RD(MMC_RX_OVERSIZE_PKTS);
+   mmc->mmc_rx_64_octets_gb += DWC_REG_RD(MMC_RX_64_OCTETS);
+   mmc->mmc_rx_65_to_127_octets_gb += DWC_REG_RD(MMC_RX_65TO127_OCTETS);
+   mmc->mmc_rx_128_to_255_octets_gb += DWC_REG_RD(MMC_RX_128TO255_OCTETS);
+   mmc->mmc_rx_256_to_511_octets_gb += DWC_REG_RD(MMC_RX_256TO511_OCTETS);
+   mmc->mmc_rx_512_to_1023_octets_gb += DWC_REG_RD(MMC_RX_512TO1023_OCTETS);
+   mmc->mmc_rx_1024_to_max_octets_gb += DWC_REG_RD(MMC_RX_1024TOMAX_OCTETS);
+   mmc->mmc_rx_unicast_g += DWC_REG_RD(MMC_RX_UNICAST_GOOD);
+   mmc->mmc_rx_length_error += DWC_REG_RD(MMC_RX_LENGTH_ERROR);
+   mmc->mmc_rx_outofrangetype += DWC_REG_RD(MMC_RX_OUT_RANGE_TYPE);
+   mmc->mmc_rx_pause_frames += DWC_REG_RD(MMC_RX_PAUSE_PKTS);
+   mmc->mmc_rx_fifo_overflow += DWC_REG_RD(MMC_RX_FIFO_OVERFLOW);
+   mmc->mmc_rx_vlan_frames_gb += DWC_REG_RD(MMC_RX_VLAN_PKTS);
+   mmc->mmc_rx_watchdog_error += DWC_REG_RD(MMC_RX_WATCHDOG_ERROR);
+   mmc->mmc_rx_receive_error += DWC_REG_RD(MMC_RX_RECEIVE_ERROR);
+   mmc->mmc_rx_ctrl_frames_g += DWC_REG_RD(MMC_RX_CONTROL_PKTS);
+
+   /* IPC */
+   mmc->mmc_rx_ipc_intr_mask = DWC_REG_RD(MMC_IPC_RX_IMR);
+   mmc->mmc_rx_ipc_intr = DWC_REG_RD(MMC_IPC_RX_IR);
+
+   /* IPv4 */
+   mmc->mmc_rx_ipv4_gd += DWC_REG_RD(MMC_RX_IPV4_GOOD_PKTS);
+   mmc->mmc_rx_ipv4_hderr += DWC_REG_RD(MMC_RX_IPV4_HEADER_ERROR_PKTS);
+   mmc->mmc_rx_ipv4_nopay += DWC_REG_RD(MMC_RX_IPV4_NO_PAYLOAD_PKTS);
+   mmc->mmc_rx_ipv4_frag += DWC_REG_RD(MMC_RX_IPV4_FRAGMENTED_PKTS);
+   mmc->mmc_rx_ipv4_udsbl += DWC_REG_RD(MMC_RX_IPV4_UDP_CSUM_DIS_PKTS);
+
+   /* IPV6 */
+   mmc->mmc_rx_ipv6_gd += DWC_REG_RD(MMC_RX_IPV6_GOOD_PKTS);
+   mmc->mmc_rx_ipv6_hderr += DWC_REG_RD(MMC_RX_IPV6_HEADER_ERROR_PKTS);
+   mmc->mmc_rx_ipv6_nopay += DWC_REG_RD(MMC_RX_IPV6_NO_PAYLOAD_PKTS);
+
+   /* Protocols */
+   mmc->mmc_rx_udp_gd += DWC_REG_RD(MMC_RX_UDP_GOOD_PKTS);
+   mmc->mmc_rx_udp_err += DWC_REG_RD(MMC_RX_UDP_ERROR_PKTS);
+   mmc->mmc_rx_tcp_gd += DWC_REG_RD(MMC_RX_TCP_GOOD_PKTS);
+   mmc->mmc_rx_tcp_err += DWC_REG_RD(MMC_RX_TCP_ERROR_PKTS);
+   mmc->mmc_rx_icmp_gd += DWC_REG_RD(MMC_RX_ICMP_GOOD_PKTS);
+   mmc->mmc_rx_icmp_err += DWC_REG_RD(MMC_RX_ICMP_ERROR_PKTS);
+
+   /* IPv4 */
+   mmc->mmc_rx_ipv4_gd_octets += DWC_REG_RD(MMC_RX_IPV4_GOOD_OCTETS);
+   mmc->mmc_rx_ipv4_hderr_octets += DWC_REG_RD(MMC_RX_IPV4_ERROR_OCTETS);
+   mmc->mmc_rx_ipv4_nopay_octets += DWC_REG_RD(MMC_RX_IPV4_NO_PAYLOAD_OCTETS);
+   mmc->mmc_rx_ipv4_frag_octets += DWC_REG_RD(MMC_RX_IPV4_FRAGMENTED_OCTETS);
+   mmc->mmc_rx_ipv4_udsbl_octets += DWC_REG_RD(MMC_RX_IPV4_UDP_CSUM_DIS_OCTETS);
+
+   /* IPV6 */
+   mmc->mmc_rx_ipv6_gd_octets += DWC_REG_RD(MMC_RX_IPV6_GOOD_OCTETS);
+   mmc->mmc_rx_ipv6_hderr_octets += DWC_REG_RD(MMC_RX_IPV6_HEADER_ERROR_OCTETS);
+   mmc->mmc_rx_ipv6_nopay_octets += DWC_REG_RD(MMC_RX_IPV6_NO_PAYLOAD_OCTETS);
+
+   /* Protocols */
+   mmc->mmc_rx_udp_gd_octets += DWC_REG_RD(MMC_RX_UDP_GOOD_OCTETS);
+   mmc->mmc_rx_udp_err_octets += DWC_REG_RD(MMC_RX_UDP_ERROR_OCTETS);
+   mmc->mmc_rx_tcp_gd_octets += DWC_REG_RD(MMC_RX_TCP_GOOD_OCTETS);
+   mmc->mmc_rx_tcp_err_octets += DWC_REG_RD(MMC_RX_TCP_ERROR_OCTETS);
+   mmc->mmc_rx_icmp_gd_octets += DWC_REG_RD(MMC_RX_ICMP_GOOD_OCTETS);
+   mmc->mmc_rx_icmp_err_octets += DWC_REG_RD(MMC_RX_ICMP_ERROR_OCTETS);
+
+   DBGPR("<--DWC_ETH_QOS_mmc_read\n");
 }
 
 phy_interface_t DWC_ETH_QOS_get_phy_interface(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	phy_interface_t ret = PHY_INTERFACE_MODE_MII;
-
-	DBGPR("-->DWC_ETH_QOS_get_phy_interface\n");
-
-	if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_GMII_MII) {
-		if (pdata->hw_feat.gmii_sel)
-			ret = PHY_INTERFACE_MODE_GMII;
-		else if (pdata->hw_feat.mii_sel)
-			ret = PHY_INTERFACE_MODE_MII;
-	} else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_RGMII) {
-		ret = PHY_INTERFACE_MODE_RGMII;
-	} else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_SGMII) {
-		ret = PHY_INTERFACE_MODE_SGMII;
-	} else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_TBI) {
-		ret = PHY_INTERFACE_MODE_TBI;
-	} else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_RMII) {
-		ret = PHY_INTERFACE_MODE_RMII;
-	} else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_RTBI) {
-		ret = PHY_INTERFACE_MODE_RTBI;
-	} else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_SMII) {
-		ret = PHY_INTERFACE_MODE_SMII;
-	} else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_RevMII) {
-		//what to return ?
-	} else {
-		printk(KERN_ALERT "Missing interface support between"\
-		    "PHY and MAC\n\n");
-		ret = PHY_INTERFACE_MODE_NA;
-	}
-
-	DBGPR("<--DWC_ETH_QOS_get_phy_interface\n");
-
-	return ret;
+   phy_interface_t ret = PHY_INTERFACE_MODE_MII;
+
+   DBGPR("-->DWC_ETH_QOS_get_phy_interface\n");
+
+   if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_GMII_MII) {
+      if (pdata->hw_feat.gmii_sel)
+         ret = PHY_INTERFACE_MODE_GMII;
+      else if (pdata->hw_feat.mii_sel)
+         ret = PHY_INTERFACE_MODE_MII;
+   } else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_RGMII) {
+      ret = PHY_INTERFACE_MODE_RGMII;
+   } else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_SGMII) {
+      ret = PHY_INTERFACE_MODE_SGMII;
+   } else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_TBI) {
+      ret = PHY_INTERFACE_MODE_TBI;
+   } else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_RMII) {
+      ret = PHY_INTERFACE_MODE_RMII;
+   } else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_RTBI) {
+      ret = PHY_INTERFACE_MODE_RTBI;
+   } else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_SMII) {
+      ret = PHY_INTERFACE_MODE_SMII;
+   } else if (pdata->hw_feat.act_phy_sel == DWC_ETH_QOS_RevMII) {
+      //what to return ?
+   } else {
+      printk(KERN_ALERT "Missing interface support between"\
+          "PHY and MAC\n\n");
+      ret = PHY_INTERFACE_MODE_NA;
+   }
+
+   DBGPR("<--DWC_ETH_QOS_get_phy_interface\n");
+
+   return ret;
 }
 
+uint32_t gbe_config_to_speed(uint32_t config)
+{
+   uint32_t speed = 0;
+   switch(config) {
+      case GBE_GCR5_PHY_SPEED_10M:
+         speed = 10;
+      break;
+      case GBE_GCR5_PHY_SPEED_100M:
+         speed = 100;
+      break;
+      case GBE_GCR5_PHY_SPEED_1G:
+         speed = 1000;
+      break;
+      case GBE_GCR5_PHY_SPEED_2_5G:
+         speed = 2500;
+      break;
+      case GBE_GCR5_PHY_SPEED_5G:
+         speed = 5000;
+      break;
+   }
+   return speed;
+}
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_eee.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_eee.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_eee.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_eee.c
@@ -60,7 +60,7 @@
 void DWC_ETH_QOS_enable_eee_mode(struct DWC_ETH_QOS_prv_data *pdata)
 {
 	struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data = NULL;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	int tx_idle = 0, qInx;
 
 	DBGPR_EEE("-->DWC_ETH_QOS_enable_eee_mode\n");
@@ -85,7 +85,7 @@ void DWC_ETH_QOS_enable_eee_mode(struct 
 
 void DWC_ETH_QOS_disable_eee_mode(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 
 	DBGPR_EEE("-->DWC_ETH_QOS_disable_eee_mode\n");
 
@@ -373,7 +373,7 @@ static int DWC_ETH_QOS_phy_init_eee(stru
 */
 bool DWC_ETH_QOS_eee_init(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	bool ret = false;
 
 	DBGPR_EEE("-->DWC_ETH_QOS_eee_init\n");
@@ -427,7 +427,7 @@ bool DWC_ETH_QOS_eee_init(struct DWC_ETH
 #define MAC_LPS_RLPIEX 0x00000008
 void DWC_ETH_QOS_handle_eee_interrupt(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	uint32_t lpi_status;
 
 	DBGPR_EEE("-->DWC_ETH_QOS_handle_eee_interrupt\n");
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_ethtool.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_ethtool.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_ethtool.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_ethtool.c
@@ -293,7 +293,7 @@ static void DWC_ETH_QOS_get_pauseparam(s
 				       struct ethtool_pauseparam *pause)
 {
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	struct phy_device *phydev = pdata->phydev;
 	unsigned int data;
 
@@ -343,7 +343,7 @@ static int DWC_ETH_QOS_set_pauseparam(st
 				      struct ethtool_pauseparam *pause)
 {
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	struct phy_device *phydev = pdata->phydev;
 	int new_pause = DWC_ETH_QOS_FLOW_CTRL_OFF;
 	unsigned int data;
@@ -393,7 +393,7 @@ static int DWC_ETH_QOS_set_pauseparam(st
 
 void DWC_ETH_QOS_configure_flow_ctrl(struct DWC_ETH_QOS_prv_data *pdata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	uint32_t qInx;
 
 	DBGPR("-->DWC_ETH_QOS_configure_flow_ctrl\n");
@@ -440,7 +440,7 @@ static int DWC_ETH_QOS_getsettings(struc
 				   struct ethtool_cmd *cmd)
 {
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	unsigned int pause, duplex;
 	unsigned int lp_pause, lp_duplex;
 	int ret = 0;
@@ -545,7 +545,7 @@ static int DWC_ETH_QOS_setsettings(struc
 				   struct ethtool_cmd *cmd)
 {
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	unsigned int speed;
 	//unsigned int pause, duplex, speed;
 	//unsigned int lp_pause, lp_duplex;
@@ -765,7 +765,7 @@ static int DWC_ETH_QOS_set_coalesce(stru
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
 	struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data =
 	    GET_RX_WRAPPER_DESC(0);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	unsigned int rx_riwt, rx_usec, local_use_riwt, qInx;
 
 	DBGPR("-->DWC_ETH_QOS_set_coalesce\n");
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_mdio.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_mdio.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_mdio.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_mdio.c
@@ -80,7 +80,7 @@ EXPORT_SYMBOL(DWC_ETH_QOS_mdio_write_ext
 int DWC_ETH_QOS_mdio_read_direct(struct DWC_ETH_QOS_prv_data *pdata,
 				 int phyaddr, int phyreg, int *phydata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	int phy_reg_read_status;
 
 	DBGPR_MDIO("--> DWC_ETH_QOS_mdio_read_direct\n");
@@ -120,7 +120,7 @@ int DWC_ETH_QOS_mdio_read_direct(struct 
 int DWC_ETH_QOS_mdio_write_direct(struct DWC_ETH_QOS_prv_data *pdata,
 				  int phyaddr, int phyreg, int phydata)
 {
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	int phy_reg_write_status;
 
 	DBGPR_MDIO("--> DWC_ETH_QOS_mdio_write_direct\n");
@@ -158,7 +158,7 @@ static int DWC_ETH_QOS_mdio_read(struct 
 {
 	struct net_device *dev = bus->priv;
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	int phydata;
 
 	DBGPR_MDIO("--> DWC_ETH_QOS_mdio_read: phyaddr = %d, phyreg = %d\n",
@@ -196,7 +196,7 @@ static int DWC_ETH_QOS_mdio_write(struct
 {
 	struct net_device *dev = bus->priv;
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	int ret = Y_SUCCESS;
 
 	DBGPR_MDIO("--> DWC_ETH_QOS_mdio_write\n");
@@ -230,7 +230,7 @@ static int DWC_ETH_QOS_mdio_reset(struct
 {
 	struct net_device *dev = bus->priv;
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	uint32_t phydata;
 
 	DBGPR_MDIO("-->DWC_ETH_QOS_mdio_reset: phyaddr : %d\n", pdata->phyaddr);
@@ -367,7 +367,7 @@ void dump_phy_registers(struct DWC_ETH_Q
 static void DWC_ETH_QOS_adjust_link(struct net_device *dev)
 {
 	struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	struct phy_device *phydev = pdata->phydev;
 	unsigned long flags;
 	int new_state = 0;
@@ -508,9 +508,7 @@ static int DWC_ETH_QOS_init_phy(struct n
 		phydev->supported = PHY_BASIC_FEATURES;
 	}
 
-#ifndef DWC_ETH_QOS_CONFIG_PGTEST
 	phydev->supported |= (SUPPORTED_Pause | SUPPORTED_Asym_Pause);
-#endif
 
 	phydev->advertising = phydev->supported;
 
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pci.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pci.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pci.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pci.c
@@ -33,10 +33,9 @@
  * @brief: Driver functions.
  */
 
+#include <linux/netip_subsystem.h>
 #include "DWC_ETH_QOS_yheader.h"
-#include "DWC_ETH_QOS_pci.h"
 #include "DWC_ETH_QOS_yregacc.h"
-#include <linux/netip_subsystem.h>
 
 /**
    Assuming an average packet size of 1522 bytes the total
@@ -51,7 +50,7 @@ static uint8_t dev_addr[6] = {0, 0x55, 0
 uint32_t dwc_eth_qos_pci_base_addr;
 bool config_prints = false;
 static bool msi_mode = true;
-static bool tso_enable = false;
+static bool tso_enable = true;
 /* Enabling only one queue by default because MAC sends
    most of the traffic to MTL FIFO 0. */
 static short num_of_queues = 1;
@@ -73,20 +72,82 @@ bool print_desc = false;
 uint metadata_on_crc = 0;
 uint mss_for_tso = 0;
 
-module_param(print_tx_pkts, bool, S_IRUGO);
+module_param(print_tx_pkts, bool, 0644);
 MODULE_PARM_DESC(print_tx_pkts, "Dump Tx packets");
-module_param(print_rx_pkts, bool, S_IRUGO);
+module_param(print_rx_pkts, bool, 0644);
 MODULE_PARM_DESC(print_rx_pkts, "Dump Rx packets");
-module_param(print_desc, bool, S_IRUGO);
+module_param(print_desc, bool, 0644);
 MODULE_PARM_DESC(print_desc, "Print Tx descriptors");
-module_param(metadata_on_crc, uint, S_IRUGO);
+module_param(metadata_on_crc, uint, 0644);
 MODULE_PARM_DESC(metadata_on_crc, "Test metadata on CRC");
-module_param(mss_for_tso, uint, S_IRUGO);
+module_param(mss_for_tso, uint, 0644);
 MODULE_PARM_DESC(mss_for_tso, "MSS value to test TSO");
 
+static ssize_t gbe_dbg_show(struct device *dev,
+   struct device_attribute *attr, char *buf)
+{
+   struct DWC_ETH_QOS_prv_data *pdata = NULL;
+   struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data = NULL;
+   struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data = NULL;
+   tx_descriptor_t *tx_desc = NULL;
+   rx_descriptor_t *rx_desc = NULL;
+   uint32_t qInx = 0, i, j;
+   char *st = buf;
+   pdata = container_of(attr, struct DWC_ETH_QOS_prv_data, debug_attr);
+   for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
+      buf += sprintf(buf, "---------------------------------------\n");
+      tx_desc_data = GET_TX_WRAPPER_DESC(qInx);
+      buf += sprintf(buf, "[%u]cur_tx        = %d\n", qInx, tx_desc_data->cur_tx);
+      buf += sprintf(buf, "[%u]dirty_tx      = %d\n", qInx, tx_desc_data->dirty_tx);
+      buf += sprintf(buf, "[%u]free_desc_cnt = %d\n", qInx, tx_desc_data->free_desc_cnt);
+      buf += sprintf(buf, "[%u]queue_stopped = %d\n", qInx, tx_desc_data->queue_stopped);
+      buf += sprintf(buf, "[%u]tx_pkt_queued = %d\n", qInx, tx_desc_data->tx_pkt_queued);
+      i = tx_desc_data->dirty_tx;
+      DECR_TX_DESC_INDEX(i);
+      j = tx_desc_data->cur_tx;
+      INCR_TX_DESC_INDEX(j, 1);
+      while(i != j) {
+         tx_desc = GET_TX_DESC_PTR(qInx, i);
+         buf += sprintf(buf, "[%u:%u] 0x%08x:0x%08x:0x%08x:0x%08x\n", qInx, i,
+            tx_desc->TDES0, tx_desc->TDES1, tx_desc->TDES2, tx_desc->TDES3);
+         INCR_TX_DESC_INDEX(i, 1);
+      }
+      buf += sprintf(buf, "---------------------------------------\n");
+      rx_desc_data = GET_RX_WRAPPER_DESC(qInx);
+      buf += sprintf(buf, "[%u]cur_rx        = %d\n", qInx, rx_desc_data->cur_rx);
+      buf += sprintf(buf, "[%u]dirty_rx      = %d\n", qInx, rx_desc_data->dirty_rx);
+      buf += sprintf(buf, "[%u]pkt_received = %d\n", qInx, rx_desc_data->pkt_received);
+
+      i = rx_desc_data->cur_rx;
+      rx_desc = GET_RX_DESC_PTR(qInx, i);
+      while(!(rx_desc->RDES3 & DWC_ETH_QOS_RDESC3_OWN)) {
+         buf += sprintf(buf, "[%u:%u] 0x%08x:0x%08x:0x%08x:0x%08x\n", qInx, i,
+            rx_desc->RDES0, rx_desc->RDES1, rx_desc->RDES2, rx_desc->RDES3);
+         INCR_RX_DESC_INDEX(i, 1);
+         rx_desc = GET_RX_DESC_PTR(qInx, i);
+      }
+      buf += sprintf(buf, "---------------------------------------\n");
+   }
+   return (buf - st);
+}
+#ifdef DWC_ETH_NETSS_PM /* TE - netip support is missing for that */
+static int gbe_handle_suspend_resume(void *args, netss_power_state_t state);
+
+static ssize_t gbe_suspend_store(struct device *dev,
+   struct device_attribute *attr, const char *buf, size_t count)
+{
+   unsigned int value = simple_strtoul(buf, NULL, 0);
+   struct DWC_ETH_QOS_prv_data *pdata = NULL;
+   pdata = container_of(attr, struct DWC_ETH_QOS_prv_data, suspend_attr);
+   gbe_handle_suspend_resume(pdata, (value)?
+                                    NETSS_NETIP_POWER_STATE_OFF :
+                                    NETSS_NETIP_POWER_STATE_ACTIVE);
+   return count;
+}
+#endif
 #endif //GBE_DEBUG
 
-static int DWC_ETH_QOS_init_general_gbe(void __iomem **gbe_base,
+static int gbe_init_top_registers(void __iomem **gbe_base,
    unsigned int *mux_cfg)
 {
    int ret = 1;
@@ -167,7 +228,7 @@ static int DWC_ETH_QOS_init_general_gbe(
    return ret;
 }
 
-static void DWC_ETH_QOS_configure_IC(void __iomem *reg_base)
+static void gbe_configure_IC(void __iomem *reg_base)
 {
    // Enable GMAC5 hardware interrupts
    GBE_REG_WR_BIT(GBE_ATOM_HIE, GBE_ATOM_INTC, 0x1);
@@ -175,38 +236,15 @@ static void DWC_ETH_QOS_configure_IC(voi
    GBE_REG_WR_BIT(GBE_ATOM_ELS, GBE_ATOM_INTC, 0x1);
 }
 
-static uint32_t DWC_ETH_QOS_gbe_config_to_speed(uint32_t config)
-{
-   uint32_t speed = 0;
-   switch(config) {
-      case GBE_GCR5_PHY_SPEED_10M:
-         speed = 10;
-      break;
-      case GBE_GCR5_PHY_SPEED_100M:
-         speed = 100;
-      break;
-      case GBE_GCR5_PHY_SPEED_1G:
-         speed = 1000;
-      break;
-      case GBE_GCR5_PHY_SPEED_2_5G:
-         speed = 2500;
-      break;
-      case GBE_GCR5_PHY_SPEED_5G:
-         speed = 5000;
-      break;
-   }
-   return speed;
-}
-
-static ssize_t DWC_ETH_QOS_gbe_speed_show(struct device *dev,
+static ssize_t gbe_speed_show(struct device *dev,
    struct device_attribute *attr, char *buf)
 {
    struct DWC_ETH_QOS_prv_data *pdata = NULL;
    pdata = container_of(attr, struct DWC_ETH_QOS_prv_data, rate_attr);
-   return sprintf(buf, "%d\n", DWC_ETH_QOS_gbe_config_to_speed(pdata->rate));
+   return sprintf(buf, "%d\n", gbe_config_to_speed(pdata->rate));
 }
 
-static ssize_t DWC_ETH_QOS_gbe_speed_store(struct device *dev,
+static ssize_t gbe_speed_store(struct device *dev,
    struct device_attribute *attr, const char *buf, size_t count)
 {
    unsigned int value = simple_strtoul(buf, NULL, 0);
@@ -216,7 +254,7 @@ static ssize_t DWC_ETH_QOS_gbe_speed_sto
    return count;
 }
 
-static ssize_t DWC_ETH_QOS_gbe_stats_show(struct device *dev,
+static ssize_t gbe_stats_show(struct device *dev,
    struct device_attribute *attr, char *buf)
 {
    struct DWC_ETH_QOS_prv_data *pdata = NULL;
@@ -234,59 +272,7 @@ static ssize_t DWC_ETH_QOS_gbe_stats_sho
    return (buf - st);
 }
 
-#ifdef GBE_DEBUG
-
-static ssize_t DWC_ETH_QOS_gbe_dbg_show(struct device *dev,
-   struct device_attribute *attr, char *buf)
-{
-   struct DWC_ETH_QOS_prv_data *pdata = NULL;
-   struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data = NULL;
-   struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data = NULL;
-   tx_descriptor_t *tx_desc = NULL;
-   rx_descriptor_t *rx_desc = NULL;
-   uint32_t qInx = 0, i, j;
-   char *st = buf;
-   pdata = container_of(attr, struct DWC_ETH_QOS_prv_data, debug_attr);
-   for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
-      buf += sprintf(buf, "---------------------------------------\n");
-      tx_desc_data = GET_TX_WRAPPER_DESC(qInx);
-      buf += sprintf(buf, "[%u]cur_tx        = %d\n", qInx, tx_desc_data->cur_tx);
-      buf += sprintf(buf, "[%u]dirty_tx      = %d\n", qInx, tx_desc_data->dirty_tx);
-      buf += sprintf(buf, "[%u]free_desc_cnt = %d\n", qInx, tx_desc_data->free_desc_cnt);
-      buf += sprintf(buf, "[%u]queue_stopped = %d\n", qInx, tx_desc_data->queue_stopped);
-      buf += sprintf(buf, "[%u]tx_pkt_queued = %d\n", qInx, tx_desc_data->tx_pkt_queued);
-      i = tx_desc_data->dirty_tx;
-      DECR_TX_DESC_INDEX(i);
-      j = tx_desc_data->cur_tx;
-      INCR_TX_DESC_INDEX(j, 1);
-      while(i != j) {
-         tx_desc = GET_TX_DESC_PTR(qInx, i);
-         buf += sprintf(buf, "[%u:%u] 0x%08x:0x%08x:0x%08x:0x%08x\n", qInx, i,
-            tx_desc->TDES0, tx_desc->TDES1, tx_desc->TDES2, tx_desc->TDES3);
-         INCR_TX_DESC_INDEX(i, 1);
-      }
-      buf += sprintf(buf, "---------------------------------------\n");
-      rx_desc_data = GET_RX_WRAPPER_DESC(qInx);
-      buf += sprintf(buf, "[%u]cur_rx        = %d\n", qInx, rx_desc_data->cur_rx);
-      buf += sprintf(buf, "[%u]dirty_rx      = %d\n", qInx, rx_desc_data->dirty_rx);
-      buf += sprintf(buf, "[%u]pkt_received = %d\n", qInx, rx_desc_data->pkt_received);
-
-      i = rx_desc_data->cur_rx;
-      rx_desc = GET_RX_DESC_PTR(qInx, i);
-      while(!(rx_desc->RDES3 & DWC_ETH_QOS_RDESC3_OWN)) {
-         buf += sprintf(buf, "[%u:%u] 0x%08x:0x%08x:0x%08x:0x%08x\n", qInx, i,
-            rx_desc->RDES0, rx_desc->RDES1, rx_desc->RDES2, rx_desc->RDES3);
-         INCR_RX_DESC_INDEX(i, 1);
-         rx_desc = GET_RX_DESC_PTR(qInx, i);
-      }
-      buf += sprintf(buf, "---------------------------------------\n");
-   }
-   return (buf - st);
-}
-
-#endif
-
-static ssize_t DWC_ETH_QOS_gbe_itr_ips_show(struct device *dev,
+static ssize_t gbe_itr_ips_show(struct device *dev,
    struct device_attribute *attr, char *buf)
 {
    struct DWC_ETH_QOS_prv_data *pdata = NULL;
@@ -294,7 +280,7 @@ static ssize_t DWC_ETH_QOS_gbe_itr_ips_s
    return sprintf(buf, "%d\n", ONE_SEC_TO_NS/pdata->itr_latency);
 }
 
-static ssize_t DWC_ETH_QOS_gbe_itr_ips_store(struct device *dev,
+static ssize_t gbe_itr_ips_store(struct device *dev,
    struct device_attribute *attr, const char *buf, size_t count)
 {
    uint32_t max_ips = simple_strtoul(buf, NULL, 0);
@@ -304,12 +290,12 @@ static ssize_t DWC_ETH_QOS_gbe_itr_ips_s
    return count;
 }
 
-static void DWC_ETH_QOS_create_gbe_sysfs(struct DWC_ETH_QOS_prv_data *pdata)
+static void create_gbe_sysfs(struct DWC_ETH_QOS_prv_data *pdata)
 {
    struct device_attribute *dev_attr = &pdata->rate_attr;
    sysfs_attr_init(&dev_attr->attr);
-   dev_attr->show = DWC_ETH_QOS_gbe_speed_show;
-   dev_attr->store = DWC_ETH_QOS_gbe_speed_store;
+   dev_attr->show = gbe_speed_show;
+   dev_attr->store = gbe_speed_store;
    dev_attr->attr.mode = S_IRUGO | S_IWUSR;
    dev_attr->attr.name = "rate";
    if (device_create_file(&pdata->dev->dev, dev_attr)) {
@@ -317,7 +303,7 @@ static void DWC_ETH_QOS_create_gbe_sysfs
    }
    dev_attr = &pdata->stats_attr;
    sysfs_attr_init(&dev_attr->attr);
-   dev_attr->show = DWC_ETH_QOS_gbe_stats_show;
+   dev_attr->show = gbe_stats_show;
    dev_attr->store = NULL;
    dev_attr->attr.mode = S_IRUGO;
    dev_attr->attr.name = "stats";
@@ -327,18 +313,29 @@ static void DWC_ETH_QOS_create_gbe_sysfs
 #ifdef GBE_DEBUG
    dev_attr = &pdata->debug_attr;
    sysfs_attr_init(&dev_attr->attr);
-   dev_attr->show = DWC_ETH_QOS_gbe_dbg_show;
+   dev_attr->show = gbe_dbg_show;
    dev_attr->store = NULL;
    dev_attr->attr.mode = S_IRUGO;
    dev_attr->attr.name = "debug";
    if (device_create_file(&pdata->dev->dev, dev_attr)) {
       printk(KERN_ALERT "[GBE] Error creating debug sysfs attribute!\n");
    }
+#ifdef DWC_ETH_NETSS_PM /* TE - netip support is missing for that */
+   dev_attr = &pdata->suspend_attr;
+   sysfs_attr_init(&dev_attr->attr);
+   dev_attr->show = NULL;
+   dev_attr->store = gbe_suspend_store;
+   dev_attr->attr.mode = S_IWUSR;
+   dev_attr->attr.name = "suspend";
+   if (device_create_file(&pdata->dev->dev, dev_attr)) {
+      printk(KERN_ALERT "[GBE] Error creating suspend sysfs attribute!\n");
+   }
+#endif
 #endif
    dev_attr = &pdata->itr_lat_attr;
    sysfs_attr_init(&dev_attr->attr);
-   dev_attr->show = DWC_ETH_QOS_gbe_itr_ips_show;
-   dev_attr->store = DWC_ETH_QOS_gbe_itr_ips_store;
+   dev_attr->show = gbe_itr_ips_show;
+   dev_attr->store = gbe_itr_ips_store;
    dev_attr->attr.mode = S_IRUGO | S_IWUSR;
    dev_attr->attr.name = "itr_max_ips";
    if (device_create_file(&pdata->dev->dev, dev_attr)) {
@@ -346,15 +343,29 @@ static void DWC_ETH_QOS_create_gbe_sysfs
    }
 }
 
-void DWC_ETH_QOS_gbe_core_version(struct DWC_ETH_QOS_prv_data *pdata)
+void gbe_core_version(struct DWC_ETH_QOS_prv_data *pdata)
 {
-   //Enable Interrupt Controller if version is 4.00
+   // Enable Interrupt Controller if version is 4.00
    pdata->version = DWC_REG_RD_FIELD(MAC_VR, MAC_VR_SNPSVER);
    CFG_PRINT("[GBE] Core version = 0x%02x\n", pdata->version);
    if (pdata->version == MAC_VER_4_00)
-      DWC_ETH_QOS_configure_IC(pdata->gbe_base);
+      gbe_configure_IC(pdata->gbe_base);
 }
 
+#ifdef DWC_ETH_NETSS_PM /* TE - netip support is missing for that */
+static int gbe_handle_suspend_resume(void *args, netss_power_state_t state)
+{
+   struct DWC_ETH_QOS_prv_data *pdata = (struct DWC_ETH_QOS_prv_data *)args;
+   int ret = -EINVAL;
+   if (state == NETSS_NETIP_POWER_STATE_OFF) {
+      ret = DWC_ETH_QOS_powerdown(pdata->dev, DWC_ETH_QOS_NETIP_WAKEUP);
+   } else if (state == NETSS_NETIP_POWER_STATE_ACTIVE) {
+      ret = DWC_ETH_QOS_powerup(pdata->dev);
+   }
+   return ret;
+}
+#endif
+
 void DWC_ETH_QOS_init_all_fptrs(struct DWC_ETH_QOS_prv_data *pdata)
 {
    DWC_ETH_QOS_init_function_ptrs_dev(&pdata->hw_if);
@@ -388,18 +399,21 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
    struct DWC_ETH_QOS_prv_data *pdata = NULL;
    struct net_device *dev = NULL;
    int i, ret = 0;
-   struct hw_if_struct *hw_if = NULL;
+   hw_interface_t *hw_if = NULL;
    struct desc_if_struct *desc_if = NULL;
    uint8_t tx_q_count = 0, rx_q_count = 0;
    void __iomem *gbe_base;
    unsigned int gbe_mux_cfg;
+#ifdef DWC_ETH_NETSS_PM /* TE - netip support is missing for that */
+   netss_power_state_callback_info_t pm_callback_info;
+#endif
 #ifdef GBE_DEBUG
    char dbg_str[]="_DEBUG";
 #else
    char dbg_str[]="";
 #endif
 
-   DBGPR("--> DWC_ETH_QOS_probe\n");
+   CFG_PRINT("--> DWC_ETH_QOS_probe\n");
 
    if ((ret = pci_enable_device(pdev)) != 0) {
       printk(KERN_ALERT "%s:Unable to enable device\n", DEV_NAME);
@@ -414,7 +428,7 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
       }
    }
 
-   if (DWC_ETH_QOS_init_general_gbe(&gbe_base, &gbe_mux_cfg)) {
+   if (gbe_init_top_registers(&gbe_base, &gbe_mux_cfg)) {
       ret = -ENODEV;
       goto err_out_req_reg_failed;
    }
@@ -474,6 +488,8 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
    hw_if = &(pdata->hw_if);
    desc_if = &(pdata->desc_if);
 
+   /* Initialize HW configuration variables */
+   memset(&pdata->hw_cfg, 0, sizeof(hw_config_t));
    pci_set_drvdata(pdev, dev);
    pdata->pdev = pdev;
    pdata->dev = dev;
@@ -486,10 +502,10 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
    pdata->itr_latency = ONE_SEC_TO_NS/DEFAULT_NUM_IPS;
 
    /* Verify GMAC core version */
-   DWC_ETH_QOS_gbe_core_version(pdata);
+   gbe_core_version(pdata);
 
    /* issue software reset to device */
-   hw_if->exit();
+   hw_if->sw_reset();
    dev->irq = pdev->irq;
 
    DWC_ETH_QOS_get_all_hw_features(pdata);
@@ -497,8 +513,13 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
 
    // Disable MDIO
    pdata->hw_feat.sma_sel = 0;
-   // Override TSO with module parameter
-   pdata->hw_feat.tso_en = tso_enable;
+	/* Override TSO with module parameter (if HW supports TSO) */
+	if (pdata->hw_feat.tso_en)
+		pdata->hw_feat.tso_en = tso_enable;
+	/* Notify of potential known issues with TSO in core v4.00 */
+	if (pdata->hw_feat.tso_en && pdata->version == MAC_VER_4_00 &&
+		num_of_queues > 1)
+		WRN_PRINT("TSO in v4.00 with more than one queue may fail!\n");
 
 #ifdef GBE_DEBUG
    // Force enable TSO if mss parameter was passed
@@ -533,7 +554,6 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
       printk(KERN_ALERT "%s: MDIO is not present\n\n", DEV_NAME);
    }
 
-#ifndef DWC_ETH_QOS_CONFIG_PGTEST
    /* enabling and registration of irq with magic wakeup */
    if (1 == pdata->hw_feat.mgk_sel) {
       device_set_wakeup_capable(&pdev->dev, 1);
@@ -584,27 +604,10 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
    DWC_ETH_QOS_ptp_init(pdata);
 #endif   /* end of DWC_ETH_QOS_CONFIG_PTP */
 
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
    spin_lock_init(&pdata->lock);
    spin_lock_init(&pdata->tx_lock);
    spin_lock_init(&pdata->pmt_lock);
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-   ret = DWC_ETH_QOS_alloc_pg(pdata);
-   if (ret < 0) {
-      printk(KERN_ALERT "ERROR:Unable to allocate PG memory\n");
-      goto err_out_pg_failed;
-   }
-   printk(KERN_ALERT "\n");
-   printk(KERN_ALERT "/*******************************************\n");
-   printk(KERN_ALERT "*\n");
-   printk(KERN_ALERT "* PACKET GENERATOR MODULE ENABLED IN DRIVER\n");
-   printk(KERN_ALERT "*\n");
-   printk(KERN_ALERT "*******************************************/\n");
-   printk(KERN_ALERT "\n");
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
    ret = register_netdev(dev);
    if (ret) {
       printk(KERN_ALERT "%s: Net device registration failed\n",
@@ -616,16 +619,29 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
    create_debug_files();
 #endif
 
-   DWC_ETH_QOS_create_gbe_sysfs(pdata);
+   create_gbe_sysfs(pdata);
 
+#ifdef DWC_ETH_NETSS_PM /* TE - netip support is missing for that */
+   /* Register PM callback with NetSS driver */
+   pm_callback_info.func = gbe_handle_suspend_resume;
+   pm_callback_info.args = pdata;
+   if (netss_power_state_change_callback_register(NETSS_DEV_GBE, &pm_callback_info)) {
+      ERR_PRINT("Failed to register PM callback with NetSS!\n");
+      // TODO:
+      // - Determine if it's ok to continue or return error code
+      // - What if NetIP is in DSBY already?
+   }
+#endif
    if (pdata->hw_feat.pcs_sel) {
       netif_carrier_off(dev);
       CFG_PRINT("Carrier off till LINK is up\n");
    }
 
-   printk(KERN_INFO "Synopsys DWC_QOS_ETH%s driver built on %s @ %s\n", dbg_str, __DATE__, __TIME__);
+   printk(KERN_INFO "Synopsys DWC_ETH_QOS%s driver built on %s @ %s\n",
+          dbg_str, __DATE__, __TIME__);
 
-   DBGPR("<-- DWC_ETH_QOS_probe\n");
+   CFG_PRINT("<-- DWC_ETH_QOS_probe\n");
+
    return 0;
 
  err_out_netdev_failed:
@@ -633,10 +649,6 @@ int DWC_ETH_QOS_probe(struct pci_dev *pd
    DWC_ETH_QOS_ptp_remove(pdata);
 #endif   /* end of DWC_ETH_QOS_CONFIG_PTP */
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-   DWC_ETH_QOS_free_pg(pdata);
-err_out_pg_failed:
-#endif
    if (1 == pdata->hw_feat.sma_sel)
       DWC_ETH_QOS_mdio_unregister(dev);
 
@@ -683,8 +695,17 @@ void DWC_ETH_QOS_remove(struct pci_dev *
    struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
    struct desc_if_struct *desc_if = &(pdata->desc_if);
    void __iomem *reg_base = pdata->gbe_base;
+#ifdef DWC_ETH_NETSS_PM /* TE - netip support is missing for that */
+   netss_power_state_callback_info_t pm_callback_info;
+#endif
+   DBGPR("--> DWC_ETH_QOS_remove\n");
 
-   DBGPR("--> DWC_ETH_QOS_remove\n");
+#ifdef DWC_ETH_NETSS_PM /* TE - netip support is missing for that */
+   /* Deregister PM callback with NetSS driver */
+   pm_callback_info.func = NULL;
+   pm_callback_info.args = NULL;
+   netss_power_state_change_callback_register(NETSS_DEV_GBE, &pm_callback_info);
+#endif
 
    if (pdata->irq_number != 0) {
       free_irq(pdata->irq_number, pdata);
@@ -700,10 +721,6 @@ void DWC_ETH_QOS_remove(struct pci_dev *
 
    unregister_netdev(dev);
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-   DWC_ETH_QOS_free_pg(pdata);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 #ifdef DWC_ETH_QOS_CONFIG_DEBUGFS
    remove_debug_files();
 #endif
@@ -729,6 +746,11 @@ void DWC_ETH_QOS_remove(struct pci_dev *
    return;
 }
 
+#ifdef CONFIG_PM
+static int DWC_ETH_QOS_suspend(struct pci_dev *, pm_message_t);
+static int DWC_ETH_QOS_resume(struct pci_dev *);
+#endif
+
 static struct pci_device_id DWC_ETH_QOS_id[] = {
    {PCI_DEVICE(VENDOR_ID, DEVICE_ID)},
    {0}, /* terminate list */
@@ -741,9 +763,6 @@ static struct pci_driver DWC_ETH_QOS_pci
    .id_table = DWC_ETH_QOS_id,
    .probe = DWC_ETH_QOS_probe,
    .remove = DWC_ETH_QOS_remove,
-   .shutdown = DWC_ETH_QOS_shutdown,
-   .suspend_late = DWC_ETH_QOS_suspend_late,
-   .resume_early = DWC_ETH_QOS_resume_early,
 #ifdef CONFIG_PM
    .suspend = DWC_ETH_QOS_suspend,
    .resume = DWC_ETH_QOS_resume,
@@ -754,33 +773,6 @@ static struct pci_driver DWC_ETH_QOS_pci
    },
 };
 
-static void DWC_ETH_QOS_shutdown(struct pci_dev *pdev)
-{
-   printk(KERN_ALERT "-->DWC_ETH_QOS_shutdown\n");
-   printk(KERN_ALERT "Handle the shutdown\n");
-   printk(KERN_ALERT ">--DWC_ETH_QOS_shutdown\n");
-
-   return;
-}
-
-static int DWC_ETH_QOS_suspend_late(struct pci_dev *pdev, pm_message_t state)
-{
-   printk(KERN_ALERT "-->DWC_ETH_QOS_suspend_late\n");
-   printk(KERN_ALERT "Handle the suspend_late\n");
-   printk(KERN_ALERT "<--DWC_ETH_QOS_suspend_late\n");
-
-   return 0;
-}
-
-static int DWC_ETH_QOS_resume_early(struct pci_dev *pdev)
-{
-   printk(KERN_ALERT "-->DWC_ETH_QOS_resume_early\n");
-   printk(KERN_ALERT "Handle the resume_early\n");
-   printk(KERN_ALERT "<--DWC_ETH_QOS_resume_early\n");
-
-   return 0;
-}
-
 #ifdef CONFIG_PM
 
 /*!
@@ -804,12 +796,11 @@ static int DWC_ETH_QOS_resume_early(stru
  *
  * \retval 0
  */
-
 static int DWC_ETH_QOS_suspend(struct pci_dev *pdev, pm_message_t state)
 {
    struct net_device *dev = pci_get_drvdata(pdev);
    struct DWC_ETH_QOS_prv_data *pdata = netdev_priv(dev);
-   struct hw_if_struct *hw_if = &(pdata->hw_if);
+   hw_interface_t *hw_if = &(pdata->hw_if);
    int ret, pmt_flags = 0;
    unsigned int rwk_filter_values[] = {
       /* for filter 0 CRC is computed on 0 - 7 bytes from offset */
@@ -856,7 +847,7 @@ static int DWC_ETH_QOS_suspend(struct pc
    if (pdata->hw_feat.mgk_sel && (pdata->wolopts & WAKE_MAGIC))
       pmt_flags |= DWC_ETH_QOS_MAGIC_WAKEUP;
 
-   ret = DWC_ETH_QOS_powerdown(dev, pmt_flags, DWC_ETH_QOS_DRIVER_CONTEXT);
+   ret = DWC_ETH_QOS_powerdown(dev, pmt_flags);
    pci_save_state(pdev);
    pci_set_power_state(pdev, pci_choose_state(pdev, state));
 
@@ -886,7 +877,6 @@ static int DWC_ETH_QOS_suspend(struct pc
  *
  * \retval 0
  */
-
 static int DWC_ETH_QOS_resume(struct pci_dev *pdev)
 {
    struct net_device *dev = pci_get_drvdata(pdev);
@@ -902,7 +892,7 @@ static int DWC_ETH_QOS_resume(struct pci
    pci_set_power_state(pdev, PCI_D0);
    pci_restore_state(pdev);
 
-   ret = DWC_ETH_QOS_powerup(dev, DWC_ETH_QOS_DRIVER_CONTEXT);
+   ret = DWC_ETH_QOS_powerup(dev);
 
    DBGPR("<--DWC_ETH_QOS_resume\n");
 
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pci.h b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pci.h
deleted file mode 100644
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pci.h
+++ /dev/null
@@ -1,52 +0,0 @@
-/* =========================================================================
- * The Synopsys DWC ETHER QOS Software Driver and documentation (hereinafter
- * "Software") is an unsupported proprietary work of Synopsys, Inc. unless
- * otherwise expressly agreed to in writing between Synopsys and you.
- *
- * The Software IS NOT an item of Licensed Software or Licensed Product under
- * any End User Software License Agreement or Agreement for Licensed Product
- * with Synopsys or any supplement thereto.  Permission is hereby granted,
- * free of charge, to any person obtaining a copy of this software annotated
- * with this license and the Software, to deal in the Software without
- * restriction, including without limitation the rights to use, copy, modify,
- * merge, publish, distribute, sublicense, and/or sell copies of the Software,
- * and to permit persons to whom the Software is furnished to do so, subject
- * to the following conditions:
- *
- * The above copyright notice and this permission notice shall be included in
- * all copies or substantial portions of the Software.
- *
- * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
- * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
- * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
- * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
- * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
- * DAMAGE.
- * ========================================================================= */
-
-#ifndef __DWC_ETH_QOS__PCI_H__
-
-#define __DWC_ETH_QOS__PCI_H__
-
-int DWC_ETH_QOS_probe(struct pci_dev *, const struct pci_device_id *);
-
-void DWC_ETH_QOS_remove(struct pci_dev *);
-
-static void DWC_ETH_QOS_shutdown(struct pci_dev *);
-
-static int DWC_ETH_QOS_suspend_late(struct pci_dev *, pm_message_t);
-
-static int DWC_ETH_QOS_resume_early(struct pci_dev *);
-
-#ifdef CONFIG_PM
-static int DWC_ETH_QOS_suspend(struct pci_dev *, pm_message_t);
-
-static int DWC_ETH_QOS_resume(struct pci_dev *);
-#endif				/* end of CONFIG_PM */
-
-#endif
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pktgen.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pktgen.c
deleted file mode 100644
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pktgen.c
+++ /dev/null
@@ -1,1466 +0,0 @@
-/* =========================================================================
- * The Synopsys DWC ETHER QOS Software Driver and documentation (hereinafter
- * "Software") is an unsupported proprietary work of Synopsys, Inc. unless
- * otherwise expressly agreed to in writing between Synopsys and you.
- *
- * The Software IS NOT an item of Licensed Software or Licensed Product under
- * any End User Software License Agreement or Agreement for Licensed Product
- * with Synopsys or any supplement thereto.  Permission is hereby granted,
- * free of charge, to any person obtaining a copy of this software annotated
- * with this license and the Software, to deal in the Software without
- * restriction, including without limitation the rights to use, copy, modify,
- * merge, publish, distribute, sublicense, and/or sell copies of the Software,
- * and to permit persons to whom the Software is furnished to do so, subject
- * to the following conditions:
- *
- * The above copyright notice and this permission notice shall be included in
- * all copies or substantial portions of the Software.
- *
- * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
- * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
- * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
- * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
- * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
- * DAMAGE.
- * ========================================================================= */
-
-/*!@file: DWC_ETH_QOS_drv.c
- * @brief: Driver functions.
- */
-
-#include "DWC_ETH_QOS_yheader.h"
-#include "DWC_ETH_QOS_yapphdr.h"
-#include "DWC_ETH_QOS_pktgen.h"
-
-extern uint32_t dwc_eth_qos_pci_base_addr;
-
-#include "DWC_ETH_QOS_yregacc.h"
-
-static int DWC_ETH_QOS_GStatus;
-
-static int DWC_ETH_QOS_FRAME_PATTERN_CH[8] = {
-	0x11111111,
-	0x22222222,
-	0x33333333,
-	0x44444444,
-	0x55555555,
-	0x66666666,
-	0x77777777,
-	0x88888888,
-};
-
-static int DWC_ETH_QOS_frame_hdrs[8][4] = {
-	/* for channel 0 : Non tagged header
-	 * Dst addr : 0x00:0x0D:0x56:0x73:0xD0:0xF3
-	 * Src addr : 0x00:0x55:0x7B:0xB5:0x7D:0xF7
-	 * Type/Length : 0x800
-	 * */
-	{0x73560D00, 0x5500F3D0, 0xF77DB57B, 0x00000008},
-
-	/* for channel 1 : VLAN tagged header with priority 1
-	 * Dst addr : 0x00:0x0D:0x56:0x73:0xD0:0xF3
-	 * Src addr : 0x00:0x55:0x7B:0xB5:0x7D:0xF7
-	 * Type/Length : 0x8100
-	 * */
-	{0x73560D00, 0x5500F3D0, 0xF77DB57B, 0x64200081},
-
-	/* for channel 2 : VLAN tagged header with priority 2
-	 * Dst addr : 0x00:0x0D:0x56:0x73:0xD0:0xF3
-	 * Src addr : 0x00:0x55:0x7B:0xB5:0x7D:0xF7
-	 * Type/Length : 0x8100
-	 * */
-	{0x73560D00, 0x5500F3D0, 0xF77DB57B, 0x64400081},
-
-	/* for channel 3 : VLAN tagged header with priority 3
-	 * Dst addr : 0x00:0x0D:0x56:0x73:0xD0:0xF3
-	 * Src addr : 0x00:0x55:0x7B:0xB5:0x7D:0xF7
-	 * Type/Length : 0x8100
-	 * */
-	{0x73560D00, 0x5500F3D0, 0xF77DB57B, 0x64600081},
-
-	/* for channel 4 : VLAN tagged header with priority 4
-	 * Dst addr : 0x00:0x0D:0x56:0x73:0xD0:0xF3
-	 * Src addr : 0x00:0x55:0x7B:0xB5:0x7D:0xF7
-	 * Type/Length : 0x8100
-	 * */
-	{0x73560D00, 0x5500F3D0, 0xF77DB57B, 0x64800081},
-
-	/* for channel 5 : VLAN tagged header with priority 5
-	 * Dst addr : 0x00:0x0D:0x56:0x73:0xD0:0xF3
-	 * Src addr : 0x00:0x55:0x7B:0xB5:0x7D:0xF7
-	 * Type/Length : 0x8100
-	 * */
-	{0x73560D00, 0x5500F3D0, 0xF77DB57B, 0x64A00081},
-
-	/* for channel 6 : VLAN tagged header with priority 6
-	 * Dst addr : 0x00:0x0D:0x56:0x73:0xD0:0xF3
-	 * Src addr : 0x00:0x55:0x7B:0xB5:0x7D:0xF7
-	 * Type/Length : 0x8100
-	 * */
-	{0x73560D00, 0x5500F3D0, 0xF77DB57B, 0x64C00081},
-
-	/* for channel 7 : VLAN tagged header with priority 7
-	 * Dst addr : 0x00:0x0D:0x56:0x73:0xD0:0xF3
-	 * Src addr : 0x00:0x55:0x7B:0xB5:0x7D:0xF7
-	 * Type/Length : 0x8100
-	 * */
-	{0x73560D00, 0x5500F3D0, 0xF77DB57B, 0x64E00081},
-};
-
-
-/*!
-* \brief API to receiv the data from device.
-*
-* \details This function reads as many packets are possible from
-* device, reinitialize the descriptor buffer pointers and other
-* control bits such that device owns the descriptor. It also does
-* some housekeeping work to manage the descriptors.
-*
-* \param[in] pdata - pointer to private data structure.
-* \param[in] qInx - DMA channel/queue no. to be checked for packet.
-*
-* \return integer
-*
-* \retval number of packets received.
-*/
-static int DWC_ETH_QOS_poll_pg_sq(struct DWC_ETH_QOS_prv_data *pdata,
-				unsigned int qInx)
-{
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *desc_data =
-		GET_RX_WRAPPER_DESC(qInx);
-	struct net_device *dev = pdata->dev;
-	rx_descriptor_t *RX_NORMAL_DESC = NULL;
-	struct DWC_ETH_QOS_rx_buffer *buffer = NULL;
-	unsigned int varrx_error_counters = 0;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input =
-		&(pdata->pg->pg_ch_input[qInx]);
-	int received = 0;
-	struct hw_if_struct *hw_if = &pdata->hw_if;
-	struct sk_buff *skb = NULL;
-
-	DBGPR_PG("-->DWC_ETH_QOS_poll_pg_sq: qInx = %u\n", qInx);
-
-	while (1) {
-		DBGPR_PG("cur_rx = %d\n", desc_data->cur_rx);
-		RX_NORMAL_DESC = GET_RX_DESC_PTR(qInx, desc_data->cur_rx);
-		buffer = GET_RX_BUF_PTR(qInx, desc_data->cur_rx);
-
-		/* reset rx packets attributes */
-		memset(&(pdata->rx_pkt_features), 0,
-		       sizeof(struct s_rx_pkt_features));
-		/* reset error counters */
-		pdata->rx_error_counters = 0;
-		buffer->len = 0;
-
-		hw_if->dev_read(pdata, qInx);
-
-		varrx_error_counters = pdata->rx_error_counters;
-		/* no more data to read */
-		if ((buffer->len == 0x0) && (varrx_error_counters == 0x0))
-			break;
-
-		/* assign it to new skb */
-		skb = buffer->skb;
-		/* good packet */
-		if (varrx_error_counters == 0) {
-			dev->last_rx = jiffies;
-			/* update the statistics */
-			dev->stats.rx_packets++;
-			dev->stats.rx_bytes += buffer->len;
-			pg_ch_input->ch_FramecountRx++;
-
-			dma_sync_single_for_cpu(&pdata->pdev->dev, buffer->dma,
-					DWC_ETH_QOS_PG_FRAME_SIZE, DMA_FROM_DEVICE);
-#ifdef DWC_ETH_QOS_ENABLE_RX_PKT_DUMP
-			if (0 == (pg_ch_input->ch_FramecountRx % 500)) {
-				//print_pkt(skb, buffer->len, 0, (desc_data->cur_rx));
-				dump_rx_desc(qInx, RX_NORMAL_DESC, desc_data->cur_rx);
-			}
-#endif
-		} else {
-			DBGPR_PG("Error in received pkt, hence failed to pass it to upper layer\n");
-			dev->stats.rx_errors++;
-			DWC_ETH_QOS_update_rx_errors(dev, varrx_error_counters);
-		}
-
-		/* Reassign same buffer pointer and give ownership to DMA */
-		//memset(buffer->skb->data, 0, buffer->len);
-		/* update buffer 1 address pointer */
-		RX_NORMAL_DESC_RDES0_Ml_Wr(RX_NORMAL_DESC->RDES0, buffer->dma);
-		/* set to zero */
-		RX_NORMAL_DESC_RDES1_Ml_Wr(RX_NORMAL_DESC->RDES1, 0);
-		/* set buffer 2 address pointer to zero */
-		RX_NORMAL_DESC_RDES2_Ml_Wr(RX_NORMAL_DESC->RDES2, 0);
-		/* set control bits - OWN, INTE and BUF1V */
-		RX_NORMAL_DESC_RDES3_Ml_Wr(RX_NORMAL_DESC->RDES3, (0xc1000000));
-
-		/* update the Rx Tail Pointer Register with address of
-		 * descriptors from which data is read */
-		DMA_RDTP_RPDR_RgWr(qInx, GET_RX_DESC_DMA_ADDR(qInx, desc_data->cur_rx));
-
-		received++;
-		INCR_RX_DESC_INDEX(desc_data->cur_rx, 1);
-	}
-
-	DBGPR_PG("<--DWC_ETH_QOS_poll_pg_sq: received = %d\n", received);
-
-	return received;
-}
-
-/*!
-* \brief API to receiv the data from device.
-*
-* \details This function is called from ISR upon receive interrupt.
-* This function will call other helper function to read the packets
-* from all DMA channel.
-*
-* \param[in] pdata - pointer to private data structure.
-*
-* \return void
-*/
-static void DWC_ETH_QOS_poll_pg(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	unsigned int qInx;
-	int received = 0;
-
-	DBGPR_PG("-->DWC_ETH_QOS_poll_pg\n");
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
-		received = DWC_ETH_QOS_poll_pg_sq(pdata, qInx);
-		DBGPR_PG("Received %d packets from RX queue %u\n",
-			received, qInx);
-	}
-
-	/* Enable all ch RX interrupt */
-	DWC_ETH_QOS_enable_rx_interrupts(pdata);
-
-	DBGPR_PG("<--DWC_ETH_QOS_poll_pg\n");
-}
-
-
-/*!
-* \brief API to update the tx status.
-*
-* \details This function is called from ISR upon transmit complete
-* interrupt to check the status of packet transmitted by device. It
-* also updates the private data structure fields.
-*
-* \param[in] pdata - pointer to private data structure.
-* \param[in] qInx - DMA channel number.
-*
-* \return void
-*/
-static void DWC_ETH_QOS_tx_interrupt_pg(struct DWC_ETH_QOS_prv_data *pdata,
-				     uint32_t qInx)
-{
-	struct net_device *dev = pdata->dev;
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data =
-	    GET_TX_WRAPPER_DESC(qInx);
-	tx_descriptor_t *txptr = NULL;
-	struct DWC_ETH_QOS_tx_buffer *buffer = NULL;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	int err_incremented;
-	uint32_t reg_tail_ptr = 0, var_tail_ptr = 0, tail_ptr = 0, head_ptr = 0;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input =
-		&(pdata->pg->pg_ch_input[qInx]);
-
-	DBGPR_PG("-->DWC_ETH_QOS_tx_interrupt_pg: dirty_tx = %d, qInx = %u\n",
-			desc_data->dirty_tx, qInx);
-
-	while (1) {
-		txptr = GET_TX_DESC_PTR(qInx, desc_data->dirty_tx);
-		buffer = GET_TX_BUF_PTR(qInx, desc_data->dirty_tx);
-
-		if (!hw_if->tx_complete(txptr))
-			break;
-
-		dev->stats.tx_bytes += buffer->len;
-
-		/* update the tx error if any by looking at last segment
-		 * for NORMAL descriptors
-		 * */
-		if ((hw_if->get_tx_desc_ls(txptr)) && !(hw_if->get_tx_desc_ctxt(txptr))) {
-			err_incremented = 0;
-			if (txptr->TDES3 & 0x8000)
-				dump_tx_desc(pdata, desc_data->dirty_tx, desc_data->dirty_tx, 0, qInx);
-
-			if (hw_if->tx_window_error) {
-				if (hw_if->tx_window_error(txptr)) {
-					err_incremented = 1;
-					dev->stats.tx_window_errors++;
-				}
-			}
-			if (hw_if->tx_aborted_error) {
-				if (hw_if->tx_aborted_error(txptr)) {
-					err_incremented = 1;
-					dev->stats.tx_aborted_errors++;
-					if (hw_if->tx_handle_aborted_error)
-						hw_if->tx_handle_aborted_error(txptr);
-				}
-			}
-			if (hw_if->tx_carrier_lost_error) {
-				if (hw_if->tx_carrier_lost_error(txptr)) {
-					err_incremented = 1;
-					dev->stats.tx_carrier_errors++;
-				}
-			}
-			if (hw_if->tx_fifo_underrun) {
-				if (hw_if->tx_fifo_underrun(txptr)) {
-					dev->stats.tx_fifo_errors++;
-					if (hw_if->tx_update_fifo_threshold)
-						hw_if->tx_update_fifo_threshold(txptr);
-				}
-			}
-			if (hw_if->tx_get_collision_count)
-				dev->stats.collisions +=
-				    hw_if->tx_get_collision_count(txptr);
-
-			if (err_incremented == 1) {
-				dev->stats.tx_errors++;
-				printk(KERN_ALERT "Error in transmission of packet\n");
-			}
-			dev->stats.tx_packets++;
-			pg_ch_input->ch_FramecountTx++;
-		}
-		else {
-			if (!hw_if->get_tx_desc_ls(txptr))
-				printk(KERN_ALERT "LS not set for %d\n", desc_data->dirty_tx);
-			if (hw_if->get_tx_desc_ctxt(txptr))
-				printk(KERN_ALERT "Context desc in %d\n", desc_data->dirty_tx);
-		}
-
-		/* reset the descriptor so that driver/host can reuse it */
-		hw_if->tx_desc_reset(desc_data->dirty_tx, pdata, qInx);
-
-		if ((pdata->prepare_pg_packet == Y_TRUE)) {
-			if (pg_ch_input->ch_debug_mode == 0) {
-				/* reassign the same buffer pointers and make it ready for transmission */
-				DWC_ETH_QOS_prepare_desc(pdata, txptr, buffer, desc_data->dirty_tx, qInx);
-				/* issue a poll command to Tx DMA by writing address
-				 * of next immediate free descriptor */
-				tail_ptr = GET_TX_DESC_DMA_ADDR(qInx, desc_data->dirty_tx);
-				DMA_TDTP_TPDR_RgWr(qInx, tail_ptr);
-			} else {
-				/* DEBUG ON */
-				if (pg_ch_input->ch_FramecountTx <= pg_ch_input->ch_desc_prepare) {
-					/* reassign the same buffer pointers and make it ready for transmission */
-					DWC_ETH_QOS_prepare_desc(pdata, txptr, buffer, desc_data->dirty_tx, qInx);
-					/* issue a poll command to Tx DMA by writing address
-					* of next immediate free descriptor */
-					tail_ptr = GET_TX_DESC_DMA_ADDR(qInx, desc_data->dirty_tx);
-					DMA_TDTP_TPDR_RgWr(qInx, tail_ptr);
-				}
-			}
-		}
-
-		INCR_TX_DESC_INDEX(desc_data->dirty_tx, 1);
-	}
-
-	/* debug print */
-	if (pg_ch_input->interrupt_prints && !(pg_ch_input->tx_interrupts % 1) &&
-			(pg_ch_input->ch_FramecountTx <= 8 /*|| pg_ch_input->ch_FramecountTx >= TX_DESC_CNT*/)) {
-		var_tail_ptr = GET_TX_DESC_DMA_ADDR(qInx, desc_data->dirty_tx);
-		DMA_TDTP_TPDR_RgRd(qInx, reg_tail_ptr);
-		DMA_CHTDR_RgRd(qInx, head_ptr);
-		printk(KERN_ALERT
-				"%d] Tail @ run     [%3llu]%#x,r%#x\n"
-				"    Head @ run     [%3llu]%#x\n"
-				"    dirty_tx @ run  %d\n"
-				"    ch_FramecountTx %lu\n\n",
-				qInx,
-				GET_TX_DESC_IDX(qInx, var_tail_ptr), var_tail_ptr, reg_tail_ptr,
-				GET_TX_DESC_IDX(qInx, head_ptr), head_ptr,
-				desc_data->dirty_tx,
-				pg_ch_input->ch_FramecountTx);
-		pg_ch_input->interrupt_prints--;
-	}
-	pg_ch_input->tx_interrupts++;
-
-	DBGPR_PG("<--DWC_ETH_QOS_tx_interrupt_pg\n");
-}
-
-
-static void DWC_ETH_QOS_save_abs_count(struct DWC_ETH_QOS_prv_data *pdata,
-		uint32_t qInx)
-{
-	struct DWC_ETH_QOS_PGStruct *pg_struct = pdata->pg;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = pg_struct->pg_ch_input;
-	uint32_t varMTL_QESR = 0;
-
-	MTL_QESR_RgRd(qInx, varMTL_QESR);
-	if (varMTL_QESR & 0x1000000) {
-		switch (pg_ch_input[qInx].ch_operating_mode) {
-		case eDWC_ETH_QOS_QDCB:
-			pg_ch_input[qInx].ch_AvgBits += (varMTL_QESR & 0xffffff);
-			break;
-
-		case eDWC_ETH_QOS_QAVB:
-			// TODO: calculation pending
-			pg_ch_input[qInx].ch_AvgBits += (varMTL_QESR & 0xffffff);
-			break;
-		}
-		pg_ch_input[qInx].ch_AvgBits_interrupt_count++;
-	}
-
-	return;
-}
-
-/*!
-* \brief Interrupt Service Routine
-*
-* \details This function is invoked by Linux when there is any interrupt
-* from GMAC. This function will check for all interrupts and call
-* appropriate functions to service them.
-*
-* \param[in] irq         - interrupt number for particular device
-* \param[in] device_id   - pointer to device structure
-*
-* \return integer
-*
-* \retval IRQ_HANDLED if inerrupt is handled successfully and
-*         IRQ_NONE if interrupt is not ours.
-*/
-irqreturn_t DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS_pg(int irq, void *device_id)
-{
-	uint32_t varDMA_ISR;
-	uint32_t varDMA_SR;
-	uint32_t varDMA_IER;
-	struct DWC_ETH_QOS_prv_data *pdata =
-	    (struct DWC_ETH_QOS_prv_data *)device_id;
-	uint32_t qInx;
-
-	DBGPR_PG("-->DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS_pg\n");
-
-	DMA_ISR_RgRd(varDMA_ISR);
-	if (varDMA_ISR == 0x0)
-		return IRQ_NONE;
-
-	DBGPR_PG("DMA_ISR = %#lx\n", varDMA_ISR);
-
-	/* Handle DMA interrupts */
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		DMA_SR_RgRd(qInx, varDMA_SR);
-		DMA_IER_RgRd(qInx, varDMA_IER);
-
-		/* handle only those DMA interrupts which are enabled */
-		varDMA_SR = (varDMA_SR & varDMA_IER);
-
-		DBGPR_PG("DMA_SR[%d] = %#lx\n", qInx, varDMA_SR);
-
-		if (varDMA_SR == 0)
-			continue;
-
-		if (GET_VALUE(varDMA_SR, DMA_SR_TI_LPOS, DMA_SR_TI_HPOS) & 1) {
-			DWC_ETH_QOS_tx_interrupt_pg(pdata, qInx);
-			DMA_SR_TI_UdfWr(qInx, 1);
-		}
-		if (GET_VALUE(varDMA_SR, DMA_SR_TPS_LPOS, DMA_SR_TPS_HPOS) & 1) {
-			DWC_ETH_QOS_GStatus = -E_DMA_SR_TPS;
-			printk(KERN_ALERT "%d] TPS Interrupt\n", qInx);
-			DMA_SR_TPS_UdfWr(qInx, 1);
-		}
-		if (GET_VALUE(varDMA_SR, DMA_SR_TBU_LPOS, DMA_SR_TBU_HPOS) & 1) {
-			DWC_ETH_QOS_GStatus = -E_DMA_SR_TBU;
-			//if (pdata->prepare_pg_packet == Y_FALSE) {
-				printk(KERN_ALERT "%d] TBU Interrupt\n", qInx);
-				pdata->pg->channel_running[qInx] = Y_FALSE;
-			//}
-			DMA_SR_TBU_UdfWr(qInx, 1);
-		}
-		if (GET_VALUE(varDMA_SR, DMA_SR_RI_LPOS, DMA_SR_RI_HPOS) & 1) {
-			DWC_ETH_QOS_disable_rx_interrupts(pdata);
-			DWC_ETH_QOS_poll_pg(pdata);
-			DMA_SR_RI_UdfWr(qInx, 1);
-		}
-		if (GET_VALUE(varDMA_SR, DMA_SR_RBU_LPOS, DMA_SR_RBU_HPOS) & 1) {
-			DWC_ETH_QOS_GStatus = -E_DMA_SR_RBU;
-			DMA_SR_RBU_UdfWr(qInx, 1);
-			printk(KERN_ALERT "RBU Interrupt\n");
-		}
-		if (GET_VALUE(varDMA_SR, DMA_SR_RPS_LPOS, DMA_SR_RPS_HPOS) & 1) {
-			DWC_ETH_QOS_GStatus = -E_DMA_SR_RPS;
-			DMA_SR_RPS_UdfWr(qInx, 1);
-			printk(KERN_ALERT "RPS Interrupt\n");
-		}
-		if (GET_VALUE(varDMA_SR, DMA_SR_RWT_LPOS, DMA_SR_RWT_HPOS) & 1) {
-			DWC_ETH_QOS_GStatus = S_DMA_SR_RWT;
-		}
-		if (GET_VALUE(varDMA_SR, DMA_SR_FBE_LPOS, DMA_SR_FBE_HPOS) & 1) {
-			DWC_ETH_QOS_GStatus = -E_DMA_SR_FBE;
-			DMA_SR_FBE_UdfWr(qInx, 1);
-			DBGPR_PG("FATAL bus error interrupt\n");
-		}
-	}
-
-	/* MTL Interrupt handler */
-	if (GET_VALUE(varDMA_ISR, DMA_ISR_MTLIS_LPOS, DMA_ISR_MTLIS_HPOS) & 1) {
-		for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-			/* ABS Interrupt handler */
-			DWC_ETH_QOS_save_abs_count(pdata, qInx);
-		}
-	}
-
-	DBGPR_PG("<--DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS_pg\n");
-
-	return IRQ_HANDLED;
-
-}
-
-/*!
- * \brief api to initialize default values.
- *
- * \details This function is used to initialize differnet parameters to
- * default values which are common parameters between Tx and Rx path.
- *
- * \param[in] pdata  pointer to private data structure.
- *
- * \return void
- */
-void DWC_ETH_QOS_default_confs(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *tx_desc_data = NULL;
-	struct DWC_ETH_QOS_rx_wrapper_descriptor *rx_desc_data = NULL;
-	uint32_t qInx;
-
-	pdata->incr_incrx = DWC_ETH_QOS_INCR_ENABLE;
-	pdata->flow_ctrl = 0;
-	pdata->oldflow_ctrl = 0;
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		tx_desc_data = GET_TX_WRAPPER_DESC(qInx);
-
-		tx_desc_data->tx_threshold_val = DWC_ETH_QOS_TX_THRESHOLD_32;
-		tx_desc_data->tsf_on = DWC_ETH_QOS_TSF_ENABLE;
-		tx_desc_data->osf_on = DWC_ETH_QOS_OSF_ENABLE;
-		tx_desc_data->tx_pbl = DWC_ETH_QOS_PBL_16;
-	}
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_RX_QUEUE_CNT; qInx++) {
-		rx_desc_data = GET_RX_WRAPPER_DESC(qInx);
-
-		rx_desc_data->rx_threshold_val = DWC_ETH_QOS_RX_THRESHOLD_64;
-		rx_desc_data->rsf_on = DWC_ETH_QOS_RSF_DISABLE;
-		rx_desc_data->rx_pbl = DWC_ETH_QOS_PBL_16;
-	}
-}
-
-/*!
-* \brief API to prepare descriptor.
-*
-* \details This function is called by other driver function to prepare
-* the transmit descriptor.
-*
-* \param[in] pdata   - pointer to private data structure
-* \param[in] txptr   - pointer to transmit descriptor structure
-* \param[in] buffer  - pointer to transmit buffer structure
-* \param[in] i       - descriptor index
-* \param[in] qInx    - DMA channel number
-*
-* \return void
-*/
-static void DWC_ETH_QOS_prepare_desc(struct DWC_ETH_QOS_prv_data *pdata,
-				tx_descriptor_t *txptr,
-				struct DWC_ETH_QOS_tx_buffer *buffer,
-				int i,
-				unsigned int qInx)
-{
-	//DBGPR_PG("-->DWC_ETH_QOS_prepare_desc\n");
-
-	/* update packet address */
-	TX_NORMAL_DESC_TDES0_Ml_Wr(txptr->TDES0, buffer->dma);
-	/* update the packet length */
-	TX_NORMAL_DESC_TDES2_HL_B1L_Mlf_Wr(txptr->TDES2, buffer->len);
-	/* update the frame length */
-	TX_NORMAL_DESC_TDES3_FL_Mlf_Wr(txptr->TDES3, buffer->len);
-	/* set Interrupt on Completion for last descriptor */
-	TX_NORMAL_DESC_TDES2_IC_Mlf_Wr(txptr->TDES2, 0x1);
-	/* Mark it as First Descriptor */
-	TX_NORMAL_DESC_TDES3_FD_Mlf_Wr(txptr->TDES3, 0x1);
-	/* Mark it as LAST descriptor */
-	TX_NORMAL_DESC_TDES3_LD_Mlf_Wr(txptr->TDES3, 0x1);
-	/* Disable CRC and Pad Insertion */
-	TX_NORMAL_DESC_TDES3_CPC_Mlf_Wr(txptr->TDES3, 0);
-	/* Mark it as NORMAL descriptor */
-	TX_NORMAL_DESC_TDES3_CTXT_Mlf_Wr(txptr->TDES3, 0);
-	/* set slot number */
-	TX_NORMAL_DESC_TDES3_SLOTNUM_TCPHDRLEN_Mlf_Wr(txptr->TDES3, buffer->slot_number);
-	/* set OWN bit at end to avoid race condition */
-	TX_NORMAL_DESC_TDES3_OWN_Mlf_Wr(txptr->TDES3, 0x1);
-
-	//DBGPR_PG("<--DWC_ETH_QOS_prepare_desc\n");
-}
-
-
-/*!
-* \brief API to prepare tx descriptor.
-*
-* \details This function will prepare all DMA channel Tx descriptor
-* in advance before starting the Tx DMA engine.
-*
-* \param[in] pdata   - pointer to private data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_prepare_tx_packets_for_pg_test(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data = NULL;
-	struct DWC_ETH_QOS_PGStruct *pg_struct = pdata->pg;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = pg_struct->pg_ch_input;
-	uint32_t head_ptr = 0, tail_ptr = 0, desc_ring_ptr = 0, i, qInx, frame_size;
-	unsigned short ch_tx_desc_slot_no_start = 0;
-	unsigned short ch_tx_desc_slot_no_skip = 0;
-	unsigned int tx_pkt_cnt = 0;
-	int desc_idx = 0;
-
-	DBGPR_PG("-->DWC_ETH_QOS_prepare_tx_packets_for_pg_test\n");
-
-	/* Descriptor memory allocation for transmission */
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		tx_descriptor_t *txptr = NULL;
-		struct DWC_ETH_QOS_tx_buffer *buffer = NULL;
-		unsigned int *skb_data = NULL;
-		unsigned int avtype = DWC_ETH_QOS_AVTYPE;
-		int payload_cnt = 0;
-		desc_data = GET_TX_WRAPPER_DESC(qInx);
-
-		/* for channel 0 no slot number checking */
-		if (qInx > 0) {
-			ch_tx_desc_slot_no_start = pg_ch_input[qInx].ch_tx_desc_slot_no_start;
-			ch_tx_desc_slot_no_skip = pg_ch_input[qInx].ch_tx_desc_slot_no_skip;
-		}
-
-		if (pg_ch_input[qInx].ch_debug_mode == 1) {
-			DMA_CHTDR_RgRd(qInx, head_ptr);
-			desc_idx = GET_TX_DESC_IDX(qInx, head_ptr);
-			if (pg_ch_input[qInx].ch_max_tx_frame_cnt >= TX_DESC_CNT) {
-				tx_pkt_cnt = TX_DESC_CNT;
-				pg_ch_input[qInx].ch_desc_prepare =
-					(pg_ch_input[qInx].ch_max_tx_frame_cnt - TX_DESC_CNT);
-				pg_ch_input[qInx].ch_desc_prepare++;
-			}
-			else {
-				pg_ch_input[qInx].ch_desc_prepare = 0;
-				tx_pkt_cnt = (pg_ch_input[qInx].ch_max_tx_frame_cnt % TX_DESC_CNT);
-				/* DUT stops when tail & head become equal,
-					 prepare one extra packet for transmit */
-				tx_pkt_cnt++;
-			}
-		} else {
-			tx_pkt_cnt = TX_DESC_CNT;
-			desc_idx = 0;
-		}
-
-		for (i = 0; i < tx_pkt_cnt; i++) {
-			txptr = GET_TX_DESC_PTR(qInx, desc_idx);
-			buffer = GET_TX_BUF_PTR(qInx, desc_idx);
-			skb_data = (unsigned int *)buffer->skb->data;
-
-			if (!skb_data) {
-				printk(KERN_ALERT "ERROR: No SKB Allocated for channel\n");
-				break;
-			}
-
-			/* populate tx pg data */
-			frame_size = pg_ch_input[qInx].ch_frame_size;
-			if (qInx == 0) {
-				/* Add Ethernet header */
-				*skb_data++ = DWC_ETH_QOS_frame_hdrs[qInx][0];
-				*skb_data++ = DWC_ETH_QOS_frame_hdrs[qInx][1];
-				*skb_data++ = DWC_ETH_QOS_frame_hdrs[qInx][2];
-				*skb_data++ = DWC_ETH_QOS_frame_hdrs[qInx][3];
-				/* Add payload */
-				for (payload_cnt = 0; payload_cnt < frame_size;) {
-					*skb_data++ = DWC_ETH_QOS_FRAME_PATTERN_CH[qInx];
-					/* increment by 4 since we are writing
-					 * one dword at a time */
-					payload_cnt += 4;
-				}
-				buffer->len = frame_size;
-			} else {
-				/* Add Ethernet header */
-				*skb_data++ = DWC_ETH_QOS_frame_hdrs[qInx][0];
-				*skb_data++ = DWC_ETH_QOS_frame_hdrs[qInx][1];
-				*skb_data++ = DWC_ETH_QOS_frame_hdrs[qInx][2];
-				*skb_data++ = DWC_ETH_QOS_frame_hdrs[qInx][3];
-
-				if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB) {
-					avtype = ((avtype << 8) | (avtype >> 8)) & 0x0000FFFF;
-					*skb_data++ = (DWC_ETH_QOS_FRAME_PATTERN_CH[qInx] << 16) | avtype;
-					payload_cnt = 4;
-				} else {
-					payload_cnt = 0;
-				}
-
-				/* Add payload */
-				while (payload_cnt < frame_size) {
-					*skb_data++ = DWC_ETH_QOS_FRAME_PATTERN_CH[qInx];
-					/* increment by 4 since we are writing
-					 * one dword at a time */
-					payload_cnt += 4;
-				}
-				buffer->len = frame_size;
-			}
-
-			dma_sync_single_for_device(&pdata->pdev->dev, buffer->dma,
-					DWC_ETH_QOS_PG_FRAME_SIZE, DMA_TO_DEVICE);
-
-			if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB &&
-					pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QDCB) {
-				/* slot number preparation */
-				if (ch_tx_desc_slot_no_skip != 0) {
-					if ((desc_idx % ch_tx_desc_slot_no_skip) == 0) {
-						ch_tx_desc_slot_no_start++;
-						/* max value of slot number is 15 */
-						ch_tx_desc_slot_no_start &= 0xF;
-					}
-				}
-				buffer->slot_number = ch_tx_desc_slot_no_start;
-			}
-			else {
-				buffer->slot_number = 0;
-			}
-
-			/* prepare descriptor for transmission */
-			DWC_ETH_QOS_prepare_desc(pdata, txptr, buffer, desc_idx, qInx);
-#ifdef DWC_ETH_QOS_ENABLE_TX_PKT_DUMP
-			if (desc_idx < 1)
-				print_pkt(buffer->skb, buffer->len, 1, desc_idx);
-#endif
-			INCR_TX_DESC_INDEX(desc_idx, 1);
-		}
-
-		if (pg_ch_input[qInx].ch_debug_mode == 1) {
-			DECR_TX_DESC_INDEX(desc_idx);
-			tail_ptr = GET_TX_DESC_DMA_ADDR(qInx, desc_idx);
-			printk(KERN_ALERT "ch_desc_prepare     %d\n",
-					pg_ch_input[qInx].ch_desc_prepare);
-		}
-		else {
-			/* Updating tail pointer to one descriptor behind head pointer */
-			DMA_CHTDR_RgRd(qInx, head_ptr);
-			DMA_TDLAR_RgRd(qInx, desc_ring_ptr);
-			if ((head_ptr == 0) || (desc_ring_ptr == head_ptr)) {
-				tail_ptr = GET_TX_DESC_DMA_ADDR(qInx, tx_pkt_cnt - 1);
-			}
-			else {
-				tail_ptr = (head_ptr - sizeof(tx_descriptor_t));
-			}
-		}
-		DMA_TDTP_TPDR_RgWr(qInx, tail_ptr);
-		desc_data->dirty_tx = GET_TX_DESC_IDX(qInx, head_ptr);
-
-		printk(KERN_ALERT
-				"%d] Tail @ init    [%3llu]%#x\n"
-				"    Head @ init    [%3llu]%#x\n"
-				"    dirty_tx @ init %d\n\n",
-				qInx, GET_TX_DESC_IDX(qInx, tail_ptr), tail_ptr,
-				GET_TX_DESC_IDX(qInx, head_ptr), head_ptr,
-				desc_data->dirty_tx);
-	}
-
-	DBGPR_PG("<--DWC_ETH_QOS_prepare_tx_packets_for_pg_test\n");
-}
-
-
-/*!
-* \brief API to configure HW for PG test.
-*
-* \details This function will configures all the TX DMA channels for
-* packet generator module.
-*
-* \param[in] pdata   - pointer to private data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_prepare_hw_for_pg_test(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	struct DWC_ETH_QOS_PGStruct *pg_struct = pdata->pg;
-	unsigned int qInx;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = pg_struct->pg_ch_input;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct timespec now;
-	uint32_t varMAC_TCR = 0;
-
-	DBGPR_PG("-->DWC_ETH_QOS_prepare_hw_for_pg_test\n");
-
-	hw_if->set_tx_rx_prio_policy(pg_struct->ch_tx_rx_arb_scheme);
-	hw_if->set_tx_rx_prio(pg_struct->ch_use_tx_high_prio);
-	hw_if->set_tx_rx_prio_ratio(pg_struct->ch_tx_rx_prio_ratio);
-	hw_if->set_dma_tx_arb_algorithm(pg_struct->dma_tx_arb_algo);
-	hw_if->set_dcb_algorithm(pg_struct->queue_dcb_algorithm);
-    hw_if->config_mac_loopback_mode(pg_struct->mac_lb_mode);
-
-	/* Timer programming */
-	hw_if->config_sub_second_increment(DWC_ETH_QOS_SYSCLOCK);
-
-	varMAC_TCR = (MAC_TCR_TSENA | MAC_TCR_TSCTRLSSR);
-	hw_if->config_hw_time_stamping(varMAC_TCR);
-
-	getnstimeofday(&now);
-	hw_if->init_systime(now.tv_sec, now.tv_nsec);
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		hw_if->set_tx_queue_operating_mode(qInx, pg_ch_input[qInx].ch_operating_mode);
-
-		/* DCB parameters */
-		hw_if->set_dcb_queue_weight(qInx, pg_ch_input[qInx].ch_queue_weight);
-		hw_if->set_ch_arb_weights(qInx, pg_ch_input[qInx].ch_arb_weight);
-
-		/* Slot parameters */
-		hw_if->config_slot_num_check(qInx, pg_ch_input[qInx].ch_EnableSlotCheck);
-		hw_if->config_slot_interrupt(qInx, pg_ch_input[qInx].ch_EnableSlotCheck);
-		hw_if->set_slot_count(qInx, pg_ch_input[qInx].ch_SlotCount);
-		hw_if->config_advance_slot_num_check(qInx, pg_ch_input[qInx].ch_EnableAdvSlotCheck);
-
-		/* AVB parameters */
-		if ((pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB) && (qInx > 0)) {
-			hw_if->set_avb_algorithm(qInx, pg_ch_input[qInx].ch_avb_algorithm);
-			if (pg_ch_input[qInx].ch_avb_algorithm == eDWC_ETH_QOS_AVB_CBS) {
-				hw_if->config_credit_control(qInx, pg_ch_input[qInx].ch_CreditControl);
-				hw_if->config_send_slope(qInx, pg_ch_input[qInx].ch_SendSlope);
-				hw_if->config_idle_slope(qInx, pg_ch_input[qInx].ch_IdleSlope);
-				hw_if->config_high_credit(qInx, pg_ch_input[qInx].ch_HiCredit);
-				hw_if->config_low_credit(qInx, pg_ch_input[qInx].ch_LoCredit);
-			}
-		}
-	}
-
-	DBGPR_PG("<--DWC_ETH_QOS_prepare_hw_for_pg_test\n");
-}
-
-
-/*!
-* \brief timer function to stop tx DMA engine.
-*
-* \details This function will stop all TX DMA engine.
-*
-* \param[in] data   - pointer to private data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_pg_timer_fun(unsigned long data)
-{
-	struct DWC_ETH_QOS_prv_data *pdata = (struct DWC_ETH_QOS_prv_data *)data;
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data = NULL;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = NULL;
-	uint32_t qInx, head_ptr = 0, tail_ptr = 0, dma_dsr = 0;
-
-	printk(KERN_ALERT "-->DWC_ETH_QOS_pg_timer_fun\n");
-
-	/* allow device to transmit pending prepared packets */
-	pdata->prepare_pg_packet = Y_FALSE;
-
-	mdelay(500);
-
-	DMA_DSR0_RgRd(dma_dsr);
-	printk(KERN_ALERT "DMA Channel state: %#x\n", dma_dsr);
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		pg_ch_input = &(pdata->pg->pg_ch_input[qInx]);
-		desc_data = GET_TX_WRAPPER_DESC(qInx);
-		/* disable only that channel for which ENABLE bit is set */
-		if ((pdata->pg->ch_SelMask) & (1 << qInx)) {
-			hw_if->stop_dma_tx(qInx);
-		}
-		DMA_TDTP_TPDR_RgRd(qInx, tail_ptr);
-		DMA_CHTDR_RgRd(qInx, head_ptr);
-		printk(KERN_ALERT
-				"%d] Tail @ stop     [%3llu]%#x\n"
-				"    Head @ stop     [%3llu]%#x\n"
-				"    dirty_tx @ stop  %d\n"
-				"    ch_FramecountTx  %lu\n"
-				"    Total interrupts %d\n\n",
-				qInx, GET_TX_DESC_IDX(qInx, tail_ptr), tail_ptr,
-				GET_TX_DESC_IDX(qInx, head_ptr), head_ptr,
-				desc_data->dirty_tx,
-				pg_ch_input->ch_FramecountTx,
-				pg_ch_input->tx_interrupts);
-	}
-	// TODO: add code to disable slot interrupt except channel 0
-
-	pdata->run_test = Y_FALSE;
-
-	printk(KERN_ALERT "PG Experiment is completed ....\n"\
-		"You can retrieve the Report\n");
-	DBGPR_PG("PG Experiment is completed ....\n"\
-		"You can retrieve the Report\n");
-
-	printk(KERN_ALERT "<--DWC_ETH_QOS_pg_timer_fun\n");
-}
-
-
-/*!
-* \brief APT to start tx DMA engine.
-*
-* \details This function will prepare all TX DMA engine in advance
-* for data transfer and start all DMA TX engine.
-*
-* \param[in] data   - pointer to private data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_pg_run(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
-	unsigned int qInx;
-
-	DBGPR_PG("-->DWC_ETH_QOS_pg_run\n");
-
-	DWC_ETH_QOS_prepare_tx_packets_for_pg_test(pdata);
-
-	pdata->run_test = Y_TRUE;
-	pdata->prepare_pg_packet = Y_TRUE;
-
-	/* start pg timer before enabling the DMA's */
-	add_timer(&pdata->pg_timer);
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		/* enable only that channel for which ENABLE bit is set */
-		if ((pdata->pg->ch_SelMask) & (1 << qInx)) {
-			pdata->pg->channel_running[qInx] = Y_TRUE;
-			hw_if->start_dma_tx(qInx);
-		}
-		else {
-			pdata->pg->channel_running[qInx] = Y_FALSE;
-		}
-	}
-
-	DBGPR_PG("<--DWC_ETH_QOS_pg_run\n");
-}
-
-
-/*!
-* \brief APT to setup krnel timer function.
-*
-* \details This function setup a kernel timer function for packet
-* generator test.
-*
-* \param[in] data   - pointer to private data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_setup_timer(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	DBGPR_PG("-->DWC_ETH_QOS_setup_timer\n");
-
-	init_timer(&pdata->pg_timer);
-	pdata->pg_timer.expires = (HZ * (pdata->pg->DurationOfExp) + jiffies);
-	pdata->pg_timer.data = (unsigned long)pdata;
-	pdata->pg_timer.function = DWC_ETH_QOS_pg_timer_fun;
-
-	printk(KERN_ALERT "Test will expire at %d\n\n", (int)pdata->pg_timer.expires);
-
-	DBGPR_PG("<--DWC_ETH_QOS_setup_timer\n");
-}
-
-
-/*!
-* \brief APT to start PG test.
-*
-* \details This function will start the packet generator test. It calls
-* other driver functions which steup kernel timer, prepares descriptor
-* and start the Tx DMA.
-*
-* \param[in] pdata   - pointer to private data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_pg_run_test(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	DBGPR_PG("-->DWC_ETH_QOS_pg_run_test\n");
-
-	printk(KERN_ALERT "PG Experiment has started ....\n");
-	DWC_ETH_QOS_setup_timer(pdata);
-	DWC_ETH_QOS_pg_run(pdata);
-
-	DBGPR_PG("<--DWC_ETH_QOS_pg_run_test\n");
-}
-
-
-/*!
-* \brief APT to display PG data structure.
-*
-* \details This function will display the packet generator data structure
-* for debugging purpose. The display shows what are the configurations are
-* enabled in the device.
-*
-* \param[in] pdata   - pointer to private data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_print_pg_struct(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	struct DWC_ETH_QOS_PGStruct *pg_struct = pdata->pg;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input = pg_struct->pg_ch_input;
-	unsigned int qInx;
-	char *space = "                               ", *strptr = NULL;
-	unsigned char display_avb_params = 0, display_dcb_params = 0;
-
-	DBGPR_PG("-->DWC_ETH_QOS_print_pg_struct\n");
-
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB) {
-			display_avb_params = 1;
-			break;
-		}
-	}
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QDCB) {
-			display_dcb_params = 1;
-			break;
-		}
-	}
-
-	printk(KERN_ALERT "DurationOfExp                       = %#02x\n",
-		pg_struct->DurationOfExp);
-	printk(KERN_ALERT "ch_SelMask                          = %#02x\n",
-		pg_struct->ch_SelMask);
-	printk(KERN_ALERT "ch_tx_rx_arb_scheme                 = %#02x\n",
-		pg_struct->ch_tx_rx_arb_scheme);
-	printk(KERN_ALERT "Ch_use_tx_high_prio                 = %#02x\n",
-		pg_struct->ch_use_tx_high_prio);
-	printk(KERN_ALERT "ch_tx_rx_prio_ratio                 = %#02x\n",
-		pg_struct->ch_tx_rx_prio_ratio);
-	printk(KERN_ALERT "dma_tx_arb_algo                     = %#02x\n",
-			pg_struct->dma_tx_arb_algo);
-    printk(KERN_ALERT "mac_lb_mode                         = %#02x\n",
-			pg_struct->mac_lb_mode);
-
-	if (display_dcb_params) {
-		switch (pg_struct->queue_dcb_algorithm) {
-			case eDWC_ETH_QOS_DCB_WRR:
-				strptr = "WRR (Weighted Round Robin)";
-				break;
-			case eDWC_ETH_QOS_DCB_WFQ:
-				strptr = "WFQ (Weighted Fair Queuing)";
-				break;
-			case eDWC_ETH_QOS_DCB_DWRR:
-				strptr = "DWRR (Deficit Weighted Round Robin)";
-				break;
-			case eDWC_ETH_QOS_DCB_SP:
-				strptr = "SP (Strict Priority)";
-				break;
-		}
-		printk(KERN_ALERT "queue_dcb_algorithm                 = %s\n",
-				strptr);
-	}
-
-	printk(KERN_ALERT "PrioTagForAV (not used)             = %#02x\n",
-		pg_struct->PrioTagForAV);
-
-	printk(KERN_ALERT "ch_operating_mode\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		switch (pg_ch_input[qInx].ch_operating_mode) {
-		case eDWC_ETH_QOS_QDISABLED:
-			printk(KERN_ALERT "%s[Ch%d] = Disabled\n", space, qInx);
-			break;
-		case eDWC_ETH_QOS_QAVB:
-			printk(KERN_ALERT "%s[Ch%d] = AVB\n", space, qInx);
-			break;
-		case eDWC_ETH_QOS_QDCB:
-			printk(KERN_ALERT "%s[Ch%d] = DCB\n", space, qInx);
-			break;
-		case eDWC_ETH_QOS_QGENERIC:
-			printk(KERN_ALERT "%s[Ch%d] = Generic\n", space, qInx);
-			break;
-		}
-	}
-
-	printk(KERN_ALERT "ch_arb_weight [DMA]\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %#01x\n", space, qInx,
-				pg_ch_input[qInx].ch_arb_weight);
-	}
-	printk(KERN_ALERT "ch_bw\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %d%%\n", space, qInx,
-			pg_ch_input[qInx].ch_bw);
-	}
-
-	printk(KERN_ALERT "ch_queue_weight\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %d\n", space, qInx,
-			pg_ch_input[qInx].ch_queue_weight);
-	}
-
-	printk(KERN_ALERT "ch_frame_size\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %d\n", space, qInx,
-			pg_ch_input[qInx].ch_frame_size);
-	}
-
-	printk(KERN_ALERT "ch_EnableSlotCheck\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %s\n", space, qInx,
-			pg_ch_input[qInx].ch_EnableSlotCheck ? "YES" : "NO");
-	}
-
-	printk(KERN_ALERT "ch_EnableAdvSlotCheck\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %s\n", space, qInx,
-			pg_ch_input[qInx].ch_EnableAdvSlotCheck ? "YES" : "NO");
-	}
-
-	printk(KERN_ALERT "ch_SlotCount\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %d\n", space, qInx,
-			pg_ch_input[qInx].ch_SlotCount);
-	}
-
-	printk(KERN_ALERT "ch_tx_desc_slot_no_start\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %#01x\n", space, qInx,
-			pg_ch_input[qInx].ch_tx_desc_slot_no_start);
-	}
-
-	printk(KERN_ALERT "ch_tx_desc_slot_no_skip\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %#01x\n", space, qInx,
-			pg_ch_input[qInx].ch_tx_desc_slot_no_skip);
-	}
-
-	printk(KERN_ALERT "ch_AvgBits\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %lu\n", space, qInx,
-			pg_ch_input[qInx].ch_AvgBits);
-	}
-
-	printk(KERN_ALERT "ch_AvgBits_interrupt_count\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %lu\n", space, qInx,
-			pg_ch_input[qInx].ch_AvgBits_interrupt_count);
-	}
-
-	if (display_avb_params) {
-		printk(KERN_ALERT "ch_avb_algorithm\n");
-		for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-			if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				printk(KERN_ALERT "%s[Ch%d] = %s\n", space, qInx,
-						(pg_ch_input[qInx].ch_avb_algorithm == eDWC_ETH_QOS_AVB_SP ?
-						 "Strict Priority": "Credit Based Shaper"));
-		}
-
-		printk(KERN_ALERT "ch_CreditControl\n");
-		for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-			if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				printk(KERN_ALERT "%s[Ch%d] = %s\n", space, qInx,
-						pg_ch_input[qInx].ch_CreditControl ? "YES" : "NO");
-		}
-
-		printk(KERN_ALERT "ch_SendSlope\n");
-		for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-			if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				printk(KERN_ALERT "%s[Ch%d] = %#08x\n", space, qInx,
-						pg_ch_input[qInx].ch_SendSlope);
-		}
-
-		printk(KERN_ALERT "ch_IdleSlope\n");
-		for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-			if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				printk(KERN_ALERT "%s[Ch%d] = %#08x\n", space, qInx,
-						pg_ch_input[qInx].ch_IdleSlope);
-		}
-
-		printk(KERN_ALERT "ch_HiCredit\n");
-		for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-			if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				printk(KERN_ALERT "%s[Ch%d] = %#08x\n", space, qInx,
-						pg_ch_input[qInx].ch_HiCredit);
-		}
-
-		printk(KERN_ALERT "ch_LoCredit\n");
-		for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-			if (pg_ch_input[qInx].ch_operating_mode == eDWC_ETH_QOS_QAVB)
-				printk(KERN_ALERT "%s[Ch%d] = %#08x\n", space, qInx,
-						pg_ch_input[qInx].ch_LoCredit);
-		}
-	}
-
-	printk(KERN_ALERT "ch_FramecountTx\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %lu\n", space, qInx,
-			pg_ch_input[qInx].ch_FramecountTx);
-	}
-
-	printk(KERN_ALERT "ch_FramecountRx\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[Ch%d] = %lu\n", space, qInx,
-			pg_ch_input[qInx].ch_FramecountRx);
-	}
-
-	printk(KERN_ALERT "Debug mode\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[CH%d]  %s\n",
-			space, qInx, (pg_ch_input[qInx].ch_debug_mode ? "YES" : "NO"));
-	}
-
-	printk(KERN_ALERT "Maximum Tx packet count\n");
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		printk(KERN_ALERT "%s[CH%d]  %d\n",
-			space, qInx, pg_ch_input[qInx].ch_max_tx_frame_cnt);
-	}
-
-	DBGPR_PG("<--DWC_ETH_QOS_print_pg_struct\n");
-}
-
-
-/*!
-* \brief APT to sync the kernel and user data structure.
-*
-* \details This function is invoked by IOCTL function when the user
-* issues a command to synchronize the user space data structure to
-* kernel space data structure.
-*
-* \param[in] pdata   - pointer to private data structure
-* \param[in] req   - pointer to IOCTL specific data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_pg_set_config(struct DWC_ETH_QOS_prv_data *pdata,
-					struct ifr_data_struct *req)
-{
-	struct DWC_ETH_QOS_PGStruct l_pg_struct;
-	struct DWC_ETH_QOS_PGStruct *user_pg_struct =
-		(struct DWC_ETH_QOS_PGStruct *)req->ptr;
-	struct DWC_ETH_QOS_PGStruct *pg_struct = pdata->pg;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input =
-		pg_struct->pg_ch_input;
-	unsigned int qInx;
-
-	DBGPR_PG("-->DWC_ETH_QOS_pg_set_config\n");
-
-	/* First, copy contents of user info in a local structure */
-	if(copy_from_user(&l_pg_struct, user_pg_struct,
-				sizeof(struct DWC_ETH_QOS_PGStruct)))
-		printk(KERN_ALERT "Failed to fetch PG Struct info from user\n");
-
-	/* Second, copy required members into kernel structure */
-	copy_PGStruct_members(pg_struct, &l_pg_struct);
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		copy_pg_ch_input_members(&(pg_ch_input[qInx]), &(l_pg_struct.pg_ch_input[qInx]));
-	}
-
-	DWC_ETH_QOS_print_pg_struct(pdata);
-
-	DBGPR_PG("<--DWC_ETH_QOS_pg_set_config\n");
-}
-
-
-/*!
-* \brief APT to sync the kernel and user data structure.
-*
-* \details This function is invoked by IOCTL function when the user
-* issue a command to get the packet generator data. This function
-* will copy kernel data structure into user data structure.
-*
-* \param[in] pdata   - pointer to private data structure
-* \param[in] req   - pointer to IOCTL specific data structure
-*
-* \return void
-*/
-static void DWC_ETH_QOS_pg_get_result(struct DWC_ETH_QOS_prv_data *pdata,
-					struct ifr_data_struct *req)
-{
-	struct DWC_ETH_QOS_PGStruct l_pg_struct;
-	struct DWC_ETH_QOS_PGStruct *user_pg_struct =
-		(struct DWC_ETH_QOS_PGStruct *)req->ptr;
-	struct DWC_ETH_QOS_PGStruct *pg_struct = pdata->pg;
-	struct DWC_ETH_QOS_pg_ch_input *pg_ch_input =
-		pg_struct->pg_ch_input;
-	unsigned int qInx;
-
-	DBGPR_PG("-->DWC_ETH_QOS_pg_get_result\n");
-	copy_PGStruct_members(&l_pg_struct, pg_struct);
-	l_pg_struct.speed_100M_1G = pdata->speed;/* Update the speed information */
-	printk(KERN_CRIT "l_pg_struct->speed_100M_1G: %d\n",l_pg_struct.speed_100M_1G);
-	for (qInx = 0; qInx < DWC_ETH_QOS_TX_QUEUE_CNT; qInx++) {
-		copy_pg_ch_input_members(&(l_pg_struct.pg_ch_input[qInx]), &(pg_ch_input[qInx]));
-	}
-	if (copy_to_user(user_pg_struct, &l_pg_struct, sizeof(struct DWC_ETH_QOS_PGStruct)))
-		printk(KERN_ALERT "Failed to send PG Struct info to user\n");
-
-	DBGPR_PG("<--DWC_ETH_QOS_pg_get_result\n");
-}
-
-/*!
-* \brief IOCTL function to handle user request.
-*
-* \details This function is invoked by IOCTL function when the user
-* issues a command to get the packet generator data. This function
-* will copy kernel data structure into user data structure.
-*
-* \param[in] pdata   - pointer to private data structure
-* \param[in] ptr   - pointer to IOCTL specific data structure
-*
-* \return zero on success and -ve number on failure.
-*/
-int DWC_ETH_QOS_handle_pg_ioctl(struct DWC_ETH_QOS_prv_data *pdata,
-				void *ptr)
-{
-	struct ifr_data_struct *req = ptr;
-	int ret = 0;
-
-	DBGPR_PG("-->DWC_ETH_QOS_handle_pg_ioctl\n");
-
-	switch (req->flags) {
-	case DWC_ETH_QOS_PG_SET_CONFIG:
-		DWC_ETH_QOS_pg_set_config(pdata, req);
-		break;
-	case DWC_ETH_QOS_PG_CONFIG_HW:
-		DWC_ETH_QOS_prepare_hw_for_pg_test(pdata);
-		DWC_ETH_QOS_prepare_tx_packets_for_pg_test(pdata);
-		printk(KERN_ALERT "\nCONFIGURING THE HW FOR PG ....\n");
-		break;
-	case DWC_ETH_QOS_PG_RUN_TEST:
-		DWC_ETH_QOS_pg_run_test(pdata);
-		printk(KERN_ALERT "PG RUN TEST STARTED ....\n");
-		break;
-	case DWC_ETH_QOS_PG_GET_RESULT:
-		DWC_ETH_QOS_pg_get_result(pdata, req);
-		break;
-	case DWC_ETH_QOS_PG_TEST_DONE:
-		req->test_done = pdata->run_test;
-		break;
-	default:
-		printk(KERN_ALERT "Wrong Parameter for PG TEST\n");
-		ret = -EINVAL;
-	}
-
-	DBGPR_PG("<--DWC_ETH_QOS_handle_pg_ioctl\n");
-
-	return ret;
-}
-
-
-/*!
-* \brief API to allocate local data structure.
-*
-* \details This function is used to allocate local data structure
-* for handling packet generator module.
-*
-* \param[in] pdata   - pointer to private data structure
-*
-* \return zero on success and -ve number on failure.
-*/
-int DWC_ETH_QOS_alloc_pg(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	DBGPR_PG("-->DWC_ETH_QOS_alloc_pg\n");
-
-	pdata->pg = kzalloc(sizeof(struct DWC_ETH_QOS_PGStruct), GFP_KERNEL);
-	if (pdata->pg == NULL) {
-		printk(KERN_ALERT "%s:Unable to alloc pg structure\n", DEV_NAME);
-		return -ENOMEM;
-	}
-
-	DBGPR_PG("<--DWC_ETH_QOS_alloc_pg\n");
-
-	return 0;
-}
-
-
-/*!
-* \brief API to free local data structure.
-*
-* \details This function is used to free the local data structure
-* which is allocated for handling packet generator module.
-*
-* \param[in] pdata   - pointer to private data structure
-*
-* \return void
-*/
-void DWC_ETH_QOS_free_pg(struct DWC_ETH_QOS_prv_data *pdata)
-{
-	DBGPR_PG("-->DWC_ETH_QOS_free_pg\n");
-
-	//kfree(pdata->pg->pg_ch_input);
-	kfree(pdata->pg);
-
-	DBGPR_PG("<--DWC_ETH_QOS_free_pg\n");
-}
-
-
-/*!
-* \brief API to allocate tx buffer.
-*
-* \details This function is used to allocate tx buffer for data
-* transmission.
-*
-* \param[in] pdata   - pointer to private data structure
-* \param[in] buffer  - pointer to tx buffer data structure
-* \param[in] gfp     - type of memory allocation.
-*
-* \return zero on success and -ve number on failure.
-*/
-int DWC_ETH_QOS_alloc_tx_buf_pg(struct DWC_ETH_QOS_prv_data *pdata,
-				struct DWC_ETH_QOS_tx_buffer *buffer,
-				gfp_t gfp)
-{
-	struct sk_buff *skb = NULL;
-
-	//DBGPR_PG("-->DWC_ETH_QOS_alloc_tx_buf_pg\n");
-
-	skb = dev_alloc_skb(DWC_ETH_QOS_PG_FRAME_SIZE);
-	if (skb == NULL) {
-		printk(KERN_ALERT "Failed to allocate tx skb\n");
-		return -ENOMEM;
-	}
-	buffer->skb = skb;
-	buffer->len = DWC_ETH_QOS_PG_FRAME_SIZE;
-	buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
-				     DWC_ETH_QOS_PG_FRAME_SIZE, DMA_TO_DEVICE);
-	if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
-		printk(KERN_ALERT "failed to do the TX dma map\n");
-
-	buffer->buf1_mapped_as_page = Y_FALSE;
-
-	//DBGPR_PG("<--DWC_ETH_QOS_alloc_tx_buf_pg\n");
-
-	return 0;
-}
-
-
-/*!
-* \brief API to allocate rx buffer.
-*
-* \details This function is used to allocate rx buffer for data
-* receive by device.
-*
-* \param[in] pdata   - pointer to private data structure
-* \param[in] buffer  - pointer to rx buffer data structure
-* \param[in] gfp     - type of memory allocation.
-*
-* \return zero on success and -ve number on failure.
-*/
-int DWC_ETH_QOS_alloc_rx_buf_pg(struct DWC_ETH_QOS_prv_data *pdata,
-				struct DWC_ETH_QOS_rx_buffer *buffer,
-				gfp_t gfp)
-{
-	struct sk_buff *skb = NULL;
-
-	//DBGPR_PG("-->DWC_ETH_QOS_alloc_rx_buf_pg\n");
-
-	skb = dev_alloc_skb(DWC_ETH_QOS_PG_FRAME_SIZE);
-	if (skb == NULL) {
-		printk(KERN_ALERT "Failed to allocate tx skb\n");
-		return -ENOMEM;
-	}
-	buffer->skb = skb;
-	buffer->len = DWC_ETH_QOS_PG_FRAME_SIZE;
-	buffer->dma = dma_map_single(&pdata->pdev->dev, skb->data,
-				     DWC_ETH_QOS_PG_FRAME_SIZE, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&pdata->pdev->dev, buffer->dma))
-		printk(KERN_ALERT "failed to do the RX dma map\n");
-
-	buffer->mapped_as_page = Y_FALSE;
-	wmb();
-
-	//DBGPR_PG("<--DWC_ETH_QOS_alloc_rx_buf_pg\n");
-
-	return 0;
-}
-
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pktgen.h b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pktgen.h
deleted file mode 100644
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_pktgen.h
+++ /dev/null
@@ -1,67 +0,0 @@
-/* =========================================================================
- * The Synopsys DWC ETHER QOS Software Driver and documentation (hereinafter
- * "Software") is an unsupported proprietary work of Synopsys, Inc. unless
- * otherwise expressly agreed to in writing between Synopsys and you.
- *
- * The Software IS NOT an item of Licensed Software or Licensed Product under
- * any End User Software License Agreement or Agreement for Licensed Product
- * with Synopsys or any supplement thereto.  Permission is hereby granted,
- * free of charge, to any person obtaining a copy of this software annotated
- * with this license and the Software, to deal in the Software without
- * restriction, including without limitation the rights to use, copy, modify,
- * merge, publish, distribute, sublicense, and/or sell copies of the Software,
- * and to permit persons to whom the Software is furnished to do so, subject
- * to the following conditions:
- *
- * The above copyright notice and this permission notice shall be included in
- * all copies or substantial portions of the Software.
- *
- * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
- * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
- * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
- * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
- * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
- * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
- * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
- * DAMAGE.
- * ========================================================================= */
-
-#ifndef __DWC_ETH_QOS_YPG_H__
-
-#define __DWC_ETH_QOS_YPG_H__
-
-static void DWC_ETH_QOS_tx_interrupt_pg(struct DWC_ETH_QOS_prv_data *pdata,
-				     uint32_t qInx);
-
-static void DWC_ETH_QOS_prepare_desc(struct DWC_ETH_QOS_prv_data *pdata,
-				tx_descriptor_t *txptr,
-				struct DWC_ETH_QOS_tx_buffer *buffer,
-				int i,
-				unsigned int qInx);
-
-static int DWC_ETH_QOS_poll_pg_sq(struct DWC_ETH_QOS_prv_data *pdata,
-					unsigned int qInx);
-
-static void DWC_ETH_QOS_poll_pg(struct DWC_ETH_QOS_prv_data *pdata);
-
-static void DWC_ETH_QOS_prepare_hw_for_pg_test(struct DWC_ETH_QOS_prv_data *pdata);
-
-static void DWC_ETH_QOS_pg_timer_fun(unsigned long data);
-
-static void DWC_ETH_QOS_pg_run(struct DWC_ETH_QOS_prv_data *pdata);
-
-static void DWC_ETH_QOS_setup_timer(struct DWC_ETH_QOS_prv_data *pdata);
-
-static void DWC_ETH_QOS_pg_run_test(struct DWC_ETH_QOS_prv_data *pdata);
-
-static void DWC_ETH_QOS_print_pg_struct(struct DWC_ETH_QOS_prv_data *pdata);
-
-static void DWC_ETH_QOS_pg_set_config(struct DWC_ETH_QOS_prv_data *pdata,
-					struct ifr_data_struct *req);
-
-static void DWC_ETH_QOS_pg_get_result(struct DWC_ETH_QOS_prv_data *pdata,
-					struct ifr_data_struct *req);
-#endif
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_ptp.c b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_ptp.c
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_ptp.c
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_ptp.c
@@ -53,7 +53,7 @@ static int DWC_ETH_QOS_adjust_freq(struc
 {
 	struct DWC_ETH_QOS_prv_data *pdata =
 		container_of(ptp, struct DWC_ETH_QOS_prv_data, ptp_clock_ops);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	unsigned long flags;
 	uint64_t adj;
 	uint32_t diff, addend;
@@ -106,7 +106,7 @@ static int DWC_ETH_QOS_adjust_time(struc
 {
 	struct DWC_ETH_QOS_prv_data *pdata =
 		container_of(ptp, struct DWC_ETH_QOS_prv_data, ptp_clock_ops);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	unsigned long flags;
 	uint32_t sec, nsec;
 	uint32_t quotient, reminder;
@@ -154,7 +154,7 @@ static int DWC_ETH_QOS_get_time(struct p
 {
 	struct DWC_ETH_QOS_prv_data *pdata =
 		container_of(ptp, struct DWC_ETH_QOS_prv_data, ptp_clock_ops);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	uint64_t ns;
 	uint32_t reminder;
 	unsigned long flags;
@@ -196,7 +196,7 @@ static int DWC_ETH_QOS_set_time(struct p
 {
 	struct DWC_ETH_QOS_prv_data *pdata =
 		container_of(ptp, struct DWC_ETH_QOS_prv_data, ptp_clock_ops);
-	struct hw_if_struct *hw_if = &(pdata->hw_if);
+	hw_interface_t *hw_if = &(pdata->hw_if);
 	unsigned long flags;
 
 	DBGPR_PTP("-->DWC_ETH_QOS_set_time: ts->tv_sec = %ld,"
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yapphdr.h b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yapphdr.h
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yapphdr.h
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yapphdr.h
@@ -387,182 +387,4 @@ struct DWC_ETH_QOS_config_ptpoffloading 
 	int mc_uc;
 };
 
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-
-/* uncomment below macro to enable application
- * to record all run reports to file */
-//#define PGTEST_LOGFILE
-
-/* TX DMA CHANNEL Weights */
-#define DWC_ETH_QOS_TX_CH_WEIGHT1	0x0
-#define DWC_ETH_QOS_TX_CH_WEIGHT2	0x1
-#define DWC_ETH_QOS_TX_CH_WEIGHT3	0x2
-#define DWC_ETH_QOS_TX_CH_WEIGHT4	0x3
-#define DWC_ETH_QOS_TX_CH_WEIGHT5	0x4
-#define DWC_ETH_QOS_TX_CH_WEIGHT6	0x5
-#define DWC_ETH_QOS_TX_CH_WEIGHT7	0x6
-#define DWC_ETH_QOS_TX_CH_WEIGHT8	0x7
-
-/* PG test sub commands macro's */
-#define DWC_ETH_QOS_PG_SET_CONFIG	0x1
-#define DWC_ETH_QOS_PG_CONFIG_HW	  0x2
-#define DWC_ETH_QOS_PG_RUN_TEST		0x3
-#define DWC_ETH_QOS_PG_GET_RESULT	0x4
-#define DWC_ETH_QOS_PG_TEST_DONE	0x5
-
-
-/* DMA channel bandwidth allocation parameters */
-struct DWC_ETH_QOS_pg_user_ch_input {
-	unsigned char ch_arb_weight;	/* Channel weights(1/2/3/4/5/6/7/8) for arbitration */
-	unsigned int ch_fr_size;	/* Channel Frame size */
-	unsigned char ch_bw_alloc;	/* The percentage bandwidth allocation for ch */
-
-	unsigned char ch_use_slot_no_check;	/* Should Ch use slot number checking ? */
-	unsigned char ch_use_adv_slot_no_check;
-	unsigned char ch_slot_count_to_use;	/* How many slot used to report pg bits per slot value */
-
-	unsigned char ch_use_credit_shape;	/* Should Ch use Credid shape algorithm for traffic shaping ? */
-	unsigned char ch_CreditControl;	/* Sould Ch use Credit Control algorithm for traffic shaping ? */
-
-	unsigned char ch_tx_desc_slot_no_start;
-	unsigned char ch_tx_desc_slot_no_skip;
-	unsigned char ch_operating_mode;
-	unsigned long ch_AvgBits;
-	unsigned long ch_AvgBits_interrupt_count;
-	unsigned char ch_avb_algorithm;
-	unsigned char ch_debug_mode; /* enable/disable debug mode */
-	unsigned int ch_max_tx_frame_cnt; /* maximum pkts to be sent on this channel, can be used for debug purpose */
-};
-
-struct DWC_ETH_QOS_pg_user_input {
-	unsigned char duration_of_exp;
-	/* enable bits for DMA. bit0=>ch0, bit1=>ch1, bit2=>ch2 */
-	unsigned char dma_ch_en;
-
-	unsigned char ch_tx_rx_arb_scheme;	/* Should Ch use Weighted RR policy with Rx:Tx/Tx:Rx or Fixed Priority */
-	unsigned char ch_use_tx_high_prio;	/* Should Ch Tx have High priority over Rx */
-	unsigned char ch_tx_rx_prio_ratio;	/* For RR what is the ratio between Tx:Rx/Rx:Tx */
-	unsigned char dma_tx_arb_algo; /* Refer DMA Mode register TAA field */
-
-	unsigned char queue_dcb_algorithm;
-
-	unsigned char mac_lb_mode; /* 0 => No MAC Loopback; 1 => MAC Loopback On */
-	unsigned int speed_100M_1G; /* 0 => No MAC Loopback; 1 => MAC Loopback On */
-
-	struct DWC_ETH_QOS_pg_user_ch_input ch_input[DWC_ETH_QOS_MAX_TX_QUEUE_CNT];
-};
-
-#define copy_pg_ch_input_members(to, from) do { \
-	(to)->interrupt_prints = (from)->interrupt_prints; \
-	(to)->tx_interrupts = (from)->tx_interrupts; \
-	(to)->ch_arb_weight = (from)->ch_arb_weight; \
-	(to)->ch_queue_weight = (from)->ch_queue_weight; \
-	(to)->ch_bw = (from)->ch_bw; \
-	(to)->ch_frame_size = (from)->ch_frame_size; \
-	(to)->ch_EnableSlotCheck = (from)->ch_EnableSlotCheck; \
-	(to)->ch_EnableAdvSlotCheck = (from)->ch_EnableAdvSlotCheck; \
-	(to)->ch_avb_algorithm = (from)->ch_avb_algorithm; \
-	(to)->ch_SlotCount = (from)->ch_SlotCount; \
-	(to)->ch_AvgBits = (from)->ch_AvgBits; \
-	(to)->ch_AvgBits_interrupt_count = (from)->ch_AvgBits_interrupt_count; \
-	(to)->ch_CreditControl = (from)->ch_CreditControl; \
-	(to)->ch_tx_desc_slot_no_start = (from)->ch_tx_desc_slot_no_start; \
-	(to)->ch_tx_desc_slot_no_skip = (from)->ch_tx_desc_slot_no_skip; \
-	(to)->ch_SendSlope = (from)->ch_SendSlope; \
-	(to)->ch_IdleSlope = (from)->ch_IdleSlope; \
-	(to)->ch_HiCredit = (from)->ch_HiCredit; \
-	(to)->ch_LoCredit = (from)->ch_LoCredit; \
-	(to)->ch_FramecountTx = (from)->ch_FramecountTx; \
-	(to)->ch_FramecountRx = (from)->ch_FramecountRx; \
-	(to)->ch_operating_mode = (from)->ch_operating_mode; \
-	(to)->ch_debug_mode = (from)->ch_debug_mode;\
-	(to)->ch_max_tx_frame_cnt = (from)->ch_max_tx_frame_cnt;\
-} while (0)
-
-struct DWC_ETH_QOS_pg_ch_input {
-	unsigned int interrupt_prints;
-	unsigned int tx_interrupts;
-	unsigned char ch_arb_weight;
-	unsigned int ch_queue_weight;
-	unsigned char ch_bw;
-	unsigned int ch_frame_size;
-	unsigned char ch_EnableSlotCheck;	/* Enable checking of slot numbers programmed in the Tx Desc */
-	unsigned char ch_EnableAdvSlotCheck;	/* When Set Data fetched for current slot and for next 2 slots in advance
-						When reset data fetched for current slot and in advance for next slot*/
-
-	unsigned char ch_avb_algorithm;
-	unsigned char ch_SlotCount;	/* Over which transmiteed bits per slot needs to be computed (Only for Credit based shaping) */
-	unsigned long ch_AvgBits;
-	unsigned long ch_AvgBits_interrupt_count;
-
-	unsigned char ch_CreditControl;	/* Will be zero (Not used) */
-
-	unsigned char ch_tx_desc_slot_no_start;
-	unsigned char ch_tx_desc_slot_no_skip;
-
-	unsigned int ch_SendSlope;
-	unsigned int ch_IdleSlope;
-	unsigned int ch_HiCredit;
-	unsigned int ch_LoCredit;
-
-	unsigned long ch_FramecountTx;	/* No of Frames Transmitted on Channel 1 */
-	unsigned long ch_FramecountRx;	/* No of Frames Received on Channel 1 */
-	unsigned char ch_operating_mode;
-
-	unsigned char ch_debug_mode; /* enable/disable debug mode */
-	unsigned int ch_max_tx_frame_cnt; /* maximum pkts to be sent on this channel, can be used for debug purpose */
-	unsigned int ch_desc_prepare; /* max packets which will be reprepared in Tx-interrupt
- 																	 do not copy contents to app-copy, only driver should use this variable*/
-};
-
-#define copy_PGStruct_members(to, from)	do { \
-	(to)->ch_SelMask = (from)->ch_SelMask; \
-	(to)->DurationOfExp = (from)->DurationOfExp; \
-	(to)->PrioTagForAV = (from)->PrioTagForAV; \
-	(to)->queue_dcb_algorithm = (from)->queue_dcb_algorithm; \
-	(to)->ch_tx_rx_arb_scheme = (from)->ch_tx_rx_arb_scheme; \
-	(to)->ch_use_tx_high_prio = (from)->ch_use_tx_high_prio; \
-	(to)->ch_tx_rx_prio_ratio = (from)->ch_tx_rx_prio_ratio; \
-	(to)->dma_tx_arb_algo = (from)->dma_tx_arb_algo; \
-	(to)->mac_lb_mode = (from)->mac_lb_mode; \
-} while (0)
-
-struct DWC_ETH_QOS_PGStruct {
-	/* This gives which DMA channel is enabled and which is disabled
-	 * Bit0 for Ch0
-	 * Bit1 for Ch1
-	 * Bit2 for Ch2 and so on
-	 * Bit7 for Ch7
-	 * */
-	unsigned char ch_SelMask;
-
-	/* Duration for which experiment should be conducted in minutes - Default 2 Minutes */
-	unsigned char DurationOfExp;
-
-	/* Used when more than One channel enabled in Rx path (Not Used)
-	 * for only CH1 Enabled:
-	 * Frames sith Priority > Value programmed, frames sent to CH1
-	 * Frames with priority < Value programmed are sent to CH0
-	 *
-	 * For both CH1 and CH2 Enabled:
-	 * Frames sith Priority > Value programmed, frames sent to CH2
-	 * Frames with priority < Value programmed are sent to CH
-	 * */
-	unsigned char PrioTagForAV;
-
-	unsigned char queue_dcb_algorithm;
-
-	unsigned char ch_tx_rx_arb_scheme;	/* Should Ch use Weighted RR policy with Rx:Tx/Tx:Rx or Fixed Priority */
-	unsigned char ch_use_tx_high_prio;	/* Should Ch Tx have High priority over Rx */
-	unsigned char ch_tx_rx_prio_ratio;	/* For RR what is the ratio between Tx:Rx/Rx:Tx */
-	unsigned char dma_tx_arb_algo; /* Refer DMA Mode register TAA field */
-
-	unsigned char mac_lb_mode; /* 0 => No MAC Loopback; 1 => MAC Loopback On */
-	unsigned int speed_100M_1G;
-	struct DWC_ETH_QOS_pg_ch_input pg_ch_input[DWC_ETH_QOS_MAX_TX_QUEUE_CNT];
-	unsigned char channel_running[DWC_ETH_QOS_MAX_TX_QUEUE_CNT];
-};
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 #endif
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yheader.h b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yheader.h
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yheader.h
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yheader.h
@@ -94,10 +94,6 @@
 #define MAC_VER_4_00	0x40
 #define MAC_VER_4_10	0x41
 
-#ifdef CONFIG_PGTEST_OBJ
-#define DWC_ETH_QOS_CONFIG_PGTEST
-#endif
-
 #ifdef CONFIG_PTPSUPPORT_OBJ
 #define DWC_ETH_QOS_CONFIG_PTP
 #endif
@@ -106,20 +102,6 @@
 #define DWC_ETH_QOS_CONFIG_DEBUGFS
 #endif
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-
-#define DWC_ETH_QOS_DA_SA 12
-#define DWC_ETH_QOS_TYPE 2
-#define DWC_ETH_QOS_VLAN_TAG 4
-#define DWC_ETH_QOS_ETH_HDR_AVB (DWC_ETH_QOS_DA_SA + \
-		DWC_ETH_QOS_TYPE + \
-		DWC_ETH_QOS_VLAN_TAG)
-
-#define DWC_ETH_QOS_PG_FRAME_SIZE (pdata->dev->mtu + DWC_ETH_QOS_ETH_HDR_AVB)
-#define DWC_ETH_QOS_AVTYPE 0x22f0
-
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 /* NOTE: Uncomment below line for TX and RX DESCRIPTOR DUMP in KERNEL LOG */
 //#define DWC_ETH_QOS_ENABLE_RX_DESC_DUMP
 
@@ -131,8 +113,9 @@
 
 /* Enable polling GBE ISR status registers */
 //#define GBE_POLLING
-/* Enable polling GBE debug logic */
-//#define GBE_DEBUG
+
+/* Enable GBE debug logic */
+#define GBE_DEBUG
 
 #ifdef DWC_ETH_QOS_CONFIG_PTP
 #undef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
@@ -150,11 +133,6 @@
 #undef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
 #endif
 
-
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-#undef DWC_ETH_QOS_TXPOLLING_MODE_ENABLE
-#endif
-
 #ifdef DWC_ETH_QOS_CERTIFICATION_PKTBURSTCNT_HALFDUPLEX
 #define DWC_ETH_QOS_CERTIFICATION_PKTBURSTCNT
 #endif
@@ -248,17 +226,19 @@
 #define DWC_ETH_QOS_Q_DCB 			0x2
 #define DWC_ETH_QOS_Q_GENERIC 		0x3
 
-/* Driver PMT macros */
-#define DWC_ETH_QOS_DRIVER_CONTEXT 1
-#define DWC_ETH_QOS_IOCTL_CONTEXT 2
-#define DWC_ETH_QOS_MAGIC_WAKEUP	(1 << 0)
-#define DWC_ETH_QOS_REMOTE_WAKEUP	(1 << 1)
-#define DWC_ETH_QOS_POWER_DOWN_TYPE(x)	\
-		((x->power_down_type & DWC_ETH_QOS_MAGIC_WAKEUP) ? \
-		"Magic packet" : \
-		((x->power_down_type & DWC_ETH_QOS_REMOTE_WAKEUP) ? \
-		"Remote wakeup packet" : \
-		"<error>"))
+/* Driver power status macros */
+#define DWC_ETH_QOS_POWER_ON           (0)
+#define DWC_ETH_QOS_MAGIC_WAKEUP       (1 << 0)
+#define DWC_ETH_QOS_REMOTE_WAKEUP      (1 << 1)
+#define DWC_ETH_QOS_NETIP_WAKEUP       (1 << 2)
+#define DWC_ETH_QOS_NETIP_PWRDWN       (1 << 3) // Intermediate state to indicate
+                                                // the device is going to StandBy mode
+#define DWC_ETH_QOS_NETIP_PWRUP        (1 << 4) // Intermediate state to indicate
+                                                // the device is exiting the StandBy mode
+#define DWC_ETH_QOS_NETIP_SPLHDR_REQ   (1 << 5) // Indicate a split header change was
+                                                // received while device was in StandBy mode
+#define DWC_ETH_QOS_NETIP_MTU_REQ      (1 << 6) // Indicate a mtu change request was
+                                                // received while device was in StandBy mode
 
 #define DWC_ETH_QOS_MAC_ADDR_LEN 6
 #define DWC_ETH_QOS_ETH_FRAME_LEN (ETH_FRAME_LEN + ETH_FCS_LEN + VLAN_HLEN)
@@ -492,7 +472,13 @@ typedef enum {
 struct DWC_ETH_QOS_prv_data;
 struct DWC_ETH_QOS_tx_wrapper_descriptor;
 
-struct hw_if_struct {
+typedef struct {
+   uint32_t mac_ier;
+   uint32_t dma_ier;
+   // TODO: Add descriptors configuration to save time in Tx and Rx operations
+} hw_config_t;
+
+typedef struct {
 
 	int(*tx_complete) (tx_descriptor_t *);
 	int(*tx_window_error) (tx_descriptor_t *);
@@ -528,7 +514,7 @@ struct hw_if_struct {
 	int(*stop_mac_tx_rx) (void);
 
 	int(*init) (struct DWC_ETH_QOS_prv_data *);
-	int(*exit) (void);
+	int(*sw_reset) (void);
 
 	void (*pre_xmit) (struct DWC_ETH_QOS_prv_data *, uint32_t qInx);
 	void (*dev_read) (struct DWC_ETH_QOS_prv_data *, uint32_t qInx);
@@ -536,54 +522,54 @@ struct hw_if_struct {
 	void (*rx_desc_init) (struct DWC_ETH_QOS_prv_data *, uint32_t qInx);
 	void (*rx_desc_reset) (uint32_t, struct DWC_ETH_QOS_prv_data *,
 			       uint32_t, uint32_t qInx);
-	 int(*tx_desc_reset) (uint32_t, struct DWC_ETH_QOS_prv_data *, uint32_t qInx);
-	/* last tx segmnet reports the tx status */
-	 int(*get_tx_desc_ls) (tx_descriptor_t *);
-	 int(*get_tx_desc_ctxt) (tx_descriptor_t *);
-	void (*update_rx_tail_ptr) (unsigned int qInx, unsigned int dma_addr);
+   int(*tx_desc_reset) (uint32_t, struct DWC_ETH_QOS_prv_data *, uint32_t qInx);
+   /* last tx segmnet reports the tx status */
+   int(*get_tx_desc_ls) (tx_descriptor_t *);
+   int(*get_tx_desc_ctxt) (tx_descriptor_t *);
+   void (*update_rx_tail_ptr) (unsigned int qInx, unsigned int dma_addr);
 
-	/* for FLOW ctrl */
-	 int(*enable_rx_flow_ctrl) (void);
-	 int(*disable_rx_flow_ctrl) (void);
-	 int(*enable_tx_flow_ctrl) (uint32_t);
-	 int(*disable_tx_flow_ctrl) (uint32_t);
+   /* for FLOW ctrl */
+   int(*enable_rx_flow_ctrl) (void);
+   int(*disable_rx_flow_ctrl) (void);
+   int(*enable_tx_flow_ctrl) (uint32_t);
+   int(*disable_tx_flow_ctrl) (uint32_t);
 
-	/* for PMT operations */
-	 int(*enable_magic_pmt) (void);
-	 int(*disable_magic_pmt) (void);
-	 int(*enable_remote_pmt) (void);
-	 int(*disable_remote_pmt) (void);
-	 int(*configure_rwk_filter) (uint32_t *, uint32_t);
+   /* for PMT operations */
+   int(*enable_magic_pmt) (void);
+   int(*disable_magic_pmt) (void);
+   int(*enable_remote_pmt) (void);
+   int(*disable_remote_pmt) (void);
+   int(*configure_rwk_filter) (uint32_t *, uint32_t);
 
-	/* for RX watchdog timer */
-	 int(*config_rx_watchdog) (uint32_t, uint32_t riwt);
+   /* for RX watchdog timer */
+   int(*config_rx_watchdog) (uint32_t, uint32_t riwt);
 
-	/* for RX and TX threshold config */
-	 int(*config_rx_threshold) (uint32_t ch_no, uint32_t val);
-	 int(*config_tx_threshold) (uint32_t ch_no, uint32_t val);
+   /* for RX and TX threshold config */
+   int(*config_rx_threshold) (uint32_t ch_no, uint32_t val);
+   int(*config_tx_threshold) (uint32_t ch_no, uint32_t val);
 
-	/* for RX and TX Store and Forward Mode config */
-	 int(*config_rsf_mode) (uint32_t ch_no, uint32_t val);
-	 int(*config_tsf_mode) (uint32_t ch_no, uint32_t val);
+   /* for RX and TX Store and Forward Mode config */
+   int(*config_rsf_mode) (uint32_t ch_no, uint32_t val);
+   int(*config_tsf_mode) (uint32_t ch_no, uint32_t val);
 
-	/* for TX DMA Operate on Second Frame config */
-	 int(*config_osf_mode) (uint32_t ch_no, uint32_t val);
+   /* for TX DMA Operate on Second Frame config */
+   int(*config_osf_mode) (uint32_t ch_no, uint32_t val);
 
-	/* for INCR/INCRX config */
-	 int(*config_incr_incrx_mode) (uint32_t val);
-	/* for AXI PBL config */
-	int(*config_axi_pbl_val) (uint32_t val);
-	/* for AXI WORL config */
-	int(*config_axi_worl_val) (uint32_t val);
-	/* for AXI RORL config */
-	int(*config_axi_rorl_val) (uint32_t val);
+   /* for INCR/INCRX config */
+   int(*config_incr_incrx_mode) (uint32_t val);
+   /* for AXI PBL config */
+   int(*config_axi_pbl_val) (uint32_t val);
+   /* for AXI WORL config */
+   int(*config_axi_worl_val) (uint32_t val);
+   /* for AXI RORL config */
+   int(*config_axi_rorl_val) (uint32_t val);
 
 	/* for RX and TX PBL config */
-	 int(*config_rx_pbl_val) (uint32_t ch_no, uint32_t val);
-	 int(*get_rx_pbl_val) (uint32_t ch_no);
-	 int(*config_tx_pbl_val) (uint32_t ch_no, uint32_t val);
-	 int(*get_tx_pbl_val) (uint32_t ch_no);
-	 int(*config_pblx8) (uint32_t ch_no, uint32_t val);
+   int(*config_rx_pbl_val) (uint32_t ch_no, uint32_t val);
+   int(*get_rx_pbl_val) (uint32_t ch_no);
+   int(*config_tx_pbl_val) (uint32_t ch_no, uint32_t val);
+   int(*get_tx_pbl_val) (uint32_t ch_no);
+   int(*config_pblx8) (uint32_t ch_no, uint32_t val);
 
 	/* for TX vlan control */
 	 void(*enable_vlan_reg_control) (struct DWC_ETH_QOS_tx_wrapper_descriptor *desc_data);
@@ -593,12 +579,12 @@ struct hw_if_struct {
 	 void(*configure_sa_via_reg) (uint32_t);
 
 	/* for handling rx interrupts */
-	void(*disable_rx_interrupt)(uint32_t);
-	void(*enable_rx_interrupt)(uint32_t);
+	void(*disable_rx_interrupt)(uint32_t, hw_config_t *);
+	void(*enable_rx_interrupt)(uint32_t, hw_config_t *);
 
 	/* for handling tx interrupts */
-	void(*disable_tx_interrupt)(uint32_t);
-	void(*enable_tx_interrupt)(uint32_t);
+	void(*disable_tx_interrupt)(uint32_t, hw_config_t *);
+	void(*enable_tx_interrupt)(uint32_t, hw_config_t *);
 
 	/* for handling MMC */
 	int(*disable_mmc_interrupts)(void);
@@ -621,18 +607,6 @@ struct hw_if_struct {
 	int(*config_low_credit)(uint32_t qInx, uint32_t lo_credit);
 	int(*config_slot_num_check)(uint32_t qInx, uint8_t slot_check);
 	int(*config_advance_slot_num_check)(uint32_t qInx, uint8_t adv_slot_check);
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	void(*tx_desc_init_pg)(struct DWC_ETH_QOS_prv_data *, uint32_t qInx);
-	void(*rx_desc_init_pg)(struct DWC_ETH_QOS_prv_data *, uint32_t qInx);
-	int(*set_ch_arb_weights)(uint32_t qInx, uint8_t weight);
-	int(*config_slot_interrupt)(uint32_t qInx, uint8_t config);
-	int(*set_slot_count)(uint32_t qInx, uint8_t slotCount);
-	int(*set_tx_rx_prio_policy)(uint8_t prio_policy);
-	int(*set_tx_rx_prio)(uint8_t prio);
-	int(*set_tx_rx_prio_ratio)(uint8_t prio_ratio);
-	int(*set_dma_tx_arb_algorithm)(uint8_t arb_algo);
-	int(*prepare_dev_pktgen)(struct DWC_ETH_QOS_prv_data *);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
 
 	/* for hw time stamping */
 	int(*config_hw_time_stamping)(uint32_t);
@@ -712,7 +686,7 @@ struct hw_if_struct {
     /* for PTP offloading */
 	void(*config_ptpoffload_engine)(uint32_t, uint32_t);
 
-};
+} hw_interface_t;
 
 /* wrapper buffer structure to hold transmit pkt details */
 struct DWC_ETH_QOS_tx_buffer {
@@ -725,9 +699,6 @@ struct DWC_ETH_QOS_tx_buffer {
 	unsigned short len2; /* length of second skb */
 	unsigned char buf2_mapped_as_page;
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	unsigned char slot_number;
-#endif
 };
 
 struct DWC_ETH_QOS_tx_wrapper_descriptor {
@@ -1071,7 +1042,8 @@ struct DWC_ETH_QOS_prv_data {
 	uint32_t mem_start_addr;
 	uint32_t mem_size;
 	int irq_number;
-	struct hw_if_struct hw_if;
+	hw_interface_t hw_if;
+	hw_config_t hw_cfg;
 	struct desc_if_struct desc_if;
 
 //	uint32_t tx_error_counters;
@@ -1124,9 +1096,8 @@ struct DWC_ETH_QOS_prv_data {
 	uint32_t tx_sa_ctrl_via_reg;
 	unsigned char mac_addr[DWC_ETH_QOS_MAC_ADDR_LEN];
 
-	/* keeps track of power mode for API based PMT control */
-	uint32_t power_down;
-	uint32_t power_down_type;
+	/* Keeps track of power mode */
+	uint32_t power_state;
 
 	/* AXI parameters */
 	uint32_t incr_incrx;
@@ -1148,14 +1119,6 @@ struct DWC_ETH_QOS_prv_data {
 	struct DWC_ETH_QOS_mmc_counters mmc;
 	struct DWC_ETH_QOS_extra_stats xstats;
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-	struct DWC_ETH_QOS_PGStruct *pg;
-	struct timer_list pg_timer;
-	int prepare_pg_packet;
-	int run_test;
-	int max_counter;
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 	/* rx split header mode */
 	unsigned char rx_split_hdr;
 
@@ -1245,6 +1208,7 @@ struct DWC_ETH_QOS_prv_data {
 	struct device_attribute itr_lat_attr;
 #ifdef GBE_DEBUG
 	struct device_attribute debug_attr;
+	struct device_attribute suspend_attr;
 #endif
 #ifdef GBE_POLLING
 	struct hrtimer gbe_timer;
@@ -1252,13 +1216,14 @@ struct DWC_ETH_QOS_prv_data {
 };
 
 typedef enum {
-	eSAVE,
-	eRESTORE
-} e_int_state;
+   GBE_STOP_STATE,
+   GBE_RUN_STATE,
+   GBE_STANDBY_STATE
+} gbe_power_state_t;
 
 /* Function prototypes*/
 
-void DWC_ETH_QOS_init_function_ptrs_dev(struct hw_if_struct *);
+void DWC_ETH_QOS_init_function_ptrs_dev(hw_interface_t *);
 void DWC_ETH_QOS_init_function_ptrs_desc(struct desc_if_struct *);
 struct net_device_ops *DWC_ETH_QOS_get_netdev_ops(void);
 struct ethtool_ops *DWC_ETH_QOS_get_ethtool_ops(void);
@@ -1287,8 +1252,8 @@ void print_pkt(struct sk_buff *skb, int 
 void DWC_ETH_QOS_get_all_hw_features(struct DWC_ETH_QOS_prv_data *pdata);
 void DWC_ETH_QOS_print_all_hw_features(struct DWC_ETH_QOS_prv_data *pdata);
 void DWC_ETH_QOS_configure_flow_ctrl(struct DWC_ETH_QOS_prv_data *pdata);
-int DWC_ETH_QOS_powerup(struct net_device *, uint32_t);
-int DWC_ETH_QOS_powerdown(struct net_device *, uint32_t, uint32_t);
+int DWC_ETH_QOS_powerup(struct net_device *);
+int DWC_ETH_QOS_powerdown(struct net_device *, uint32_t);
 uint32_t DWC_ETH_QOS_usec2riwt(uint32_t usec, struct DWC_ETH_QOS_prv_data *pdata);
 void DWC_ETH_QOS_init_rx_coalesce(struct DWC_ETH_QOS_prv_data *pdata);
 void DWC_ETH_QOS_enable_rx_interrupts(struct DWC_ETH_QOS_prv_data *pdata);
@@ -1308,20 +1273,6 @@ void DWC_ETH_QOS_handle_eee_interrupt(st
 void DWC_ETH_QOS_disable_eee_mode(struct DWC_ETH_QOS_prv_data *pdata);
 void DWC_ETH_QOS_enable_eee_mode(struct DWC_ETH_QOS_prv_data *pdata);
 
-#ifdef DWC_ETH_QOS_CONFIG_PGTEST
-irqreturn_t DWC_ETH_QOS_ISR_SW_DWC_ETH_QOS_pg(int irq, void *device_id);
-void DWC_ETH_QOS_default_confs(struct DWC_ETH_QOS_prv_data *pdata);
-int DWC_ETH_QOS_handle_pg_ioctl(struct DWC_ETH_QOS_prv_data *pdata, void *ptr);
-int DWC_ETH_QOS_alloc_pg(struct DWC_ETH_QOS_prv_data *pdata);
-void DWC_ETH_QOS_free_pg(struct DWC_ETH_QOS_prv_data *pdata);
-int DWC_ETH_QOS_alloc_rx_buf_pg(struct DWC_ETH_QOS_prv_data *pdata,
-				struct DWC_ETH_QOS_rx_buffer *buffer,
-				gfp_t gfp);
-int DWC_ETH_QOS_alloc_tx_buf_pg(struct DWC_ETH_QOS_prv_data *pdata,
-				struct DWC_ETH_QOS_tx_buffer *buffer,
-				gfp_t gfp);
-#endif /* end of DWC_ETH_QOS_CONFIG_PGTEST */
-
 #define MIN(a,b) ((a) < (b))? (a) : (b)
 
 /* For debug prints*/
@@ -1374,6 +1325,12 @@ do { \
    } \
 } while (0)
 
+#define ERR_PRINT(x) \
+   printk(KERN_ERR "[%s] ERROR: " x, __FUNCTION__)
+
+#define WRN_PRINT(x) \
+   printk(KERN_ALERT "[%s] WARNING: " x, __FUNCTION__)
+
 #ifdef GBE_DEBUG
 
 extern bool print_desc;
@@ -1389,4 +1346,6 @@ do { \
 
 #endif //GBE_DEBUG
 
+uint32_t gbe_config_to_speed(uint32_t config);
+
 #endif
diff --git a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yregacc.h b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yregacc.h
--- a/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yregacc.h
+++ b/drivers/net/ethernet/synopsys/DWC_ETH_QOS_yregacc.h
@@ -1577,7 +1577,7 @@ do {\
 #define DMA_IER_RBUE_OFF            7
 #define DMA_IER_RIE_OFF             6
 #define DMA_IER_TBUE_OFF            2
-#define DMA_IER_TXSE_OFF            1
+#define DMA_IER_TSE_OFF             1
 #define DMA_IER_TIE_OFF             0
 
 /* DMA Receive Interrupt Watchdog Timer */
diff --git a/drivers/net/ethernet/synopsys/Kconfig b/drivers/net/ethernet/synopsys/Kconfig
--- a/drivers/net/ethernet/synopsys/Kconfig
+++ b/drivers/net/ethernet/synopsys/Kconfig
@@ -21,10 +21,4 @@ config DWC_QOS_PTP
 	help
 	  Adds PTP support.
 
-config DWC_QOS_PG
-	bool "Packet generator support"
-	default n
-	help
-	  Adds PG support.
-
 endif # DWC_QOS
diff --git a/drivers/net/ethernet/synopsys/Makefile b/drivers/net/ethernet/synopsys/Makefile
--- a/drivers/net/ethernet/synopsys/Makefile
+++ b/drivers/net/ethernet/synopsys/Makefile
@@ -1,16 +1,7 @@
 #default values
-#PGTEST=n	#pg(packet generator) is disabled	
 #DEBUGFS=y	#debugfs is enabled
 #PTPSUPPORT=n	#ptp is disabled
 
-ifeq "$(CONFIG_DWC_QOS_PG)" "y"
-CONFIG_PGTEST_OBJ=y
-DWC_ETH_QOS_CONFIG_PGTEST=-DPGTEST
-EXTRA_CFLAGS+=-DCONFIG_PGTEST_OBJ
-else
-CONFIG_PGTEST_OBJ=n
-endif
-
 ifeq "$(CONFIG_DWC_QOS_DEBUGFS)" "y"
 CONFIG_DEBUGFS_OBJ=y
 DWC_ETH_QOS_CONFIG_DEBUGFS=-DDEBUGFS
@@ -38,5 +29,4 @@ DWC_ETH_QOS-y += DWC_ETH_QOS_dev.o \
 			DWC_ETH_QOS_eee.o
 
 DWC_ETH_QOS-$(CONFIG_DEBUGFS_OBJ) += DWC_ETH_QOS_debug_operation.o
-DWC_ETH_QOS-$(CONFIG_PGTEST_OBJ) += DWC_ETH_QOS_pktgen.o
 DWC_ETH_QOS-$(CONFIG_PTPSUPPORT_OBJ) += DWC_ETH_QOS_ptp.o
