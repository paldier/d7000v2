APRP related code changes and extensions, including the framework provided to load the Voice FW

diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -2038,6 +2038,49 @@
 	  Includes a loader for loading an elf relocatable object
 	  onto another VPE and running it.
 
+config LTQ_VPE_EXT
+	bool "LTQ APRP Extensions"
+	depends on MIPS_VPE_LOADER
+	default y
+	help
+	  LTQ included extensions in APRP
+
+config LTQ_VPE_CACHE_SPLIT
+	bool "LTQ Cache Split Ways"
+	depends on LTQ_VPE_EXT
+	help
+	  LTQ extension for reserving (splitting) cache ways among VPEs. You must
+	  give kernel command line arguments vpe_icache_shared=0 or
+	  vpe_dcache_shared=0 to enable splitting of icache or dcache
+	  respectively. Then you can specify which cache ways should be
+	  assigned to which VPE. There are total 8 cache ways, 4 each
+	  for dcache and icache: dcache_way0, dcache_way1,dcache_way2,
+	  dcache_way3 and icache_way0,icache_way1, icache_way2,icache_way3.
+	  
+	  For example, if you specify vpe_icache_shared=0 and icache_way2=1,
+	  then the 3rd icache way will be assigned to VPE0 and denied in VPE1.
+
+	  For icache, software is required to make atleast one cache way available
+	  for a VPE at all times i.e., one can't assign all the icache ways to one VPE.
+	  
+	  By default, vpe_dcache_shared and vpe_icache_shared are set to 1
+	  (i.e., both icache and dcache are shared among VPEs)
+
+config PERFCTRS
+	bool "34K Performance counters"
+	depends on MIPS_MT && PROC_FS
+	default n
+	help
+	  34K Performance counter through /proc
+
+config MTSCHED
+	bool "Support mtsched priority configuration for TCs"
+	depends on MIPS_MT && PROC_FS
+	default y
+	help
+	  Support for mtsched priority configuration for TCs through
+	  /proc/mips/mtsched
+ 
 config MIPS_MT_SMTC_IM_BACKSTOP
 	bool "Use per-TC register bits as backstop for inhibited IM bits"
 	depends on MIPS_MT_SMTC
diff --git a/arch/mips/include/asm/ltq_vpe.h b/arch/mips/include/asm/ltq_vpe.h
new file mode 100644
--- /dev/null
+++ b/arch/mips/include/asm/ltq_vpe.h
@@ -0,0 +1,49 @@
+/*
+** =============================================================================
+** FILE NAME     : ltq_vpe.h
+** PROJECT       : LXDB
+** MODULES       : LXDB
+** DATE          : 24-03-2008
+** AUTHOR        : LXDB Team
+** DESCRIPTION   : This header file contains APIs for LTQ related enhancements
+**		   and requirements in MIPS MT code.
+** REFERENCES    : AR9 Product Specification
+** COPYRIGHT     : Copyright (c) 2008
+**                 Infineon Technologies AG,
+**                 Am Campeon 1-12, 85579 Neubiberg, Germany
+**
+** Any use of this software is subject to the conclusion of a respective
+** License agreement. Without such a License agreement no rights to the
+** software are granted
+**
+** HISTORY       :
+** $Date   $Author    $Comment
+** 24-03-2008	LXDB	Initial version
+** ============================================================================
+*/
+
+#ifndef _LTQ_VPE_H
+#define _LTQ_VPE_H
+
+/* For the explanation of the APIs please refer the section "MT APRP Kernel
+ * Programming" in AR9 SW Architecutre Specification 
+ */
+int32_t vpe1_sw_start(void* sw_start_addr, uint32_t tcmask, uint32_t flags);
+int32_t vpe1_sw_stop(uint32_t flags);
+uint32_t vpe1_get_load_addr (uint32_t flags);
+uint32_t vpe1_get_max_mem (uint32_t flags);
+
+int32_t vpe1_set_boot_param(char *field, char *value, char flags);
+int32_t vpe1_get_boot_param(char *field, char **value, char flags);
+
+/* Watchdog APIs */
+extern uint32_t vpe1_wdog_ctr;
+extern uint32_t vpe1_wdog_timeout;
+
+uint32_t vpe1_sw_wdog_start(uint32_t);
+uint32_t vpe1_sw_wdog_stop(uint32_t);
+
+typedef int (*VPE_SW_WDOG_RESET)(uint32_t wdog_cleared_ok_count);
+int32_t vpe1_sw_wdog_register_reset_handler(VPE_SW_WDOG_RESET reset_fn);
+
+#endif  
diff --git a/arch/mips/include/asm/mipsmtregs.h b/arch/mips/include/asm/mipsmtregs.h
--- a/arch/mips/include/asm/mipsmtregs.h
+++ b/arch/mips/include/asm/mipsmtregs.h
@@ -31,14 +31,31 @@
 #define read_c0_vpeconf1()		__read_32bit_c0_register($1, 3)
 #define write_c0_vpeconf1(val)		__write_32bit_c0_register($1, 3, val)
 
+#define read_c0_vpeschedule()          __read_32bit_c0_register($1, 5)
+#define write_c0_vpeschedule(val)      __write_32bit_c0_register($1, 5, val)
+
+#define read_c0_vpeschefback()         __read_32bit_c0_register($1, 6)
+#define write_c0_vpeschefback(val)     __write_32bit_c0_register($1, 6, val)
+
+#define read_c0_vpeopt()              __read_32bit_c0_register($1, 7)
+#define write_c0_vpeopt(val)          __write_32bit_c0_register($1, 7, val)
+
 #define read_c0_tcstatus()		__read_32bit_c0_register($2, 1)
 #define write_c0_tcstatus(val)		__write_32bit_c0_register($2, 1, val)
 
 #define read_c0_tcbind()		__read_32bit_c0_register($2, 2)
+#define write_c0_tcbind(val)           __write_32bit_c0_register($2, 2, val)
 
 #define read_c0_tccontext()		__read_32bit_c0_register($2, 5)
 #define write_c0_tccontext(val)		__write_32bit_c0_register($2, 5, val)
 
+#define read_c0_tcschedule()           __read_32bit_c0_register($2, 6)
+#define write_c0_tcschedule(val)       __write_32bit_c0_register($2, 6, val)
+
+#define read_c0_tcschefback()          __read_32bit_c0_register($2, 7)
+#define write_c0_tcschefback(val)      __write_32bit_c0_register($2, 7, val)
+
+
 #else /* Assembly */
 /*
  * Macros for use in assembly language code
@@ -363,6 +380,10 @@
 #define write_vpe_c0_vpeconf0(val)	mttc0(1, 2, val)
 #define read_vpe_c0_vpeconf1()		mftc0(1, 3)
 #define write_vpe_c0_vpeconf1(val)	mttc0(1, 3, val)
+#define read_vpe_c0_vpeschedule()      mftc0(1, 5)
+#define write_vpe_c0_vpeschedule(val)  mttc0(1, 5, val)
+#define read_vpe_c0_vpeschefback()     mftc0(1, 6)
+#define write_vpe_c0_vpeschefback(val) mttc0(1, 6, val)
 #define read_vpe_c0_count()		mftc0(9, 0)
 #define write_vpe_c0_count(val)		mttc0(9, 0, val)
 #define read_vpe_c0_status()		mftc0(12, 0)
@@ -382,6 +403,10 @@
 #define read_vpe_c0_epc()		mftc0(14, 0)
 #define write_vpe_c0_epc(val)		mttc0(14, 0, val)
 
+#define read_vpe_c0_vpeopt()            mftc0(1, 7)
+#define write_vpe_c0_vpeopt(val)        mttc0(1, 7, val)
+#define read_vpe_c0_wired()            mftc0(6, 0)
+#define write_vpe_c0_wired(val)                mttc0(6, 0, val)
 
 /* TC */
 #define read_tc_c0_tcstatus()		mftc0(2, 1)
@@ -394,7 +419,13 @@
 #define write_tc_c0_tchalt(val)		mttc0(2, 4, val)
 #define read_tc_c0_tccontext()		mftc0(2, 5)
 #define write_tc_c0_tccontext(val)	mttc0(2, 5, val)
-
+#define read_tc_c0_tcschedule()         mftc0(2, 6)
+#define write_tc_c0_tcschedule(val)    	mttc0(2,6,val)
+#define read_tc_c0_tcschefback()       	mftc0(2, 7)
+#define write_tc_c0_tcschefback(val)   	mttc0(2,7,val)
+#define read_tc_c0_entryhi()            mftc0(10, 0)
+#define write_tc_c0_entryhi(val)        mttc0(10,0,val)
+            
 /* GPR */
 #define read_tc_gpr_sp()		mftgpr(29)
 #define write_tc_gpr_sp(val)		mttgpr(29, val)
diff --git a/arch/mips/include/asm/mmu_context.h b/arch/mips/include/asm/mmu_context.h
--- a/arch/mips/include/asm/mmu_context.h
+++ b/arch/mips/include/asm/mmu_context.h
@@ -114,6 +114,16 @@
 	extern void kvm_local_flush_tlb_all(void);
 	unsigned long asid = asid_cache(cpu);
 
+#ifdef CONFIG_LTQ_VPE_EXT 
+       extern int stlb; //defined in arch/mips/kernel/mips-mt.c
+       /* If TLB is shared between AP & RP, leave out max ASID i.e.
+          ASID_MASK for RP. If it is not shared follow the old
+          processing
+        */
+       if (stlb && ((asid & ASID_MASK) == (ASID_MASK - 1)))    //shared TLB
+               asid++; //skip ASID_MASK ie. last entry
+#endif
+
 	if (! ((asid += ASID_INC) & ASID_MASK) ) {
 		if (cpu_has_vtag_icache)
 			flush_icache_all();
diff --git a/arch/mips/kernel/Makefile b/arch/mips/kernel/Makefile
--- a/arch/mips/kernel/Makefile
+++ b/arch/mips/kernel/Makefile
@@ -74,6 +74,8 @@
 
 obj-$(CONFIG_KGDB)		+= kgdb.o
 obj-$(CONFIG_PROC_FS)		+= proc.o
+obj-$(CONFIG_MTSCHED)           += mtsched_proc.o
+obj-$(CONFIG_PERFCTRS)          += perf_proc.o
 
 obj-$(CONFIG_64BIT)		+= cpu-bugs64.o
 
diff --git a/arch/mips/kernel/mips-mt.c b/arch/mips/kernel/mips-mt.c
--- a/arch/mips/kernel/mips-mt.c
+++ b/arch/mips/kernel/mips-mt.c
@@ -41,6 +41,93 @@
 
 __setup("maxtcs=", maxtcs);
 
+#ifdef CONFIG_LTQ_VPE_EXT
+int stlb;
+
+static int __init istlbshared(char *str)
+{
+       get_option(&str, &stlb);
+
+       return 1;
+}
+
+__setup("vpe_tlb_shared=", istlbshared);
+
+int vpe0_wired;
+
+static int __init vpe0wired(char *str)
+{
+       get_option(&str, &vpe0_wired);
+
+       return 1;
+}
+
+__setup("vpe0_wired_tlb_entries=", vpe0wired);
+
+int vpe1_wired;
+
+static int __init vpe1wired(char *str)
+{
+       get_option(&str, &vpe1_wired);
+
+       return 1;
+}
+
+__setup("vpe1_wired_tlb_entries=", vpe1wired);
+
+#ifdef CONFIG_MIPS_MT_SMTC
+extern int nostlb;
+#endif
+void configure_tlb(void)
+{
+               int vpeflags, tcflags, tlbsiz;
+        unsigned int config1val;
+       vpeflags = dvpe();
+       tcflags = dmt();
+       write_c0_vpeconf0((read_c0_vpeconf0() | VPECONF0_MVP));
+       write_c0_mvpcontrol((read_c0_mvpcontrol() | MVPCONTROL_VPC));
+       mips_ihb();
+       //printk("stlb = %d, vpe0_wired = %d vpe1_wired=%d\n", stlb,vpe0_wired, vpe1_wired);
+       if (stlb) {
+                if (!(read_c0_mvpconf0() & MVPCONF0_TLBS)) {
+                       emt(tcflags);
+                        evpe(vpeflags);
+                        return;
+                }
+
+               write_c0_mvpcontrol(read_c0_mvpcontrol() | MVPCONTROL_STLB);
+               write_c0_wired(vpe0_wired + vpe1_wired);
+                if (((read_vpe_c0_config() & MIPS_CONF_MT) >> 7) == 1) {
+                        config1val = read_vpe_c0_config1();
+                        tlbsiz = (((config1val >> 25) & 0x3f) + 1);
+                        if (tlbsiz > 64)
+                                tlbsiz = 64;
+                        cpu_data[0].tlbsize = tlbsiz;
+			current_cpu_data.tlbsize = tlbsiz;
+                }
+
+       }
+       else {
+               write_c0_mvpcontrol(read_c0_mvpcontrol() & ~MVPCONTROL_STLB);
+               write_c0_wired(vpe0_wired);
+       }
+
+       ehb();
+       write_c0_mvpcontrol((read_c0_mvpcontrol() & ~MVPCONTROL_VPC));
+       ehb();
+        local_flush_tlb_all();
+
+       printk("Wired TLB entries for Linux read_c0_wired() = %d\n", read_c0_wired());
+#ifdef CONFIG_MIPS_MT_SMTC
+       nostlb = !stlb;
+#endif
+       emt(tcflags);
+       evpe(vpeflags);
+}
+
+#endif
+
+
 /*
  * Dump new MIPS MT state for the core. Does not leave TCs halted.
  * Takes an argument which taken to be a pre-call MVPControl value.
@@ -286,6 +373,9 @@
 		printk("Mapped %ld ITC cells starting at 0x%08x\n",
 			((itcblkgrn & 0x7fe00000) >> 20), itc_base);
 	}
+#ifdef CONFIG_LTQ_VPE_EXT
+        configure_tlb();
+#endif
 }
 
 /*
diff --git a/arch/mips/kernel/mtsched_proc.c b/arch/mips/kernel/mtsched_proc.c
new file mode 100644
--- /dev/null
+++ b/arch/mips/kernel/mtsched_proc.c
@@ -0,0 +1,284 @@
+/*
+ * /proc hooks for MIPS MT scheduling policy management for 34K cores
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ *
+ * Copyright (C) 2006 Mips Technologies, Inc
+ */
+
+#include <linux/kernel.h>
+
+#include <asm/cpu.h>
+#include <asm/processor.h>
+#include <asm/barrier.h>
+#include <asm/mipsregs.h>
+#include <asm/mipsmtregs.h>
+#include <asm/uaccess.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+
+
+static struct proc_dir_entry *mtsched_proc;
+
+#ifndef CONFIG_MIPS_MT_SMTC
+#define NTCS 2
+#else
+#define NTCS NR_CPUS
+#endif
+#define NVPES 2
+
+int lastvpe = 1;
+int lasttc = 8;
+
+static int proc_read_mtsched(struct seq_file *s, void *v)
+{
+
+	int i;
+	int vpe;
+	int mytc;
+	unsigned long flags;
+	unsigned int mtflags;
+	unsigned int haltstate;
+	unsigned int vpes_checked[NVPES];
+	unsigned int vpeschedule[NVPES];
+	unsigned int vpeschefback[NVPES];
+	unsigned int tcschedule[NTCS];
+	unsigned int tcschefback[NTCS];
+
+	/* Dump the state of the MIPS MT scheduling policy manager */
+	/* Inititalize control state */
+	for(i = 0; i < NVPES; i++){
+		vpes_checked[i] = 0;
+		vpeschedule[i] = 0;
+		vpeschefback[i] = 0;
+	}
+
+	for(i = 0; i < NTCS; i++)
+	{
+		tcschedule[i] = 0;
+		tcschefback[i] = 0;
+	}
+	
+	/* Disable interrupts and multithreaded issue */
+	local_irq_save(flags);
+	mtflags = dvpe();
+
+	/* Then go through the TCs, halt 'em, and extract the values */
+	mytc = (read_c0_tcbind() & TCBIND_CURTC) >> TCBIND_CURTC_SHIFT;
+	for(i = 0; i < NTCS; i++) {
+		if(i == mytc) {
+			/* No need to halt ourselves! */
+			tcschedule[i] = read_c0_tcschedule();
+			tcschefback[i] = read_c0_tcschefback();
+                    /* If VPE bound to TC hasn't been checked, do it */ 
+                   vpe = read_c0_tcbind() & TCBIND_CURVPE; 
+		   if(!vpes_checked[vpe]) { 
+                        vpeschedule[vpe] = read_c0_vpeschedule(); 
+                        vpeschefback[vpe] = read_c0_vpeschefback(); 
+                        vpes_checked[vpe] = 1; 
+                    } 
+
+		} else {
+			settc(i);
+			haltstate = read_tc_c0_tchalt();
+			write_tc_c0_tchalt(TCHALT_H);
+			mips_ihb();
+			tcschedule[i] = read_tc_c0_tcschedule();
+			tcschefback[i] = read_tc_c0_tcschefback();
+			/* If VPE bound to TC hasn't been checked, do it */
+			vpe = read_tc_c0_tcbind() & TCBIND_CURVPE;
+			if(!vpes_checked[vpe]) {
+			    vpeschedule[vpe] = read_vpe_c0_vpeschedule();
+			    vpeschefback[vpe] = read_vpe_c0_vpeschefback();
+			    vpes_checked[vpe] = 1;
+			}
+			if(!haltstate) write_tc_c0_tchalt(0);
+		}
+	}
+	/* Re-enable MT and interrupts */
+	evpe(mtflags);
+	local_irq_restore(flags);
+
+	for(vpe=0; vpe < NVPES; vpe++) {	
+		seq_printf(s, "VPE[%d].VPEschedule = 0x%08x\n",
+			vpe, vpeschedule[vpe]);
+		seq_printf(s, "VPE[%d].VPEschefback = 0x%08x\n",
+			vpe, vpeschefback[vpe]);
+	}
+	for(i=0; i < NTCS; i++) {	
+		seq_printf(s, "TC[%d].TCschedule = 0x%08x\n",
+			i, tcschedule[i]);
+		seq_printf(s, "TC[%d].TCschefback = 0x%08x\n",
+			i, tcschefback[i]);
+	}
+	return 0;
+}
+
+/*
+ * Write to perf counter registers based on text input
+ */
+
+#define TXTBUFSZ 1000
+
+static ssize_t mtsched_proc_write(struct file *file, const char __user *buffer, 
+				size_t count, loff_t *data)
+{
+	size_t len = 0;
+	char mybuf[TXTBUFSZ];
+	/* At most, we will set up 9 TCs and 2 VPEs, 11 entries in all */
+	char entity[1];   //, entity1[1];
+	int number[1];
+	unsigned long value[1];
+	int nparsed = 0 , index = 0;
+	unsigned long flags;
+	unsigned int mtflags;
+	unsigned int haltstate;
+	unsigned int tcbindval;
+	
+	if(count >= TXTBUFSZ) len = TXTBUFSZ-1;
+	else len = count;
+	memset(mybuf,0,TXTBUFSZ);
+	if(copy_from_user(mybuf, buffer, len)) return -EFAULT;
+
+	nparsed = sscanf(mybuf, "%c%d %lx",
+		 &entity[0] ,&number[0], &value[0]);
+
+	/* 
+	 * Having acquired the inputs, which might have
+	 * generated exceptions and preemptions,
+	 * program the registers. 
+	 */
+	/* Disable interrupts and multithreaded issue */
+	local_irq_save(flags);
+	mtflags = dvpe();
+	         	
+ 	if(entity[index] == 't' ) {
+                /* Set TCSchedule or TCScheFBack of specified TC */
+                if(number[index] > NTCS) goto skip;
+                /* If it's our own TC, do it direct */
+                if(number[index] ==
+                                ((read_c0_tcbind() & TCBIND_CURTC)
+                                >> TCBIND_CURTC_SHIFT)) {
+                        if(entity[index] == 't')
+				 write_c0_tcschedule(value[index]);
+                        else 
+				write_c0_tcschefback(value[index]);
+                } else {
+                /* Otherwise, we do it via MTTR */
+                        settc(number[index]);
+                        haltstate = read_tc_c0_tchalt();
+                        write_tc_c0_tchalt(TCHALT_H);
+                        mips_ihb();
+                        if(entity[index] == 't')
+				 write_tc_c0_tcschedule(value[index]);
+                        else 
+				write_tc_c0_tcschefback(value[index]);
+                        mips_ihb();
+                        if(!haltstate) write_tc_c0_tchalt(0);
+                }
+	} else if(entity[index] == 'v') {
+                /* Set VPESchedule of specified VPE */
+                if(number[index] > NVPES) goto skip;
+                tcbindval = read_c0_tcbind();
+                /* Are we doing this to our current VPE? */
+                if((tcbindval & TCBIND_CURVPE) == number[index]) {
+                        /* Then life is simple */
+                        write_c0_vpeschedule(value[index]);
+                } else {
+                        /*
+                         * Bind ourselves to the other VPE long enough
+                         * to program the bind value.
+                         */
+                        write_c0_tcbind((tcbindval & ~TCBIND_CURVPE)
+                                           | number[index]);
+                        mips_ihb();
+                        write_c0_vpeschedule(value[index]);
+                        mips_ihb();
+                        /* Restore previous binding */
+                        write_c0_tcbind(tcbindval);
+                        mips_ihb();
+                }
+	}
+
+	else if(entity[index] == 'r') {
+		unsigned int vpes_checked[2], vpe ,i , mytc;
+		vpes_checked[0] = vpes_checked[1] = 0;
+
+		/* Then go through the TCs, halt 'em, and extract the values */
+		mytc = (read_c0_tcbind() & TCBIND_CURTC) >> TCBIND_CURTC_SHIFT;
+
+		for(i = 0; i < NTCS; i++) {
+			if(i == mytc) {
+				/* No need to halt ourselves! */
+				write_c0_vpeschefback(0);
+				write_c0_tcschefback(0);
+				
+			} else {
+				settc(i);
+				haltstate = read_tc_c0_tchalt();
+				write_tc_c0_tchalt(TCHALT_H);
+				mips_ihb();
+				write_tc_c0_tcschefback(0);
+				/* If VPE bound to TC hasn't been checked, do it */
+				vpe = read_tc_c0_tcbind() & TCBIND_CURVPE;
+				if(!vpes_checked[vpe]) {
+				    write_vpe_c0_vpeschefback(0);
+				    vpes_checked[vpe] = 1;
+				}
+				if(!haltstate) write_tc_c0_tchalt(0);
+			}
+		}
+	}
+	else {
+		printk (" \n Usage : <t/v><0/1> <Hex Value> \n Example : t0 0x01");
+	}
+
+skip:
+	/* Re-enable MT and interrupts */
+	evpe(mtflags);
+	local_irq_restore(flags);
+	return (len);
+}
+
+static int mtsched_proc_open(struct inode *inode, struct file *file)
+{
+ return single_open(file,proc_read_mtsched, NULL);
+}
+
+static const struct file_operations mtsched_proc_fops = {
+ .open           = mtsched_proc_open,
+ .read           = seq_read,
+ .write    			 = mtsched_proc_write,
+ .llseek         = seq_lseek,
+ .release        = single_release,
+};
+
+static int __init init_mtsched_proc(void)
+{
+	extern struct proc_dir_entry *get_mips_proc_dir(void);
+
+	struct proc_dir_entry *mips_proc_dir;
+	if (!cpu_has_mipsmt) {
+		printk("mtsched: not a MIPS MT capable processor\n");
+		return -ENODEV;
+	}
+
+	mips_proc_dir = get_mips_proc_dir();
+
+	mtsched_proc = proc_create("mtsched", 0644, mips_proc_dir,&mtsched_proc_fops);
+	return 0;
+}
+
+/* Automagically create the entry */
+module_init(init_mtsched_proc);
diff --git a/arch/mips/kernel/perf_proc.c b/arch/mips/kernel/perf_proc.c
new file mode 100644
--- /dev/null
+++ b/arch/mips/kernel/perf_proc.c
@@ -0,0 +1,183 @@
+/*
+ * /proc hooks for CPU performance counter support for SMTC kernel 
+ * (and ultimately others)
+ * Copyright (C) 2006 Mips Technologies, Inc
+ */
+
+#include <linux/kernel.h>
+
+#include <asm/cpu.h>
+#include <asm/processor.h>
+#include <asm/barrier.h>
+#include <asm/mipsregs.h>
+#include <asm/uaccess.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+
+/*
+ * /proc diagnostic and statistics hooks
+ */
+
+/* Internal software-extended event counters */
+
+static unsigned long long extencount[4] = {0,0,0,0};
+
+static struct proc_dir_entry *perf_proc;
+
+static int proc_read_perf(struct seq_file *s, void *v)
+{
+
+	seq_printf(s, "PerfCnt[0].Ctl : 0x%08x\n", read_c0_perfctrl0());
+	seq_printf(s, "PerfCnt[0].Cnt : %Lu\n", 
+	  extencount[0] + (unsigned long long)((unsigned)read_c0_perfcntr0()));
+	seq_printf(s, "PerfCnt[1].Ctl : 0x%08x\n", read_c0_perfctrl1());
+	seq_printf(s, "PerfCnt[1].Cnt : %Lu\n",
+	  extencount[1] + (unsigned long long)((unsigned)read_c0_perfcntr1()));
+	seq_printf(s, "PerfCnt[2].Ctl : 0x%08x\n", read_c0_perfctrl2());
+	seq_printf(s, "PerfCnt[2].Cnt : %Lu\n",
+	  extencount[2] + (unsigned long long)((unsigned)read_c0_perfcntr2()));
+	seq_printf(s, "PerfCnt[3].Ctl : 0x%08x\n", read_c0_perfctrl3());
+	seq_printf(s, "PerfCnt[3].Cnt : %Lu\n",
+	  extencount[3] + (unsigned long long)((unsigned)read_c0_perfcntr3()));
+
+	return 0;
+}
+
+/*
+ * Write to perf counter registers based on text input
+ */
+
+#define TXTBUFSZ 512
+
+static ssize_t perf_proc_write(struct file *file, const char *buffer, 
+					size_t count, loff_t *data)
+{
+	size_t len;
+	int nparsed;
+	int index;
+	char mybuf[TXTBUFSZ];
+
+	int which[4];
+	unsigned long control[4];
+	long long ctrdata[4];
+
+	if(count >= TXTBUFSZ) len = TXTBUFSZ-1;
+	else len = count;
+	memset(mybuf,0,TXTBUFSZ);
+	if(copy_from_user(mybuf, buffer, len)) return -EFAULT;
+
+	nparsed = sscanf(mybuf,
+			"%d %lx %Ld %d %lx %Ld %d %lx %Ld %d %lx %Ld", 
+				&which[0], &control[0], &ctrdata[0],
+				&which[1], &control[1], &ctrdata[1],
+				&which[2], &control[2], &ctrdata[2],
+				&which[3], &control[3], &ctrdata[3]);
+
+	for(index = 0; nparsed >= 3; index++) { 
+		switch (which[index]) {
+		case 0:
+			write_c0_perfctrl0(control[index]);
+			if(ctrdata[index] != -1) {
+			    extencount[0] = (unsigned long long)ctrdata[index];
+			    write_c0_perfcntr0((unsigned long)0);
+			}
+			break;
+		case 1:
+			write_c0_perfctrl1(control[index]);
+			if(ctrdata[index] != -1) {
+			    extencount[1] = (unsigned long long)ctrdata[index];
+			    write_c0_perfcntr1((unsigned long)0);
+			}
+			break;
+		case 2:
+			write_c0_perfctrl2(control[index]);
+			if(ctrdata[index] != -1) {
+			    extencount[2] = (unsigned long long)ctrdata[index];
+			    write_c0_perfcntr2((unsigned long)0);
+			}
+			break;
+		case 3:
+			write_c0_perfctrl3(control[index]);
+			if(ctrdata[index] != -1) {
+			    extencount[3] = (unsigned long long)ctrdata[index];
+			    write_c0_perfcntr3((unsigned long)0);
+			}
+			break;
+		}
+		nparsed -= 3;
+	}
+	return (len);
+}
+
+extern int (*perf_irq)(struct pt_regs *regs);
+
+/*
+ * Invoked when timer interrupt vector picks up a perf counter overflow
+ */
+
+static int perf_proc_irq(struct pt_regs *regs)
+{
+	unsigned long snapshot;
+
+	/* 
+	 * It would be nice to do this as a loop, but we don't have
+	 * indirect access to CP0 registers.
+	 */
+	snapshot = read_c0_perfcntr0();
+	if((long)snapshot < 0) {
+		extencount[0] += 
+			(unsigned long long)((unsigned)read_c0_perfcntr0());
+		write_c0_perfcntr0(0);
+	}
+	snapshot = read_c0_perfcntr1();
+	if((long)snapshot < 0) {
+		extencount[1] += 
+			(unsigned long long)((unsigned)read_c0_perfcntr1());
+		write_c0_perfcntr1(0);
+	}
+	snapshot = read_c0_perfcntr2();
+	if((long)snapshot < 0) {
+		extencount[2] += 
+			(unsigned long long)((unsigned)read_c0_perfcntr2());
+		write_c0_perfcntr2(0);
+	}
+	snapshot = read_c0_perfcntr3();
+	if((long)snapshot < 0) {
+		extencount[3] += 
+			(unsigned long long)((unsigned)read_c0_perfcntr3());
+		write_c0_perfcntr3(0);
+	}
+	return 0;
+}
+
+static int perf_proc_open(struct inode *inode, struct file *file)
+{
+ return single_open(file,proc_read_perf, NULL);
+}
+
+static const struct file_operations perf_proc_fops={
+ .open           = perf_proc_open,
+ .read           = seq_read,
+ .write          = perf_proc_write,
+ .llseek         = seq_lseek,
+ .release        = single_release,
+};
+
+static int __init init_perf_proc(void)
+{
+	extern struct proc_dir_entry *get_mips_proc_dir(void);
+
+	struct proc_dir_entry *mips_proc_dir = get_mips_proc_dir();
+
+	write_c0_perfcntr0(0);
+	write_c0_perfcntr1(0);
+	write_c0_perfcntr2(0);
+	write_c0_perfcntr3(0);
+	perf_proc = proc_create("perf", 0644, mips_proc_dir,&perf_proc_fops);
+	perf_irq = perf_proc_irq;
+
+	return 0;
+}
+
+/* Automagically create the entry */
+module_init(init_perf_proc);
diff --git a/arch/mips/kernel/proc.c b/arch/mips/kernel/proc.c
--- a/arch/mips/kernel/proc.c
+++ b/arch/mips/kernel/proc.c
@@ -15,6 +15,10 @@
 #include <asm/processor.h>
 #include <asm/prom.h>
 
+#include <asm/uaccess.h>
+#include <linux/proc_fs.h>
+
+
 unsigned int vced_count, vcei_count;
 
 static int show_cpuinfo(struct seq_file *m, void *v)
@@ -151,3 +155,20 @@
 	.stop	= c_stop,
 	.show	= show_cpuinfo,
 };
+
+
+/*
+* Support for MIPS/local /proc hooks in /proc/mips/
+*/
+
+static struct proc_dir_entry *mips_proc = NULL;
+
+struct proc_dir_entry *get_mips_proc_dir(void)
+{
+	/*
+	* This ought not to be preemptable.
+	*/
+	if(mips_proc == NULL)
+		mips_proc = proc_mkdir("mips", NULL);
+	return(mips_proc);
+}
diff --git a/arch/mips/kernel/smtc-proc.c b/arch/mips/kernel/smtc-proc.c
--- a/arch/mips/kernel/smtc-proc.c
+++ b/arch/mips/kernel/smtc-proc.c
@@ -67,6 +67,8 @@
 void init_smtc_stats(void)
 {
 	int i;
+	extern struct proc_dir_entry *get_mips_proc_dir(void);
+	struct proc_dir_entry *mips_proc_dir = get_mips_proc_dir();
 
 	for (i=0; i<NR_CPUS; i++) {
 		smtc_cpu_stats[i].timerints = 0;
@@ -75,5 +77,5 @@
 
 	atomic_set(&smtc_fpu_recoveries, 0);
 
-	proc_create("smtc", 0444, NULL, &smtc_proc_fops);
+	proc_create("smtc", 0444, mips_proc_dir, &smtc_proc_fops);
 }
diff --git a/arch/mips/kernel/smtc.c b/arch/mips/kernel/smtc.c
--- a/arch/mips/kernel/smtc.c
+++ b/arch/mips/kernel/smtc.c
@@ -110,7 +110,11 @@
 
 static int vpe0limit;
 static int ipibuffers;
+#ifdef CONFIG_LTQ_VPE_EXT
+int nostlb = 0;
+#else
 static int nostlb;
+#endif
 static int asidmask;
 unsigned long smtc_asid_mask = 0xff;
 
@@ -1394,6 +1398,13 @@
 	asid = asid_cache(cpu);
 
 	do {
+#ifdef CONFIG_LTQ_VPE_EXT
+	/* If TLB is shared between AP and RP (AP is running SMTC),
+	leave out max ASID i.e., ASID_MASK for RP
+	*/
+	if (!nostlb && ((asid & ASID_MASK) == (ASID_MASK - 1)))
+		asid++;
+#endif
 		if (!((asid += ASID_INC) & ASID_MASK) ) {
 			if (cpu_has_vtag_icache)
 				flush_icache_all();
diff --git a/arch/mips/kernel/vpe.c b/arch/mips/kernel/vpe.c
--- a/arch/mips/kernel/vpe.c
+++ b/arch/mips/kernel/vpe.c
@@ -50,6 +50,7 @@
 #include <asm/mips_mt.h>
 #include <asm/processor.h>
 #include <asm/vpe.h>
+#include <linux/cred.h>
 
 typedef void *vpe_handle;
 
@@ -68,6 +69,63 @@
 static int major;
 static const int minor = 1;	/* fixed for now  */
 
+#ifdef CONFIG_LTQ_VPE_EXT
+static int is_sdepgm;
+extern int stlb;
+extern int vpe0_wired;
+extern int vpe1_wired;
+unsigned int vpe1_load_addr;
+
+//#define set_c0_mvpcontrol(MVPCONTROL_VPC) write_c0_mvpcontrol(read_c0_mvpcontrol() | MVPCONTROL_VPC); ehb();
+//#define clear_c0_mvpcontrol(MVPCONTROL_VPC) write_c0_mvpcontrol(read_c0_mvpcontrol() & ~MVPCONTROL_VPC); ehb();
+
+static int __init load_address(char *str)
+{
+	get_option(&str, &vpe1_load_addr);
+	return 1;
+}
+
+__setup("vpe1_load_addr=", load_address);
+
+#include <asm/setup.h>
+#include <asm/ltq_vpe.h>
+char command_line[COMMAND_LINE_SIZE * 2];
+extern char *saved_command_line;
+static unsigned int vpe1_mem;
+static void __init vpe1mem(void)
+{
+	char *ptr;
+	ptr = strstr(command_line, "vpe1_mem=");
+
+	if (ptr && (ptr != command_line) && (*(ptr - 1) != ' '))
+		ptr = strstr(ptr, " vpe1_mem=");
+
+	if (ptr)
+		vpe1_mem = memparse(ptr + 9, &ptr);
+       printk("vpe1_mem = %x\n", vpe1_mem);
+}
+
+uint32_t vpe1_wdog_ctr;
+static int __init wdog_ctr(char *str)
+{
+        get_option(&str, &vpe1_wdog_ctr);
+        return 1;
+}
+
+__setup("vpe1_wdog_ctr_addr=", wdog_ctr);
+EXPORT_SYMBOL(vpe1_wdog_ctr);
+
+uint32_t vpe1_wdog_timeout;
+static int __init wdog_timeout(char *str)
+{
+        get_option(&str, &vpe1_wdog_timeout);
+        return 1;
+}
+
+__setup("vpe1_wdog_timeout=", wdog_timeout);
+EXPORT_SYMBOL(vpe1_wdog_timeout);
+#endif
+
 /* grab the likely amount of memory we will need. */
 #ifdef CONFIG_MIPS_VPE_LOADER_TOM
 #define P_SIZE (2 * 1024 * 1024)
@@ -264,8 +322,19 @@
 	 * This means you must tell Linux to use less memory than you
 	 * physically have, for example by passing a mem= boot argument.
 	 */
+#ifdef CONFIG_LTQ_VPE_EXT
+	if (vpe1_load_addr){
+		//printk ("vpe1_load_addr = 0x%x\n", vpe1_load_addr);
+		return (void *)vpe1_load_addr;
+
+	}
+	else {
+#endif
 	addr = pfn_to_kaddr(max_low_pfn);
 	memset(addr, 0, len);
+#ifdef CONFIG_LTQ_VPE_EXT
+	}
+#endif
 #else
 	/* simple grab some mem for now */
 	addr = kzalloc(len, GFP_KERNEL);
@@ -728,6 +797,7 @@
 		return -ENOEXEC;
 	}
 
+
 	/* Write the address we want it to start running from in the TCPC register. */
 	write_tc_c0_tcrestart((unsigned long)v->__start);
 	write_tc_c0_tccontext((unsigned long)0);
@@ -741,7 +811,22 @@
 	write_tc_c0_tcstatus(val);
 
 	write_tc_c0_tchalt(read_tc_c0_tchalt() & ~TCHALT_H);
+	mips_ihb();
 
+#ifdef CONFIG_LTQ_VPE_EXT
+       /*
+        * $a2 & $a3 are used to pass command line parameters to VPE1. $a2
+        * points to the start of the command line string and $a3 points to
+        * the end of the string. This convention is identical to the Linux
+        * kernel boot parameter passing mechanism. Please note that $a3 is
+        * used to pass physical memory size or 0 in SDE tool kit. So, if you
+        * are passing comand line parameters through $a2 & $a3 SDE programs
+        * don't work as desired.
+        */
+       mttgpr(6, command_line);
+       mttgpr(7, (command_line + strlen(command_line)));
+       if (is_sdepgm) {
+#endif
 	/*
 	 * The sde-kit passes 'memsize' to __start in $a3, so set something
 	 * here...  Or set $a3 to zero and define DFLT_STACK_SIZE and
@@ -749,7 +834,9 @@
 	 */
 	mttgpr(6, v->ntcs);
 	mttgpr(7, physical_memsize);
-
+#ifdef CONFIG_LTQ_VPE_EXT
+	}
+#endif
 	/* set up VPE1 */
 	/*
 	 * bind the TC to VPE 1 as late as possible so we only have the final
@@ -767,6 +854,14 @@
 
 	back_to_back_c0_hazard();
 
+#ifdef CONFIG_LTQ_VPE_EXT
+       settc(t->index);
+
+       if (stlb)
+               write_vpe_c0_wired(vpe0_wired + vpe1_wired);
+       else
+               write_vpe_c0_wired(vpe1_wired);
+#endif
 	/* enable this VPE */
 	write_vpe_c0_vpeconf0(read_vpe_c0_vpeconf0() | VPECONF0_VPA);
 
@@ -816,6 +911,10 @@
 	if ( (v->__start == 0) || (v->shared_ptr == NULL))
 		return -1;
 
+#ifdef CONFIG_LTQ_VPE_EXT
+       is_sdepgm = 1;
+#endif
+
 	return 0;
 }
 
@@ -981,7 +1080,17 @@
 			   (unsigned long)v->load_addr + v->len);
 	set_fs(old_fs);
 
+	//printk ("outside findvpesym vpe1_load_addr = %x\n", vpe1_load_addr);
 	if ((find_vpe_symbols(v, sechdrs, symindex, strtab, &mod)) < 0) {
+#ifdef CONFIG_LTQ_VPE_EXT
+               if (vpe1_load_addr) {
+			//printk ("inside findvpesym vpe1_load_addr = %x", vpe1_load_addr);
+                       /* Conversion to KSEG1 is required ??? */
+                       v->__start = KSEG1ADDR(vpe1_load_addr);
+                       is_sdepgm = 0;
+                       return 0;
+               }
+#endif
 		if (v->__start == 0) {
 			printk(KERN_WARNING "VPE loader: program does not contain "
 			       "a __start symbol\n");
@@ -1052,7 +1161,9 @@
 	struct vpe_notifications *not;
 	struct vpe *v;
 	int ret;
-
+#ifdef CONFIG_LTQ_VPE_EXT
+	int progsize;
+#endif
 	if (minor != iminor(inode)) {
 		/* assume only 1 device at the moment. */
 		pr_warning("VPE loader: only vpe1 is supported\n");
@@ -1078,6 +1189,15 @@
 		cleanup_tc(get_tc(tclimit));
 	}
 
+#ifdef CONFIG_LTQ_VPE_EXT
+       progsize = (vpe1_mem  != 0) ? vpe1_mem : P_SIZE;
+       v->pbuffer = vmalloc(progsize);
+	if (!v->pbuffer) {
+		pr_warning("VPE loader: unable to allocate memory\n");
+		return -ENOMEM;
+	}
+       v->plen = progsize;
+#else
 	/* this of-course trashes what was there before... */
 	v->pbuffer = vmalloc(P_SIZE);
 	if (!v->pbuffer) {
@@ -1085,6 +1205,7 @@
 		return -ENOMEM;
 	}
 	v->plen = P_SIZE;
+#endif
 	v->load_addr = NULL;
 	v->len = 0;
 
@@ -1246,6 +1367,9 @@
 	write_vpe_c0_vpeconf0(read_vpe_c0_vpeconf0() & ~VPECONF0_VPA);
 
 	/* halt the TC */
+#ifdef CONFIG_LTQ_VPE_EXT
+	write_tc_c0_tcstatus(read_tc_c0_tcstatus() & ~TCSTATUS_A);
+#endif
 	write_tc_c0_tchalt(TCHALT_H);
 	mips_ihb();
 
@@ -1323,6 +1447,134 @@
 
 EXPORT_SYMBOL(vpe_getcwd);
 
+#ifdef CONFIG_LTQ_VPE_EXT
+int32_t vpe1_sw_start(void* sw_start_addr, uint32_t tcmask, uint32_t flags)
+{
+       enum vpe_state state;
+        struct vpe *v = get_vpe(tclimit);
+       struct vpe_notifications *not;
+
+        if (tcmask || flags) {
+               printk(KERN_WARNING "Currently tcmask and flags should be 0."
+                               "other values not supported\n");
+               return -1;
+        }
+
+        state = xchg(&v->state, VPE_STATE_INUSE);
+        if (state != VPE_STATE_UNUSED) {
+               vpe_stop(v);
+
+               list_for_each_entry(not, &v->notify, list) {
+                        not->stop(tclimit);
+               }
+        }
+
+        v->__start = (unsigned long)sw_start_addr;
+       is_sdepgm = 0;
+
+        if (!vpe_run(v)) {
+               printk(KERN_DEBUG "VPE loader: VPE1 running successfully\n");
+                return 0;
+       }
+       return -1;
+}
+
+EXPORT_SYMBOL(vpe1_sw_start);
+
+int32_t vpe1_sw_stop(uint32_t flags)
+{
+	struct vpe *v = get_vpe(tclimit);
+
+        if (!vpe_free(v)) {
+               printk(KERN_DEBUG "RP Stopped\n");
+               return 0;
+       }
+        else
+        	return -1;
+}
+
+EXPORT_SYMBOL(vpe1_sw_stop);
+
+uint32_t vpe1_get_load_addr (uint32_t flags)
+{
+       return vpe1_load_addr;
+}
+
+EXPORT_SYMBOL(vpe1_get_load_addr);
+
+uint32_t vpe1_get_max_mem (uint32_t flags)
+{
+       if (!vpe1_mem)
+               return P_SIZE;
+       else
+               return vpe1_mem;
+}
+
+EXPORT_SYMBOL(vpe1_get_max_mem);
+
+void* vpe1_get_cmdline_argument(void)
+{
+       return saved_command_line;
+}
+
+EXPORT_SYMBOL(vpe1_get_cmdline_argument);
+
+int32_t vpe1_set_boot_param(char *field, char *value, char flags)
+{
+       char *ptr, string[64];
+       int start_off, end_off;
+       if (!field)
+               return -1;
+       strcpy(string, field);
+       if (value) {
+               strcat(string, "=");
+               strcat(string, value);
+               strcat(command_line, " ");
+               strcat(command_line, string);
+       }
+       else {
+               ptr = strstr(command_line, string);
+               if (ptr) {
+                       start_off = ptr - command_line;
+                       ptr += strlen(string);
+                       while ((*ptr != ' ') && (*ptr != '\0'))
+                               ptr++;
+                       end_off = ptr - command_line;
+                       command_line[start_off] = '\0';
+                       strcat (command_line, command_line+end_off);
+               }
+       }
+       return 0;
+}
+
+EXPORT_SYMBOL(vpe1_set_boot_param);
+
+int32_t vpe1_get_boot_param(char *field, char **value, char flags)
+{
+       char *ptr, string[64];
+       int i = 0;
+       if (!field)
+               return -1;
+       if ((ptr = strstr(command_line, field))) {
+               ptr += strlen(field) + 1; /* including = */
+               while ((*ptr != ' ') && (*ptr != '\0'))
+                       string[i++] = *ptr++;
+               string[i] = '\0';
+               *value = kmalloc((strlen(string) + 1), GFP_KERNEL);
+               if (*value != NULL)
+                       strcpy(*value, string);
+       }
+       else
+               *value = NULL;
+
+       return 0;
+}
+
+EXPORT_SYMBOL(vpe1_get_boot_param);
+
+extern void configure_tlb(void);
+#endif
+
 static ssize_t store_kill(struct device *dev, struct device_attribute *attr,
 			  const char *buf, size_t len)
 {
@@ -1397,14 +1649,41 @@
 	unsigned long flags, val;
 	struct vpe *v = NULL;
 	struct tc *t;
-	int tc, err;
+	int tc, err = 0;
 
 	if (!cpu_has_mipsmt) {
 		printk("VPE loader: not a MIPS MT capable processor\n");
 		return -ENODEV;
 	}
 
-	if (vpelimit == 0) {
+#ifdef CONFIG_LTQ_VPE_EXT
+       strcpy(command_line, saved_command_line);
+       vpe1mem();
+#ifndef CONFIG_MIPS_MT_SMTC
+        configure_tlb();
+#endif
+#endif
+
+#ifndef CONFIG_MIPS_MT_SMTC
+       if (!vpelimit)
+               vpelimit = 1;
+       if (!tclimit)
+               tclimit = 1;
+#endif
+
+#ifdef CONFIG_LTQ_VPE_EXT
+       val = read_c0_mvpconf0();
+
+        hw_tcs = (val & MVPCONF0_PTC) + 1;
+        hw_vpes = ((val & MVPCONF0_PVPE) >> MVPCONF0_PVPE_SHIFT) + 1;
+
+#endif
+
+	if (vpelimit == 0
+#ifdef CONFIG_LTQ_VPE_EXT
+	|| (vpelimit >= hw_vpes)
+#endif
+) {
 		printk(KERN_WARNING "No VPEs reserved for AP/SP, not "
 		       "initializing VPE loader.\nPass maxvpes=<n> argument as "
 		       "kernel argument\n");
@@ -1412,7 +1691,11 @@
 		return -ENODEV;
 	}
 
-	if (tclimit == 0) {
+	if (tclimit == 0
+#ifdef CONFIG_LTQ_VPE_EXT
+|| (tclimit >= hw_tcs)
+#endif
+) {
 		printk(KERN_WARNING "No TCs reserved for AP/SP, not "
 		       "initializing VPE loader.\nPass maxtcs=<n> argument as "
 		       "kernel argument\n");
@@ -1446,7 +1729,10 @@
 	local_irq_save(flags);
 	mtflags = dmt();
 	vpflags = dvpe();
-
+#ifdef CONFIG_LTQ_VPE_EXT
+	back_to_back_c0_hazard();
+	val = hw_tcs = hw_vpes = 0;
+#endif
 	/* Put MVPE's into 'configuration state' */
 	set_c0_mvpcontrol(MVPCONTROL_VPC);
 
@@ -1555,7 +1841,9 @@
 out_reenable:
 	/* release config state */
 	clear_c0_mvpcontrol(MVPCONTROL_VPC);
-
+#ifdef CONFIG_LTQ_VPE_EXT 
+	back_to_back_c0_hazard();
+#endif
 	evpe(vpflags);
 	emt(mtflags);
 	local_irq_restore(flags);
