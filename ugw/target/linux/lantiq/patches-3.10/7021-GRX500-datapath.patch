# HG changeset patch
# Parent 4e7d9d6ea7f81ea603106366ebbed75051530a91

diff --git a/drivers/net/ethernet/lantiq/datapath/Kconfig b/drivers/net/ethernet/lantiq/datapath/Kconfig
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/Kconfig
@@ -0,0 +1,102 @@
+#
+# Datapath Lib
+#
+config LTQ_DATAPATH
+	bool "Datapath Lib"
+	default y
+	depends on SOC_GRX500
+	---help---
+	  Datapath Lib is to provide common rx/tx wrapper API without taking
+	  care of much HW knowledge and also provide common interface for legacy
+	  devices and different HW like to CBM or LRO.
+	  Take note: All devices need to register to datapath API first
+
+config LTQ_DATAPATH_MIB
+	bool "Datapath aggregated mib support"
+	default n
+	---help---
+	   It is to aggregate GSWIP-L/R, TMU and driver's MIB counter
+config LTQ_DATAPATH_MIB_TMU_MPW_MIB
+        bool "Support TMU-HAL mib API and MPE_HAL mib API"
+        default y
+        depends on LTQ_DATAPATH_MIB
+        ---help---
+          it is to provide dummpy TMU HAL mib api for standalone testing only
+config LTQ_DATAPATH_DUMMY_TMU_MIB
+	bool "Dummy TMU-HAL mib API"
+	default n
+	depends on LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	---help---
+	  it is to provide dummpy TMU HAL mib api for standalone testing only
+config LTQ_DATAPATH_DUMMY_MPE_MIB
+        bool "Dummy MPE-HAL mib API"
+        default n
+        depends on LTQ_DATAPATH_MIB_TMU_MPW_MIB
+        ---help---
+          it is to provide dummpy MPE HAL mib api for standalone testing only
+config LTQ_DATAPATH_OLD_TMU_HAL
+        bool "Integrate with non-standard TMU HAL"
+        default n
+        depends on LTQ_DATAPATH_MIB_TMU_MPW_MIB
+        ---help---
+          it is to used to do integraion with non-standard TMU HAL. For testing only with old TMU HAL
+config LTQ_DATAPATH_CPUFREQ
+        bool "Datapath DFS(COC) support"
+        default n
+	depends on LTQ_CPUFREQ
+        ---help---
+           It is to support DFS(COC) in Datapath
+
+config LTQ_DATAPATH_MANUAL_PARSE
+        bool "Datapath manual parse network protocol"
+        default y
+        ---help---
+           Manual parse network protocol for tcp offloading with some tunnel limit
+
+config LTQ_DATAPATH_COPY_LINEAR_BUF_ONLY
+        bool "Datapath Copy linear buffer only for skb"
+        default n
+        ---help---
+           Datapath Copy linear buffer only for skb if need to alloc new buffer. But it needs CBM driver supports
+
+
+config LTQ_DATAPATH_DBG
+	bool "Datapath Debug Tool"
+	default y
+	depends on LTQ_DATAPATH
+	---help---
+	  Datapath Debug Tool is used to provide simple debug proc tool
+	  Each flag can be enabled/disabled easily
+	  Once this flag is enabled, the debugging information will be printed out
+	  otherwise, no debugging information for this flag will be printed
+
+config LTQ_DATAPATH_LOOPETH
+	bool "pseudo driver simulation"
+	default n
+	depends on LTQ_DATAPATH
+	---help---
+	  Pseudo driver is to simulate ethernet/wifi device to register to datapath
+	  api. Use this pseudo driver can test whether datatpath API is implemented
+	  properly or not.
+	  Also it can be used to measure the directpath performance
+
+config LTQ_DP_MPE_FASTHOOK_TEST
+	bool "MPE FW Fast Hook Test for skb"
+	default n
+	depends on  LTQ_DATAPATH
+	---help---
+	  MPE FW Fast Hook is used to quick verify MPE FW Functionality without
+	  fullPPA support. Once it is enabled, it will add some fields in skb structure
+	  in order to support MPE FAST HOOK. The reason is that some network driver is
+	  pre-build out of this build system.
+
+config LTQ_DP_MPE_FASTHOOK_TEST_COMPILE
+        bool "MPE FW Fast Hook Test"
+        default n
+        depends on  LTQ_DP_MPE_FASTHOOK_TEST
+        ---help---
+          MPE FW Fast Hook is used to quick verify MPE FW Functionality without
+          fullPPA support. It will install two hook in dp_rx/dp_xmit API and
+          quickly learn session informatin. Once the session is learned,
+          it will configure MPE FW session table, ie, the compare table and
+          test MPE FW functionalities.
diff --git a/drivers/net/ethernet/lantiq/datapath/Makefile b/drivers/net/ethernet/lantiq/datapath/Makefile
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/Makefile
@@ -0,0 +1,21 @@
+obj-$(CONFIG_LTQ_DATAPATH) = datapath_api.o datapath_proc_api.o datapath_proc.o datapath_pmac.o datapath_mib.o
+
+ifneq ($(CONFIG_LTQ_DATAPATH_LOOPETH),)
+obj-$(CONFIG_LTQ_DATAPATH) += datapath_loopeth_dev.o
+endif
+
+ifneq ($(CONFIG_LTQ_DATAPATH_CPUFREQ),)
+obj-$(CONFIG_LTQ_DATAPATH) += datapath_coc.o
+endif
+
+ifneq ($(LTQ_DATAPATH_FILTER),)
+obj-$(CONFIG_LTQ_DATAPATH_FILTER) += datapath_filter.o
+endif
+
+
+ifneq ($(CONFIG_LTQ_DP_MPE_FASTHOOK_TEST_COMPILE),)
+obj-$(CONFIG_LTQ_DP_MPE_FASTHOOK_TEST_COMPILE) += mpe/
+endif
+
+
+
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath.h b/drivers/net/ethernet/lantiq/datapath/datapath.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath.h
@@ -0,0 +1,303 @@
+#ifndef DATAPATH_H
+#define DATAPATH_H		/*! PMAC port informatin data */
+
+#include <linux/klogging.h>
+#include <linux/skbuff.h>	/*skb */
+#define SEQ_PRINTF  seq_printf
+
+#define PRINTK  LOGF_KLOG_CONT
+#define PR_ERR  LOGF_KLOG_ERROR
+#define PR_INFO LOGF_KLOG_INFO
+#define PR_CONT LOGF_KLOG_CONT
+#define PR_INFO_ONCE    LOGF_KLOG_INFO_ONCE
+#define PR_RATELIMITED LOGF_KLOG_RATELIMITED
+
+#define GSWIP_L_DEV_NAME "/dev/switch_api/0"
+#define GSWIP_R_DEV_NAME "/dev/switch_api/1"
+#define SEQ_PRINTF seq_printf
+
+#define dp_set_val(reg, val, mask, offset) do \
+	{(reg) &= ~(mask);\
+	(reg) |= (((val) << (offset)) & (mask));\
+	} while (0)
+
+#define dp_get_val(val, mask, offset) (((val) & (mask)) >> (offset))
+
+#define DP_DEBUG_ASSERT(expr, fmt, arg...)  do { if (expr) \
+	PR_ERR(fmt, ##arg); }	\
+	while (0)
+
+#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+#define DP_DEBUG(flags, fmt, arg...)  do { if (unlikely((dp_dbg_flag & flags) \
+	&& (((dp_print_num_en) && (dp_max_print_num)) || (!dp_print_num_en))))\
+	{ PRINTK(fmt, ##arg); if ((dp_print_num_en) &&\
+	(dp_max_print_num)) dp_max_print_num--; } } \
+	while (0)
+
+#define DP_ASSERT_SCOPE __func__
+
+#else
+#define DP_DEBUG(flags, fmt, arg...)
+#endif				/* end of CONFIG_LTQ_DATAPATH_DBG */
+
+#define SET_PMAC_PORTMAP(pmac, port_id) do { if (port_id <= 7)\
+	pmac->port_map2 = 1 << (port_id); \
+	else \
+		pmac->port_map = (1 << (port_id-8)); } \
+	while (0)
+
+#define SET_PMAC_SUBIF(pmac, subif) do {;\
+	pmac->src_sub_inf_id2 = (subif) & 0xff; \
+	pmac->src_sub_inf_id =  ((subif) >> 8) & 0x1f; } \
+	while (0)
+
+#define IFNAMSIZ 16
+#define PMAC_MAX_NUM  16
+#define PAMC_LAN_MAX_NUM 7
+
+#define DP_LIB_LOCK    spin_lock_bh
+#define DP_LIB_UNLOCK  spin_unlock_bh
+
+#define PARSER_FLAG_SIZE   40
+#define PARSER_OFFSET_SIZE 8
+#define PMAC_SIZE          8
+
+#define MAX_SUBIF_PER_PORT 16
+
+#define PKT_PASER_FLAG_OFFSET   0
+#define PKT_PASER_OFFSET_OFFSET (PARSER_FLAG_SIZE)
+#define PKT_PMAC_OFFSET         ((PARSER_FLAG_SIZE) + (PARSER_OFFSET_SIZE))
+#define PKT_DATA_OFFSET         ((PKT_PMAC_OFFSET) + (PMAC_SIZE))
+
+#define CHECK_BIT(var, pos) (((var) & (1<<(pos))) ? 1 : 0)
+
+#define VAP_OFFSET 8
+#define VAP_MASK  0xF
+#define VAP_DSL_OFFSET 3
+#define NEW_CBM_API 1
+
+#define PASAR_OFFSETS_NUM 40	/*40 bytes offset */
+#define PASAR_FLAGS_NUM 8	/*8 bytes */
+
+enum PARSER_FLAGS {
+	PASER_FLAGS_NO = 0,
+	PASER_FLAGS_END,
+	PASER_FLAGS_CAPWAP,
+	PASER_FLAGS_GRE,
+	PASER_FLAGS_LEN,
+	PASER_FLAGS_GREK,
+	PASER_FLAGS_NN1,
+	PASER_FLAGS_NN2,
+
+	PASER_FLAGS_ITAG,
+	PASER_FLAGS_1VLAN,
+	PASER_FLAGS_2VLAN,
+	PASER_FLAGS_3VLAN,
+	PASER_FLAGS_4VLAN,
+	PASER_FLAGS_SNAP,
+	PASER_FLAGS_PPPOES,
+	PASER_FLAGS_1IPV4,
+
+	PASER_FLAGS_1IPV6,
+	PASER_FLAGS_2IPV4,
+	PASER_FLAGS_2IPV6,
+	PASER_FLAGS_ROUTEXP,
+	PASER_FLAGS_TCP,
+	PASER_FLAGS_1UDP,
+	PASER_FLAGS_IGMP,
+	PASER_FLAGS_IPV4OPT,
+
+	PASER_FLAGS_IPV6EXT,
+	PASER_FLAGS_TCPACK,
+	PASER_FLAGS_IPFRAG,
+	PASER_FLAGS_EAPOL,
+	PASER_FLAGS_2IPV6EXT,
+	PASER_FLAGS_2UDP,
+	PASER_FLAGS_L2TPNEXP,
+	PASER_FLAGS_LROEXP,
+
+	PASER_FLAGS_L2TP,
+	PASER_FLAGS_GRE_VLAN1,
+	PASER_FLAGS_GRE_VLAN2,
+	PASER_FLAGS_GRE_PPPOE,
+	PASER_FLAGS_BYTE4_BIT4,
+	PASER_FLAGS_BYTE4_BIT5,
+	PASER_FLAGS_BYTE4_BIT6,
+	PASER_FLAGS_BYTE4_BIT7,
+
+	PASER_FLAGS_BYTE5_BIT0,
+	PASER_FLAGS_BYTE5_BIT1,
+	PASER_FLAGS_BYTE5_BIT2,
+	PASER_FLAGS_BYTE5_BIT3,
+	PASER_FLAGS_BYTE5_BIT4,
+	PASER_FLAGS_BYTE5_BIT5,
+	PASER_FLAGS_BYTE5_BIT6,
+	PASER_FLAGS_BYTE5_BIT7,
+
+	PASER_FLAGS_BYTE6_BIT0,
+	PASER_FLAGS_BYTE6_BIT1,
+	PASER_FLAGS_BYTE6_BIT2,
+	PASER_FLAGS_BYTE6_BIT3,
+	PASER_FLAGS_BYTE6_BIT4,
+	PASER_FLAGS_BYTE6_BIT5,
+	PASER_FLAGS_BYTE6_BIT6,
+	PASER_FLAGS_BYTE6_BIT7,
+
+	PASER_FLAGS_BYTE7_BIT0,
+	PASER_FLAGS_BYTE7_BIT1,
+	PASER_FLAGS_BYTE7_BIT2,
+	PASER_FLAGS_BYTE7_BIT3,
+	PASER_FLAGS_BYTE7_BIT4,
+	PASER_FLAGS_BYTE7_BIT5,
+	PASER_FLAGS_BYTE7_BIT6,
+	PASER_FLAGS_BYTE7_BIT7,
+
+	/*Must be put at the end of the enum */
+	PASER_FLAGS_MAX
+};
+
+/*! PMAC port flag */
+enum PORT_FLAG {
+	PORT_FREE = 0,		/*! The port is free */
+	PORT_ALLOCATED,		/*! the port is already allocated to some driver,
+				   but not registered or no need to register at all.\n
+				   for example, LRO/CAPWA, only need to allocate,
+				   but no need to register
+				 */
+	PORT_DEV_REGISTERED,	/*! dev Registered already. */
+	PORT_SUBIF_REGISTERED,	/*! subif Registered already. */
+
+	PORT_FLAG_NO_VALID	/*! Not valid flag */
+};
+
+struct dev_mib {
+	uint32_t rx_fn_rxif_pkt;	/*! received packet counter */
+	uint32_t rx_fn_txif_pkt;	/*! transmitted packet coutner */
+	uint32_t rx_fn_dropped;	/*! transmitted packet coutner */
+	uint32_t tx_cbm_pkt;	/*! transmitted packet counter */
+	uint32_t tx_clone_pkt;	/*! duplicate unicast packet for cloned flag */
+	uint32_t tx_hdr_room_pkt;	/*! duplicate packet for no enough skb header room */
+	uint32_t tx_tso_pkt;	/*! transmitted packet counter */
+	uint32_t tx_pkt_dropped;	/*! dropped packet counter */
+
+};
+
+/*! Sub interface detail information */
+struct dp_subif_info {
+	int32_t flags;
+	uint32_t subif:15;
+	struct net_device *netif;	/*! pointer to  net_device */
+	char device_name[IFNAMSIZ]; /*! devide name, like wlan0, */
+	struct dev_mib mib; /*! mib */
+};
+
+struct gsw_itf {
+	u8 ep; /*-1 means no assigned yet for dynamic case */
+	u8 fixed; /*fixed (1) or dynamically allocate (0)*/
+	u16 start;
+	u16 end;
+};
+
+struct pmac_port_info {
+	enum PORT_FLAG status;	/*! port status */
+	int alloc_flags;	/* the flags saved when calling dp_port_alloc */
+	struct dp_cb cb;	/*! Callback Pointer to DIRECTPATH_CB */
+	struct module *owner;
+	struct net_device *dev;
+	uint32_t dev_port;
+	dp_pmac_cfg_t pmac_cfg;
+	uint32_t num_subif;
+	int32_t port_id;
+	struct dp_subif_info subif_info[MAX_SUBIF_PER_PORT];
+	uint32_t tx_err_drop;
+	uint32_t rx_err_drop;
+	struct gsw_itf *itf_info;  /*point to switch interface configuration */
+};
+
+struct parser_info {
+	uint8_t v;
+	int8_t size;
+};
+
+#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+extern unsigned int dp_dbg_flag;
+extern unsigned int dp_dbg_err;
+extern unsigned int dp_max_print_num;
+extern unsigned int dp_print_num_en;
+#endif
+extern struct pmac_port_info dp_port_info[PMAC_MAX_NUM];	/*port 0 is reserved */
+extern int dp_loop_eth_dev_init(struct proc_dir_entry *parent);
+extern void dp_loop_eth_dev_exit(void);
+extern struct proc_dir_entry *dp_proc_install(void);
+extern char *dp_dbg_flag_str[];
+extern unsigned int dp_dbg_flag_list[];
+extern u32 dp_port_flag[];
+extern char *dp_port_type_str[];
+extern char *dp_port_status_str[];
+extern struct parser_info pinfo[];
+extern int get_dp_dbg_flag_str_size(void);
+extern int get_dp_port_status_str_size(void);
+extern int get_dp_port_type_str_size(void);
+extern GSW_API_HANDLE gswr_r;
+enum TEST_MODE {
+	DP_RX_MODE_NORMAL = 0,
+	DP_RX_MODE_LAN_WAN_BRIDGE,
+	DP_RX_MODE_LOCALTCP_FAST,
+	DPR_RX_MODE_MAX
+};
+extern u32 dp_rx_test_mode;
+
+extern int32_t dp_pmac_set(uint32_t port, dp_pmac_cfg_t *pmac_cfg);
+char *parser_flag_str(uint8_t f);
+ssize_t proc_print_mode_write(struct file *file, const char *buf,
+			      size_t count, loff_t *ppos);
+void proc_print_mode_read(struct seq_file *s);
+int parser_size_via_index(u8 index);
+struct pmac_port_info *get_port_info_via_dp_name(struct net_device *dev);
+void dp_clear_mib(dp_subif_t *subif, uint32_t flag);
+extern u32 dp_drop_all_tcp_err;
+extern u32 dp_pkt_size_check;
+int dp_mib_init(void);
+void dp_mib_exit(void);
+int gsw_mib_reset(int dev, u32 flag);
+void print_parser_status(struct seq_file *s);
+int dp_get_drv_mib(dp_subif_t *subif, dp_drv_mib_t *mib, uint32_t flag);
+void proc_mib_timer_read(struct seq_file *s);
+ssize_t proc_mib_timer_write(struct file *file, const char *buf, size_t count,
+			     loff_t *ppos);
+int proc_mib_inside_dump(struct seq_file *s, int pos);
+int proc_mib_inside_start(void);
+ssize_t proc_mib_inside_write(struct file *file, const char *buf,
+			      size_t count, loff_t *ppos);
+int proc_mib_port_start(void);
+int proc_mib_port_dump(struct seq_file *s, int pos);
+int proc_mib_vap_start(void);
+int proc_mib_vap_dump(struct seq_file *s, int pos);
+ssize_t proc_mib_vap_write(struct file *, const char *, size_t, loff_t *);
+ssize_t proc_mib_port_write(struct file *file, const char *buf, size_t count,
+		      loff_t *ppos);
+int mpe_fh_netfiler_install(void);
+int dp_coc_cpufreq_exit(void);
+int dp_coc_cpufreq_init(void);
+int update_coc_up_sub_module(enum ltq_cpufreq_state new_state,
+			     enum ltq_cpufreq_state old_state, uint32_t flag);
+int get_gsw_port_rmon(u32 ep, char *gsw_drv_name, GSW_RMON_Port_cnt_t *mib);
+void proc_coc_read(struct seq_file *s);
+ssize_t proc_coc_write(struct file *file, const char *buf, size_t count,
+		       loff_t *ppos);
+void dp_sys_mib_reset(uint32_t flag);
+int dp_reset_sys_mib(u32 flag);
+
+void dp_clear_all_mib_inside(uint32_t flag);
+
+static inline unsigned int get_vap(uint32_t subif)
+{
+	return (subif >> VAP_OFFSET) & VAP_MASK;
+}
+
+static inline unsigned int set_vap(int vap)
+{
+	return (vap & VAP_MASK) << VAP_OFFSET;
+}
+
+#endif				/*DATAPATH_H */
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_api.c b/drivers/net/ethernet/lantiq/datapath/datapath_api.c
new file mode 100644
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_api.c
@@ -0,0 +1,2912 @@
+#include<linux/init.h>
+#include<linux/module.h>
+#include <linux/kernel.h>	/* printk */
+#include <linux/types.h>	/* size_t */
+#include <linux/version.h>
+#include <linux/if_ether.h>
+#include <linux/ethtool.h>
+#include <linux/proc_fs.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+#include <linux/if_ether.h>
+#include <linux/clk.h>
+#include <linux/ip.h>
+#include <net/ip.h>
+
+#include <lantiq.h>
+#include <lantiq_soc.h>
+#include <net/lantiq_cbm.h>
+#include <net/datapath_api.h>
+#include "datapath_pmac.h"
+#include "datapath.h"
+#include <net/lantiq_cbm_api.h>
+#include <xway/switch-api/lantiq_gsw_api.h>
+#include <xway/switch-api/lantiq_gsw_flow.h>
+#ifdef CONFIG_LTQ_TMU
+#include <net/drv_tmu_ll.h>
+#endif
+#include <linux/ltq_hwmcpy.h>
+#if defined(CONFIG_LTQ_PPA_API) || defined(CONFIG_LTQ_PPA_API_MODULE)
+#include <net/ppa_api.h>
+#endif
+
+#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+unsigned int dp_max_print_num = -1, dp_print_num_en = 0;
+#endif
+
+GSW_API_HANDLE gswr_r;
+u32    dp_rx_test_mode = DP_RX_MODE_NORMAL;
+struct dma_rx_desc_1 dma_rx_desc_mask1;
+struct dma_rx_desc_3 dma_rx_desc_mask3;
+struct dma_rx_desc_0 dma_tx_desc_mask0;
+struct dma_rx_desc_1 dma_tx_desc_mask1;
+u32 dp_drop_all_tcp_err;
+u32 dp_pkt_size_check;
+
+#ifdef CONFIG_LTQ_DP_MPE_FASTHOOK_TEST
+int (*ltq_mpe_fasthook_free_fn)(struct sk_buff *) = NULL;
+EXPORT_SYMBOL(ltq_mpe_fasthook_free_fn);
+
+int (*ltq_mpe_fasthook_tx_fn)(struct sk_buff *, u32, void *) = NULL;
+EXPORT_SYMBOL(ltq_mpe_fasthook_tx_fn);
+
+int (*ltq_mpe_fasthook_rx_fn)(struct sk_buff *, u32, void *) = NULL;
+EXPORT_SYMBOL(ltq_mpe_fasthook_rx_fn);
+#endif	/*CONFIG_LTQ_DP_MPE_FASTHOOK_TEST */
+
+#if defined(CONFIG_LTQ_HWMCPY) && CONFIG_LTQ_HWMCPY
+/*#define dp_memcpy(x, y, z)
+* ltq_hwmemcpy(x, y, z, 0, MCPY_IOCU_TO_IOCU, HWMCPY_F_PRIO_HIGH)
+*/
+#define dp_memcpy(x, y, z)   memcpy(x, y, z)
+#else
+#define dp_memcpy(x, y, z)   memcpy(x, y, z)
+#endif
+
+#undef DP_DBG_ENUM_OR_STRING
+#define DP_DBG_ENUM_OR_STRING(name, value, short_name) short_name
+char *dp_dbg_flag_str[] = DP_DBG_FLAG_LIST;
+
+#undef DP_DBG_ENUM_OR_STRING
+
+#undef DP_DBG_ENUM_OR_STRING
+#define DP_DBG_ENUM_OR_STRING(name, value, short_name) value
+u32 dp_dbg_flag_list[] = DP_DBG_FLAG_LIST;
+
+#undef DP_DBG_ENUM_OR_STRING
+
+#undef DP_F_ENUM_OR_STRING
+#define DP_F_ENUM_OR_STRING(name, value, short_name) short_name
+char *dp_port_type_str[] = DP_F_FLAG_LIST;
+
+#undef DP_F_ENUM_OR_STRING
+
+#undef DP_F_ENUM_OR_STRING
+#define DP_F_ENUM_OR_STRING(name, value, short_name) value
+u32 dp_port_flag[] = DP_F_FLAG_LIST;
+
+#undef DP_F_ENUM_OR_STRING
+
+char *dp_port_status_str[] = {
+	"PORT_FREE",
+	"PORT_ALLOCATED",
+	"PORT_DEV_REGISTERED",
+	"PORT_SUBIF_REGISTERED",
+	"Invalid"
+};
+
+static int dp_init_ok;
+spinlock_t dp_lock; /*datapath spinlock*/
+unsigned int dp_dbg_flag;
+unsigned int dp_dbg_err = 1; /*print error */
+static int32_t dp_rx_one_skb(struct sk_buff *skb, uint32_t flags);
+/*port 0 is reserved and never assigned to any one */
+struct pmac_port_info dp_port_info[PMAC_MAX_NUM];
+struct parser_info pinfo[4];
+static int print_len;
+static char *parser_flags_str[] = {
+	"PASER_FLAGS_NO",
+	"PASER_FLAGS_END",
+	"PASER_FLAGS_CAPWAP",
+	"PASER_FLAGS_GRE",
+	"PASER_FLAGS_LEN",
+	"PASER_FLAGS_GREK",
+	"PASER_FLAGS_NN1",
+	"PASER_FLAGS_NN2",
+
+	"PASER_FLAGS_ITAG",
+	"PASER_FLAGS_1VLAN",
+	"PASER_FLAGS_2VLAN",
+	"PASER_FLAGS_3VLAN",
+	"PASER_FLAGS_4VLAN",
+	"PASER_FLAGS_SNAP",
+	"PASER_FLAGS_PPPOES",
+	"PASER_FLAGS_1IPV4",
+
+	"PASER_FLAGS_1IPV6",
+	"PASER_FLAGS_2IPV4",
+	"PASER_FLAGS_2IPV6",
+	"PASER_FLAGS_ROUTEXP",
+	"PASER_FLAGS_TCP",
+	"PASER_FLAGS_1UDP",
+	"PASER_FLAGS_IGMP",
+	"PASER_FLAGS_IPV4OPT",
+
+	"PASER_FLAGS_IPV6EXT",
+	"PASER_FLAGS_TCPACK",
+	"PASER_FLAGS_IPFRAG",
+	"PASER_FLAGS_EAPOL",
+	"PASER_FLAGS_2IPV6EXT",
+	"PASER_FLAGS_2UDP",
+	"PASER_FLAGS_L2TPNEXP",
+	"PASER_FLAGS_LROEXP",
+
+	"PASER_FLAGS_L2TP",
+	"PASER_FLAGS_GRE_VLAN1",
+	"PASER_FLAGS_GRE_VLAN2",
+	"PASER_FLAGS_GRE_PPPOE",
+	"PASER_FLAGS_BYTE4_BIT4_UNDEF",
+	"PASER_FLAGS_BYTE4_BIT5_UNDEF",
+	"PASER_FLAGS_BYTE4_BIT6_UNDEF",
+	"PASER_FLAGS_BYTE4_BIT7_UNDEF",
+
+	"PASER_FLAGS_BYTE5_BIT0_UNDEF",
+	"PASER_FLAGS_BYTE5_BIT1_UNDEF",
+	"PASER_FLAGS_BYTE5_BIT2_UNDEF",
+	"PASER_FLAGS_BYTE5_BIT3_UNDEF",
+	"PASER_FLAGS_BYTE5_BIT4_UNDEF",
+	"PASER_FLAGS_BYTE5_BIT5_UNDEF",
+	"PASER_FLAGS_BYTE5_BIT6_UNDEF",
+	"PASER_FLAGS_BYTE5_BIT7_UNDEF",
+
+	"PASER_FLAGS_BYTE6_BIT0_UNDEF",
+	"PASER_FLAGS_BYTE6_BIT1_UNDEF",
+	"PASER_FLAGS_BYTE6_BIT2_UNDEF",
+	"PASER_FLAGS_BYTE6_BIT3_UNDEF",
+	"PASER_FLAGS_BYTE6_BIT4_UNDEF",
+	"PASER_FLAGS_BYTE6_BIT5_UNDEF",
+	"PASER_FLAGS_BYTE6_BIT6_UNDEF",
+	"PASER_FLAGS_BYTE6_BIT7_UNDEF",
+
+	"PASER_FLAGS_BYTE7_BIT0_UNDEF",
+	"PASER_FLAGS_BYTE7_BIT1_UNDEF",
+	"PASER_FLAGS_BYTE7_BIT2_UNDEF",
+	"PASER_FLAGS_BYTE7_BIT3_UNDEF",
+	"PASER_FLAGS_BYTE7_BIT4_UNDEF",
+	"PASER_FLAGS_BYTE7_BIT5_UNDEF",
+	"PASER_FLAGS_BYTE7_BIT6_UNDEF",
+	"PASER_FLAGS_BYTE7_BIT7_UNDEF",
+
+	/*Must be put at the end of the enum */
+	"PASER_FLAGS_MAX"
+};
+
+struct gsw_itf itf_assign[] = {
+		{0, 1, 0, 16},
+		{15, 1, 17, 33},
+		{1, 1, 34, 50},
+		{2, 1, 51, 67},
+		{3, 1, 68, 84},
+		{4, 1, 85, 101},
+		{5, 1, 102, 118},
+		{-1, 1, 119, 135},
+		{-1, 1, 136, 152},
+		{-1, 1, 153, 169},
+		{-1, 1, 170, 186},
+		{-1, 1, 187, 203},
+		{-1, 1, 204, 220},
+		{-1, 1, 221, 237},
+		{-1, 1, 238, 255}
+};
+
+int get_dp_port_type_str_size(void)
+{
+	return ARRAY_SIZE(dp_port_type_str);
+}
+
+int get_dp_dbg_flag_str_size(void)
+{
+	return ARRAY_SIZE(dp_dbg_flag_str);
+}
+
+int get_dp_port_status_str_size(void)
+{
+	return ARRAY_SIZE(dp_port_status_str);
+}
+
+int parser_size_via_index(u8 index)
+{
+	if (index >= ARRAY_SIZE(pinfo)) {
+		PR_ERR("Wrong index=%d, it should less than %d\n", index,
+		       ARRAY_SIZE(pinfo));
+		return 0;
+	}
+
+	return pinfo[index].size;
+}
+
+/*check whether the paser is existing or not in the current packet */
+static inline int parser_enabled(int ep, struct dma_rx_desc_1 *desc_1)
+{
+	u8 index;
+
+	if (!desc_1) {
+		PR_ERR("NULL desc_1 is not allowed\n");
+		return 0;
+	} else if (ep) {
+		/*only cpu may have parser, otherwise no parser */
+		return 0;
+	}
+	index = (desc_1->field.mpe2 << 1) + desc_1->field.mpe1;
+	return parser_size_via_index(index);
+}
+
+struct pmac_port_info *get_port_info(int index)
+{
+	if (index < PMAC_MAX_NUM)
+		return &dp_port_info[index];
+
+	return NULL;
+}
+
+struct pmac_port_info *get_port_info_via_dp_port(int dp_port)
+{
+	int i;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		if ((dp_port_info[i].status & PORT_DEV_REGISTERED) &&
+		    (dp_port_info[i].port_id == dp_port))
+			return &dp_port_info[i];
+	}
+
+	return NULL;
+}
+
+struct pmac_port_info *get_port_info_via_dp_name(struct net_device *dev)
+{
+	int i;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		if ((dp_port_info[i].status & PORT_DEV_REGISTERED) &&
+		    (dp_port_info[i].dev == dev))
+			return &dp_port_info[i];
+	}
+
+	return NULL;
+}
+
+int8_t parser_size(int8_t v)
+{
+	if (v == DP_PARSER_F_DISABLE)
+		return 0;
+
+	if (v == DP_PARSER_F_HDR_ENABLE)
+		return PASAR_OFFSETS_NUM;
+
+	if (v == DP_PARSER_F_HDR_OFFSETS_ENABLE)
+		return PASAR_OFFSETS_NUM + PASAR_FLAGS_NUM;
+
+	PR_ERR("Wrong parser setting: %d\n", v);
+	/*error */
+	return -1;
+}
+
+char *parser_str(int index)
+{
+	if (index == 0)
+		return "cpu";
+
+	if (index == 1)
+		return "mpe1";
+
+	if (index == 2)
+		return "mpe2";
+
+	if (index == 3)
+		return "mpe3";
+
+	PR_ERR("Wrong index:%d\n", index);
+	return "Wrong index";
+}
+
+/*some module may have reconfigure parser configuration in FMDA_PASER.
+* It is necessary to refresh the pinfo
+*/
+void dp_parser_info_refresh(u32 v, u32 verify)
+{
+	int i;
+
+	pinfo[0].v = (v >> 0) & 0x3;
+	pinfo[1].v = (v >> 2) & 0x3;
+	pinfo[2].v = (v >> 4) & 0x3;
+	pinfo[3].v = (v >> 6) & 0x3;
+
+	for (i = 0; i < ARRAY_SIZE(pinfo); i++) {
+		if (verify) {
+			if (pinfo[i].size != parser_size(pinfo[i].v))
+				PR_ERR
+				    ("Why local parser size pinfo[%d](%d) != register setting(%d)\n",
+				     i, pinfo[i].size,
+				     parser_size(pinfo[i].v));
+		}
+
+		/*force to update */
+		pinfo[i].size = parser_size(pinfo[i].v);
+
+		if ((pinfo[i].size < 0) || (pinfo[i].size > PKT_PMAC_OFFSET)) {
+			PR_ERR("Wrong parser setting for %s: %d\n",
+			       parser_str(i), pinfo[i].v);
+		}
+	}
+}
+EXPORT_SYMBOL(dp_parser_info_refresh);
+
+void print_parser_status(struct seq_file *s)
+{
+	if (!s)
+		return;
+
+	SEQ_PRINTF(s, "REG.cpu  value=%u size=%u\n", pinfo[0].v,
+		   pinfo[0].size);
+	SEQ_PRINTF(s, "REG.MPE1 value=%u size=%u\n", pinfo[1].v,
+		   pinfo[1].size);
+	SEQ_PRINTF(s, "REG.MPE2 value=%u size=%u\n", pinfo[2].v,
+		   pinfo[2].size);
+	SEQ_PRINTF(s, "REG.MPE3 value=%u size=%u\n", pinfo[3].v,
+		   pinfo[3].size);
+}
+
+static int dp_get_index_via_module_dev_port_priv(struct module *owner,
+						 struct net_device *dev,
+						 uint32_t dev_port)
+{
+	int i;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		if (dp_port_info[i].status) {
+			if ((dp_port_info[i].owner == owner) &&
+			    (dp_port_info[i].dev_port == dev_port))
+				return i;
+		}
+	}
+
+	return -1;
+}
+
+int set_gsw_itf(u8 ep, u8 ena, int start)
+{
+	union gsw_var tmp;
+
+	if (ep >= PMAC_MAX_NUM)
+		return -1;
+
+	/*get this ports itf base */
+	tmp.port_cfg.nPortId = ep;
+	if (dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_PORT_CFG_GET, (u32)&tmp)) {
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "Why dp_gsw_kioctl return failjure: GSW_PORT_CFG_GET for port_id=%d\n",
+			 tmp.port_cfg.nPortId);
+		return -1;
+	}
+	tmp.port_cfg.nIfCountStartIdx = start;
+	tmp.port_cfg.bIfCounters = ena ? 1 : 0;
+	if (dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_PORT_CFG_SET, (u32)&tmp)) {
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "Why dp_gsw_kioctl return failjure: GSW_PORT_CFG_SET for port_id=%d\n",
+			 tmp.port_cfg.nPortId);
+		return -1;
+	}
+
+	return 0;
+}
+
+struct gsw_itf *get_free_itf(u8 ep, u32 flag)
+{
+	int i;
+	int free_id = -1;
+
+	if (ep >= PMAC_MAX_NUM)
+		return NULL;
+
+	for (i = 0; i < ARRAY_SIZE(itf_assign); i++) {
+		if (ep == itf_assign[i].ep) {
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				"Found the free gsw itf for itf_assign[i]=%d\n",
+				i);
+			set_gsw_itf(ep, 1, itf_assign[i].start);
+			return &itf_assign[i];
+		}
+		if ((itf_assign[i].ep == -1) && (free_id == -1))
+			free_id = i;
+	}
+	if (free_id != -1) {
+		i = free_id;
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			"Found the free gsw itf for itf_assign[i]=%d\n",
+			i);
+		itf_assign[i].ep = ep;
+		set_gsw_itf(ep, 1, itf_assign[i].start);
+		return &itf_assign[i];
+	}
+
+	return NULL;
+}
+
+int reset_gsw_itf(u8 ep)
+{
+	int i;
+
+	if (ep >= PMAC_MAX_NUM)
+		return -1;
+
+	/* only matched the fixed assignment one */
+	for (i = 0; i < ARRAY_SIZE(itf_assign); i++)
+		if (itf_assign[i].ep == ep)
+			break;
+	if (i >= ARRAY_SIZE(itf_assign)) {
+		set_gsw_itf(ep, 0, 0);
+	} else if (itf_assign[i].fixed) {
+		set_gsw_itf(ep, 1, itf_assign[i].start);
+	} else {
+		set_gsw_itf(ep, 0, 0);
+		itf_assign[i].ep = -1;
+	}
+
+	return 0;
+}
+
+/*note: dev can be NULL */
+static int32_t dp_alloc_port_private(struct module *owner,
+				     struct net_device *dev,
+				     uint32_t dev_port, int32_t port_id,
+				     dp_pmac_cfg_t *pmac_cfg, uint32_t flags)
+{
+	int i;
+
+	if (!owner) {
+		PR_ERR("Allocate port failed for owner NULL\n");
+		return DP_FAILURE;
+	}
+
+	if (port_id >= PMAC_MAX_NUM || port_id < 0) {
+		DP_DEBUG_ASSERT((port_id >= PMAC_MAX_NUM),
+				"port_id(%d) >= PMAC_MAX_NUM(%d)", port_id,
+				PMAC_MAX_NUM);
+		DP_DEBUG_ASSERT((port_id < 0), "port_id(%d) < 0", port_id);
+		return DP_FAILURE;
+	}
+
+	DP_DEBUG(DP_DBG_FLAG_DBG, "Flags=");
+
+	for (i = 0; i < get_dp_port_type_str_size(); i++) {
+		if (flags & dp_port_flag[i])
+			DP_DEBUG(DP_DBG_FLAG_DBG, "%s ", dp_port_type_str[i]);
+	}
+
+	DP_DEBUG(DP_DBG_FLAG_DBG, "\n");
+
+	if (flags & DP_F_DEREGISTER) {	/*De-register */
+		if (dp_port_info[port_id].status != PORT_ALLOCATED) {
+			PR_ERR
+			    ("No Deallocate for module %s w/o deregistered\n",
+			     owner->name);
+			return DP_FAILURE;
+		}
+
+		cbm_dp_port_dealloc(owner, dev_port, port_id, flags);
+		DP_DEBUG(DP_DBG_FLAG_DBG, "de-alloc port %d\n", port_id);
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+		reset_gsw_itf(port_id);
+#endif
+		memset(&dp_port_info[port_id], 0,
+		       sizeof(dp_port_info[port_id]));
+		return DP_SUCCESS;
+	}
+
+	/*sanity check here: "onwner + dev_port" should be unique  */
+	i = dp_get_index_via_module_dev_port_priv(owner, dev, dev_port);
+
+	if (i > 0) {
+		DP_DEBUG_ASSERT(i > 0,
+				"module %s(dev_port %d)already alloc %d\n",
+				owner->name, dev_port,
+				dp_port_info[i].port_id);
+		return DP_FAILURE;
+	}
+
+	if (port_id) {		/*with specified port_id */
+		if (dp_port_info[port_id].status != PORT_FREE) {
+			DP_DEBUG_ASSERT(i > 0,
+					"module %s (dev_port %d) failed to allocate port %d used by %s %d\n",
+					owner->name, dev_port, port_id,
+					dp_port_info[i].owner->name,
+					dp_port_info[i].dev_port);
+			return DP_FAILURE;
+		}
+	}
+	port_id = cbm_dp_port_alloc(owner, dev, dev_port, port_id, flags);
+	if (port_id <= 0) {
+		PR_ERR
+		    ("cbm_dp_port_alloc allocation failed for module %s with dev_port %d\n",
+		     owner->name, dev_port);
+		return DP_FAILURE;
+	}
+	memset(&dp_port_info[port_id], 0, sizeof(dp_port_info[port_id]));
+	dp_port_info[port_id].owner = owner;
+	dp_port_info[port_id].dev = dev;
+	dp_port_info[port_id].dev_port = dev_port;
+	dp_port_info[port_id].alloc_flags = flags;
+	dp_port_info[port_id].status = PORT_ALLOCATED;
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+	dp_port_info[port_id].itf_info = get_free_itf(port_id, flags);
+#endif
+	if (pmac_cfg)
+		dp_pmac_set(port_id, pmac_cfg);
+
+	DP_DEBUG(DP_DBG_FLAG_DBG,
+		 "Port %d allocation succeed for module %s with dev_port %d\n",
+		 port_id, owner->name, dev_port);
+	return port_id;
+}
+
+int32_t dp_alloc_port(struct module *owner, struct net_device *dev,
+		      uint32_t dev_port, int32_t port_id,
+		      dp_pmac_cfg_t *pmac_cfg, uint32_t flags)
+{
+	int res;
+
+	if (unlikely(!dp_init_ok)) {
+		PR_ERR("dp_alloc_port failed for datapath not init yet\n");
+		return DP_FAILURE;
+	}
+
+	DP_LIB_LOCK(&dp_lock);
+	res =
+	    dp_alloc_port_private(owner, dev, dev_port, port_id, NULL, flags);
+	DP_LIB_UNLOCK(&dp_lock);
+	return res;
+}
+EXPORT_SYMBOL(dp_alloc_port);
+
+int32_t dp_register_dev(struct module *owner, uint32_t port_id,
+			dp_cb_t *dp_cb, uint32_t flags)
+{
+	int res = DP_FAILURE;
+
+	if (unlikely(!dp_init_ok)) {
+		PR_ERR("dp_register_dev failed for datapath not init yet\n");
+		return DP_FAILURE;
+	}
+
+	if (!port_id || !owner || port_id >= PMAC_MAX_NUM) {
+		if (!owner)
+			DP_DEBUG(DP_DBG_FLAG_DBG, "owner NULL\n");
+		else
+			DP_DEBUG(DP_DBG_FLAG_DBG, "Wrong port_id:%d\n",
+				 port_id);
+
+		return DP_FAILURE;
+	}
+
+	if (flags & DP_F_DEREGISTER) {	/*de-register */
+		DP_LIB_LOCK(&dp_lock);
+
+		if (dp_port_info[port_id].status != PORT_DEV_REGISTERED) {
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "No or %s to de-register for num_subif=%d\n",
+				 owner->name,
+				 dp_port_info[port_id].num_subif);
+		} else if (dp_port_info[port_id].status ==
+			   PORT_DEV_REGISTERED) {
+			dp_port_info[port_id].status = PORT_ALLOCATED;
+			res = DP_SUCCESS;
+		} else {
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "No for %s to de-register for unknown status:%d\n",
+				 owner->name, dp_port_info[port_id].status);
+		}
+
+		DP_LIB_UNLOCK(&dp_lock);
+		return res;
+	}
+
+	DP_LIB_LOCK(&dp_lock);
+
+	/*register a device */
+	if (dp_port_info[port_id].status != PORT_ALLOCATED) {
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "No de-register for %s for unknown status:%d\n",
+			 owner->name, dp_port_info[port_id].status);
+		return DP_FAILURE;
+	}
+
+	if (dp_port_info[port_id].owner != owner) {
+		DP_DEBUG(DP_DBG_FLAG_DBG, "No matched owner(%s):%p->%p\n",
+			 owner->name, owner, dp_port_info[port_id].owner);
+		DP_LIB_UNLOCK(&dp_lock);
+		return res;
+	}
+
+	dp_port_info[port_id].status = PORT_DEV_REGISTERED;
+
+	if (dp_cb)
+		dp_port_info[port_id].cb = *dp_cb;
+
+	DP_LIB_UNLOCK(&dp_lock);
+	return DP_SUCCESS;
+}
+EXPORT_SYMBOL(dp_register_dev);
+
+int32_t dp_register_subif(struct module *owner, struct net_device *dev,
+			  char *subif_name, dp_subif_t *subif_id,
+			  uint32_t flags)
+{
+	int res = DP_FAILURE;
+	int i, port_id, start, end;
+
+	if (unlikely(!dp_init_ok)) {
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "dp_register_subif failed for datapath not init yet\n");
+		return DP_FAILURE;
+	}
+
+	DP_DEBUG(DP_DBG_FLAG_DBG,
+		 "%s:owner=%s dev=%s subif_name=%s port_id=%d subif=%d(%s)\n",
+		 (flags & DP_F_DEREGISTER) ? "unregister subif:" :
+		 "register subif", owner ? owner->name : "NULL",
+		 dev ? dev->name : "NULL", subif_name, subif_id->port_id,
+		 subif_id->subif,
+		 (subif_id->subif < 0) ? "dynamic" : "fixed");
+
+	if ((!subif_id) || (!subif_id->port_id) || (!owner) ||
+	    (subif_id->port_id >= PMAC_MAX_NUM) ||
+	    (subif_id->port_id <= 0)) {
+		if (!owner)
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "Unregister subif failed for owner NULL\n");
+		else if (!subif_id)
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "Unregister subif failed for NULL subif_id\n");
+		else
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "Unregister subif failed port_id=%d or others\n",
+				 subif_id->port_id);
+
+		return DP_FAILURE;
+	}
+
+	port_id = subif_id->port_id;
+
+	if (((!dev) && !(dp_port_info[port_id].alloc_flags & DP_F_FAST_DSL)) ||
+	    !subif_name) {
+		DP_DEBUG(DP_DBG_FLAG_DBG, "Wrong dev=%p, subif_name=%p\n",
+			 dev, subif_name);
+		return DP_FAILURE;
+	}
+
+	DP_LIB_LOCK(&dp_lock);
+
+	/*register a device */
+	if (dp_port_info[port_id].owner != owner) {
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "Unregister subif failed:Not matching:%p(%s)->%p(%s)\n",
+			 owner, owner->name, dp_port_info[port_id].owner,
+			 dp_port_info[port_id].owner->name);
+		DP_LIB_UNLOCK(&dp_lock);
+		return res;
+	}
+
+	if (flags & DP_F_DEREGISTER) {	/*de-register */
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "Try to unregister subif=%s with dp_port=%d subif=%d\n",
+			 subif_name, subif_id->port_id, subif_id->subif);
+
+		if (dp_port_info[port_id].status != PORT_SUBIF_REGISTERED) {
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "Unregister failed:%s not registered subif!\n",
+				 subif_name);
+			DP_LIB_UNLOCK(&dp_lock);
+			return DP_FAILURE;
+		}
+
+		for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+			if (dp_port_info[port_id].subif_info[i].subif ==
+			    subif_id->subif) {
+				memset(&dp_port_info[port_id].subif_info[i],
+				       0,
+				       sizeof(dp_port_info[port_id].subif_info
+					      [i]));
+				dp_port_info[port_id].num_subif--;
+
+				if (dp_port_info[port_id].num_subif == 0) {
+					dp_port_info[port_id].status =
+					    PORT_DEV_REGISTERED;
+					/*last subif deregistered,
+					*   so disable cbm port
+					*/
+#if defined(NEW_CBM_API) && NEW_CBM_API
+
+					if (cbm_dp_enable
+					    (owner, port_id,
+					     CBM_PORT_F_DISABLE,
+					     dp_port_info[port_id].
+					     alloc_flags)) {
+						DP_LIB_UNLOCK(&dp_lock);
+						DP_DEBUG(DP_DBG_FLAG_DBG,
+							 "cbm_dp_disable for port %d\n",
+							 port_id);
+
+						return res;
+					}
+#else
+
+					if (cbm_dp_enable
+					    (owner, port_id,
+					     CBM_PORT_F_DISABLE)) {
+						DP_LIB_UNLOCK(&dp_lock);
+						DP_DEBUG(DP_DBG_FLAG_DBG,
+							 "cbm_dp_disable for port %d\n",
+							 port_id);
+						return res;
+					}
+#endif
+				}
+
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "Found matched subif: %d_%d!\n",
+					 subif_id->port_id, subif_id->subif);
+				break;
+			}
+		}
+
+		if (i < MAX_SUBIF_PER_PORT) {
+			DP_DEBUG(DP_DBG_FLAG_DBG, "  dp_port=%d subif=%d\n",
+				 subif_id->port_id, subif_id->subif);
+			res = DP_SUCCESS;
+		}
+
+		DP_LIB_UNLOCK(&dp_lock);
+		return res;
+	}
+
+	/*Register subif */
+	if (dp_port_info[port_id].status < PORT_DEV_REGISTERED) {
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "Unregister subif failed:%s is not a registered dev!\n",
+			 subif_name);
+		DP_LIB_UNLOCK(&dp_lock);
+		return res;
+	}
+
+	if (subif_id->subif < 0) {	/*dynamic mode */
+		start = 0;
+		end = MAX_SUBIF_PER_PORT;
+	} else {
+		/*caller provided the vap. Try to get its vap value as start */
+		start = get_vap(subif_id->subif);
+		end = start + 1;
+	}
+
+	/*PRINTK("search range: start=%d end=%d\n",start, end);*/
+	/*allocate a free subif */
+	for (i = start; i < end; i++) {
+		if (dp_port_info[port_id].subif_info[i].flags)
+			continue;
+
+		/*free */
+		dp_port_info[port_id].subif_info[i].flags = 1;
+		dp_port_info[port_id].subif_info[i].netif = dev;
+		dp_port_info[port_id].port_id = port_id;
+
+		if (subif_id->subif < 0)	/*dynamic */
+			dp_port_info[port_id].subif_info[i].subif =
+			    set_vap(i);
+		else		/*provided by caller */
+			dp_port_info[port_id].subif_info[i].subif =
+			    subif_id->subif;
+
+		strcpy(dp_port_info[port_id].subif_info[i].device_name,
+		       subif_name);
+		dp_port_info[port_id].subif_info[i].flags =
+		    PORT_SUBIF_REGISTERED;
+		dp_port_info[port_id].status = PORT_SUBIF_REGISTERED;
+		subif_id->port_id = port_id;
+		subif_id->subif = dp_port_info[port_id].subif_info[i].subif;
+		dp_port_info[port_id].num_subif++;
+#if defined(NEW_CBM_API) && NEW_CBM_API
+
+		if (dp_port_info[port_id].num_subif == 1) {
+			if (cbm_dp_enable
+			    (owner, port_id, 0,
+			     dp_port_info[port_id].alloc_flags)) {
+				DP_LIB_UNLOCK(&dp_lock);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "cbm_dp_disable for port %d\n",
+					 port_id);
+				return res;
+			}
+		}
+#else
+
+		/*if this is the first subif for this port id */
+		if (dp_port_info[port_id].num_subif == 1) {
+			if (cbm_dp_enable(owner, port_id, 0)) {
+				res = DP_FAILURE;
+				DP_LIB_UNLOCK(&dp_lock);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "cbm_dp_disable for port %d\n",
+					 port_id);
+				return res;
+			}
+		}
+#endif
+		break;
+	}
+
+	if (i < end)
+		res = DP_SUCCESS;
+	else
+		DP_DEBUG(DP_DBG_FLAG_DBG, "register subif failed\n");
+
+	DP_LIB_UNLOCK(&dp_lock);
+	return res;
+}
+EXPORT_SYMBOL(dp_register_subif);
+
+/*Note:
+** try to get subif according to netif, skb,vcc,dst_mac.
+** For DLS nas interface, must provide valid subif_data, otherwise set to NULL.
+** Note: subif_data is mainly used for DSL WAN mode, esp ATM.
+*/
+int32_t dp_get_netif_subifid(struct net_device *netif, struct sk_buff *skb,
+			     void *subif_data, uint8_t dst_mac[MAX_ETH_ALEN],
+			     dp_subif_t *subif, uint32_t flags)
+{
+	int res = -1;
+	int i, k;
+	int port_id = -1;
+	int dst_subifid = -1;
+	dp_get_netif_subifid_fn_t subifid_fn_t;
+
+	DP_DEBUG(DP_DBG_FLAG_DBG,
+		 "dp_get_netif_subifid failed:dev=%s skb=0x%p subif_data=0x%p subif.port_id=%d(%s) flag=0x%x\n",
+		 netif ? netif->name : "NULL", skb, subif_data,
+		 subif->port_id,
+		 (subif->port_id <=
+		  0) ? "not specified portid" : "specified portid", flags);
+
+	if (!netif && !subif_data) {
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "dp_get_netif_subifid failed: netif=%p subif_data=%p\n",
+			 netif, subif_data);
+		return res;
+	}
+
+	if (!subif) {
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "dp_get_netif_subifid failed:subif=%p\n", subif);
+		return res;
+	}
+
+	if (subif->port_id >= PMAC_MAX_NUM) {
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "dp_get_netif_subifid wrong port_id: %d\n",
+			 subif->port_id);
+		return res;
+	}
+
+	DP_LIB_LOCK(&dp_lock);
+
+	for (k = 0; k < PMAC_MAX_NUM; k++) {
+		if (dp_port_info[k].status != PORT_SUBIF_REGISTERED)
+			continue;
+
+		/*Workaround for VRX318 */
+		if (subif_data &&
+		    (dp_port_info[k].alloc_flags & DP_F_FAST_DSL)) {
+			/*VRX318 should overwritten them later if necessary */
+			port_id = k;
+			dst_subifid = 0;
+			break;
+		}
+
+		/*search sub-interfaces */
+		for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+			if (!dp_port_info[k].subif_info[i].flags)
+				continue;
+
+			if (dp_port_info[k].subif_info[i].netif == netif) {
+				if ((subif->port_id > 0) &&
+				    (subif->port_id != k)) {
+					DP_DEBUG(DP_DBG_FLAG_DBG,
+						"dp_get_netif_subifid portid not match\n");
+				} else {
+					port_id = k;
+					dst_subifid =
+					    dp_port_info[k].subif_info[i].
+					    subif;
+				}
+
+				break;
+			}
+		}
+	}
+
+	DP_LIB_UNLOCK(&dp_lock);
+
+	if ((dst_subifid < 0) || (port_id < 0)) {
+		if (subif_data)
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "dp_get_netif_subifid failed with subif_data %p\n",
+				 subif_data);
+		else		/*netif must should be valid */
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "dp_get_netif_subifid failed: %s\n",
+				 netif->name);
+
+		return res;
+	}
+
+	subif->port_id = port_id;
+	subifid_fn_t = dp_port_info[port_id].cb.get_subifid_fn;
+
+	if (subifid_fn_t && !(flags & DP_F_SUBIF_LOGICAL)) {
+		/*subif->subif will be set by callback api itself */
+		res =
+		    subifid_fn_t(netif, skb, subif_data, dst_mac, subif,
+				 flags);
+
+		if (res != 0)
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "get_netif_subifid callback failed\n");
+
+		return res;
+	}
+	subif->subif = dst_subifid;
+	res = 0;
+	return res;
+}
+EXPORT_SYMBOL(dp_get_netif_subifid);
+
+int update_coc_up_sub_module(enum ltq_cpufreq_state new_state,
+			     enum ltq_cpufreq_state old_state, uint32_t flag)
+{
+	int i;
+	dp_coc_confirm_stat fn;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		fn = dp_port_info[i].cb.dp_coc_confirm_stat_fn;
+
+		if (fn)
+			fn(new_state, old_state, flag);
+	}
+
+	return 0;
+}
+
+/* return DP_SUCESS -- found
+*  return DP_FAILURE -- not found
+*/
+int dp_get_port_subitf_via_dev_private(struct net_device *dev,
+				       dp_subif_t *subif)
+{
+	int i, j;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++)
+		for (j = 0; j < MAX_SUBIF_PER_PORT; j++) {
+			if (dp_port_info[i].subif_info[j].netif == dev) {
+				subif->port_id = i;
+				subif->subif = j << VAP_OFFSET;
+				return DP_SUCCESS;
+			}
+		}
+
+	return DP_FAILURE;
+}
+
+int dp_get_port_subitf_via_dev(struct net_device *dev, dp_subif_t *subif)
+{
+	int res;
+
+	DP_LIB_LOCK(&dp_lock);
+	res = dp_get_port_subitf_via_dev_private(dev, subif);
+	DP_LIB_UNLOCK(&dp_lock);
+	return res;
+}
+EXPORT_SYMBOL(dp_get_port_subitf_via_dev);
+
+int dp_get_port_subitf_via_ifname_private(char *ifname, dp_subif_t *subif)
+{
+	int i, j;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		for (j = 0; j < MAX_SUBIF_PER_PORT; j++) {
+			if (strcmp
+			    (dp_port_info[i].subif_info[j].device_name,
+			     ifname) == 0) {
+				subif->port_id = i;
+				subif->subif = j << VAP_OFFSET;
+				return DP_SUCCESS;
+			}
+		}
+	}
+
+	return DP_FAILURE;
+}
+
+int dp_get_port_subitf_via_ifname(char *ifname, dp_subif_t *subif)
+{
+	int res;
+
+	DP_LIB_LOCK(&dp_lock);
+	res = dp_get_port_subitf_via_ifname_private(ifname, subif);
+	DP_LIB_UNLOCK(&dp_lock);
+	return res;
+}
+EXPORT_SYMBOL(dp_get_port_subitf_via_ifname);
+
+int32_t dp_check_if_netif_fastpath_fn(struct net_device *netif,
+				      dp_subif_t *subif, char *ifname,
+				      uint32_t flags)
+{
+	int res = 1;
+	dp_subif_t tmp_subif = { 0 };
+
+	DP_LIB_LOCK(&dp_lock);
+	if (unlikely(!dp_init_ok)) {
+		PR_ERR("dp_check_if_netif_fastpath_fn failed for datapath not init yet\n");
+		return DP_FAILURE;
+	}
+	if (subif)
+		tmp_subif = *subif;
+	else if (netif)
+		dp_get_port_subitf_via_dev_private(netif, &tmp_subif);
+	else if (ifname)
+		dp_get_port_subitf_via_ifname_private(ifname, &tmp_subif);
+
+	if (tmp_subif.port_id <= 0 && tmp_subif.port_id >= PMAC_MAX_NUM)
+		res = 0;
+	else if (!
+		 (dp_port_info[tmp_subif.port_id].
+		  alloc_flags & (DP_F_FAST_DSL || DP_F_FAST_ETH_LAN ||
+				 DP_F_FAST_ETH_WAN || DP_F_FAST_WLAN)))
+		res = 0;
+
+	DP_LIB_UNLOCK(&dp_lock);
+	return res;
+}
+EXPORT_SYMBOL(dp_check_if_netif_fastpath_fn);
+
+struct module *dp_get_module_owner(int ep)
+{
+	if (unlikely(!dp_init_ok)) {
+		PR_ERR
+		    ("dp_get_module_owner failed for datapath not init yet\n");
+		return NULL;
+	}
+
+	if ((ep >= 0) && (ep < PMAC_MAX_NUM))
+		return dp_port_info[ep].owner;
+
+	return NULL;
+}
+EXPORT_SYMBOL(dp_get_module_owner);
+
+/*if subif->vap == -1, it means all vap */
+void dp_clear_mib(dp_subif_t *subif, uint32_t flag)
+{
+	int i, j, start_vap, end_vap;
+	dp_reset_mib_fn_t reset_mib_fn;
+
+	if (!subif || (subif->port_id >= PMAC_MAX_NUM) ||
+	    (subif->port_id < 0)) {
+		DP_DEBUG(DP_DBG_FLAG_DBG, "dp_clear_mib Wrong subif\n");
+		return;
+	}
+
+	i = subif->port_id;
+
+	if (subif->subif == -1) {
+		start_vap = 0;
+		end_vap = MAX_SUBIF_PER_PORT;
+	} else {
+		start_vap = get_vap(subif->subif);
+		end_vap = start_vap + 1;
+	}
+
+	for (j = start_vap; j < end_vap; j++) {
+		dp_port_info[i].tx_err_drop = 0;
+		dp_port_info[i].rx_err_drop = 0;
+		memset(&dp_port_info[i].subif_info[j].mib, 0,
+		       sizeof(dp_port_info[i].subif_info[j].mib));
+		reset_mib_fn = dp_port_info[i].cb.reset_mib_fn;
+
+		if (reset_mib_fn)
+			reset_mib_fn(subif, 0);
+	}
+}
+
+void dp_clear_all_mib_inside(uint32_t flag)
+{
+	dp_subif_t subif;
+	int i;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		subif.port_id = i;
+		subif.subif = -1;
+		dp_clear_mib(&subif, flag);
+	}
+}
+
+
+int dp_get_drv_mib(dp_subif_t *subif, dp_drv_mib_t *mib, uint32_t flag)
+{
+	dp_get_mib_fn_t get_mib_fn;
+	dp_drv_mib_t tmp;
+	int i, vap;
+
+	if (unlikely(!dp_init_ok)) {
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "dp_get_drv_mib failed for datapath not init yet\n");
+		return DP_FAILURE;
+	}
+
+	if (!subif || !mib)
+		return -1;
+
+	vap = get_vap(subif->subif);
+
+	memset(mib, 0, sizeof(*mib));
+	get_mib_fn = dp_port_info[subif->port_id].cb.get_mib_fn;
+
+	if (!get_mib_fn)
+		return -1;
+
+	if (!(flag & DP_F_STATS_SUBIF)) {
+		/*get all VAP's  mib counters if it is -1 */
+		for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+			if (!dp_port_info[subif->port_id].subif_info[i].flags)
+				continue;
+
+			subif->subif =
+			    dp_port_info[subif->port_id].subif_info[i].subif;
+			memset(&tmp, 0, sizeof(tmp));
+			get_mib_fn(subif, &tmp, flag);
+			mib->rx_drop_pkts += tmp.rx_drop_pkts;
+			mib->rx_error_pkts += tmp.rx_error_pkts;
+			mib->tx_drop_pkts += tmp.tx_drop_pkts;
+			mib->tx_error_pkts += tmp.tx_error_pkts;
+		}
+	} else {
+		if (dp_port_info[subif->port_id].subif_info[vap].flags)
+			get_mib_fn(subif, mib, flag);
+	}
+
+	return 0;
+}
+
+int32_t dp_api_init(void)
+{
+	spin_lock_init(&dp_lock);
+	DP_LIB_LOCK(&dp_lock);
+	memset(dp_port_info, 0, sizeof(dp_port_info));
+	dp_init_ok = 1;
+	DP_LIB_UNLOCK(&dp_lock);
+	return 0;
+}
+
+void dump_parser_flag(char *buf)
+{
+	int i, j;
+	unsigned char *pflags = buf + PKT_PMAC_OFFSET - 1;
+	unsigned char *poffset = buf;
+
+	if (!buf) {
+		PR_ERR("dump_parser_flag buf NULL\n");
+		return;
+	}
+
+	/* one TCP example: offset
+	   offset 0
+	   00 3a 00 00 00 00 00 00 00 00 00 00 00 00 00 0e
+	   00 00 00 16 22 00 00 00 00 00 00 00 00 00 00 2e
+	   00 00 00 00 00 00 00 00
+	   flags: FLAG_L2TPFLAG_NO
+	   00 00 00 00 80 18 80 00
+	 */
+	PRINTK("paser flag at 0x%p: ", buf);
+
+	for (i = 0; i < 8; i++)
+		PRINTK("%02x ", *(pflags - 7 + i));
+
+	PRINTK("\n");
+#if 1
+	PRINTK("paser flag: ");
+
+	for (i = 0; i < 8; i++)
+		PRINTK("%02x ", *(pflags - i));
+
+	PRINTK("(reverse)\n");
+#endif
+
+	for (i = 0; i < PASAR_FLAGS_NUM; i++) {	/*8 flags per byte */
+		for (j = 0; j < 8; j++) {	/*8 bits per byte */
+			if ((i * 8 + j) >= PASER_FLAGS_MAX)
+				break;
+
+			if ((*(pflags - i)) & (1 << j)) {	/*flag is set */
+				if ((i * 8 + j) < PASAR_OFFSETS_NUM)
+					PRINTK
+					    ("  Flag %02d offset=%02d: %s\n",
+					     i * 8 + j,
+					     *(poffset + i * 8 + j),
+					     parser_flags_str[i * 8 + j]);
+				else
+					PRINTK("  Flag %02d %s (No offset)\n",
+					       i * 8 + j,
+					       parser_flags_str[i * 8 + j]);
+			}
+		}
+	}
+}
+
+void dump_rx_dma_desc(struct dma_rx_desc_0 *desc_0,
+		      struct dma_rx_desc_1 *desc_1,
+		      struct dma_rx_desc_2 *desc_2,
+		      struct dma_rx_desc_3 *desc_3)
+{
+	if (!desc_0 || !desc_1 || !desc_2 || !desc_3) {
+		PR_ERR("rx desc_0/1/2/3 NULL\n");
+		return;
+	}
+
+	PRINTK(" DMA Descripotr:D0=0x%08x D1=0x%08x D2=0x%08x D3=0x%08x\n",
+	       *(u32 *)desc_0, *(u32 *)desc_1,
+	       *(u32 *)desc_2, *(u32 *)desc_3);
+	PRINTK
+	    ("  DW0:resv0=%d tunnel_id=%02d flow_id=%d eth_type=%d dest_sub_if_id=0x%04x\n",
+	     desc_0->field.resv0, desc_0->field.tunnel_id,
+	     desc_0->field.flow_id, desc_0->field.eth_type,
+	     desc_0->field.dest_sub_if_id);
+	PRINTK
+	    ("  DW1:session_id=0x%03x tcp_err=%d nat=%d dec=%d enc=%d mpe2=%d mpe1=%d \n",
+	     desc_1->field.session_id, desc_1->field.tcp_err,
+	     desc_1->field.nat, desc_1->field.dec, desc_1->field.enc,
+	     desc_1->field.mpe2, desc_1->field.mpe1);
+	PRINTK("      color=%02d ep=%02d resv1=%d classid=%02d\n",
+	       desc_1->field.color, desc_1->field.ep, desc_1->field.resv1,
+	       desc_1->field.classid);
+	PRINTK("  DW2:data_ptr=0x%08x\n", desc_2->field.data_ptr);
+	PRINTK("  DW3:own=%d c=%d sop=%d eop=%d dic=%d pdu_type=%d\n",
+	       desc_3->field.own, desc_3->field.c, desc_3->field.sop,
+	       desc_3->field.eop, desc_3->field.dic, desc_3->field.pdu_type);
+	PRINTK
+	    ("      byte_offset=%d atm_qid=%d mpoa_pt=%d mpoa_mode=%d data_len=% 4d\n",
+	     desc_3->field.byte_offset, desc_3->field.qid,
+	     desc_3->field.mpoa_pt, desc_3->field.mpoa_mode,
+	     desc_3->field.data_len);
+}
+
+void dump_tx_dma_desc(struct dma_tx_desc_0 *desc_0,
+		      struct dma_tx_desc_1 *desc_1,
+		      struct dma_tx_desc_2 *desc_2,
+		      struct dma_tx_desc_3 *desc_3)
+{
+	int lookup;
+
+	if (!desc_0 || !desc_1 || !desc_2 || !desc_3) {
+		PR_ERR("tx desc_0/1/2/3 NULL\n");
+		return;
+	}
+	PRINTK(" DMA Descripotr:D0=0x%08x D1=0x%08x D2=0x%08x D3=0x%08x\n",
+		*(u32 *)desc_0, *(u32 *)desc_1,
+		*(u32 *)desc_2, *(u32 *)desc_3);
+	PRINTK("  DW0:resv0=%d tunnel_id=%02d flow_id=%d eth_type=%d dest_sub_if_id=0x%04x\n",
+		desc_0->field.resv0, desc_0->field.tunnel_id,
+		desc_0->field.flow_id, desc_0->field.eth_type,
+		desc_0->field.dest_sub_if_id);
+	PRINTK("  DW1:session_id=0x%03x tcp_err=%d nat=%d dec=%d enc=%d mpe2=%d mpe1=%d \n",
+		desc_1->field.session_id, desc_1->field.tcp_err,
+		desc_1->field.nat, desc_1->field.dec, desc_1->field.enc,
+		desc_1->field.mpe2, desc_1->field.mpe1);
+	PRINTK("  color=%02d ep=%02d resv1=%d classid=%02d\n",
+		desc_1->field.color, desc_1->field.ep, desc_1->field.resv1,
+		desc_1->field.classid);
+	PRINTK("  DW2:data_ptr=0x%08x\n", desc_2->field.data_ptr);
+	PRINTK("  DW3:own=%d c=%d sop=%d eop=%d dic=%d pdu_type=%d\n",
+		desc_3->field.own, desc_3->field.c, desc_3->field.sop,
+		desc_3->field.eop, desc_3->field.dic, desc_3->field.pdu_type);
+	PRINTK("  byte_offset=%d atm_qid=%d mpoa_pt=%d mpoa_mode=%d data_len=% 4d\n",
+		desc_3->field.byte_offset, desc_3->field.qid,
+		desc_3->field.mpoa_pt, desc_3->field.mpoa_mode,
+		desc_3->field.data_len);
+	lookup =
+	    ((desc_0->field.flow_id >> 6) << 12) | ((desc_1->field.
+						     dec) << 11) | ((desc_1->
+								     field.
+								     enc) <<
+								    10) |
+	    ((desc_1->field.mpe2) << 9) | ((desc_1->field.
+					    mpe1) << 8) | ((desc_1->field.
+							    ep) << 4) |
+	    ((desc_1->field.classid) << 0);
+	PRINTK("  lookup index=0x%x qid=%d\n", lookup,
+	       get_lookup_qid_via_index(lookup));
+}
+
+void dump_rx_pmac(struct pmac_rx_hdr *pmac)
+{
+	int i;
+	unsigned char *p = (char *)pmac;
+
+	if (!pmac) {
+		PR_ERR("dump_rx_pmac pmac NULL ??\n");
+		return;
+	}
+
+	PRINTK("PMAC at 0x%p: ", p);
+
+	for (i = 0; i < 8; i++)
+		PRINTK("0x%02x ", p[i]);
+
+	PRINTK("\n");
+	/*byte 0 */
+	PRINTK("  byte 0:res=%d ver_done=%d ip_offset=%d\n", pmac->res1,
+	       pmac->ver_done, pmac->ip_offset);
+	/*byte 1 */
+	PRINTK("  byte 1:tcp_h_offset=%d tcp_type=%d\n", pmac->tcp_h_offset,
+	       pmac->tcp_type);
+	/*byte 2 */
+	PRINTK("  byte 2:ppid=%d class=%d\n", pmac->sppid, pmac->class);
+	/*byte 3 */
+	PRINTK("  byte 3:res=%d pkt_type=%d\n", pmac->res2, pmac->pkt_type);
+	/*byte 4 */
+	PRINTK("  byte 4:res=%d redirect=%d res2=%d src_sub_inf_id=%d\n",
+	       pmac->res3, pmac->redirect, pmac->res4, pmac->src_sub_inf_id);
+	/*byte 5 */
+	PRINTK("  byte 5:src_sub_inf_id2=%d\n", pmac->src_sub_inf_id2);
+	/*byte 6 */
+	PRINTK("  byte 6:port_map=%d\n", pmac->port_map);
+	/*byte 7 */
+	PRINTK("  byte 7:port_map2=%d\n", pmac->port_map2);
+}
+
+void dump_tx_pmac(struct pmac_tx_hdr *pmac)
+{
+	int i;
+	unsigned char *p = (char *)pmac;
+
+	if (!pmac) {
+		PR_ERR("dump_tx_pmac pmac NULL ??\n");
+		return;
+	}
+
+	PRINTK(" PMAC at 0x%p:", p);
+
+	for (i = 0; i < 8; i++)
+		PRINTK("0x%02x ", p[i]);
+	PRINTK("\n");
+	/*byte 0 */
+	PRINTK("  byte 0:tcp_chksum=%d res=%d ip_offset=%d\n",
+	       pmac->tcp_chksum, pmac->res1, pmac->ip_offset);
+	/*byte 1 */
+	PRINTK("  byte 1:tcp_h_offset=%d tcp_type=%d\n", pmac->tcp_h_offset,
+	       pmac->tcp_type);
+	/*byte 2 */
+	PRINTK("  byte 2:ppid=%d res=%d\n", pmac->sppid, pmac->res);
+	/*byte 3 */
+	PRINTK
+	    ("  byte 3:port_map_en=%d res=%d time_dis=%d class_en=%d res=%d pkt_type=%d\n",
+	     pmac->port_map_en, pmac->res2, pmac->time_dis, pmac->class_en,
+	     pmac->res3, pmac->pkt_type);
+	/*byte 4 */
+	PRINTK
+	    ("  byte 4:fcs_ins_dis=%d redirect=%d time_stmp=%d src_sub_inf_id=%d\n",
+	     pmac->fcs_ins_dis, pmac->redirect, pmac->time_stmp,
+	     pmac->src_sub_inf_id);
+	/*byte 5 */
+	PRINTK("  byte 5:src_sub_inf_id2=%d\n", pmac->src_sub_inf_id2);
+	/*byte 6 */
+	PRINTK("  byte 6:port_map=%d\n", pmac->port_map);
+	/*byte 7 */
+	PRINTK("  byte 7:port_map2=%d\n", pmac->port_map2);
+}
+
+void dp_dump_raw_data(char *buf, int len, char *prefix_str)
+{
+	int i;
+	int r;
+	int line_num = 32;
+	unsigned char *p = (unsigned char *)buf;
+
+	if (!p) {
+		PR_ERR("dp_dump_raw_data: p NULL ?\n");
+		return;
+	}
+
+	PR_CONT("%s in hex at 0x%p\n",
+		prefix_str ? (char *)prefix_str : "Data", p);
+
+	for (i = 0; i < len; i++) {
+		r = i % line_num;
+
+		if (r == 0)
+			PR_CONT(" %04d: ", i);
+		else if (r == (line_num / 2))
+			PR_CONT(" ");	/*inser seperator */
+
+		PR_CONT("%02x ", p[i]);
+
+		if (r == (line_num - 1))
+			PR_CONT("\n");	/*insert new line */
+	}
+
+	PRINTK("\n");
+}
+EXPORT_SYMBOL(dp_dump_raw_data);
+
+int32_t dp_rx(struct sk_buff *skb, uint32_t flags)
+{
+	struct sk_buff *next;
+	int res = -1;
+
+	if (unlikely(!dp_init_ok)) {
+		while (skb) {
+			next = skb->next;
+			skb->next = 0;
+			dev_kfree_skb_any(skb);
+			skb = next;
+		}
+	}
+
+	while (skb) {
+		next = skb->next;
+		skb->next = 0;
+		res = dp_rx_one_skb(skb, flags);
+		skb = next;
+	}
+
+	return res;
+}
+EXPORT_SYMBOL(dp_rx);
+
+int dp_lan_wan_bridging(int port_id, struct sk_buff *skb)
+{
+	dp_subif_t subif;
+	struct net_device *dev;
+	static int lan_port = 4;
+
+	if (!skb)
+		return DP_FAILURE;
+
+	skb_pull(skb, 8);	/*remove pmac */
+
+	if (port_id == 15) {
+		/*recv from WAN and forward to LAN via lan_port */
+		subif.port_id = lan_port;	/*send to last lan port */
+		subif.subif = 0;
+	} else if (port_id <= 6) {	/*recv from LAN and forward to WAN */
+		subif.port_id = 15;
+		subif.subif = 0;
+		lan_port = port_id;	/*save lan port id */
+	} else {
+		dev_kfree_skb_any(skb);
+		return DP_FAILURE;
+	}
+
+	dev = dp_port_info[subif.port_id].subif_info[0].netif;
+
+	if (!dp_port_info[subif.port_id].subif_info[0].flags || !dev) {
+		dev_kfree_skb_any(skb);
+		return DP_FAILURE;
+	}
+
+	((struct dma_tx_desc_1 *)&skb->DW1)->field.ep = subif.port_id;
+	((struct dma_tx_desc_0 *)&skb->DW0)->field.dest_sub_if_id =
+	    subif.subif;
+
+	dp_xmit(dev, &subif, skb, skb->len, 0);
+	return DP_SUCCESS;
+}
+
+#define PRINT_INTERVAL  (5 * HZ) /* 5 seconds */
+unsigned long dp_err_interval = PRINT_INTERVAL;
+static inline int32_t dp_rx_one_skb(struct sk_buff *skb, uint32_t flags)
+{
+	int res = DP_SUCCESS;
+	struct dma_rx_desc_0 *desc_0 = (struct dma_rx_desc_0 *)&skb->DW0;
+	struct dma_rx_desc_1 *desc_1 = (struct dma_rx_desc_1 *)&skb->DW1;
+	struct dma_rx_desc_2 *desc_2 = (struct dma_rx_desc_2 *)&skb->DW2;
+	struct dma_rx_desc_3 *desc_3 = (struct dma_rx_desc_3 *)&skb->DW3;
+	struct pmac_rx_hdr *pmac;
+	unsigned char *parser = NULL;
+	int rx_tx_flag = 0;	/*0-rx, 1-tx */
+	u32 ep = desc_1->field.ep;	/* ep: 0 -15 */
+	int vap;		/*vap: 0-15 */
+	int paser_exist;
+	u32 port_id = ep; /*same with ep now, later set to sspid if ep is 0 */
+	struct net_device *dev;
+	dp_rx_fn_t rx_fn;
+	static unsigned long last_jiffies;
+#define K (1024)
+#define M (K * K)
+
+	if (!skb) {
+		PR_ERR("why skb NULL\n");
+		return DP_FAILURE;
+	}
+
+	if (!skb->data) {
+		PR_ERR("skb->data NULL\n");
+		dev_kfree_skb_any(skb);
+		return DP_FAILURE;
+	}
+
+	paser_exist = parser_enabled(port_id, desc_1);
+
+	if (dp_dbg_flag) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX,
+			 "\ndp_rx:skb->data=%p Loc=%x offset=%d skb->len=%d\n",
+			 skb->data, desc_2->field.data_ptr,
+			 desc_3->field.byte_offset, skb->len);
+
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DATA)
+			dp_dump_raw_data(skb->data,
+					 (skb->len >
+					  print_len) ? skb->len : print_len,
+					 "Original Data");
+
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "parse hdr size = %d\n",
+			 paser_exist);
+	}
+
+	if (paser_exist) {
+		parser = skb->data;
+		skb_pull(skb, paser_exist);	/*remove parser */
+#if defined(CONFIG_LTQ_PPA_API) || defined(CONFIG_LTQ_PPA_API_MODULE)
+#if defined(CONFIG_LTQ_PPA_API_SW_FASTPATH)
+		skb->mark |= FLG_PPA_PROCESSED;
+#endif
+#endif
+	}
+
+	pmac = (struct pmac_rx_hdr *)(skb->data);
+
+	if (((ep >= 1) && (ep <= 6)) || (ep == 15)) {
+		PR_ERR("Wrong: why ep=%d\n", ep);
+		dump_rx_dma_desc(desc_0, desc_1, desc_2, desc_3);
+		dp_dump_raw_data(skb->data,
+				 (skb->len >
+				  print_len) ? skb->len : print_len,
+				 "Recv Data");
+	}
+
+	if (dp_pkt_size_check && ((skb->len < 60) || (skb->len > 0x600))) {
+		PR_ERR("\n----dp_rx wrong packet size: %d ----??\n",
+		       skb->len);
+		dump_rx_dma_desc(desc_0, desc_1, desc_2, desc_3);
+
+		if (paser_exist)
+			dump_parser_flag(parser);
+
+		dump_rx_pmac(pmac);
+		dp_dump_raw_data(skb->data,
+				 (skb->len >
+				  print_len) ? skb->len : print_len,
+				 "Recv Data");
+		dev_kfree_skb_any(skb);
+		return DP_FAILURE;
+	}
+
+	if (dp_drop_all_tcp_err && desc_1->field.tcp_err) {
+		PR_ERR("\n----dp_rx why tcp_err ???\n");
+		dump_rx_dma_desc(desc_0, desc_1, desc_2, desc_3);
+
+		if (paser_exist)
+			dump_parser_flag(parser);
+
+		dump_rx_pmac(pmac);
+		dp_dump_raw_data(skb->data,
+				 (skb->len >
+				  print_len) ? skb->len : print_len,
+				 "Recv Data");
+		dev_kfree_skb_any(skb);
+		return DP_FAILURE;
+	}
+
+	if (dp_dbg_flag) {
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DESCRIPTOR)
+			dump_rx_dma_desc(desc_0, desc_1, desc_2, desc_3);
+
+		if (paser_exist && (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_PASER))
+			dump_parser_flag(parser);
+
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_PMAC)
+			dump_rx_pmac(pmac);
+	}
+#ifdef LTQ_TSO_SW_WORKAROUND
+
+	if (desc_1->field.mpe2 && desc_1->field.enc && desc_1->field.dec) {
+		DP_DEBUG(DP_DBG_FLAG_DBG, "TSO LB\n");
+		desc_1->field.mpe2 = 0;
+		desc_1->field.dec = 0;
+		desc_1->field.enc = 0;
+		desc_0->field.flow_id = 0;
+		pmac->ip_offset += PMAC_SIZE;
+		res = cbm_cpu_pkt_tx(skb, desc_1->field.ep, 0);
+		return res;
+	}
+#endif
+
+	if (port_id == PMAC_CPU_ID) {	/*To CPU and need check src pmac port */
+		port_id = pmac->sppid;	/*get the port_id from pmac's sppid */
+		if (dp_port_info[port_id].alloc_flags & DP_F_LOOPBACK) {
+			/*get the real source port from VAP for ipsec */
+			/* related tunnel decap case */
+			port_id =
+			    get_vap((uint32_t)pmac->src_sub_inf_id2 +
+				    (uint32_t)(pmac->src_sub_inf_id << 8));
+			vap = 0;
+		} else
+			vap =
+			    get_vap((uint32_t)pmac->src_sub_inf_id2 +
+				    (uint32_t)(pmac->src_sub_inf_id << 8));
+	} else {		/*GSWIP-R already know the destination */
+		rx_tx_flag = 1;
+		vap = get_vap(desc_0->field.dest_sub_if_id);
+	}
+
+	if (port_id == 0) {
+		if (jiffies < last_jiffies) /* wraparuond */
+			last_jiffies = 0;
+		if (jiffies <= last_jiffies + dp_err_interval)
+			/* not print in order to keep console not busy */
+			goto RX_DROP;
+		last_jiffies = jiffies;
+		if (!dp_dbg_err) /*bypass dump */
+			goto RX_DROP;
+		DP_DEBUG(-1, "%s=%d vap=%d\n",
+			 (ep) ? "ep" : "port_id", port_id, vap);
+		PR_ERR("\nDrop for ep and source port id both zero ??\n");
+		dump_rx_dma_desc(desc_0, desc_1, desc_2, desc_3);
+
+		if (paser_exist)
+			dump_parser_flag(parser);
+		if (pmac)
+			dump_rx_pmac(pmac);
+		dp_dump_raw_data((char *)(skb->data),
+				 (skb->len >
+				  print_len) ? skb->len : print_len,
+				 "Recv Data");
+		goto RX_DROP;
+	}
+
+	rx_fn = dp_port_info[port_id].cb.rx_fn;
+
+	if (port_id >= PMAC_END_ID) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "%s=%d vap=%d\n",
+			 (ep) ? "ep" : "port_id", port_id, vap);
+		PR_ERR("Drop for wrong ep or soruce port id=%u ??\n",
+		       port_id);
+		goto RX_DROP;
+	} else if (dp_port_info[port_id].status == PORT_FREE) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "%s=%d vap=%d\n",
+			 (ep) ? "ep" : "port_id", port_id, vap);
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "Drop for port %u free\n",
+			 port_id);
+		goto RX_DROP;
+	} else if (!rx_fn) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX,
+			 "Drop for subif of port %u not registered yet\n",
+			 port_id);
+		DP_LIB_LOCK(&dp_lock);
+		dp_port_info[port_id].subif_info[vap].mib.rx_fn_dropped++;
+		DP_LIB_UNLOCK(&dp_lock);
+		goto RX_DROP2;
+	}
+	/*Clear some fields as SWAS V3.7 required */
+	desc_1->all &= dma_rx_desc_mask1.all;
+	desc_3->all &= dma_rx_desc_mask3.all;
+	skb->priority = desc_1->field.classid;
+	skb->dev = dp_port_info[port_id].subif_info[vap].netif;
+	dev = dp_port_info[port_id].subif_info[vap].netif;
+
+	if (!dev &&
+	    ((dp_port_info[port_id].alloc_flags & DP_F_FAST_DSL) == 0)) {
+		DP_LIB_LOCK(&dp_lock);
+		dp_port_info[port_id].subif_info[vap].mib.rx_fn_dropped++;
+		DP_LIB_UNLOCK(&dp_lock);
+		goto RX_DROP;
+	}
+
+	if (dp_dbg_flag) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "%s=%d vap=%d\n",
+			 (ep) ? "ep" : "port_id", port_id, vap);
+
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DATA)
+			dp_dump_raw_data(skb->data,
+					 (skb->len >
+					  print_len) ? skb->len : print_len,
+					 "Data to top drivers");
+	}
+#ifdef CONFIG_LTQ_DP_MPE_FASTHOOK_TEST
+
+	if (unlikely(ltq_mpe_fasthook_rx_fn))
+		ltq_mpe_fasthook_rx_fn(skb, 1, NULL);	/*with pmac */
+
+#endif
+
+	if (likely((enum TEST_MODE)dp_rx_test_mode == DP_RX_MODE_NORMAL)) {
+		rx_fn((rx_tx_flag == 0) ? dev : NULL,
+		      (rx_tx_flag == 1) ? dev : NULL, skb, skb->len);
+	} else if ((enum TEST_MODE)dp_rx_test_mode == DP_RX_MODE_LAN_WAN_BRIDGE) {
+		/*for datapath performance test only */
+		dp_lan_wan_bridging(port_id, skb);
+		/*return DP_SUCCESS;*/
+	}
+#ifdef CONFIG_LTQ_DATAPATH_LOCAL_SESSION
+	else if ((enum TEST_MODE)dp_rx_test_mode == DP_RX_MODE_LOCALTCP_FAST) {
+		/*for local TCP performance test only */
+		if (!dp_tcp_fast_ok(ep, skb, pmac))
+			rx_fn((rx_tx_flag == 0) ? dev : NULL,
+			      (rx_tx_flag == 1) ? dev : NULL, skb, skb->len);
+	} else
+#else
+	else
+#endif
+		rx_fn((rx_tx_flag == 0) ? dev : NULL,
+		      (rx_tx_flag == 1) ? dev : NULL, skb, skb->len);
+
+	DP_LIB_LOCK(&dp_lock);
+
+	if (rx_tx_flag)
+		dp_port_info[port_id].subif_info[vap].mib.rx_fn_txif_pkt++;
+	else
+		dp_port_info[port_id].subif_info[vap].mib.rx_fn_rxif_pkt++;
+
+	DP_LIB_UNLOCK(&dp_lock);
+	return DP_SUCCESS;
+ RX_DROP:
+	DP_LIB_LOCK(&dp_lock);
+	dp_port_info[port_id].rx_err_drop++;
+	DP_LIB_UNLOCK(&dp_lock);
+	DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "RX_DROP port_id=%d  ????\n", port_id);
+ RX_DROP2:
+	dev_kfree_skb_any(skb);
+	return res;
+}
+
+#define PROTOCOL_IPIP 4
+#define PROTOCOL_TCP 6
+#define PROTOCOL_UDP 17
+#define PROTOCOL_ENCAPSULATED_IPV6 41
+#define PROTOCOL_ROUTING 43
+#define PROTOCOL_NONE 59
+#define PROTOCOL_IPV6_FRAGMENT 44
+
+#define TWO_MAC_SIZE 12
+#define VLAN_HDR_SIZE  4
+#define PPPOE_HDR_SIZE  8
+#define IPV6_HDR_SIZE  40
+#define IPV6_EXTENSION_SIZE 8
+
+#define IP_CHKSUM_OFFSET_IPV4 10
+#define UDP_CHKSUM_OFFSET 6
+#define TCP_CHKSUM_OFFSET 16
+/*Workaround: Currently need to includes PMAC
+**although spec said it starts from mac address. ?
+*/
+
+struct ip_hdr_info {
+	u8 ip_ver;
+	u8 proto;		/*udp/tcp */
+	u16 ip_offset;		/*this offset is based on L2 MAC header */
+	u16 udp_tcp_offset;	/*this offset is based on ip header */
+	u16 next_ip_hdr_offset;	/*0 - means no next valid ip header.*/
+				/* Based on current IP header */
+	u8 is_fragment;		/*0 means non fragmented packet */
+};
+
+/*input p: pointers to ip header
+* output info:
+* return: 0:  it is UDP/TCP packet
+* -1: not UDP/TCP
+*/
+#define DP_IP_VER4 4
+#define DP_IP_VER6 6
+int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
+{
+	int ip_hdr_size;
+	u8 *p = pdata;
+	struct iphdr *iphdr = (struct iphdr *)pdata;
+
+	memset((void *)info, 0, sizeof(*info));
+	info->ip_ver = p[0] >> 4;
+
+	if (info->ip_ver == DP_IP_VER4) {	/*ipv4 */
+		ip_hdr_size = (p[0] & 0xf) << 2;
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "IPV4 packet with protocol 0x%x with ip hdr size %d\n",
+			 p[9], ip_hdr_size);
+		info->proto = p[9];
+
+		if ((info->proto == PROTOCOL_UDP) ||
+			(info->proto == PROTOCOL_TCP)) {
+			if ((iphdr->frag_off & IP_MF) ||
+			    (iphdr->frag_off & IP_OFFSET)) {
+				DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+					"fragmented packet with frag_off = %x, IP_MF = %x, IP_OFFSET = %x \n",
+					iphdr->frag_off, IP_MF, IP_OFFSET);
+				info->udp_tcp_offset = (p[0] & 0x0f) << 2;
+				info->is_fragment = 1;
+				return -1;
+			}
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+				 "%s packet with src/dst port:%u/%u\n",
+				 (p[9] ==
+				  PROTOCOL_UDP) ? "UDP" : "TCP",
+				 *(unsigned short *)(pdata +
+						     ip_hdr_size),
+				 *(unsigned short *)(pdata +
+						     ip_hdr_size +
+						     2));
+			info->udp_tcp_offset = (p[0] & 0x0f) << 2;
+			return 0;
+		} else if (p[9] == PROTOCOL_ENCAPSULATED_IPV6) {
+			/*6RD */
+			info->next_ip_hdr_offset = (p[0] & 0x0f) << 2;
+			return 0;
+		}
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "Not supported extension hdr:0x%x\n", p[9]);
+		return -1;
+	} else if (info->ip_ver == DP_IP_VER6) {	/*ipv6 */
+		int i;
+		int ip_hdr_size;
+		u8 next_hdr;
+		u8 udp_tcp_h_offset;
+		u8 first_extension = 1;
+
+		ip_hdr_size = IPV6_HDR_SIZE;
+		udp_tcp_h_offset = IPV6_HDR_SIZE;
+		next_hdr = p[6];
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX) {
+			PRINTK("IPV6 packet with next hdr:0x%x\n", next_hdr);
+			PRINTK(" src IP: ");
+
+			for (i = 0; i < 16; i++)
+				PRINTK("%02x%s", pdata[8 + i],
+				       (i != 15) ? ":" : " ");
+
+			PRINTK("\n");
+
+			PRINTK(" Dst IP: ");
+
+			for (i = 0; i < 16; i++)
+				PRINTK("%02x%s", pdata[24 + i],
+				       (i != 15) ? ":" : " ");
+
+			PRINTK("\n");
+		}
+
+		while (1) {
+			/*Next Header: UDP/TCP */
+			if ((next_hdr == PROTOCOL_UDP) ||
+			    (next_hdr == PROTOCOL_TCP)) {
+				info->proto = next_hdr;
+
+				if (!first_extension)
+					udp_tcp_h_offset +=
+					    IPV6_EXTENSION_SIZE + p[1];
+
+				info->udp_tcp_offset = udp_tcp_h_offset;
+				DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+					 "IPV6 UDP: src/dst port:%u/%u udp_tcp_offset=%d\n",
+					 *(unsigned short *)(pdata +
+							     udp_tcp_h_offset),
+					 *(unsigned short *)(pdata +
+							     udp_tcp_h_offset
+							     + 2),
+					 udp_tcp_h_offset);
+				return 0;
+			} else if (next_hdr == PROTOCOL_IPIP) {	/*dslite */
+				if (!first_extension)
+					udp_tcp_h_offset +=
+					    IPV6_EXTENSION_SIZE + p[1];
+
+				info->next_ip_hdr_offset = udp_tcp_h_offset;
+				return 0;
+			} else if (next_hdr == PROTOCOL_IPV6_FRAGMENT) {
+				pr_info_once("fragmented IPV6 packet !\n");
+				info->is_fragment = 1;
+				return -1;
+			}
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+				 "Skip extension hdr:0x%x\n", next_hdr);
+			if ((next_hdr == PROTOCOL_NONE) ||
+			    (next_hdr == PROTOCOL_ENCAPSULATED_IPV6))
+				break;
+
+			if (first_extension) {
+				/*skip ip header */
+				p += IPV6_HDR_SIZE;
+				first_extension = 0;
+			} else {
+				/*TO NEXT */
+				udp_tcp_h_offset +=
+				    IPV6_EXTENSION_SIZE + p[1];
+				p += IPV6_EXTENSION_SIZE + p[1];
+			}
+			next_hdr = p[0];
+			if (udp_tcp_h_offset > len) {
+				DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+				 "\n- Wrong IPV6 packet header ?\n");
+				break;
+			}
+		}
+	}
+
+	/*not supported protocol */
+	return -1;
+}
+
+#ifdef CONFIG_LTQ_DATAPATH_MANUAL_PARSE
+#define IP_OFFSET_HW_ADJUST 8
+
+/*parse protol and get the ip_offset/tcp_h_offset and its type:
+* return: 0-found udp/tcp header, -1 - not found  udp/tcp header
+* Note: skb->data points to pmac header, not L2 MAC header;
+*/
+int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
+			    u32 *tcp_h_offset, u32 *tcp_type)
+{
+	u8 *p_l2_mac = skb->data + sizeof(struct pmac_tx_hdr);
+	u8 *p = p_l2_mac + TWO_MAC_SIZE;
+	struct ip_hdr_info pkt_info[2];
+	u8 ip_num = 0;
+	int i;
+	int len;
+
+	if (skb->ip_summed != CHECKSUM_PARTIAL)
+		return -1;
+
+	*ip_offset = 0;
+	*tcp_h_offset = 0;
+
+	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX)
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "flags DP_TX_CAL_CHKSUM is set\n");
+
+	while ((p[0] == 0x81) && (p[1] == 0x00))	/*skip vlan header */
+		p += VLAN_HDR_SIZE;
+
+	if ((p[0] == 0x88) && (p[1] == 0x64))	/*skip pppoe header */
+		p += PPPOE_HDR_SIZE;
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+		 "Try to find ip header:%02x %02x %02x %02x %02x %02x %02x %02x\n",
+		 p[0], p[1], p[2], p[3], p[4], p[5], p[6], p[7]);
+
+	if (((p[0] != 0x08) || (p[1] != 0x00)) &&
+	    ((p[0] != 0x86) && (p[1] != 0xdd))) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "None IP type:%02x%02x\n", p[0],
+			 p[1]);
+	}
+
+	p += 2;			/* jump to ip header */
+	len = skb->len - TWO_MAC_SIZE - 2;
+
+	while (1) {
+		if (get_ip_hdr_info(p, len, &pkt_info[ip_num]) == 0) {
+			pkt_info[ip_num].ip_offset = (u32)p - (u32)p_l2_mac;
+
+			if (pkt_info[ip_num].next_ip_hdr_offset) {
+				p += pkt_info[ip_num].next_ip_hdr_offset;
+				ip_num++;
+
+				if (ip_num >= ARRAY_SIZE(pkt_info))
+					return -1;
+
+				len -= pkt_info[ip_num].next_ip_hdr_offset;
+				continue;
+
+			} else {
+				ip_num++;
+
+				if (ip_num >= ARRAY_SIZE(pkt_info))
+					return -1;
+
+				break;
+			}
+		} else {
+			/*Not UDP/TCP and cannot do checksum calculation */
+			pr_info_once
+			    ("Not UDP/TCP and cannot do checksum calculation !\n");
+			return -1;
+		}
+	}
+
+	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX) {
+		for (i = 0; i < ip_num; i++) {
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+				 "Parsing: ip[%d]:ver=%d proto=%d ip_offset=%d udp_tcp_offset=%d, next_iphdr_offset=%d\n",
+				 i, pkt_info[i].ip_ver, pkt_info[i].proto,
+				 pkt_info[i].ip_offset,
+				 pkt_info[i].udp_tcp_offset,
+				 pkt_info[i].next_ip_hdr_offset);
+		}
+	}
+
+	if (ip_num == 1) {
+		if (pkt_info[0].ip_ver == DP_IP_VER4) {
+			*ip_offset = pkt_info[0].ip_offset;
+			*tcp_h_offset = pkt_info[0].udp_tcp_offset;
+
+			if (pkt_info[0].proto == PROTOCOL_UDP) {
+				*tcp_type = UDP_OVER_IPV4;
+				/*clear original udp checksum */
+				if (!pkt_info[0].is_fragment)
+					*(uint16_t *)(p_l2_mac + *ip_offset +
+						       *tcp_h_offset +
+						       UDP_CHKSUM_OFFSET) = 0;
+			} else {
+				*tcp_type = TCP_OVER_IPV4;
+				/*clear original TCP checksum */
+				*(uint16_t *)(p_l2_mac + *ip_offset +
+					       *tcp_h_offset +
+					       TCP_CHKSUM_OFFSET) = 0;
+			}
+
+			if (!pkt_info[0].is_fragment) {
+				/*clear original ip4 checksum */
+				*(uint16_t *)(p_l2_mac + *ip_offset +
+					       IP_CHKSUM_OFFSET_IPV4) = 0;
+			} else {
+				return 1;
+			}
+
+			return 0;
+		} else if (pkt_info[0].ip_ver == DP_IP_VER6) {
+			*ip_offset = pkt_info[0].ip_offset;
+			*tcp_h_offset = pkt_info[0].udp_tcp_offset;
+
+			if (pkt_info[0].proto == PROTOCOL_UDP) {
+				*tcp_type = UDP_OVER_IPV6;
+				if (!pkt_info[0].is_fragment)
+					/*clear original udp checksum */
+					*(uint16_t *)(p_l2_mac + *ip_offset +
+						       *tcp_h_offset +
+						       UDP_CHKSUM_OFFSET) = 0;
+			} else {
+				*tcp_type = TCP_OVER_IPV6;
+				/*clear original TCP checksum */
+				if (!pkt_info[0].is_fragment) {
+					*(uint16_t *)(p_l2_mac + *ip_offset +
+						       *tcp_h_offset +
+						       TCP_CHKSUM_OFFSET) = 0;
+				} else {
+					return 1;
+				}
+			}
+
+			return 0;
+		}
+	} else if (ip_num == 2) {
+		/*for tunnels:current for 6rd/dslite only */
+		if ((pkt_info[0].ip_ver == DP_IP_VER4) &&
+		   (pkt_info[1].ip_ver == DP_IP_VER6)) {
+			/*6rd */
+			*ip_offset = pkt_info[0].ip_offset;
+			*tcp_h_offset =
+			    (pkt_info[0].next_ip_hdr_offset +
+			     pkt_info[1].udp_tcp_offset);
+
+			if (pkt_info[1].proto == PROTOCOL_UDP) {
+				*tcp_type = UDP_OVER_IPV6_IPV4;
+				/*clear original udp checksum */
+				if (!pkt_info[0].is_fragment)
+					*(uint16_t *)(p_l2_mac + *ip_offset +
+						       *tcp_h_offset +
+						       UDP_CHKSUM_OFFSET) = 0;
+			} else {
+				*tcp_type = TCP_OVER_IPV6_IPV4;
+				/*clear original udp checksum */
+				*(uint16_t *)(p_l2_mac + *ip_offset +
+					       *tcp_h_offset +
+					       TCP_CHKSUM_OFFSET) = 0;
+			}
+
+			if (!pkt_info[0].is_fragment) {
+				/*clear original ip4 checksum */
+				*(uint16_t *)(p_l2_mac + *ip_offset +
+					       IP_CHKSUM_OFFSET_IPV4) = 0;
+			} else {
+				return 1;
+			}
+
+			return 0;
+
+		} else if ((pkt_info[0].ip_ver == DP_IP_VER6) &&
+			(pkt_info[1].ip_ver == DP_IP_VER4)) {	/*dslite */
+			*ip_offset = pkt_info[0].ip_offset;
+			*tcp_h_offset =
+			    (pkt_info[0].next_ip_hdr_offset +
+			     pkt_info[1].udp_tcp_offset);
+
+			if (pkt_info[1].proto == PROTOCOL_UDP) {
+				*tcp_type = UDP_OVER_IPV4_IPV6;
+				if (!pkt_info[0].is_fragment)
+					/*clear original udp checksum */
+					*(uint16_t *)(p_l2_mac +
+						       pkt_info[1].ip_offset +
+						       *tcp_h_offset +
+						       UDP_CHKSUM_OFFSET) = 0;
+			} else {
+				*tcp_type = TCP_OVER_IPV4_IPV6;
+				/*clear original udp checksum */
+				*(uint16_t *)(p_l2_mac +
+					       pkt_info[1].ip_offset +
+					       pkt_info[1].udp_tcp_offset +
+					       TCP_CHKSUM_OFFSET) = 0;
+			}
+
+			if (!pkt_info[0].is_fragment) {
+				/*clear original ip4 checksum */
+				*(uint16_t *)(p_l2_mac +
+					       pkt_info[1].ip_offset +
+					       IP_CHKSUM_OFFSET_IPV4) = 0;
+			} else {
+				return 1;
+			}
+
+			return 0;
+		}
+	}
+
+	return -1;
+}
+#else				/* CONFIG_LTQ_DATAPATH_MANUAL_PARSE */
+/*parse protol and get the ip_offset/tcp_h_offset and its type
+* based on skb_inner_network_header/skb_network_header/
+*           skb_inner_transport_header/skb_transport_header
+* return: 0-found udp/tcp header, -1 - not found  udp/tcp header
+*  Note: skb->data points to pmac header, not L2 MAC header;
+*/
+#define IP_OFFSET_HW_ADJUST  0
+
+int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
+			    u32 *tcp_h_offset, u32 *tcp_type)
+{
+	struct iphdr *iph;
+	struct tcphdr *tcph;
+	struct udphdr *udph;
+	unsigned char *l4_p;
+
+	if (skb->ip_summed != CHECKSUM_PARTIAL) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+			 "No need HW checksum Support\n");
+		return -1;
+	}
+
+	if (skb->encapsulation) {
+		iph = (struct iphdr *)skb_inner_network_header(skb);
+		*ip_offset =
+		    (uint32_t)(skb_inner_network_header(skb) - skb->data);
+		*tcp_h_offset =
+		    (uint32_t)(skb_inner_transport_header(skb) -
+				skb_inner_network_header(skb));
+		l4_p = skb_inner_transport_header(skb);
+	} else {
+		iph = (struct iphdr *)skb_network_header(skb);
+		*ip_offset = (uint32_t)(skb_network_header(skb) - skb->data);
+		*tcp_h_offset =
+		    (uint32_t)(skb_transport_header(skb) -
+				skb_network_header(skb));
+		l4_p = skb_transport_header(skb);
+	}
+	if (((int)(ip_offset) <= 0) || ((int)(tcp_h_offset) <= 0)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+			 "Wrong IP offset(%d) or TCP/UDP offset(%d)\n",
+			 ((int)(ip_offset) <= 0), ((int)(tcp_h_offset) <= 0));
+		return -1;
+	}
+
+	if (iph->protocol == IPPROTO_UDP) {
+		if (iph->version == DP_IP_VER4) {
+			*tcp_type = UDP_OVER_IPV4;
+			iph->check = 0;	/*clear original ip checksum */
+		} else if (iph->version == DP_IP_VER6) {
+			*tcp_type = UDP_OVER_IPV6;
+		} else { /*wrong ver*/
+			return -1;
+		}
+		udph = (struct udphdr *)l4_p;
+		udph->check = 0; /*clear original UDP checksum */
+	} else if (iph->protocol == IPPROTO_TCP) {
+		if (iph->version == DP_IP_VER4) {
+			*tcp_type = TCP_OVER_IPV4;
+			iph->check = 0;	/*clear original ip checksum */
+		} else if (iph->version == DP_IP_VER6) {
+			*tcp_type = TCP_OVER_IPV6;
+		} else {
+			return -1;
+		}
+		tcph = (struct tcphdr *)l4_p;
+		tcph->check = 0;	/*clear original UDP checksum */
+	}
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM, "Found tcp_type=%u ip_offset=%u\n",
+		 *tcp_type, *ip_offset);
+	return 0;
+}
+#endif				/* CONFIG_LTQ_DATAPATH_MANUAL_PARSE */
+
+/*Don't know why kernel does not define skb_inner_transport_offset */
+static inline int skb_inner_transport_offset(const struct sk_buff *skb)
+{
+	return skb_inner_transport_header(skb) - skb->data;
+}
+
+/*  Make a copy of both an &sk_buff and part of its data, located
+ * in header. Fragmented data remain shared. This is used since
+ * datapath need to modify only header of &sk_buff and needs
+ * private copy of the header to alter.
+ *  Returns NULL on failure, or the pointer to the buffer on success
+ *  Note, this API will used in dp_xmit when there is no enough room
+ *        to insert pmac header or the packet is cloned but we need
+ *        to insert pmac header or reset udp/tcp checksum
+ *  This logic is mainly copied from API __pskb_copy(...)
+*/
+struct sk_buff *dp_create_new_skb(struct sk_buff *skb)
+{
+	struct sk_buff *new_skb;
+#ifndef CONFIG_LTQ_DATAPATH_COPY_LINEAR_BUF_ONLY
+	/* seems CBM driver does not support it yet */
+	void *p;
+	const skb_frag_t *frag;
+	int len;
+#else
+	int linear_len;
+#endif
+	int i;
+
+	if (unlikely(skb->data_len >= skb->len)) {
+		PR_ERR("why skb->data_len(%d) >= skb->len(%d)\n",
+		       skb->data_len, skb->len);
+		dev_kfree_skb_any(skb);
+		return NULL;
+	}
+
+	if (skb_shinfo(skb)->frag_list) {
+		PR_ERR("DP Not support skb_shinfo(skb)->frag_list yet !!\n");
+		dev_kfree_skb_any(skb);
+		return NULL;
+	}
+#ifndef CONFIG_LTQ_DATAPATH_COPY_LINEAR_BUF_ONLY
+	new_skb = cbm_alloc_skb(skb->len + 8, GFP_ATOMIC);
+#else
+	linear_len = skb->len - skb->data_len;
+	/*cbm_alloc_skb will reserve enough header room */
+	new_skb = cbm_alloc_skb(linear_len, GFP_ATOMIC);
+#endif
+
+	if (unlikely(!new_skb)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "allocate cbm buffer fail\n");
+		dev_kfree_skb_any(skb);
+		return NULL;
+	}
+#ifndef CONFIG_LTQ_DATAPATH_COPY_LINEAR_BUF_ONLY
+	p = new_skb->data;
+	dp_memcpy(p, skb->data, skb->len - skb->data_len);
+	p += skb->len - skb->data_len;
+
+	if (skb->data_len) {
+		for (i = 0; i < (skb_shinfo(skb)->nr_frags); i++) {
+			frag = &skb_shinfo(skb)->frags[i];
+			len = skb_frag_size(frag);
+			dp_memcpy(p, skb_frag_address(frag), len);
+			p += len;
+		}
+	}
+	skb_put(new_skb, skb->len);
+#else
+	/* Copy the linear data part only */
+	memcpy(new_skb->data, skb->data, linear_len);
+	skb_put(new_skb, linear_len);
+
+	/*Share the Fragmented data */
+	if (skb_shinfo(skb)->nr_frags) {
+		for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+			skb_shinfo(new_skb)->frags[i] =
+			    skb_shinfo(skb)->frags[i];
+			skb_frag_ref(skb, i);	/*increase counter */
+		}
+		skb_shinfo(new_skb)->nr_frags = i;
+		skb_shinfo(new_skb)->gso_size = skb_shinfo(skb)->gso_size;
+		skb_shinfo(new_skb)->gso_segs = skb_shinfo(skb)->gso_segs;
+		skb_shinfo(new_skb)->gso_type = skb_shinfo(skb)->gso_type;
+		new_skb->data_len = skb->data_len;
+		new_skb->len += skb->data_len;
+	}
+#endif
+	new_skb->dev = skb->dev;
+	new_skb->priority = skb->priority;
+	new_skb->truesize += skb->data_len;
+	new_skb->DW0 = skb->DW0;
+	new_skb->DW1 = skb->DW1;
+	new_skb->DW2 = skb->DW2;
+	new_skb->DW3 = skb->DW3;
+
+	/*copy other necessary fields for checksum calculation case */
+	new_skb->ip_summed = skb->ip_summed;
+	new_skb->encapsulation = skb->encapsulation;
+	new_skb->inner_mac_header = skb->inner_mac_header;
+	new_skb->protocol = skb->protocol;
+
+	if (skb->encapsulation) {
+		skb_reset_inner_network_header(new_skb);
+		skb_set_inner_network_header(new_skb,
+					     skb_inner_network_offset(skb));
+		skb_reset_transport_header(new_skb);
+		skb_set_inner_transport_header(new_skb,
+					       skb_inner_transport_offset
+					       (skb));
+	} else {
+		skb_reset_network_header(new_skb);
+		skb_set_network_header(new_skb, skb_network_offset(skb));
+		skb_reset_transport_header(new_skb);
+		skb_set_transport_header(new_skb, skb_transport_offset(skb));
+	}
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "alloc new buffer succeed\n");
+	/*free old skb */
+	dev_kfree_skb_any(skb);
+	return new_skb;
+}
+
+char *dp_skb_csum_str(struct sk_buff *skb)
+{
+	if (!skb)
+		return "NULL";
+	if (skb->ip_summed == CHECKSUM_PARTIAL)
+		return "HW Checksum";
+	if (skb->ip_summed == CHECKSUM_NONE)
+		return "SW Checksum";
+	return "Unknown";
+}
+
+int32_t dp_xmit(struct net_device *rx_if, dp_subif_t *rx_subif,
+		struct sk_buff *skb, int32_t len, uint32_t flags)
+{
+	struct dma_tx_desc_0 *desc_0;
+	struct dma_tx_desc_1 *desc_1;
+	struct dma_tx_desc_2 *desc_2;
+	struct dma_tx_desc_3 *desc_3;
+	struct pmac_tx_hdr *pmac = NULL;
+	u32 ip_offset, tcp_h_offset, tcp_type;
+	int tx_chksum_flag = 0;	/*check checksum cal can be supported or not */
+	int insert_pmac_f = 1;	/*flag to insert one pmac */
+	int res = DP_SUCCESS;
+	int ep, vap;
+	int clone_f, no_hdr_room_f;
+
+	if (unlikely(!skb)) {
+		PR_RATELIMITED("skb NULL");
+		return DP_FAILURE;
+	}
+	if (unlikely(!dp_init_ok)) {
+		dev_kfree_skb_any(skb);
+		PR_RATELIMITED("dp_xmit failed for datapath not init yet\n");
+		return DP_FAILURE;
+	}
+	if (unlikely(!rx_subif)) {
+		dev_kfree_skb_any(skb);
+		PR_RATELIMITED("dp_xmit failed for rx_subif null\n");
+		DP_LIB_LOCK(&dp_lock);
+		dp_port_info[0].tx_err_drop++;
+		DP_LIB_UNLOCK(&dp_lock);
+		return DP_FAILURE;
+	}
+	ep = rx_subif->port_id;
+	vap = get_vap(rx_subif->subif);
+	if (unlikely(ep >= PMAC_MAX_NUM)) {
+		dev_kfree_skb_any(skb);
+		DP_LIB_LOCK(&dp_lock);
+		dp_port_info[0].tx_err_drop++;
+		DP_LIB_UNLOCK(&dp_lock);
+		PR_RATELIMITED("rx_subif->port_id >= PMAC_MAX_NUM");
+		return DP_FAILURE;
+	}
+	if (unlikely(in_irq())) {
+		PR_RATELIMITED
+		    ("Not allowed to call dp_xmit in interrupt context\n");
+		dev_kfree_skb_any(skb);
+		DP_LIB_LOCK(&dp_lock);
+		dp_port_info[ep].tx_err_drop++;
+		dp_port_info[ep].subif_info[vap].mib.tx_pkt_dropped++;
+		DP_LIB_UNLOCK(&dp_lock);
+		return DP_FAILURE;
+	}
+	if (unlikely(!rx_if &&	/*For atm pppoa case, rx_if is NULL now */
+		     !(dp_port_info[ep].alloc_flags & DP_F_FAST_DSL))) {
+		dev_kfree_skb_any(skb);
+		DP_LIB_LOCK(&dp_lock);
+		dp_port_info[ep].subif_info[vap].mib.tx_pkt_dropped++;
+		DP_LIB_UNLOCK(&dp_lock);
+		PR_RATELIMITED("rx_if NULL");
+		return DP_FAILURE;
+	}
+#ifdef CONFIG_LTQ_DP_MPE_FASTHOOK_TEST
+	if (unlikely(ltq_mpe_fasthook_tx_fn))
+		ltq_mpe_fasthook_tx_fn(skb, 0, NULL);
+#endif
+
+	/*No PMAC for WAVE500 and DSL by default except bonding case */
+	if ((dp_port_info[ep].alloc_flags &
+		(DP_F_FAST_WLAN | DP_F_FAST_DSL)) &&
+		!(flags & (DP_TX_CAL_CHKSUM | DP_TX_DSL_FCS)))
+		insert_pmac_f = 0;
+
+	if (unlikely(dp_dbg_flag)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "dp_xmit:skb->data/len=0x%p/%d data_ptr=%x from port=%d and subitf=%d\n",
+			 skb->data, len,
+			 ((struct dma_tx_desc_2 *)&skb->DW2)->field.data_ptr,
+			 ep, rx_subif->subif);
+
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "dp_xmit:skb->data/len=0x%p/%d data_ptr=%x from port=%d and subitf=%d\n",
+			 skb->data, len,
+			 ((struct dma_tx_desc_2 *)&skb->DW2)->field.data_ptr,
+			 ep, rx_subif->subif);
+
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DATA)
+			dp_dump_raw_data(skb->data,
+					 (skb->len >
+					  print_len) ? skb->len : print_len,
+					 "Tx Orig Data");
+
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+			 "ip_summed=%s(%d) encapsulation=%s\n",
+			 dp_skb_csum_str(skb), skb->ip_summed,
+			 skb->encapsulation ? "Yes" : "No");
+		if (skb->encapsulation)
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+				 "inner ip start=0x%x(%d), transport=0x%x(%d)\n",
+				 (unsigned int)skb_inner_network_header(skb),
+				 (int)(skb_inner_network_header(skb) -
+				       skb->data),
+				 (unsigned int)
+				 skb_inner_transport_header(skb),
+				 (int)(skb_inner_transport_header(skb) -
+				       skb_inner_network_header(skb)));
+		else
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+				 "ip start=0x%x(%d), transport=0x%x(%d)\n",
+				 (unsigned int)(unsigned int)
+				 skb_network_header(skb),
+				 (int)(skb_network_header(skb) - skb->data),
+				 (unsigned int)skb_transport_header(skb),
+				 (int)(skb_transport_header(skb) -
+				       skb_network_header(skb)));
+
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DESCRIPTOR)
+			dump_tx_dma_desc((struct dma_tx_desc_0 *)&skb->DW0,
+					 (struct dma_tx_desc_1 *)&skb->DW1,
+					 (struct dma_tx_desc_2 *)&skb->DW2,
+					 (struct dma_tx_desc_3 *)&skb->DW3);
+
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "flags=0x%x skb->len=%d\n",
+			 flags, skb->len);
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "skb->data=0x%p with pmac hdr size=%u\n", skb->data,
+			 sizeof(struct pmac_tx_hdr));
+	}
+
+	if (insert_pmac_f) {	/*insert one pmac header */
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "flags DP_TX_INSERT_PMAC is set\n");
+		clone_f = skb_cloned(skb);
+		no_hdr_room_f =
+		    skb_headroom(skb) < sizeof(struct pmac_tx_hdr) ? 1 : 0;
+
+		if (clone_f && !skb_is_gso(skb)) {
+			if (clone_f && (skb->data[0] & 1)) {
+				/*not boradcast/mc */
+				DP_LIB_LOCK(&dp_lock);
+				dp_port_info[ep].subif_info[vap].mib.
+				    tx_clone_pkt++;
+				DP_LIB_UNLOCK(&dp_lock);
+			}
+			/*make sure dp_create_new_skb copied correct */
+			/* flags like ip_summed, encapsulation and so on */
+			skb = dp_create_new_skb(skb);
+
+			if (unlikely(!skb)) {
+				PR_INFO_ONCE("dp_create_new_skb failed\n");
+				return DP_FAILURE;
+			}
+		} else if (no_hdr_room_f) {
+			PR_INFO_ONCE
+			    ("dp_xmit:no header room to insert pmac:%s ?\n",
+			     rx_if ? rx_if->name : "NULL");
+			DP_LIB_LOCK(&dp_lock);
+			dp_port_info[ep].subif_info[vap].mib.
+			    tx_hdr_room_pkt++;
+			DP_LIB_UNLOCK(&dp_lock);
+			/*make sure dp_create_new_skb copied correct flags */
+			/*like ip_summed encapsulation and so on */
+			skb = dp_create_new_skb(skb);
+			if (unlikely(!skb)) {
+				PR_INFO_ONCE("dp_create_new_skb failed\n");
+				return DP_FAILURE;
+			}
+		}
+
+		skb_push(skb, sizeof(struct pmac_tx_hdr));
+		pmac = (struct pmac_tx_hdr *)(skb->data);
+		memset(pmac, 0, sizeof(struct pmac_tx_hdr));
+	}
+
+	desc_0 = (struct dma_tx_desc_0 *)&skb->DW0;
+	desc_1 = (struct dma_tx_desc_1 *)&skb->DW1;
+	desc_2 = (struct dma_tx_desc_2 *)&skb->DW2;
+	desc_3 = (struct dma_tx_desc_3 *)&skb->DW3;
+
+	if (flags & DP_TX_CAL_CHKSUM) {
+		int ret_flg;
+
+		ret_flg =
+		    get_offset_clear_chksum(skb, &ip_offset, &tcp_h_offset,
+					    &tcp_type);
+		if (ret_flg == 0) {
+			pr_debug("packet CAN do hw checksum\n");
+			tx_chksum_flag = 1;
+		} else if (ret_flg == -1) {
+			pr_info_once("packet cant do hw checksum\n");
+		}
+	}
+
+	/*reset all descriptors as SWAS required since SWAS 3.7 */
+	/*As new SWAS 3.7 required, MPE1/Color/FlowID is set by applications */
+	desc_0->all &= dma_tx_desc_mask0.all;
+	desc_1->all &= dma_tx_desc_mask1.all;
+	desc_2->all = 0;
+	desc_3->all = 0;
+
+	if (flags & DP_TX_OAM)
+		desc_3->field.pdu_type = 1;
+
+	desc_1->field.classid = (skb->priority >= 15) ? 15 : skb->priority;
+	desc_2->field.data_ptr = (uint32_t)skb->data;
+
+	/*for ETH LAN/WAN */
+	if (dp_port_info[ep].
+	    alloc_flags & (DP_F_FAST_ETH_LAN | DP_F_FAST_ETH_WAN)) {
+		if (pmac) {
+			pmac->port_map_en = 1;
+			SET_PMAC_PORTMAP(pmac, ep);
+			SET_PMAC_SUBIF(pmac, rx_subif->subif);
+			pmac->sppid = PMAC_CPU_ID;	/*must set cpu port */
+
+			if (dp_port_info[ep].alloc_flags & DP_F_FAST_ETH_WAN)
+				pmac->redirect = 1;
+			else
+				pmac->redirect = 0;
+		} else
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+				 "Why !pmac for ETH Port?\n");
+	} else if (dp_port_info[ep].
+		   alloc_flags & (DP_F_DIRECT | DP_F_FAST_WLAN | DP_F_FAST_DSL
+				  | DP_F_DIRECTLINK)) {
+		if (flags & DP_TX_TO_DL_MPEFW) {
+			if (pmac) {
+				pmac->port_map_en = 1;
+				SET_PMAC_PORTMAP(pmac, ep);
+				pmac->sppid = PMAC_CPU_ID;
+				SET_PMAC_SUBIF(pmac, rx_subif->subif);
+			}
+
+			desc_1->field.enc = 0;
+			desc_1->field.dec = 0;
+			desc_1->field.mpe2 = 0;
+		} else if (flags & (DP_TX_CAL_CHKSUM | DP_TX_DSL_FCS)) {
+			/*checksum/fcs(bonding) queue */
+			if (pmac) {
+				pmac->port_map_en = 1;
+				/*specify destination */
+				SET_PMAC_PORTMAP(pmac, ep);
+				pmac->sppid = PMAC_CPU_ID;
+				pmac->redirect = 1;
+				SET_PMAC_SUBIF(pmac, rx_subif->subif);
+			} else
+				DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+					 "Why !pmac for Checksum/Redirect?\n");
+
+			desc_1->field.enc = 1;
+			desc_1->field.dec = 1;
+			desc_1->field.mpe2 = 1;
+		} else if (dp_port_info[ep].alloc_flags & DP_F_FAST_DSL) {
+			/* VRX318 queue */
+			desc_1->field.enc = 0;
+			desc_1->field.dec = 0;
+			desc_1->field.mpe2 = 0;
+		} else {	/*normal directpath queue */
+			if (pmac) {
+				pmac->port_map_en = 0;
+				pmac->port_map = 0xff;
+				pmac->port_map2 = 0xff;
+				pmac->sppid = ep;
+				SET_PMAC_SUBIF(pmac, rx_subif->subif);
+			} else
+				DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+					 "Why !pmac for normal directpath ?\n");
+
+			desc_1->field.enc = 1;
+			desc_1->field.dec = 1;
+			desc_1->field.mpe2 = 0;
+		}
+	} else {
+		dev_kfree_skb_any(skb);
+		dp_port_info[ep].subif_info[vap].mib.tx_pkt_dropped++;
+		PR_INFO_ONCE("Why come to here:%x\n",
+			     dp_port_info[ep].status);
+		return DP_FAILURE;
+	}
+
+	if (tx_chksum_flag) {	/*definately have pmac if tx_chksum_flag == 1 */
+		if (pmac) {
+			pmac->tcp_chksum = 1;
+			pmac->tcp_type = tcp_type;
+			pmac->ip_offset = ip_offset + IP_OFFSET_HW_ADJUST;
+			pmac->tcp_h_offset = tcp_h_offset >> 2;
+		} else
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+				 "Why !pmac for Checksum?\n");
+	}
+
+	desc_3->field.data_len = skb->len;
+#if 0
+	if (flags & DP_TX_DSL_FCS) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "flags DP_TX_DSL_FCS is set\n");
+		if (likely(pmac))
+			pmac->fcs_ins_dis = 1;
+		else
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+				 "Why !pmac for DP_TX_DSL_FCS\n");
+	}
+#endif
+
+	if (unlikely(dp_dbg_flag)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "pmac=0x%p data_len=%u skb->len=%u\n", pmac,
+			 desc_3->field.data_len, skb->len);
+
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DESCRIPTOR) {
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX_DESCRIPTOR,
+				 "Final DMA descriptor after modification:\n");
+			dump_tx_dma_desc((struct dma_tx_desc_0 *)&skb->DW0,
+					 (struct dma_tx_desc_1 *)&skb->DW1,
+					 (struct dma_tx_desc_2 *)&skb->DW2,
+					 (struct dma_tx_desc_3 *)&skb->DW3);
+		}
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_PMAC && pmac) {
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX_PMAC,
+				 "Final PMAC header after modification:\n");
+			dump_tx_pmac(pmac);
+		}
+		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DATA)
+			dp_dump_raw_data(skb->data,
+					 (skb->len >
+					  print_len) ? skb->len : print_len,
+					 "Final Data");
+	}
+#ifdef CONFIG_LTQ_TOE_DRIVER
+	if (skb_is_gso(skb)) {
+#ifdef LTQ_TSO_SW_WORKAROUND
+		/*Need TSO segmentation */
+		/* Hack in the PMAC header to make the ip_offset to 14 */
+		if (pmac)
+			pmac->ip_offset = ip_offset - 8;
+		else
+			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+				 "Why !pmac for TSO?\n");
+
+		desc_0->field.flow_id = 1 << 6;
+		desc_1->field.enc = 1;
+		desc_1->field.dec = 1;
+		desc_1->field.mpe2 = 1;
+#else
+		res = ltq_tso_xmit(skb, desc_1->field.ep, 0);
+		if (likely(res >= 0)) {
+			DP_LIB_LOCK(&dp_lock);
+			dp_port_info[ep].subif_info[vap].mib.tx_tso_pkt++;
+			DP_LIB_UNLOCK(&dp_lock);
+		} else {
+			pr_err("no available TSO ports !!\n");
+		}
+
+		return res;
+#endif /* LTQ_TSO_SW_WORKAROUND */
+	}
+#endif /* CONFIG_LTQ_TOE_DRIVER */
+
+	if (pmac)
+		pmac->class_en = 1;
+
+	DP_LIB_LOCK(&dp_lock);
+	dp_port_info[ep].subif_info[vap].mib.tx_cbm_pkt++;
+	DP_LIB_UNLOCK(&dp_lock);
+
+	if (unlikely(!desc_1->field.ep)) {
+		PR_ERR("Why ep zero in dp_xmit for device name %s\n",
+		       skb->dev ? skb->dev->name : "NULL");
+		dev_kfree_skb_any(skb);
+		return DP_FAILURE;
+	}
+
+	res = cbm_cpu_pkt_tx(skb, desc_1->field.ep, 0);
+	return res;
+}
+EXPORT_SYMBOL(dp_xmit);
+
+void set_dp_dbg_flag(uint32_t flags)
+{
+	dp_dbg_flag = flags;
+}
+
+uint32_t get_dp_dbg_flag(void)
+{
+	return dp_dbg_flag;
+}
+
+#ifdef DP_TEST_EXAMPLE
+void test(void)
+{
+	/* Base on below example data, it should print like below log
+	*DMA Descripotr:D0=0x00004000 D1=0x00001000 D2=0xa0c02080 D3=0xb0000074
+	*DW0:resv0=0 tunnel_id=00 flow_id=0 eth_type=0 dest_sub_if_id=0x4000
+	*DW1:session_id=0x000 tcp_err=0 nat=0 dec=0 enc=0 mpe2=0 mpe1=0
+	*color=01 ep=00 resv1=0 classid=00
+	*DW2:data_ptr=0xa0c02080
+	*DW3:own=1 c=0 sop=1 eop=1 dic=0 pdu_type=0
+	*byte_offset=0 atm_qid=0 mpoa_pt=0 mpoa_mode=0 data_len= 116
+	*paser flags: 00 00 00 00 80 18 80 00
+	*paser flags: 00 80 18 80 00 00 00 00 (reverse)
+	*flags 15 offset=14: PASER_FLAGS_1IPV4
+	*flags 19 offset=22: PASER_FLAGS_ROUTEXP
+	*flags 20 offset=34: PASER_FLAGS_TCP
+	*flags 31 offset=46: PASER_FLAGS_LROEXP
+	*pmac:0x4e 0x28 0xf0 0x00 0x00 0x00 0x00 0x01
+	*byte 0:res=0 ver_done =1 ip_offset=14
+	*byte 1:tcp_h_offset=5 tcp_type=0
+	*byte 2:ppid=15 class=0
+	*byte 3:res=0 pkt_type=0
+	*byte 4:res=0 redirect=0 res2=0 src_sub_inf_id=0
+	*byte 5:src_sub_inf_id2=0
+	*byte 6:port_map=0
+	*byte 7:port_map2=1
+	*/
+#ifdef CONFIG_LITTLE_ENDIAN
+	char example_data[] = {
+		0x00, 0x3a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e,
+		0x00, 0x00, 0x00, 0x16, 0x22, 0x00, 0x00, 0x00, 0x00, 0x00,
+		0x00, 0x00, 0x00, 0x00, 0x00, 0x2e,
+		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+		0x00, 0x00, 0x80, 0x18, 0x80, 0x00,
+		0x00, 0xf0, 0x28, 0x4e, 0x01, 0x00, 0x00, 0x00, 0xaa, 0x00,
+		0x00, 0x00, 0x04, 0x03, 0xbb, 0x00,
+		0x00, 0x00, 0x04, 0x02, 0x08, 0x00, 0x45, 0x00, 0x00, 0x2e,
+		0x00, 0x00, 0x00, 0x00, 0x01, 0x06,
+		0xb9, 0xcb, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+		0x04, 0x00, 0xb2, 0x9a, 0x03, 0xde
+	};
+#else
+	char example_data[] = {
+		0x00, 0x3a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e,
+		0x00, 0x00, 0x00, 0x16, 0x22, 0x00, 0x00, 0x00, 0x00, 0x00,
+		0x00, 0x00, 0x00, 0x00, 0x00, 0x2e,
+		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+		0x00, 0x00, 0x80, 0x18, 0x80, 0x00,
+		0x4e, 0x28, 0xf0, 0x00, 0x00, 0x00, 0x00, 0x01, 0xaa, 0x00,
+		0x00, 0x00, 0x04, 0x03, 0xbb, 0x00,
+		0x00, 0x00, 0x04, 0x02, 0x08, 0x00, 0x45, 0x00, 0x00, 0x2e,
+		0x00, 0x00, 0x00, 0x00, 0x01, 0x06,
+		0xb9, 0xcb, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+		0x04, 0x00, 0xb2, 0x9a, 0x03, 0xde
+	};
+#endif
+	struct sk_buff skb;
+
+	skb.DW0 = 0x4000;
+	skb.DW1 = 0x1000;
+	skb.DW2 = 0xa0c02080;
+	skb.DW3 = 0xb0000074;
+	skb.data = example_data;
+	skb.len = sizeof(example_data);
+	dp_rx(&skb, 0);
+}
+#endif				/* DP_TEST_EXAMPLE */
+
+static __init int dp_init_module(void)
+{
+	int res;
+	struct proc_dir_entry *proc_node = dp_proc_install();
+
+	/*mask to reset some field as SWAS required  all others try to keep */
+	dma_rx_desc_mask1.all = 0xFFFFFFFF;
+	dma_rx_desc_mask3.all = 0xFFFFFFFF;
+	dma_rx_desc_mask3.field.own = 0;
+	dma_rx_desc_mask3.field.c = 0;
+	dma_rx_desc_mask3.field.sop = 0;
+	dma_rx_desc_mask3.field.eop = 0;
+	dma_rx_desc_mask3.field.dic = 0;
+	dma_rx_desc_mask3.field.byte_offset = 0;
+	dma_rx_desc_mask1.field.dec = 0;
+	dma_rx_desc_mask1.field.enc = 0;
+	dma_rx_desc_mask1.field.mpe2 = 0;
+	dma_rx_desc_mask1.field.mpe1 = 0;
+	/*mask to keep some value set by top application all others set to 0*/
+	dma_tx_desc_mask0.all = 0;
+	dma_tx_desc_mask1.all = 0;
+	dma_tx_desc_mask0.field.flow_id = 0xFF;
+	dma_tx_desc_mask0.field.dest_sub_if_id = 0x7FFF;
+	dma_tx_desc_mask1.field.mpe1 = 0x1;
+	dma_tx_desc_mask1.field.color = 0x3;
+	dma_tx_desc_mask1.field.ep = 0xF;
+#ifdef CONFIG_LTQ_DATAPATH_LOOPETH
+	dp_loop_eth_dev_init(proc_node);
+#endif
+#ifdef CONFIG_LTQ_TMU
+	tmu_proc_install(proc_node);
+#endif
+	/*dp_set_gsw_parser(3, 2, 2, 0, 0);*/
+	dp_get_gsw_parser(NULL, NULL, NULL, NULL);
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+	dp_mib_init();
+	gsw_mib_reset(0, 0); /* GSW L */
+	gsw_mib_reset(1, 0); /* GSW R */
+	cbm_counter_mode_set(0, 1); /*enqueue to byte */
+	cbm_counter_mode_set(1, 1); /*dequeue to byte */
+#endif
+	res = dp_api_init();
+#ifdef CONFIG_LTQ_DATAPATH_FILTER
+	mpe_fh_netfiler_install();
+#endif
+#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+	dp_coc_cpufreq_init();
+#endif
+
+#ifdef CONFIG_LTQ_DATAPATH_LOCAL_SESSION
+	dp_local_session_fast_init(0);
+#endif
+	PRINTK("dp init done\n");
+	return res;
+}
+
+static __exit void dp_cleanup_module(void)
+{
+	if (dp_init_ok) {
+		DP_LIB_LOCK(&dp_lock);
+		memset(dp_port_info, 0, sizeof(dp_port_info));
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+		dp_mib_exit();
+#endif
+		dp_init_ok = 0;
+		DP_LIB_UNLOCK(&dp_lock);
+#ifdef CONFIG_LTQ_DATAPATH_LOOPETH
+		dp_loop_eth_dev_exit();
+#endif
+#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+		dp_coc_cpufreq_exit();
+#endif
+	}
+}
+
+module_init(dp_init_module);
+module_exit(dp_cleanup_module);
+
+MODULE_LICENSE("GPL");
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_coc.c b/drivers/net/ethernet/lantiq/datapath/datapath_coc.c
new file mode 100644
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_coc.c
@@ -0,0 +1,906 @@
+/*
+ *
+ *			 Copyright (c) 2012, 2014, 2015
+ *			Lantiq Beteiligungs-GmbH & Co. KG
+ *
+ *  For licensing information, see the file 'LICENSE' in the root folder of
+ *  this software module.
+ */
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/module.h>
+#include <linux/types.h>	/* size_t */
+#include <linux/timer.h>
+#include <net/datapath_api.h>
+#include <net/datapath_proc_api.h>
+#include "datapath.h"
+#include "datapath_pmac.h"
+
+#define DP_MODULE  LTQ_CPUFREQ_MODULE_DP
+#define DP_ID 0			/* this ID should represent the Datapath interface No. */
+static struct timer_list dp_coc_timer;
+static u32 polling_period;	/*seconds */
+static int rmon_timer_en;
+static spinlock_t dp_coc_lock;
+
+/* threshold data for D0:D3 */
+struct ltq_cpufreq_threshold rmon_threshold = { 0, 30, 20, 10 };	/*packets */
+
+/* driver is busy and needs highest performance */
+static int dp_coc_init_stat;	/*DP COC is Initialized or not */
+static int dp_coc_ena;		/*DP COC is enabled or not */
+enum ltq_cpufreq_state dp_coc_ps_curr = LTQ_CPUFREQ_PS_UNDEF;	/*current state */
+enum ltq_cpufreq_state dp_coc_ps_new = LTQ_CPUFREQ_PS_UNDEF;	/*new statue wanted to switch to */
+
+static GSW_RMON_Port_cnt_t rmon_last[PMAC_MAX_NUM];
+static u64 last_rmon_rx;
+
+/*meter */
+#define PCE_OVERHD 20
+static u32 meter_id;
+static u32 meter_ncbs = 0x8000 + (1514 + PCE_OVERHD) * 3 + 200;	/*3 ~ 4 packet size */
+static u32 meter_nebs = 0x8000 + (1514 + PCE_OVERHD) * 1 + 200;	/*1 ~ 2 packet size */
+static u32 meter_nrate[4] = { 0 /*D0 */ , 700 /*D1 */ , 600 /*D2 */ , 500 /*D3 */  };	/*k bits */
+
+static int dp_coc_cpufreq_notifier(struct notifier_block *nb,
+				   unsigned long val, void *data);
+static int dp_coc_stateget(enum ltq_cpufreq_state *state);
+static int dp_coc_fss_ena(int ena);
+int dp_coc_new_stat_req(enum ltq_cpufreq_state new_state, uint32_t flag);
+static int apply_meter_rate(u32 rate, enum ltq_cpufreq_state new_state);
+static int enable_meter_interrupt(void);
+static int clear_meter_interrupt(void);
+int dp_set_meter_rate(enum ltq_cpufreq_state stat, unsigned int rate)
+{				/*set the rate for upscaling to D0 from specified stat */
+	if (stat == LTQ_CPUFREQ_PS_D1)
+		meter_nrate[1] = rate;
+	else if (stat == LTQ_CPUFREQ_PS_D2)
+		meter_nrate[2] = rate;
+	else if (stat == LTQ_CPUFREQ_PS_D3)
+		meter_nrate[3] = rate;
+	else
+		return -1;
+	if (dp_coc_ps_curr == stat)
+		apply_meter_rate(-1, stat);
+	return 0;
+}
+EXPORT_SYMBOL(dp_set_meter_rate);
+
+static struct notifier_block dp_coc_cpufreq_notifier_block = {
+	.notifier_call = dp_coc_cpufreq_notifier
+};
+
+static inline void coc_lock(void)
+{
+	if (unlikely(in_irq())) {
+		PR_ERR("Not allowed to call COC API in_irq mode\n");
+		return;
+	} else
+		spin_lock_bh(&dp_coc_lock);
+}
+
+static inline void coc_unlock(void)
+{
+	spin_unlock_bh(&dp_coc_lock);
+}
+
+struct ltq_cpufreq_module_info dp_coc_feature_fss = {
+	.name = "Datapath FSS",
+	.pmcuModule = DP_MODULE,
+	.pmcuModuleNr = DP_ID,
+	.powerFeatureStat = 1,
+	.ltq_cpufreq_state_get = dp_coc_stateget,
+	.ltq_cpufreq_pwr_feature_switch = dp_coc_fss_ena,
+};
+
+static char *get_sub_module_str(uint32_t flag)
+{
+	if (flag == DP_COC_REQ_DP)
+		return "DP";
+	else if (flag == DP_COC_REQ_ETHERNET)
+		return "Ethernet";
+	else if (flag == DP_COC_REQ_VRX318)
+		return "VRX318";
+	else
+		return "Unknown";
+}
+
+static char *get_coc_stat_string(enum ltq_cpufreq_state stat)
+{
+	if (stat == LTQ_CPUFREQ_PS_D0)
+		return "D0";
+	else if (stat == LTQ_CPUFREQ_PS_D1)
+		return "D1";
+	else if (stat == LTQ_CPUFREQ_PS_D2)
+		return "D2";
+	else if (stat == LTQ_CPUFREQ_PS_D3)
+		return "D3";
+	else if (stat == LTQ_CPUFREQ_PS_D0D3)
+		return "D0D3-NotCare";
+	else if (stat == LTQ_CPUFREQ_PS_BOOST)
+		return "Boost";
+	else
+		return "Undef";
+}
+
+static void dp_rmon_polling(unsigned long data)
+{
+	GSW_RMON_Port_cnt_t curr;
+	int i;
+	u64 rx = 0;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		memset(&curr, 0, sizeof(curr));
+		get_gsw_port_rmon(i, GSWIP_R_DEV_NAME, &curr);
+
+		coc_lock();
+		/*wrapround handling */
+		if (curr.nRxGoodPkts >= rmon_last[i].nRxGoodPkts)
+			rx += curr.nRxGoodPkts - rmon_last[i].nRxGoodPkts;
+		else
+			rx +=
+			    (u64) 0xFFFFFFFF + (u64) curr.nRxGoodPkts -
+			    rmon_last[i].nRxGoodPkts;
+
+		if (curr.nRxDroppedPkts >= rmon_last[i].nRxDroppedPkts)
+			rx +=
+			    curr.nRxDroppedPkts - rmon_last[i].nRxDroppedPkts;
+		else
+			rx +=
+			    (u64) 0xFFFFFFFF + (u64) curr.nRxDroppedPkts -
+			    rmon_last[i].nRxDroppedPkts;
+
+		memcpy(&rmon_last[i], &curr, sizeof(curr));
+		coc_unlock();
+	}
+	last_rmon_rx = rx;
+	if (dp_coc_ps_curr != LTQ_CPUFREQ_PS_UNDEF	/*&&
+							   dp_coc_ps_curr != LTQ_CPUFREQ_PS_D3 */) {
+		if (rx < rmon_threshold.th_d3) {
+			if (dp_coc_new_stat_req
+			    (LTQ_CPUFREQ_PS_D3, DP_COC_REQ_DP) == 0) {
+				/*succeed to request although may not confirm yet */
+				coc_lock();
+				rmon_timer_en = 0;
+				coc_unlock();
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "DP request to D3 since rx (%u) < th_d3 %d\n",
+					 (unsigned int)rx,
+					 rmon_threshold.th_d3);
+			} else
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "DP request to D3 failed for dp_coc_new_stat_req\n");
+		} else if (rx < rmon_threshold.th_d2) {
+			if (dp_coc_new_stat_req
+			    (LTQ_CPUFREQ_PS_D2, DP_COC_REQ_DP) == 0) {
+				/*succeed to request although may not confirm yet */
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "DP request to D2 since rx (%u) < th_d2 %d\n",
+					 (unsigned int)rx,
+					 rmon_threshold.th_d2);
+			} else
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "DP request to D2 failed for dp_coc_new_stat_req\n");
+		} else if (rx < rmon_threshold.th_d1) {
+			if (dp_coc_new_stat_req
+			    (LTQ_CPUFREQ_PS_D1, DP_COC_REQ_DP) == 0) {
+				/*succeed to request although may not confirm yet */
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "DP request to D1 since rx (%u) < th_d1 %d\n",
+					 (unsigned int)rx,
+					 rmon_threshold.th_d1);
+			} else
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "DP request to D1 failed for dp_coc_new_stat_req\n");
+		} else
+			DP_DEBUG(DP_DBG_FLAG_COC,
+				 "State no change since rx (%u) >= any thresholds %d_%d_%d\n",
+				 (unsigned int)rx, rmon_threshold.th_d3,
+				 rmon_threshold.th_d2, rmon_threshold.th_d1);
+	} else
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "DP COC not get its initial power state yet\n");
+
+	coc_lock();
+
+	if (rmon_timer_en)
+		mod_timer(&dp_coc_timer,
+			  jiffies + msecs_to_jiffies(polling_period * 1000));
+	else
+		last_rmon_rx = 0;
+
+	coc_unlock();
+}
+
+static int dp_coc_stateget(enum ltq_cpufreq_state *state)
+{
+	DP_DEBUG(DP_DBG_FLAG_COC, "dp_coc_stateget with %d(%s)\n",
+		 dp_coc_ps_curr, get_coc_stat_string(dp_coc_ps_curr));
+	coc_lock();
+	*state = dp_coc_ps_curr;
+	coc_unlock();
+	return LTQ_CPUFREQ_RETURN_SUCCESS;
+}
+
+static int dp_coc_fss_ena(int ena)
+{
+	DP_DEBUG(DP_DBG_FLAG_COC,
+		 "dp_coc_fss_ena: %d(%s frequency scaling)\n", ena,
+		 ena ? "enable" : "disable");
+	coc_lock();
+	dp_coc_ena = ena;
+	coc_unlock();
+	return LTQ_CPUFREQ_RETURN_SUCCESS;
+}
+
+void update_rmon_last(void)
+{
+	int i;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++)
+		get_gsw_port_rmon(i, GSWIP_R_DEV_NAME, &rmon_last[i]);
+}
+
+int update_coc_rmon_timer(enum ltq_cpufreq_state new_state, uint32_t flag)
+{
+	if (new_state == LTQ_CPUFREQ_PS_D0) {
+		/*enable rmon timer */
+		if (!rmon_timer_en)
+			update_rmon_last();
+		mod_timer(&dp_coc_timer,
+			  jiffies + msecs_to_jiffies(polling_period * 1000));
+		rmon_timer_en = 1;
+
+		/*disable meter */
+		apply_meter_rate(0, 0);
+	} else if (new_state == LTQ_CPUFREQ_PS_D1 ||
+		   new_state == LTQ_CPUFREQ_PS_D2) {
+		/*enable rmon timer */
+		if (!rmon_timer_en)
+			update_rmon_last();
+		mod_timer(&dp_coc_timer,
+			  jiffies + msecs_to_jiffies(polling_period * 1000));
+		rmon_timer_en = 1;
+
+		/*enable meter */
+		apply_meter_rate(0, 0);	/*disable first to solve red color issue if last time already triggered */
+		apply_meter_rate(-1, new_state);	/*enable again */
+	} else if (new_state == LTQ_CPUFREQ_PS_D3) {
+		/*disable rmon timer */
+		del_timer(&dp_coc_timer);
+		rmon_timer_en = 0;
+		last_rmon_rx = 0;
+
+		/*enable meter */
+		apply_meter_rate(0, 0);	/*disable first to solve red color issue if last time already triggered */
+		apply_meter_rate(-1, new_state);	/*enable again */
+	}
+
+	return 0;
+}
+
+static int update_coc_cfg(enum ltq_cpufreq_state new_state,
+			  enum ltq_cpufreq_state old_state, uint32_t flag)
+{
+	update_coc_up_sub_module(new_state, old_state, flag);
+	update_coc_rmon_timer(new_state, flag);
+	return 0;
+}
+
+static int dp_coc_prechange(enum ltq_cpufreq_module module,
+			    enum ltq_cpufreq_state new_state,
+			    enum ltq_cpufreq_state old_state, u8 flags)
+{
+	int res = -1;
+
+	/*check whether can be switched or not */
+	if (!dp_coc_init_stat || !dp_coc_ena)
+		res = 0;
+	else if ((flags & CPUFREQ_PM_NO_DENY) || (dp_coc_ps_curr == LTQ_CPUFREQ_PS_UNDEF) || (dp_coc_ps_new == LTQ_CPUFREQ_PS_UNDEF) || (dp_coc_ps_new == LTQ_CPUFREQ_PS_D0D3))	/*accept */
+		res = 0;
+	else if (dp_coc_ps_new >= new_state) {
+		/* Accept any upscale request */
+		res = 0;
+	}
+
+	DP_DEBUG(DP_DBG_FLAG_COC,
+		 "dp_coc_prechange:%s to switch from %s to %s\n",
+		 res ? "Deny" : "Accept", get_coc_stat_string(old_state),
+		 get_coc_stat_string(new_state));
+
+	return res;
+}
+
+static int dp_coc_postchange(enum ltq_cpufreq_module module,
+			     enum ltq_cpufreq_state new_state,
+			     enum ltq_cpufreq_state old_state, u8 flags)
+{
+	if (!dp_coc_init_stat || !dp_coc_ena)
+		return 0;
+
+	DP_DEBUG(DP_DBG_FLAG_COC, "dp_coc_postchange:switch from %s to %s\n",
+		 get_coc_stat_string(old_state),
+		 get_coc_stat_string(new_state));
+
+	coc_lock();
+	dp_coc_ps_curr = new_state;
+	dp_coc_ps_new = LTQ_CPUFREQ_PS_UNDEF;
+	update_coc_cfg(new_state, old_state, flags);	/*don't lock before it */
+	coc_unlock();
+
+	return 0;
+}
+
+/* keep track of frequency transitions */
+static int dp_coc_cpufreq_notifier(struct notifier_block *nb,
+				   unsigned long val, void *data)
+{
+	struct cpufreq_freqs *freq = data;
+	enum ltq_cpufreq_state new_state, old_state;
+
+	new_state = ltq_cpufreq_get_ps_from_khz(freq->new);
+
+	if (new_state == LTQ_CPUFREQ_PS_UNDEF) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "dp_coc_cpufreq_notifier new_state=UNDEF with val=%u \n",
+			 (unsigned int)val);
+		return NOTIFY_STOP_MASK | (DP_MODULE << 4);
+	}
+
+	old_state = ltq_cpufreq_get_ps_from_khz(freq->old);
+
+	if (old_state == LTQ_CPUFREQ_PS_UNDEF) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "dp_coc_cpufreq_notifier new_state=%s old_state=UNDEF with val=%u\n",
+			 get_coc_stat_string(new_state), (unsigned int)val);
+		return NOTIFY_STOP_MASK | (DP_MODULE << 4);
+	}
+
+	if (val == CPUFREQ_PRECHANGE) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "dp_coc_cpufreq_notifier prechange from %s to %s\n",
+			 get_coc_stat_string(old_state),
+			 get_coc_stat_string(new_state));
+
+		if (dp_coc_prechange
+		    (DP_MODULE, new_state, old_state, freq->flags))
+			return NOTIFY_STOP_MASK | (DP_MODULE << 4);
+	} else if (val == CPUFREQ_POSTCHANGE) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "dp_coc_cpufreq_notifier postchange from %s to %s\n",
+			 get_coc_stat_string(old_state),
+			 get_coc_stat_string(new_state));
+
+		if (dp_coc_postchange
+		    (DP_MODULE, new_state, old_state, freq->flags))
+			return NOTIFY_STOP_MASK | (DP_MODULE << 4);
+	}
+
+	return NOTIFY_OK | (DP_MODULE << 4);
+}
+
+void proc_coc_read(struct seq_file *s)
+{
+	union gsw_var tmp;
+
+	SEQ_PRINTF(s, "Basic DP COC Info:\n");
+	SEQ_PRINTF(s, "  dp_coc_ena=%d @ 0x%p (DP %s)\n", dp_coc_ena,
+		   &dp_coc_ena, dp_coc_ena ? "COC Enabled" : "COC Disabled");
+	SEQ_PRINTF(s, "  Rmon timer interval: %u sec (Timer %s)\n",
+		   (unsigned int)polling_period,
+		   rmon_timer_en ? "enabled" : "disabled");
+	/*SEQ_PRINTF(s, "  RMON D0 Threshold: %d\n", rmon_threshold.th_d0); */
+	SEQ_PRINTF(s, "  RMON D1 Threshold: %d\n", rmon_threshold.th_d1);
+	SEQ_PRINTF(s, "  RMON D2 Threshold: %d\n", rmon_threshold.th_d2);
+	SEQ_PRINTF(s, "  RMON D3 Threshold: %d\n", rmon_threshold.th_d3);
+	SEQ_PRINTF(s, "  dp_coc_init_stat=%d @ %p (%s)\n", dp_coc_init_stat,
+		   &dp_coc_init_stat,
+		   dp_coc_init_stat ? "initialized ok" : "Not initialized");
+	SEQ_PRINTF(s, "  dp_coc_ps_curr=%d (%s) @ 0x%p\n", dp_coc_ps_curr,
+		   get_coc_stat_string(dp_coc_ps_curr), &dp_coc_ps_curr);
+	SEQ_PRINTF(s, "  dp_coc_ps_new=%d (%s)@ 0x%p\n", dp_coc_ps_new,
+		   get_coc_stat_string(dp_coc_ps_new), &dp_coc_ps_new);
+	SEQ_PRINTF(s, "  last_rmon_rx=%llu pkts@ 0x%p (%s)\n", last_rmon_rx,
+		   &last_rmon_rx, rmon_timer_en ? "Valid" : "Not valid");
+
+	SEQ_PRINTF(s, "Metering Info:\n");
+	/*PCE_OVERHD */
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0x46C;	/*PCE_OVERHD */
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_GET, (u32) &tmp);
+	SEQ_PRINTF(s, "  PCE_OVERHD=%d\n", tmp.reg.nData);
+
+	tmp.meter_cfg.nMeterId = meter_id;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_METER_CFG_GET, (u32) &tmp);
+	SEQ_PRINTF(s, "  meter id=%u (%s)\n", meter_id,
+		   tmp.meter_cfg.bEnable ? "Enabled" : "Disabled");
+	SEQ_PRINTF(s, "  meter nCbs=%u \n", tmp.meter_cfg.nCbs);
+	SEQ_PRINTF(s, "  meter nEbs=%u \n", tmp.meter_cfg.nEbs);
+	SEQ_PRINTF(s, "  meter nRate=%u \n", tmp.meter_cfg.nRate);
+	SEQ_PRINTF(s, "  meter nPiRate=%u \n", tmp.meter_cfg.nPiRate);
+	SEQ_PRINTF(s, "  meter eMtrType=%u \n", (int)tmp.meter_cfg.eMtrType);
+	SEQ_PRINTF(s, "  D1 nRate=%u\n", meter_nrate[1]);
+	SEQ_PRINTF(s, "  D2 nRate=%u\n", meter_nrate[2]);
+	SEQ_PRINTF(s, "  D3 nRate=%u\n", meter_nrate[3]);
+
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0x489 + meter_id * 10;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_GET, (u32) &tmp);
+	SEQ_PRINTF(s, "  PCE_PISR(0x%x)=%u(0x%x)-interrupt %s\n",
+		   tmp.reg.nRegAddr, tmp.reg.nData, tmp.reg.nData,
+		   (tmp.reg.nData & 0x100) ? "on" : "off");
+
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0xE11;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_GET, (u32) &tmp);
+	SEQ_PRINTF(s, "  GSW_PCE_TCM_STAT(0x%x)=%u(0x%x)-backpress %s\n",
+		   tmp.reg.nRegAddr, tmp.reg.nData, tmp.reg.nData,
+		   (tmp.reg.nData & 1) ? "on" : "off");
+}
+
+int dp_set_rmon_threshold(struct ltq_cpufreq_threshold *threshold,
+			  uint32_t flags)
+{
+	if (!threshold)
+		return -1;
+
+	memcpy((void *)&rmon_threshold, (void *)threshold,
+	       sizeof(rmon_threshold));
+	return 0;
+}
+EXPORT_SYMBOL(dp_set_rmon_threshold);
+
+ssize_t proc_coc_write(struct file *file, const char *buf, size_t count,
+		       loff_t *ppos)
+{
+	int len, num;
+	char str[64];
+	char *param_list[3];
+#define MIN_POLL_TIME 1
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (dp_strcmpi(param_list[0], "timer") == 0) {
+		polling_period = dp_atoi(param_list[1]);
+
+		if (polling_period < MIN_POLL_TIME)
+			polling_period = MIN_POLL_TIME;
+
+		coc_lock();
+
+		if (rmon_timer_en) {
+			mod_timer(&dp_coc_timer,
+				  jiffies +
+				  msecs_to_jiffies(polling_period * 1000));
+		}
+
+		coc_unlock();
+	} else if (dp_strcmpi(param_list[0], "threshold0") == 0) {
+		coc_lock();
+		rmon_threshold.th_d0 = dp_atoi(param_list[1]);
+
+		if (!rmon_threshold.th_d0)
+			rmon_threshold.th_d0 = 1;
+
+		coc_unlock();
+	} else if (dp_strcmpi(param_list[0], "threshold1") == 0) {
+		coc_lock();
+		rmon_threshold.th_d1 = dp_atoi(param_list[1]);
+
+		if (!rmon_threshold.th_d1)
+			rmon_threshold.th_d1 = 1;
+
+		coc_unlock();
+	} else if (dp_strcmpi(param_list[0], "threshold2") == 0) {
+		coc_lock();
+		rmon_threshold.th_d2 = dp_atoi(param_list[1]);
+
+		if (!rmon_threshold.th_d2)
+			rmon_threshold.th_d2 = 1;
+
+		coc_unlock();
+	} else if (dp_strcmpi(param_list[0], "threshold3") == 0) {
+		coc_lock();
+		rmon_threshold.th_d3 = dp_atoi(param_list[1]);
+
+		if (!rmon_threshold.th_d3)
+			rmon_threshold.th_d3 = 1;
+
+		coc_unlock();
+	} else if (dp_strcmpi(param_list[0], "D0") == 0)
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D0, DP_COC_REQ_DP);
+	else if (dp_strcmpi(param_list[0], "D1") == 0)
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D1, DP_COC_REQ_DP);
+	else if (dp_strcmpi(param_list[0], "D2") == 0)
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D2, DP_COC_REQ_DP);
+	else if (dp_strcmpi(param_list[0], "D3") == 0)
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D3, DP_COC_REQ_DP);
+	else if (dp_strncmpi(param_list[0], "rate", 4) == 0) {	/*meter rate */
+		u32 rate = dp_atoi(param_list[1]);
+		if (!rate) {
+			PRINTK("rate should not be zero\n");
+			return count;
+		}
+		if (dp_strcmpi(param_list[0], "rate1") == 0) {
+			dp_set_meter_rate(LTQ_CPUFREQ_PS_D1, rate);
+
+		} else if (dp_strcmpi(param_list[0], "rate2") == 0) {
+			dp_set_meter_rate(LTQ_CPUFREQ_PS_D2, rate);
+		} else if ((dp_strcmpi(param_list[0], "rate3") == 0) ||
+			   (dp_strcmpi(param_list[0], "rate") ==
+			    0) /*back-compatiable */) {
+			dp_set_meter_rate(LTQ_CPUFREQ_PS_D3, rate);
+		} else
+			PRINTK
+			    ("Wrong COC state, it should be D1/D2/D3 only\n");
+	} else if (dp_strcmpi(param_list[0], "interrupt") == 0) {	/*meter */
+		enable_meter_interrupt();
+		PRINTK("Enabled meter interurpt\n");
+	} else if (dp_strcmpi(param_list[0], "clear") == 0) {	/*meter */
+		clear_meter_interrupt();
+		PRINTK("Clear meter interurpt src\n");
+	} else
+		goto help;
+
+	return count;
+
+ help:
+	PR_INFO("Datapath COC Proc Usage:\n");
+	PR_INFO("  echo timer polling_interval_in_seconds > /proc/dp/coc\n");
+	PR_INFO("  echo <thresholdx> its_threshold_value > /proc/dp/coc\n");
+	PR_INFO("       Note:Valid x of ranage: 1 2 3\n");
+	PR_INFO
+	    ("            For downscaling to D<x> if rmon < threshold<x>'s setting\n");
+	PR_INFO("            threshold1's >= threshold'2 > threshold'3\n");
+	PR_INFO("  echo <ratex> <meter_rate_in_knps> /proc/dp/coc\n");
+	PR_INFO("       Note:Valid x of ranage: 1 2 3\n");
+	PR_INFO
+	    ("            For upscaling to D0 from D<x> if rmon >= rate<x>'s setting\n");
+	PR_INFO("            Rate1's >= Rate2's > D3's threshold\n");
+	PR_INFO
+	    ("  echo interrupt > /proc/dp/coc  :enable/disable meter interrupt\n");
+	PR_INFO("  echo clear > /proc/dp/coc  :clear meter interrupt\n");
+	return count;
+}
+
+int clear_meter_interrupt(void)
+{
+	union gsw_var tmp;
+
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0x489 + meter_id * 10;
+	tmp.reg.nData = -1;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_SET, (u32) &tmp);
+	return 0;
+}
+
+int enable_meter_interrupt(void)
+{
+	union gsw_var tmp;
+
+	/*#Enable PCE Interupt
+	   switch_cli GSW_REGISTER_SET nRegAddr=0x14 nData=0x2 dev=1
+	 */
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0x14;	/*ETHSW_IER */
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_GET, (u32) &tmp);
+	tmp.reg.nRegAddr |= 1 << 1; /*Enable PCEIE */
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_SET, (u32) &tmp);
+
+	/*#Enable PCE Port Interrupt
+	*  switch_cli GSW_REGISTER_SET nRegAddr=0x465 nData=0x1 dev=1 */
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0x465;	/*PCE_IER_0 */
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_GET, (u32) &tmp);
+	tmp.reg.nRegAddr |= 1 << 0 /*Enable PCE Port 0 */ ;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_SET, (u32) &tmp);
+
+	/*#Enable Meter Interrupt
+	   switch_cli GSW_REGISTER_SET nRegAddr=0x488 nData=0x100 dev=1 */
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0x488;	/*PCE_PIER */
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_GET, (u32) &tmp);
+	tmp.reg.nRegAddr |= 1 << 8
+	    /*Enable Metering Based Backpressure Status Change Interrupt Enable */
+	    ;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_SET, (u32) &tmp);
+
+	return 0;
+}
+
+/*
+*  rate      0: disable meter
+* -1: enable meter
+* others: really change rate.
+*/
+int apply_meter_rate(u32 rate, enum ltq_cpufreq_state new_state)
+{
+	union gsw_var tmp;
+
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.meter_cfg.nMeterId = meter_id;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_METER_CFG_GET, (u32) &tmp);
+	if (rate == 0)		/*only need to disable the meter */
+		tmp.meter_cfg.bEnable = 0;
+	else if (rate == -1) {
+		tmp.meter_cfg.bEnable = 1;
+		/*set PAE metering */
+		if (new_state == LTQ_CPUFREQ_PS_D1)
+			tmp.meter_cfg.nRate = meter_nrate[1];
+		else if (new_state == LTQ_CPUFREQ_PS_D2)
+			tmp.meter_cfg.nRate = meter_nrate[2];
+		else if (new_state == LTQ_CPUFREQ_PS_D3)
+			tmp.meter_cfg.nRate = meter_nrate[3];
+		else {
+			DP_DEBUG(DP_DBG_FLAG_COC,
+				 "Why still try to enable meter with status %s\n",
+				 get_coc_stat_string(dp_coc_ps_curr));
+
+			return -1;
+		}
+	} else {
+		return -1;
+	}
+
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_METER_CFG_SET, (u32) &tmp);
+
+	return 0;
+}
+
+int meter_set_default(void)
+{
+	int i;
+	union gsw_var tmp;
+
+	/*#currently directly change global setting, later should use
+	* GSW_QOS_WRED_PORT_CFG_SET instead
+	* switch_cli dev=1 GSW_REGISTER_SET nRegAddr=0x4a nData=0x518
+	*/
+#if 0
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0x4a;
+	tmp.reg.nData = 0x518;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_SET, (u32) &tmp);
+#else
+	memset(&tmp, 0, sizeof(tmp));
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {	/*copy green setting to yellow/red */
+		tmp.wred_p.nPortId = i;
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_WRED_PORT_CFG_GET,
+			      (u32) &tmp);
+		tmp.wred_p.nYellow_Min = tmp.wred_p.nGreen_Min;
+		tmp.wred_p.nYellow_Max = tmp.wred_p.nGreen_Max;
+		tmp.wred_p.nRed_Min = tmp.wred_p.nGreen_Min;
+		tmp.wred_p.nRed_Max = tmp.wred_p.nGreen_Max;
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_WRED_PORT_CFG_SET,
+			      (u32) &tmp);
+	}
+
+#endif
+
+	/*#Enable Meter 0, configure the rate
+	* switch_cli GSW_QOS_METER_CFG_SET bEnable=1 nMeterId=0 nCbs=0xA000 nEbs=0x9000 nRate=500 dev=1
+	*/
+	memset(&tmp, 0, sizeof(tmp));
+	/*tmp.meter_cfg.bEnable = 1; */
+	tmp.meter_cfg.nMeterId = meter_id;
+	tmp.meter_cfg.nCbs = meter_ncbs;
+	tmp.meter_cfg.nEbs = meter_nebs;
+	tmp.meter_cfg.nRate = meter_nrate[3];
+	tmp.meter_cfg.nPiRate = 0xFFFFFF; /* try to set maximum */
+	tmp.meter_cfg.eMtrType = GSW_QOS_Meter_trTCM;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_METER_CFG_SET, (u32) &tmp);
+
+	/*#Assign Port0 ingress to Meter 0
+	* switch_cli GSW_QOS_METER_PORT_ASSIGN nMeterId=0 eDir=1 nPortIngressId=0 dev=1
+	*/
+	memset(&tmp, 0, sizeof(tmp));
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		tmp.meter_port.nMeterId = meter_id;
+		tmp.meter_port.eDir = 1;
+		tmp.meter_port.nPortIngressId = i;
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_METER_PORT_ASSIGN,
+			      (u32) &tmp);
+	}
+
+	/*#Enable Port 0 Meter Based Flow control (Bit 2 MFCEN)
+	*  switch_cli GSW_REGISTER_SET nRegAddr=0xBC0 nData=0x5107 dev=1
+	*/
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0xBC0;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_GET, (u32) &tmp);
+	tmp.reg.nData |= 1 << 2;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_SET, (u32) &tmp);
+
+	/*#Configure Red and Yellow watermark for each queue (Yellow and Red shall not be 0 in CoC case in order to avoid packet drop)
+	*  i=0
+	*  while [$i -lt 32]
+	*  do
+	*  switch_cli GSW_QOS_WRED_QUEUE_CFG_SET nQueueId=$i nRed_Min=0x40 nRed_Max=0x40 nYellow_Min=0x40 nYellow_Max=0x40 nGreen_Min=0x40 nGreen_Max=0x40 dev=1
+	*  i=$(($i+1))
+	*  done */
+	memset(&tmp, 0, sizeof(tmp));
+
+	for (i = 0; i < 32; i++) {	/*copy green setting to yellow/red */
+		tmp.wred_q.nQueueId = i;
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_WRED_QUEUE_CFG_GET,
+			      (u32) &tmp);
+		tmp.wred_q.nYellow_Min = tmp.wred_q.nGreen_Min;
+		tmp.wred_q.nYellow_Max = tmp.wred_q.nGreen_Max;
+		tmp.wred_q.nRed_Min = tmp.wred_q.nGreen_Min;
+		tmp.wred_q.nRed_Max = tmp.wred_q.nGreen_Max;
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_WRED_QUEUE_CFG_SET,
+			      (u32) &tmp);
+
+	}
+
+	/*
+	*  ##Configure Red and Yellow watermark for each queue (Yellow and Red shall not be 0 in CoC case in order to avoid packet drop)
+	*  switch_cli GSW_QOS_WRED_CFG_SET nRed_Min=255 nRed_Max=255 nYellow_Min=255 nYellow_Max=255  nGreen_Min=255 nGreen_Max=255 dev=1
+	*/
+	memset(&tmp, 0, sizeof(tmp));
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_WRED_CFG_GET, (u32) &tmp);
+	tmp.wred_cfg.nYellow_Min = tmp.wred_cfg.nGreen_Min;
+	tmp.wred_cfg.nYellow_Max = tmp.wred_cfg.nGreen_Max;
+	tmp.wred_cfg.nRed_Min = tmp.wred_cfg.nGreen_Min;
+	tmp.wred_cfg.nRed_Max = tmp.wred_cfg.nGreen_Max;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_QOS_WRED_CFG_SET, (u32) &tmp);
+
+	/*#Configure OVERHEAD */
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.reg.nRegAddr = 0x46C;	/*PCE_OVERHD */
+	tmp.reg.nData = PCE_OVERHD;
+	dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_REGISTER_SET, (u32) &tmp);
+
+	return 0;
+}
+
+/* For Datapth's sub-module to request power state change, esp for
+*  Ethernet/VRX318 driver to call it if there is state change needed.
+*   The flag can be:
+*     DP_COC_REQ_DP
+*     DP_COC_REQ_ETHERNET
+*     DP_COC_REQ_VRX318
+*/
+int dp_coc_new_stat_req(enum ltq_cpufreq_state new_state, uint32_t flag)
+{
+	int ret;
+
+	DP_DEBUG(DP_DBG_FLAG_COC,
+		 "SubModular [%s] requesting to switch from %s to %s\n",
+		 get_sub_module_str(flag),
+		 get_coc_stat_string(dp_coc_ps_curr),
+		 get_coc_stat_string(new_state));
+
+	if (unlikely(in_irq())) {
+		PR_ERR
+		    ("Not allowed to cal dp_coc_new_stat_req in_irq mode\n");
+		return -1;
+	}
+
+	if (!dp_coc_init_stat) {
+		PR_ERR("COC is not initialized yet in DP\n");
+		return -1;
+	}
+
+	if (!dp_coc_ena) {
+		PR_ERR("COC is not enabled in DP yet\n");
+		return -1;
+	}
+
+	coc_lock();
+
+	if (dp_coc_ps_curr == new_state) {
+		/*Workaround: if no change but this API still is called,
+		   it means need to update interrupt enable/disable status */
+		DP_DEBUG(DP_DBG_FLAG_COC, "No change\n");
+		update_coc_cfg(new_state, new_state, flag);
+		coc_unlock();
+		return 0;
+	}
+
+	dp_coc_ps_new = new_state;
+	coc_unlock();
+
+	DP_DEBUG(DP_DBG_FLAG_COC, "ltq_cpufreq_state_req(%d,%d,%d)\n",
+		 DP_MODULE, DP_ID, new_state);
+	ret = ltq_cpufreq_state_req(DP_MODULE, DP_ID, new_state);
+
+	if (ret != LTQ_CPUFREQ_RETURN_SUCCESS) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "Power state request to %d (%s) failed via ltq_cpufreq_state_req ??\n",
+			 new_state, get_coc_stat_string(new_state));
+		DP_DEBUG(DP_DBG_FLAG_COC, "return value: %d ??\n", ret);
+		return -1;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(dp_coc_new_stat_req);
+
+int dp_coc_cpufreq_init(void)
+{
+	struct ltq_cpufreq *dp_coc_cpufreq_p;
+	struct ltq_cpufreq_threshold *th_data;
+
+	pr_debug("enter dp_coc_cpufreq_init\n");
+	spin_lock_init(&dp_coc_lock);
+	dp_coc_init_stat = 0;
+	dp_coc_ena = 0;
+	dp_coc_cpufreq_p = ltq_cpufreq_get();
+
+	if (dp_coc_cpufreq_p == NULL) {
+		PR_ERR
+		    ("dp_coc_cpufreq_init failed:ltq_cpufreq_get failed?\n");
+		return -1;
+	}
+
+	if (cpufreq_register_notifier
+	    (&dp_coc_cpufreq_notifier_block, CPUFREQ_TRANSITION_NOTIFIER)) {
+		PR_ERR
+		    ("dp_coc_cpufreq_init failed:cpufreq_register_notifier failed ?\n");
+		return -1;
+	}
+
+	ltq_cpufreq_mod_list(&dp_coc_feature_fss.list, LTQ_CPUFREQ_LIST_ADD);
+
+	th_data = ltq_cpufreq_get_threshold(DP_MODULE, DP_ID);
+	if (th_data) {		/*copy threshold to local */
+		rmon_threshold.th_d0 = th_data->th_d0;
+		rmon_threshold.th_d1 = th_data->th_d1;
+		rmon_threshold.th_d2 = th_data->th_d2;
+		rmon_threshold.th_d3 = th_data->th_d3;
+	}
+	/*santity check */
+	if (rmon_threshold.th_d2 < rmon_threshold.th_d3)
+		rmon_threshold.th_d2 = rmon_threshold.th_d3 + 100;
+	if (rmon_threshold.th_d1 < rmon_threshold.th_d2)
+		rmon_threshold.th_d1 = rmon_threshold.th_d2 + 100;
+
+	polling_period = ltq_cpufreq_get_poll_period(DP_MODULE, DP_ID);
+
+	if (!polling_period)
+		polling_period = 2;
+
+	meter_set_default();
+	/*Set to D0 Stage from the beginning */
+	dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D0, 0);
+	init_timer_on_stack(&dp_coc_timer);
+	dp_coc_timer.data = 0;
+	dp_coc_timer.function = dp_rmon_polling;
+	dp_coc_init_stat = 1;
+	dp_coc_ena = 1;
+	pr_debug("Register DP to CPUFREQ successfully.\n");
+	return 0;
+}
+
+int dp_coc_cpufreq_exit(void)
+{
+	if (dp_coc_init_stat) {
+		int ret;
+		coc_lock();
+		ret = del_timer(&dp_coc_timer);
+
+		if (ret)
+			pr_err("The timer is still in use...\n");
+
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D0D3, 0);	/*dont care mode */
+
+		if (cpufreq_unregister_notifier
+		    (&dp_coc_cpufreq_notifier_block,
+		     CPUFREQ_TRANSITION_NOTIFIER))
+			PR_ERR("CPUFREQ unregistration failed.");
+
+		ltq_cpufreq_mod_list(&dp_coc_feature_fss.list,
+				     LTQ_CPUFREQ_LIST_DEL);
+		dp_coc_init_stat = 0;
+		dp_coc_ena = 0;
+		coc_unlock();
+	}
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_loopeth_dev.c b/drivers/net/ethernet/lantiq/datapath/datapath_loopeth_dev.c
new file mode 100644
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_loopeth_dev.c
@@ -0,0 +1,1705 @@
+/*
+* ####################################
+*              Head File
+
+cd /proc/dp/loopeth
+
+#create loopeth devices
+echo add > dev
+
+#dynamically register loopeth1 to datapath
+echo register dev   loopeth1 1 DIRECTPATH > directpath
+echo register subif loopeth1 > directpath
+
+#dynamically register loopeth2 to datapath
+echo register dev   loopeth2 2 DIRECTPATH > directpath
+echo register subif loopeth2 > directpath
+
+#dynamically register loopeth3 to datapath
+echo register dev   loopeth3 3 DIRECTPATH > directpath
+echo register subif loopeth3 > directpath
+
+#register loopeth4 to datapath with specified port_id 12
+echo register dev   loopeth4 4 DIRECTPATH 12 > directpath
+echo register subif loopeth4 > directpath
+echo register subif loopeth5 12 > directpath
+
+* ####################################
+*/
+
+/*  Common Head File*/
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/spinlock.h>
+#include <linux/sched.h>
+#include <linux/kthread.h>
+#include <linux/version.h>
+#include <linux/types.h>
+#include <linux/ctype.h>
+#include <linux/fs.h>
+#include <linux/miscdevice.h>
+#include <linux/atmdev.h>
+#include <linux/init.h>
+#include <linux/etherdevice.h>	/*  eth_type_trans  */
+#include <linux/ethtool.h>	/*  ethtool_cmd     */
+#include <linux/if_ether.h>
+#include <linux/skbuff.h>
+#include <linux/inetdevice.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>
+#include <linux/icmp.h>
+#include <net/tcp.h>
+#include <linux/uaccess.h>
+#include <asm/unistd.h>
+#include <asm/irq.h>
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <asm/checksum.h>
+#include <linux/errno.h>
+#ifdef CONFIG_XFRM
+#include <net/xfrm.h>
+#endif
+
+#include <net/datapath_api.h>
+#include <net/datapath_proc_api.h>
+#include "datapath.h"
+
+/*####################################
+*              Definition
+* ####################################
+*/
+
+#define ENABLE_DEBUG                            1
+
+#define ENABLE_ASSERT                           1
+
+#define DEBUG_DUMP_SKB                          1
+
+#if defined(ENABLE_DEBUG) && ENABLE_DEBUG
+#define ENABLE_DEBUG_PRINT                    1
+#define DISABLE_INLINE                        1
+#else
+#define ENABLE_DEBUG_PRINT                    0
+#define DISABLE_INLINE                        0
+#endif
+
+#if !defined(DISABLE_INLINE) || !DISABLE_INLINE
+#define INLINE                                inline
+#else
+#define INLINE
+#endif
+
+#define err(format, arg...)    do {;\
+		PRINTK(KERN_ERR ":%d:%s: " format "\n", \
+		       __LINE__, __FUNCTION__, ##arg); } \
+	while (0)
+
+#if defined(ENABLE_DEBUG_PRINT) && ENABLE_DEBUG_PRINT
+#undef  dbg
+#define dbg(format, arg...) do { if ((g_dbg_enable &\
+					      DBG_ENABLE_MASK_DEBUG_PRINT)) \
+		PRINTK(KERN_WARNING ":%d:%s: " format "\n",\
+		       __LINE__, __FUNCTION__, ##arg); } \
+while (0)
+#else
+#if !defined(dbg)
+#define dbg(format, arg...)
+#endif
+#endif
+
+#if defined(ENABLE_ASSERT) && ENABLE_ASSERT
+#define ASSERT(cond, format, arg...)      do {                \
+		if ((g_dbg_enable & DBG_ENABLE_MASK_ASSERT) && !(cond)) \
+			pr_err(KERN_ERR ":%d:%s: " format "\n",      \
+			       __LINE__, __FUNCTION__, ##arg); } \
+	while (0)
+#else
+#define ASSERT(cond, format, arg...)
+#endif
+
+#if defined(DEBUG_DUMP_SKB) && DEBUG_DUMP_SKB
+#define DUMP_SKB_LEN                          ~0
+#endif
+
+#if (defined(DEBUG_DUMP_SKB) && DEBUG_DUMP_SKB)                     \
+|| (defined(ENABLE_DEBUG_PRINT) && ENABLE_DEBUG_PRINT)          \
+|| (defined(ENABLE_ASSERT) && ENABLE_ASSERT)
+#define ENABLE_DBG_PROC                       1
+#else
+#define ENABLE_DBG_PROC                       0
+#endif
+
+/* Debug Print Mask*/
+#define DBG_ENABLE_MASK_ERR                     0x0001
+#define DBG_ENABLE_MASK_DEBUG_PRINT             0x0002
+#define DBG_ENABLE_MASK_ASSERT                  0x0004
+#define DBG_ENABLE_MASK_DUMP_SKB_RX             0x0008
+#define DBG_ENABLE_MASK_DUMP_SKB_TX             0x0010
+#define DBG_ENABLE_MASK_ALL     (DBG_ENABLE_MASK_ERR | \
+				 DBG_ENABLE_MASK_DEBUG_PRINT |\
+				 DBG_ENABLE_MASK_ASSERT |\
+				 DBG_ENABLE_MASK_DUMP_SKB_RX |\
+				 DBG_ENABLE_MASK_DUMP_SKB_TX)
+
+/* Constant Definition*/
+#define ETH_WATCHDOG_TIMEOUT                    (10 * HZ)
+#define MAX_RX_QUEUE_LENGTH                     100
+#define TASKLET_HANDLE_BUDGET                   25
+
+/* Ethernet Frame Definitions*/
+#define ETH_CRC_LENGTH                          4
+#define ETH_MAX_DATA_LENGTH                     ETH_DATA_LEN
+#define ETH_MIN_TX_PACKET_LENGTH                ETH_ZLEN
+
+/* ####################################
+*              Data Type
+* ####################################
+*/
+
+/* Internal Structure of Devices (ETH/ATM)*/
+#define LOOPETH_F_FREE           0
+#define LOOPETH_F_REGISTER_DEV   1
+#define LOOPETH_F_REGISTER_SUBIF 2
+
+struct loop_eth_priv_data {
+	int id;
+	struct net_device_stats stats;
+	unsigned int rx_preprocess_drop;
+	struct sk_buff_head rx_queue;
+	struct tasklet_struct rx_tasklet;
+	int f_tx_queue_stopped;
+	unsigned char dev_addr[MAX_ADDR_LEN];
+	unsigned int dp_pkts_to_ppe;
+	unsigned int dp_pkts_to_ppe_fail;
+	unsigned int dp_pkts_from_ppe;
+	unsigned int dp_pkts_tx;
+
+	struct module *owner;
+	dp_subif_t dp_subif;
+	int32_t dev_port;	/*dev  instance */
+	int32_t f_dp;		/* status for register to datapath */
+};
+
+static const char *const dbg_enable_mask_str[] = {
+	"err",			/*DBG_ENABLE_MASK_ERR */
+	"dbg",			/*DBG_ENABLE_MASK_DEBUG_PRINT */
+	"assert",		/*DBG_ENABLE_MASK_ASSERT */
+	"rx",			/*DBG_ENABLE_MASK_DUMP_SKB_RX */
+	"tx"			/*DBG_ENABLE_MASK_DUMP_SKB_TX */
+};
+
+/*####################################
+*            Local Variable
+* ####################################
+*/
+
+#define MAX_LOOPETH_NUM ((PMAC_MAX_NUM*MAX_SUBIF_PER_PORT)+2)	/* 16 PMAC and each port support 16 subif */
+static struct net_device *g_loop_eth_dev[MAX_LOOPETH_NUM] = { 0 };
+static uint32_t g_loop_eth_dev_flag[MAX_LOOPETH_NUM] = { 0 };
+
+
+static struct module g_loop_eth_module[MAX_LOOPETH_NUM];
+
+#if defined(ENABLE_DBG_PROC) && ENABLE_DBG_PROC
+static int g_dbg_enable = DBG_ENABLE_MASK_ERR | DBG_ENABLE_MASK_ASSERT;
+#endif
+
+/* Network Operations*/
+static void eth_setup(struct net_device *);
+static struct net_device_stats *eth_get_stats(struct net_device *);
+static int eth_open(struct net_device *);
+static int eth_stop(struct net_device *);
+static int eth_hard_start_xmit(struct sk_buff *, struct net_device *);
+static int eth_ioctl(struct net_device *, struct ifreq *, int);
+static void eth_tx_timeout(struct net_device *);
+
+/* RX path functions*/
+static INLINE int eth_rx_preprocess(struct sk_buff *, int);
+static INLINE void eth_rx_handler(struct sk_buff *, int);
+static void do_loop_eth_rx_tasklet(unsigned long);
+
+/* Datapath directpath functions*/
+static int32_t dp_fp_stop_tx(struct net_device *);
+static int32_t dp_fp_restart_tx(struct net_device *);
+static int32_t dp_fp_rx(struct net_device *, struct net_device *,
+			struct sk_buff *, int32_t);
+
+static const struct net_device_ops loop_netdev_ops = {
+	.ndo_open = eth_open,
+	.ndo_stop = eth_stop,
+	.ndo_start_xmit = eth_hard_start_xmit,
+	.ndo_do_ioctl = eth_ioctl,
+	.ndo_tx_timeout = eth_tx_timeout,
+	.ndo_get_stats = eth_get_stats,
+	.ndo_set_mac_address = eth_mac_addr,
+	.ndo_change_mtu = eth_change_mtu,
+};
+
+/*###################################
+*           Global Variable
+* ####################################
+*/
+
+/*####################################
+*             Declaration
+* ####################################
+*/
+
+/* Wrapper for Different Kernel Version
+*/
+static inline struct net_device *ltq_dev_get_by_name(const char *name)
+{
+	return dev_get_by_name(&init_net, name);
+}
+
+/*find the loopeth index via its device name
+return -1: not found
+>=0: index
+
+*/
+int find_loopeth_index_via_name(char *ifname)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++) {
+		if (g_loop_eth_dev[i]
+		    && dp_strcmpi(ifname, g_loop_eth_dev[i]->name) == 0)
+			return i;
+	}
+
+	return -1;
+}
+
+static inline unsigned long ltq_get_xmit_fn(struct net_device *dev)
+{
+	return (unsigned long)dev->netdev_ops->ndo_start_xmit;
+}
+
+/*####################################
+*            Local Function
+* ####################################
+*/
+
+static void eth_setup(struct net_device *dev)
+{
+	struct loop_eth_priv_data *priv = netdev_priv(dev);
+
+	ether_setup(dev);	/*  assign some members */
+	dev->netdev_ops = &loop_netdev_ops;
+	dev->watchdog_timeo = ETH_WATCHDOG_TIMEOUT;
+	priv->id = -1;
+	priv->dp_subif.port_id = -1;
+	skb_queue_head_init(&priv->rx_queue);
+	return;
+}
+
+struct net_device_stats *eth_get_stats(struct net_device *dev)
+{
+	struct loop_eth_priv_data *priv = netdev_priv(dev);
+	return &priv->stats;
+}
+
+int eth_open(struct net_device *dev)
+{
+	dbg("open %s", dev->name);
+	netif_start_queue(dev);
+	return 0;
+}
+
+int eth_stop(struct net_device *dev)
+{
+	netif_stop_queue(dev);
+	return 0;
+}
+
+int eth_hard_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	unsigned long sysflag;
+	struct loop_eth_priv_data *priv = netdev_priv(dev);
+	int rx_queue_len;
+	struct sk_buff *old_skb = skb;
+
+	if (!skb)
+		return 0;
+	if (g_dbg_enable & DBG_ENABLE_MASK_DEBUG_PRINT)
+		dp_dump_raw_data(skb->data, skb->len,
+				 "loopeth_xmit original data");
+	if (skb_cloned(old_skb) && !skb_is_gso(old_skb)) {
+		/*sanity check before creating a new skb */
+		if (skb_shinfo(old_skb)->frag_list) {
+			pr_err(" Not support frag_list here !!\n");
+			dev_kfree_skb_any(old_skb);
+			return 0;
+		}
+		if (old_skb->data_len) {
+			pr_err(" Not support nr_frags here since data_len not zero!!\n");
+			dev_kfree_skb_any(old_skb);
+			return 0;
+		}
+		skb = alloc_skb(old_skb->len, GFP_KERNEL);
+		if (!skb) {
+			dev_kfree_skb_any(old_skb);
+			return 0;
+		}
+		memcpy(skb->data, old_skb->data, old_skb->len);
+		skb_put(skb, old_skb->len);
+		dev_kfree_skb_any(old_skb);
+		if (g_dbg_enable & DBG_ENABLE_MASK_DEBUG_PRINT)
+			dp_dump_raw_data(skb->data, skb->len,
+				 "loopeth_xmit original data after creating skb");
+	}
+
+	ASSERT((skb->prev == NULL &&
+		skb->next == NULL),
+	       "skb on list: prev = 0x%08x, next = 0x%08x",
+	       (unsigned int)skb->prev, (unsigned int)skb->next);
+
+	if (g_dbg_enable & DBG_ENABLE_MASK_DEBUG_PRINT)
+		dp_dump_raw_data(skb->data, skb->len,
+				 "loopeth_xmit for spoofing check:");
+
+	skb->dev = g_loop_eth_dev[priv->id];
+	spin_lock_irqsave(&priv->rx_queue.lock, sysflag);
+	rx_queue_len = skb_queue_len(&priv->rx_queue);
+
+	if (rx_queue_len < MAX_RX_QUEUE_LENGTH) {
+		__skb_queue_tail(&priv->rx_queue, skb);
+
+		if (rx_queue_len == 0)
+			tasklet_schedule(&priv->rx_tasklet);
+
+		if (skb_queue_len(&priv->rx_queue) >= MAX_RX_QUEUE_LENGTH)
+			netif_stop_queue(g_loop_eth_dev[priv->id]);
+
+		priv->stats.tx_packets++;
+		priv->stats.tx_bytes += skb->len;
+	} else {
+		dbg("drop packet for long queue\n");
+		dev_kfree_skb_any(skb);
+		priv->stats.tx_dropped++;
+	}
+
+	spin_unlock_irqrestore(&priv->rx_queue.lock, sysflag);
+	return 0;
+}
+
+int eth_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+	switch (cmd) {
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+void eth_tx_timeout(struct net_device *dev)
+{
+	/*TODO:must restart the TX channels */
+	struct loop_eth_priv_data *priv = netdev_priv(dev);
+	priv->stats.tx_errors++;
+	netif_wake_queue(dev);
+	return;
+}
+
+/* Ethernet frame types according to RFC 2516 */
+#define ETH_PPPOE_DISCOVERY 0x8863
+#define ETH_PPPOE_SESSION   0x8864
+
+/* A PPPoE Packet, including Ethernet headers */
+struct pppoe_pkt {
+#ifdef PACK_BITFIELDS_REVERSED
+	unsigned int type:4;	/* PPPoE Type (must be 1) */
+	unsigned int ver:4;	/* PPPoE Version (must be 1) */
+#else
+	unsigned int ver:4;	/* PPPoE Version (must be 1) */
+	unsigned int type:4;	/* PPPoE Type (must be 1) */
+#endif
+	unsigned int code:8;	/* PPPoE code */
+	unsigned int session:16;	/* PPPoE session */
+	unsigned int length:16;	/* Payload length */
+	unsigned char payload[ETH_DATA_LEN];	/* A bit of room to spare, here just for space holder only */
+};
+
+/* PPPoE Tag */
+
+unsigned char ppp_ipv4_proto[2] = {
+	0x00, 0x21
+};
+
+unsigned char ppp_ipv6_proto[2] = {
+	0x00, 0x57
+};
+
+#define VLAN_HEAD_SIZE  4
+#define PPPOE_HEAD_SIZE  8
+
+/*return 1: send to directpath API dp_xmit to pae
+* return 0: Should be dropped for not know how to spoof
+*/
+static INLINE int eth_rx_preprocess(struct sk_buff *skb, int id)
+{
+	unsigned char *p;
+	unsigned char mac[6];
+	unsigned char ip[4];
+	unsigned char port[2];
+	unsigned char ip_templ[4] = { 0 };
+	struct iphdr *iph;
+	struct icmphdr *icmph;
+	struct tcphdr *tcph;
+	uint32_t t, off_t, *opt;
+	int csum;
+	struct pppoe_pkt *pppoe;
+	int offset = 0;
+	int vlan_num = 0;
+	unsigned char *p_new_src_mac;
+	struct in_device __rcu *in_dev = NULL;
+	struct in_ifaddr *if_info = NULL;
+	__u8 *addr;
+	if (!skb)
+		return 0;
+	p = skb->data;
+
+	if (skb->data[6] & 0x1) {
+		/*source mac is broadcast or multicast. no spoof */
+		return 0;
+	}
+
+	if (g_dbg_enable & DBG_ENABLE_MASK_DEBUG_PRINT)
+		dp_dump_raw_data(skb->data, 20,
+				 "eth_rx_preprocess original skb:");
+
+	read_lock_bh(&dev_base_lock);
+	in_dev = (struct in_device *)skb->dev->ip_ptr;
+
+	if (!in_dev)
+		dbg("ip_ptr NULL. No IP\n");
+	else
+		if_info = in_dev->ifa_list;
+
+	if (if_info) {
+		memcpy(ip_templ, (char *)&if_info->ifa_address, 4);
+		addr = (char *)&if_info->ifa_local;
+
+		dbg("Device %s ifa_local: %u.%u.%u.%u\n", skb->dev->name,
+		    (__u32) addr[0], (__u32) addr[1], (__u32) addr[2],
+		    (__u32) addr[3]);
+
+		addr = (char *)&if_info->ifa_address;
+		dbg("Device %s ifa_address: %u.%u.%u.%u\n", skb->dev->name,
+		    (__u32) addr[0], (__u32) addr[1], (__u32) addr[2],
+		    (__u32) addr[3]);
+
+		addr = (char *)&if_info->ifa_mask;
+		dbg("Device %s ifa_mask: %u.%u.%u.%u\n", skb->dev->name,
+		    (__u32) addr[0], (__u32) addr[1], (__u32) addr[2],
+		    (__u32) addr[3]);
+
+		addr = (char *)&if_info->ifa_broadcast;
+		dbg("Device %s ifa_broadcast: %u.%u.%u.%u\n", skb->dev->name,
+		    (__u32) addr[0], (__u32) addr[1], (__u32) addr[2],
+		    (__u32) addr[3]);
+	}
+
+	read_unlock_bh(&dev_base_lock);
+
+	if (p[offset + 12] == 0x81 && p[offset + 13] == 0x00) {	/*VLAN header */
+		offset += VLAN_HEAD_SIZE;
+		vlan_num++;
+		dbg("Found VLAN%d\n", vlan_num);
+	}
+
+	if (p[offset + 12] == 0x88 && p[offset + 13] == 0x63) {
+		/*pppoe Discover(0x9)/Offer(0x7)/request(0x19)/Confirm(0x65) */
+		return 0;
+	}
+
+	if (p[offset + 12] == 0x88 && p[offset + 13] == 0x64) {	/*ppp */
+		pppoe = (struct pppoe_pkt *) (p + offset + 14);
+
+		if ((pppoe->payload[0] == ppp_ipv4_proto[0]
+		     && pppoe->payload[1] == ppp_ipv4_proto[1]) /*PPP IPv4 */ ||
+		    ((pppoe->payload[0] == ppp_ipv6_proto[0])
+		     && (pppoe->payload[1] ==
+			 ppp_ipv6_proto[1])) /*  PPP IPv6 */) {
+			offset += PPPOE_HEAD_SIZE;	/* skip 8 bytes ppp header */
+			dbg("Found PPP IP packet\n");
+		} else
+			return 0;
+	}
+
+	/*swap dst/src mac address */
+	memcpy(mac, p, 6);
+	memcpy(p, p + 6, 6);
+	memcpy(p + 6, mac, 6);
+	p_new_src_mac = p + 6;
+	p += offset;		/*Note, now p[12~13] points to protocol */
+
+	if (p[12] == 0x08 && p[13] == 0x06) {
+		/* arp request */
+		if (p[14] == 0x00 && p[15] == 0x01 && p[16] == 0x08 &&
+		    p[17] == 0x00 && p[20] == 0x00 && p[21] == 0x01) {
+			/*fill in spoof mac address */
+			p_new_src_mac[0] = 0;
+			p_new_src_mac[1] = 1;
+			p_new_src_mac[2] = id;
+			p_new_src_mac[3] = id;
+			p_new_src_mac[4] = id;
+			p_new_src_mac[5] = id;
+
+			if ((p[38] == ip_templ[0] && p[39] == ip_templ[1])
+			    || (*(u32 *) ip_templ == 0)) {
+				dbg("Spoof arp request:%d.%d.%d.%d mac:%02x:%02x:%02x:%02x:%02x:%02x\n", p[38], p[39], p[40], p[41], p_new_src_mac[0], p_new_src_mac[1], p_new_src_mac[2], p_new_src_mac[3], p_new_src_mac[4], p_new_src_mac[5]);
+
+				/*  arp reply */
+				p[21] = 0x02;
+				/*  sender mac */
+				memcpy(mac, p + 22, 6);	/*save orignal sender mac */
+				memcpy(p + 22, p_new_src_mac, 6);	/*set new sender mac */
+
+				if (memcmp(p + 28, p + 38, 4) == 0) {
+					dbg("Not reply arp request for:%d.%d.%d.%d\n", p[38], p[39], p[40], p[41]);
+					return 1;
+				}
+
+				/* sender IP */
+				memcpy(ip, p + 28, 4);	/*save original sender ip address */
+				memcpy(p + 28, p + 38, 4);	/*set new sender ip address */
+				/* target mac */
+				memcpy(p + 32, mac, 6);
+				/* target IP */
+				memcpy(p + 38, ip, 4);
+
+				if (g_dbg_enable &
+				    DBG_ENABLE_MASK_DEBUG_PRINT)
+					dp_dump_raw_data(skb->data, 20,
+							 "skb data after arp spoof");
+
+				return 1;
+			} else
+				dbg("Not reply arp request for:%d.%d.%d.%d\n",
+				    p[38], p[39], p[40], p[41]);
+
+			return 1;
+		}
+
+		return 0;
+	} else if (((p[12] == 0x08) && (p[13] == 0x00)) /*Normal IPV4 */ ||
+		   ((p[12] == ppp_ipv4_proto[0]) &&
+		    (p[13] == ppp_ipv4_proto[1])) /*PPP IPV4 */ ||
+		   ((p[12] == ppp_ipv6_proto[0]
+		     && p[13] == ppp_ipv6_proto[1])) /*PPP IPV6 */) {
+		/* IP */
+		switch ((int)p[23]) {
+		case 0x01:
+
+			/* ICMP - request */
+			if (p[34] == 0x08) {
+				/* src IP */
+				memcpy(ip, p + 26, 4);
+				memcpy(p + 26, p + 30, 4);
+				/* dest IP */
+				memcpy(p + 30, ip, 4);
+				/* ICMP reply */
+				p[34] = 0x00;
+				/* IP checksum */
+				iph = (struct iphdr *)(p + 14);
+				iph->check = 0;
+				iph->check =
+				    ip_fast_csum((unsigned char *)iph,
+						 iph->ihl);
+				/* ICMP checksum */
+				icmph = (struct icmphdr *)(p + 34);
+				icmph->checksum = 0;
+				csum = csum_partial((unsigned char *)
+						    icmph, skb->len - 34, 0);
+				icmph->checksum = csum_fold(csum);
+				dbg("spoof ping\n");
+				return 1;
+			}
+
+			break;
+
+		case 0x11:
+
+			/* UDP */
+		case 0x06:
+			/* TCP */
+			/*swap src/dst ip */
+			/* src IP */
+			dbg("spoof udp/tcp\n");
+			memcpy(ip, p + 26, 4);
+			memcpy(p + 26, p + 30, 4);
+			/* dest IP */
+			memcpy(p + 30, ip, 4);
+			/*shaoguoh remove below checksum item since we
+			   just swap ip and port only
+			 */
+#if 0
+			/* IP checksum */
+			iph = (struct iphdr *)(p + 14);
+			iph->check = 0;
+			iph->check =
+			    ip_fast_csum((unsigned char *)iph, iph->ihl);
+			/* no UDP checksum */
+			p[40] = p[41] = 0x00;
+#endif
+			/*shaoguoh add below to swap src/dst port 34~35 36~37 */
+			/*save src port to port array and copy original dest
+			   port to new src port
+			 */
+			memcpy(port, p + 34, 2);
+			memcpy(p + 34, p + 36, 2);
+			/* copy original src port to dest port */
+			memcpy(p + 36, port, 2);
+
+			/*return if UDP */
+			if ((int)p[23] == 0x11)
+				return 1;
+
+			iph = (struct iphdr *)(p + 14);
+			tcph = (struct tcphdr *)(p + 34);
+
+			if (tcph->syn == 1) {	/*set syn & ack, set seq NO same as the incoming syn TCP packet, set ack seq NO as seq NO + 1 */
+				tcph->ack = 1;
+				tcph->ack_seq = tcph->seq + 1;
+			} else if (tcph->fin == 1) {	/*set fin & ack */
+				tcph->ack = 1;
+				t = tcph->ack_seq;
+				tcph->ack_seq = tcph->seq + 1;
+				tcph->seq = t;
+			} else if (tcph->rst == 1 || (tcph->psh == 0 && tcph->ack == 1))	/*rest or only ack, we ignore it. */
+				return 0;
+			else if (tcph->psh == 1) {
+				t = tcph->ack_seq;
+
+				if (iph->tot_len < 40)	/*corrupt packet, ignore it. */
+					return -1;
+
+				tcph->ack_seq =
+				    tcph->seq + iph->tot_len -
+				    (iph->ihl * 4) - (tcph->doff * 4);
+				tcph->seq = t;
+			}
+
+			/*check timestamp */
+			off_t = 14 + 20 + 20;	/*mac + ip + tcp */
+
+			while ((tcph->doff << 2) > (off_t - 34)) {	/*tcp option compare tcp header length */
+
+				switch (p[off_t]) {
+				case 0x0:	/*Option End */
+					break;
+
+				case 0x1:	/* NO Operation */
+					off_t += 1;
+					continue;
+
+				case 0x2:	/*Max Segment Size */
+					off_t += 4;
+					continue;
+
+				case 0x3:	/* Window Scale */
+					off_t += 3;
+					continue;
+
+				case 0x4:	/*TCP Sack permitted */
+					off_t += 2;
+					continue;
+
+				case 0x8:	/*TCP timestamp */
+#if 1
+					opt = (uint32_t *) (p + off_t + 2);
+					*(opt + 1) = htons(tcp_time_stamp);
+					t = *opt;
+					*opt = *(opt + 1);
+					*(opt + 1) = t;
+
+#else
+
+					for (t = 0; t < 10; t++)
+						*(p + off_t + t) = 1;
+
+#endif
+					off_t += 10;	/*option max is 64-20 */
+					continue;
+
+				default:
+					off_t += 64;
+					break;
+				}
+			}
+
+			/* IP checksum */
+			iph = (struct iphdr *)(p + 14);
+			iph->check = 0;
+			iph->check =
+			    ip_fast_csum((unsigned char *)iph, iph->ihl);
+			/* TCP checksum */
+			tcph->check = 0;
+			t = iph->tot_len - (iph->ihl * 4);
+			/*tcph->check = csum_partial((unsigned char *)tcph, iph->tot_len - 20, 0); */
+			tcph->check =
+			    csum_tcpudp_magic(iph->saddr, iph->daddr, t,
+					      IPPROTO_TCP, csum_partial(tcph,
+									t,
+									0));
+			return 1;
+
+		default:
+			break;
+		}
+
+	}
+
+	dbg("Don't know how to spoof. Should be dropped\n");
+	return 0;
+}
+
+static INLINE void eth_rx_handler(struct sk_buff *skb, int id)
+{
+	struct loop_eth_priv_data *priv = netdev_priv(g_loop_eth_dev[id]);
+	int pktlen;
+	int flag = 0;
+
+	pktlen = 0;
+
+	if (!netif_running(g_loop_eth_dev[id])) {
+		dev_kfree_skb_any(skb);
+		priv->stats.rx_dropped++;
+		return;
+	}
+
+	if (priv->dp_subif.port_id > 0) {
+		dbg("to dp_xmit: %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n", skb->data[0], skb->data[1], skb->data[2], skb->data[3], skb->data[4], skb->data[5], skb->data[6], skb->data[7], skb->data[8], skb->data[9], skb->data[10], skb->data[11], skb->data[12], skb->data[13]);
+
+		((struct dma_tx_desc_1 *)&(skb->DW1))->field.ep =
+		    priv->dp_subif.port_id;
+		((struct dma_tx_desc_0 *)&(skb->DW0))->field.dest_sub_if_id =
+		    priv->dp_subif.subif;
+		if (g_loop_eth_dev_flag[id] & DP_F_FAST_DSL)
+			flag = DP_TX_DSL_FCS;
+		if (dp_xmit
+		    (g_loop_eth_dev[id], &priv->dp_subif, skb, skb->len,
+		     flag) == DP_SUCCESS) {
+			priv->dp_pkts_to_ppe++;
+			return;
+		} else {
+			priv->dp_pkts_to_ppe_fail++;
+			return;
+		}
+	}
+#if 0
+	pktlen = skb->len;
+	skb->dev = g_loop_eth_dev[id];
+	skb->protocol = eth_type_trans(skb, g_loop_eth_dev[id]);
+
+	if (netif_rx(skb) == NET_RX_DROP)
+		priv->stats.rx_dropped++;
+	else {
+		priv->stats.rx_packets++;
+		priv->stats.rx_bytes += pktlen;
+	}
+
+#else
+	dbg("Drop packet since loopeth not registered yet to dp\n");
+	dev_kfree_skb_any(skb);
+	priv->stats.rx_packets++;
+	priv->stats.rx_bytes += pktlen;
+	return;
+#endif
+}
+
+static void do_loop_eth_rx_tasklet(unsigned long id)
+{
+	struct loop_eth_priv_data *priv = netdev_priv(g_loop_eth_dev[id]);
+	struct sk_buff *skb;
+	int i = 0;
+
+	if ((id >= ARRAY_SIZE(g_loop_eth_dev))) {
+		PR_ERR("Wrong id(%ld) in do_loop_eth_rx_tasklet\n", id);
+		return;
+	}
+
+	while (1) {
+		if (i >= TASKLET_HANDLE_BUDGET) {
+			tasklet_schedule(&priv->rx_tasklet);
+			break;
+		}
+
+		skb = skb_dequeue(&priv->rx_queue);
+
+		if (!skb)
+			break;
+
+		netif_wake_queue(g_loop_eth_dev[id]);
+		dbg("dequeue one skb\n");
+
+		if (eth_rx_preprocess(skb, (int)id))
+			eth_rx_handler(skb, (int)id);
+		else {
+			priv->rx_preprocess_drop++;
+			dev_kfree_skb_any(skb);
+			dbg("Drop for eth_rx_preprocess failed\n");
+		}
+
+		i++;
+	}
+}
+
+static int32_t dp_fp_stop_tx(struct net_device *netif)
+{
+	return 0;
+}
+
+static int32_t dp_fp_restart_tx(struct net_device *netif)
+{
+	return 0;
+}
+
+static int32_t dp_fp_rx(struct net_device *rxif, struct net_device *txif,
+			struct sk_buff *skb, int32_t len)
+{
+	struct loop_eth_priv_data *priv;
+	int pktlen;
+
+	skb_pull(skb, 8);	/*remove pmac header*/
+
+	if (g_dbg_enable & DBG_ENABLE_MASK_DEBUG_PRINT)
+		dp_dump_raw_data(skb->data, 20, "dp_fp_rx raw data");
+
+	if (rxif) {
+		dbg("dp_fp_rx to stack via %s\n", rxif->name);
+
+		if (netif_running(rxif)) {
+			priv = netdev_priv(rxif);
+			pktlen = skb->len;
+			skb->dev = rxif;
+			skb->protocol = eth_type_trans(skb, rxif);
+
+			if (netif_rx(skb) == NET_RX_DROP)
+				priv->stats.rx_dropped++;
+			else {
+				priv->stats.rx_packets++;
+				priv->stats.rx_bytes += pktlen;
+			}
+
+			priv->dp_pkts_from_ppe++;
+			return 0;
+		}
+	} else if (txif) {
+		dbg("dp_fp_rx to loopeth_xmit via %s for specified ep\n",
+		    rxif->name);
+		priv = netdev_priv(txif);
+		skb->dev = txif;
+		dev_queue_xmit(skb);
+		priv->dp_pkts_tx++;
+		return 0;
+	}
+
+	dev_kfree_skb_any(skb);
+	return 0;
+}
+
+#if defined(ENABLE_DBG_PROC) && ENABLE_DBG_PROC
+static void proc_read_dbg(struct seq_file *s)
+{
+	int i;
+
+	SEQ_PRINTF(s, "g_dbg_enable=0x%08x\n. \tEnabled Flags:",
+		   g_dbg_enable);
+
+	for (i = 0; i < ARRAY_SIZE(dbg_enable_mask_str); i++)
+		if ((g_dbg_enable & (1 << i)))
+			SEQ_PRINTF(s, "%s ", dbg_enable_mask_str[i]);
+
+	SEQ_PRINTF(s, "\n");
+}
+
+static int proc_write_dbg(struct file *file, const char *buf, size_t count,
+			  loff_t *ppos)
+{
+	char str[100];
+	int len, rlen;
+	int f_enable = 0;
+	int i, j;
+	int num;
+	char *param_list[30];
+
+	len = count < sizeof(str) ? count : sizeof(str) - 1;
+	rlen = len - copy_from_user(str, buf, len);
+	str[rlen] = 0;
+
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 1)
+		goto help;
+
+	if (dp_strcmpi(param_list[0], "enable") == 0)
+		f_enable = 1;
+	else if (dp_strcmpi(param_list[0], "disable") == 0)
+		f_enable = -1;
+	else
+		goto help;
+
+	if (!param_list[1])
+		set_ltq_dbg_flag(g_dbg_enable, f_enable, -1);
+	else {
+		for (i = 1; i < num; i++) {
+			for (j = 0; j < ARRAY_SIZE(dbg_enable_mask_str); j++) {
+				if (dp_strcmpi
+				    (param_list[i],
+				     dbg_enable_mask_str[j]) == 0) {
+					set_ltq_dbg_flag(g_dbg_enable,
+							 f_enable, (1 << j));
+
+					break;
+				}
+			}
+		}
+	}
+
+	return count;
+ help:
+	PR_INFO("echo <enable/disable> [");
+
+	for (i = 0; i < ARRAY_SIZE(dbg_enable_mask_str); i++) {
+		if (i == 0)
+			PR_INFO("%s", dbg_enable_mask_str[i]);
+		else
+			PR_INFO("/%s", dbg_enable_mask_str[i]);
+	}
+
+	PR_INFO("] > /proc/loopeth/dbg\n");
+	return count;
+}
+#endif
+
+static int proc_read_dev(struct seq_file *s, int pos)
+{
+	if (g_loop_eth_dev[pos])
+		SEQ_PRINTF(s, "  %s\n", g_loop_eth_dev[pos]->name);
+
+	pos++;
+
+	if (pos >= MAX_LOOPETH_NUM)
+		pos = -1;
+
+	return pos;
+}
+
+static int unregister_dev(int i)
+{
+	struct loop_eth_priv_data *priv;
+	struct pmac_port_info *port_info;
+	int res;
+
+	if (!g_loop_eth_dev[i])
+		return -1;
+
+	priv = netdev_priv(g_loop_eth_dev[i]);
+
+	if (priv->dp_subif.port_id == 0)
+		return 0;
+
+	if (priv->f_dp == LOOPETH_F_REGISTER_SUBIF) {
+		res =
+		    dp_register_subif(priv->owner, g_loop_eth_dev[i],
+				      g_loop_eth_dev[i]->name,
+				      &priv->dp_subif, DP_F_DEREGISTER);
+
+		if (res != DP_SUCCESS)
+			PR_ERR
+			    ("dp_register_subif failed for port %d subif %d\n",
+			     priv->dp_subif.port_id, priv->dp_subif.subif);
+
+		priv->f_dp = LOOPETH_F_REGISTER_DEV;
+		priv->dp_subif.subif = -1;
+	}
+
+	port_info = get_port_info_via_dp_port(priv->dp_subif.port_id);
+
+	if (!port_info) {
+		PR_ERR
+		    ("get_port_info_via_dp_port failed for %s with specified port %d subif=%d\n",
+		     g_loop_eth_dev[i]->name, priv->dp_subif.port_id,
+		     priv->dp_subif.subif);
+		return -1;
+	}
+
+	if (port_info->num_subif == 0) {
+		if (priv->f_dp == LOOPETH_F_REGISTER_DEV) {
+			if (dp_register_dev
+			    (priv->owner, priv->dp_subif.port_id, NULL,
+			     DP_F_DEREGISTER) != DP_SUCCESS)
+				PR_ERR("dp_unregister_dev failed \
+					for %s with port_id/subif %d/%d\n", g_loop_eth_dev[i]->name, priv->dp_subif.port_id, priv->dp_subif.subif);
+
+			if (dp_alloc_port
+			    (priv->owner, g_loop_eth_dev[i], i,
+			     priv->dp_subif.port_id, NULL,
+			     DP_F_DEREGISTER) != DP_SUCCESS) {
+				PR_ERR("dp_dealloc_port failed \
+					for %s with port_id/subif %d/%d\n", g_loop_eth_dev[i]->name, priv->dp_subif.port_id, priv->dp_subif.subif);
+			}
+
+			priv->dp_subif.port_id = -1;
+		}
+
+		priv->f_dp = LOOPETH_F_FREE;
+	}
+
+	return 0;
+}
+
+static int delete_loopeth_dev(int i)
+{
+	struct loop_eth_priv_data *priv;
+
+	if (!g_loop_eth_dev[i])
+		return -1;
+
+	priv = netdev_priv(g_loop_eth_dev[i]);
+
+	unregister_dev(i);
+
+	/*unregister loopeth dev itself */
+	unregister_netdev(g_loop_eth_dev[i]);
+	free_netdev(g_loop_eth_dev[i]);
+	g_loop_eth_dev[i] = NULL;
+	return 0;
+}
+
+int create_loopeth_dev(int i)
+{
+	char ifname[IFNAMSIZ];
+	struct loop_eth_priv_data *priv;
+
+	if (g_loop_eth_dev[i]) {
+		PR_ERR("g_loop_eth_dev[%d] already exist\n", i);
+		return 0;
+	}
+
+	snprintf(ifname, sizeof(ifname), "loopeth%d", i);
+
+	g_loop_eth_dev[i] =
+	    alloc_netdev(sizeof(struct loop_eth_priv_data), ifname,
+			 eth_setup);
+
+	if (g_loop_eth_dev[i] == NULL) {
+		PR_ERR("alloc_netdev fail\n");
+		return -1;
+	}
+
+	g_loop_eth_dev[i]->dev_addr[0] = 0x00;
+	g_loop_eth_dev[i]->dev_addr[1] = 0x00;
+	g_loop_eth_dev[i]->dev_addr[2] = 0x00;
+	g_loop_eth_dev[i]->dev_addr[3] = 0x00;
+	g_loop_eth_dev[i]->dev_addr[4] = 0x00;
+	g_loop_eth_dev[i]->dev_addr[5] = i;
+	priv = netdev_priv(g_loop_eth_dev[i]);
+	priv->id = i;
+	tasklet_init(&priv->rx_tasklet, do_loop_eth_rx_tasklet, i);
+
+	if (register_netdev(g_loop_eth_dev[i])) {
+		free_netdev(g_loop_eth_dev[i]);
+		g_loop_eth_dev[i] = NULL;
+		PR_INFO("register device \"%s\" fail ??\n", ifname);
+	} else {
+		PR_INFO("add \"%s\" successfully\n", ifname);
+		priv = netdev_priv(g_loop_eth_dev[i]);
+		priv->f_dp = LOOPETH_F_FREE;
+	}
+
+	return 0;
+}
+
+static int proc_write_dev(struct file *file, const char *buf, size_t count,
+			  loff_t *ppos)
+{
+	char str[100];
+	int len, rlen;
+	char *param_list[10];
+	int num;
+	int i;
+
+	len = count < sizeof(str) ? count : sizeof(str) - 1;
+	rlen = len - copy_from_user(str, buf, len);
+	str[rlen] = 0;
+
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 1)
+		goto help;
+
+	if (dp_strcmpi(param_list[0], "add") == 0) {
+		if (param_list[1]) {
+			i = dp_atoi(param_list[1]);
+
+			if ((i < 0) || (i >= ARRAY_SIZE(g_loop_eth_dev))) {
+				PR_ERR("Wrong index value: %d\n", i);
+				return count;
+			}
+
+			if (g_loop_eth_dev[i]) {
+				PR_ERR
+				    ("interface index %d already exist and no need to create it\n",
+				     i);
+				return count;
+			}
+
+			/*create one dev */
+			create_loopeth_dev(i);
+		} else
+			for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++) {
+				/*create all dev if not created yet */
+				if (g_loop_eth_dev[i])
+					continue;
+
+				create_loopeth_dev(i);
+			}
+	} else if (dp_strcmpi(param_list[0], "del") == 0) {
+		if (param_list[1]) {
+			for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++) {
+				if (g_loop_eth_dev[i] &&
+				    (dp_strcmpi
+				     (g_loop_eth_dev[i]->name,
+				      param_list[1]) == 0)) {
+					delete_loopeth_dev(i);
+					break;
+				}
+			}
+		} else {
+			for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++)
+				delete_loopeth_dev(i);
+		}
+	} else {
+		PR_ERR("Wrong command: %s\n", param_list[0]);
+		goto help;
+	}
+
+	return count;
+
+ help:
+	PR_INFO("echo add [index] /proc/dp/loop/dev\n");
+	PR_INFO("   example: echo add 1 > /proc/dp/loop/dev\n");
+	PR_INFO("   example: echo add    > /proc/dp/loop/dev\n");
+	PR_INFO("        Note, the maximum index is %d\n",
+		ARRAY_SIZE(g_loop_eth_dev));
+	PR_INFO("echo <del> [device name] > /proc/dp/loop/dev\n");
+	PR_INFO("   example: echo del loopeth1 > /proc/dp/loop/dev\n");
+	PR_INFO("   example: echo del          > /proc/dp/loop/dev\n");
+
+	return count;
+}
+
+static int proc_read_mib(struct seq_file *s, int pos)
+{
+	struct loop_eth_priv_data *priv;
+
+	if (g_loop_eth_dev[pos]) {
+		priv = netdev_priv(g_loop_eth_dev[pos]);
+		SEQ_PRINTF(s, "  %s:\n", g_loop_eth_dev[pos]->name);
+		SEQ_PRINTF(s, "    rx_packets: %lu\n",
+			   priv->stats.rx_packets);
+		SEQ_PRINTF(s, "    rx_bytes:   %lu\n", priv->stats.rx_bytes);
+		SEQ_PRINTF(s, "    rx_errors:  %lu\n", priv->stats.rx_errors);
+		SEQ_PRINTF(s, "    rx_dropped: %lu\n",
+			   priv->stats.rx_dropped);
+		SEQ_PRINTF(s, "    tx_packets: %lu\n",
+			   priv->stats.tx_packets);
+		SEQ_PRINTF(s, "    tx_bytes:   %lu\n", priv->stats.tx_bytes);
+		SEQ_PRINTF(s, "    tx_errors:  %lu\n", priv->stats.tx_errors);
+		SEQ_PRINTF(s, "    tx_dropped: %lu\n",
+			   priv->stats.tx_dropped);
+		SEQ_PRINTF(s, "    rx_preprocess_drop:  %u\n",
+			   priv->rx_preprocess_drop);
+		SEQ_PRINTF(s, "    dp_pkts_to_ppe:      %u\n",
+			   priv->dp_pkts_to_ppe);
+		SEQ_PRINTF(s, "    dp_pkts_to_ppe_fail: %u\n",
+			   priv->dp_pkts_to_ppe_fail);
+		SEQ_PRINTF(s, "    dp_pkts_from_ppe:    %u\n",
+			   priv->dp_pkts_from_ppe);
+		SEQ_PRINTF(s, "    dp_pkts_tx:          %u\n",
+			   priv->dp_pkts_tx);
+	}
+
+	pos++;
+
+	if (pos >= MAX_LOOPETH_NUM)
+		pos = -1;
+
+	return pos;
+}
+
+void clear_mib(int i)
+{
+	struct loop_eth_priv_data *priv;
+
+	priv = netdev_priv(g_loop_eth_dev[i]);
+	memset(&priv->stats, 0, sizeof(priv->stats));
+	priv->rx_preprocess_drop = 0;
+	priv->dp_pkts_to_ppe = 0;
+	priv->dp_pkts_to_ppe_fail = 0;
+	priv->dp_pkts_from_ppe = 0;
+	priv->dp_pkts_tx = 0;
+}
+
+static int proc_write_mib(struct file *file, const char *buf, size_t count,
+			  loff_t *ppos)
+{
+	char str[100];
+	int len, rlen;
+	int i;
+	int num;
+	char *param_list[4];
+
+	len = count < sizeof(str) ? count : sizeof(str) - 1;
+	rlen = len - copy_from_user(str, buf, len);
+	str[rlen] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 2)
+		goto help;
+
+	if (dp_strcmpi(param_list[0], "clear") != 0) {
+		PR_ERR("Wrong command:%s\n", param_list[0]);
+		goto help;
+	}
+
+	if ((dp_strcmpi(param_list[1], "all") != 0)) {
+		for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++) {
+			if (g_loop_eth_dev[i] &&
+			    (dp_strcmpi
+			     (g_loop_eth_dev[i]->name, param_list[1]) == 0)) {
+				clear_mib(i);
+				break;
+			}
+		}
+
+		if (i >= ARRAY_SIZE(g_loop_eth_dev))
+			PR_ERR("not found device %s\n", param_list[1]);
+	} else {
+		for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++)
+			clear_mib(i);
+	}
+
+	return count;
+ help:
+	PR_INFO("echo <clear> [all/device name] > /proc/loopeth/mib\n");
+	return count;
+}
+
+static int proc_read_dp(struct seq_file *s, int pos)
+{
+	struct loop_eth_priv_data *priv;
+
+	if (g_loop_eth_dev[pos]) {
+		priv = netdev_priv(g_loop_eth_dev[pos]);
+
+		if (priv->dp_subif.port_id >= 0) {
+			SEQ_PRINTF(s,
+				   "%s - directpath on (ifid %d subif %d)\n",
+				   g_loop_eth_dev[pos]->name,
+				   priv->dp_subif.port_id,
+				   priv->dp_subif.subif);
+		} else
+			SEQ_PRINTF(s, "%s - directpath off\n",
+				   g_loop_eth_dev[pos]->name);
+	}
+
+	pos++;
+
+	if (pos >= MAX_LOOPETH_NUM)
+		pos = -1;
+
+	return pos;
+}
+
+void unregister_from_dp(struct net_device *dev)
+{
+	struct loop_eth_priv_data *priv;
+	int32_t dp_port_id;
+	int i;
+
+	priv = netdev_priv(dev);
+	dp_port_id = priv->dp_subif.port_id;
+
+	if (dp_port_id <= 0) {
+		PR_ERR
+		    ("Cannot undregister %s since it is not reigstered yet\n",
+		     dev->name);
+		return;
+	}
+
+	/*unregister all subif with same port_id first */
+	for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++) {
+		if (g_loop_eth_dev[i]) {
+			struct loop_eth_priv_data *priv =
+			    netdev_priv(g_loop_eth_dev[i]);
+
+			if (priv->dp_subif.port_id != dp_port_id)
+				continue;
+
+			if (priv->f_dp != LOOPETH_F_REGISTER_SUBIF)
+				continue;
+
+			if (dp_register_subif
+			    (priv->owner, g_loop_eth_dev[i],
+			     g_loop_eth_dev[i]->name, &priv->dp_subif,
+			     0) != DP_SUCCESS) {
+				PR_ERR("dp_unregister_subif failed for %s \
+					with port_id/subif %d/%d ?\n", dev->name, priv->dp_subif.port_id, priv->dp_subif.subif);
+			}
+
+			priv->f_dp = LOOPETH_F_REGISTER_DEV;
+			priv->dp_subif.subif = 0;
+		}
+	}
+
+	/*unregister/deallocate devices and reset all devices with same port_id */
+	if (dp_register_dev(priv->owner, dp_port_id, NULL, DP_F_DEREGISTER)
+	    != DP_SUCCESS) {
+		PR_INFO("dp_unregister_dev failed for %s \
+			with port_id %d ??? \n", dev->name, dp_port_id);
+	}
+
+	if (dp_alloc_port
+	    (priv->owner, dev, priv->dev_port, dp_port_id, NULL,
+	     DP_F_DEREGISTER) != DP_SUCCESS) {
+		PR_INFO("dp_dealloc_port failed for %s with port_id %d \n",
+			dev->name, dp_port_id);
+	}
+
+	for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++) {
+		if (g_loop_eth_dev[i]) {
+			struct loop_eth_priv_data *priv =
+			    netdev_priv(g_loop_eth_dev[i]);
+
+			if (priv->dp_subif.port_id != dp_port_id)
+				continue;
+
+			priv->f_dp = LOOPETH_F_FREE;
+			priv->dp_subif.port_id = 0;
+		}
+	}
+}
+
+/*to find out the device type index via its flag name. for example eth_lan, eth_wan,....
+return value:
+-1: not found
+>=0: type index
+*/
+int get_dev_type_index(char *flag_name)
+{
+	int i;
+
+	for (i = 1; i < get_dp_port_type_str_size(); i++) {	/*skip i = 0 */
+		if (dp_strcmpi(flag_name, dp_port_type_str[i]) == 0) {
+			return i;
+			;
+		}
+	}
+
+	return -1;
+}
+
+static int proc_write_directpath(struct file *file, const char *buf,
+				 size_t count, loff_t *ppos)
+{
+	char str[300];
+	int len, rlen;
+	char *ifname = NULL;
+	dp_cb_t cb = {
+		0
+	};
+	char *param_list[10] = {
+		NULL
+	};
+	int param_list_num = 0;
+	struct loop_eth_priv_data *priv = NULL;
+	int i, k;
+	int32_t dp_port_id = 0;
+	uint32_t dev_port = 0;
+	int flag_index = 0;
+	char *flag_str = NULL;
+	char *dev_port_str = NULL;
+	char *dp_port_str = NULL;
+	struct pmac_port_info *port_info = NULL;
+
+	len = count < sizeof(str) ? count : sizeof(str) - 1;
+	rlen = len - copy_from_user(str, buf, len);
+	str[rlen] = 0;
+	param_list_num =
+	    dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (param_list_num < 3)
+		goto help;
+
+	ifname = param_list[2];
+	/*device must ready before register to Datapath */
+	i = find_loopeth_index_via_name(ifname);
+	if (i < 0) {
+		PR_ERR("Not found device %s in loopeth \n", ifname);
+		goto exit;
+	}
+
+	priv = netdev_priv(g_loop_eth_dev[i]);
+
+	if (((dp_strcmpi(param_list[0], "register") == 0) ||
+	     (dp_strcmpi(param_list[0], "reg") == 0)) &&
+	    (dp_strcmpi(param_list[1], "dev") == 0)) {
+		if (param_list_num < 5)
+			goto help;
+
+		PR_INFO("Try to register dev %s to datapath\n", ifname);
+		dev_port_str = param_list[3];
+		flag_str = param_list[4];
+		dp_port_str = param_list[5];
+		PR_INFO("dev_port_str=%s\n",
+			dev_port_str ? dev_port_str : "NULL");
+		PR_INFO("flag_str=%s\n", flag_str ? flag_str : "NULL");
+		PR_INFO("dp_port_str=%s\n",
+			dp_port_str ? dp_port_str : "NULL");
+
+		dev_port = dp_atoi(dev_port_str);
+		flag_index = get_dev_type_index(flag_str);
+		dp_port_id = dp_atoi(dp_port_str);
+
+		if (flag_index <= 0) {
+			PR_INFO("Not valid device type:%s(%d)\n", flag_str,
+				flag_index);
+			goto help;
+		}
+
+		priv->owner = &g_loop_eth_module[i];
+		sprintf(priv->owner->name, "module%02d", i);
+		dp_port_id =
+		    dp_alloc_port(priv->owner, g_loop_eth_dev[i], dev_port,
+				  dp_port_id, NULL, 1 << flag_index);
+		g_loop_eth_dev_flag[i] = 1 << flag_index;
+
+		if (dp_port_id <= 0) {
+			PR_INFO("failed in register directpath for %s\n",
+				ifname);
+			goto exit;
+		}
+
+		PR_INFO("dp_alloc_port get port %d for %s\n", dp_port_id,
+			ifname);
+		cb.stop_fn = (dp_stop_tx_fn_t) dp_fp_stop_tx;
+		cb.restart_fn = (dp_restart_tx_fn_t) dp_fp_restart_tx;
+		cb.rx_fn = (dp_rx_fn_t) dp_fp_rx;
+		priv->dp_subif.port_id = dp_port_id;
+		priv->dev_port = dev_port;
+
+		if (dp_register_dev(priv->owner, dp_port_id, &cb, 0) !=
+		    DP_SUCCESS) {
+			PR_INFO
+			    ("dp_register_dev failed for %s\n and port_id %d",
+			     ifname, dp_port_id);
+			dp_alloc_port(priv->owner, g_loop_eth_dev[i],
+				      dev_port, 0, NULL, DP_F_DEREGISTER);
+			goto exit;
+		}
+
+		priv->f_dp = LOOPETH_F_REGISTER_DEV;
+		PR_INFO("Succeed to register dev %s dev_port %d to \
+			datapath with dp_port %d \n", ifname, dev_port, dp_port_id);
+	} else if (((dp_strcmpi(param_list[0], "register") == 0)
+		    || (dp_strcmpi(param_list[0], "reg") == 0))
+		   && (dp_strcmpi(param_list[1], "subif") == 0)) {
+		if (param_list_num < 3)
+			goto help;
+
+		PR_INFO("Try to register subif %s to datapath\n", ifname);
+
+		if (priv->f_dp == LOOPETH_F_REGISTER_DEV) {	/*already alloc a port and registered dev */
+			if (param_list[3])
+				priv->dp_subif.subif = dp_atoi(param_list[3]);
+			else
+				priv->dp_subif.subif = -1;	/*dynamic */
+
+			if (dp_register_subif
+			    (priv->owner, g_loop_eth_dev[i],
+			     g_loop_eth_dev[i]->name, &priv->dp_subif,
+			     0) != DP_SUCCESS)
+				goto exit;
+
+			priv->f_dp = LOOPETH_F_REGISTER_SUBIF;
+			PR_INFO("Succeed to register subitf %s dev port %d: \
+				dp_port %d subif %d dp_flag=%d\n", ifname, priv->dev_port, priv->dp_subif.port_id, priv->dp_subif.subif, priv->f_dp);
+		} else if (priv->f_dp == LOOPETH_F_FREE) {
+			char *parent_dev_name = param_list[3];
+			struct net_device *parent_dev;
+
+			parent_dev =
+			    dev_get_by_name(&init_net, parent_dev_name);
+
+			if (!parent_dev) {
+				PR_ERR("Not found device %s\n",
+				       parent_dev_name);
+				goto exit;
+			}
+
+			port_info = get_port_info_via_dp_name(parent_dev);
+
+			if (!port_info) {
+				PR_INFO("No such registered device %s yet\n",
+					parent_dev_name);
+				goto exit;
+			}
+
+			priv->dp_subif.subif = -1;	/*dynamic */
+			priv->dp_subif.port_id = port_info->port_id;
+			priv->dev_port = port_info->dev_port;
+			priv->owner = port_info->owner;
+
+			if (dp_register_subif
+			    (priv->owner, port_info->dev,
+			     g_loop_eth_dev[i]->name, &priv->dp_subif,
+			     0) != DP_SUCCESS) {
+				PR_INFO
+				    ("dp_register_subif failed for %s to register under %s\n",
+				     g_loop_eth_dev[i]->name,
+				     parent_dev_name);
+				goto exit;
+			}
+
+			priv->f_dp = LOOPETH_F_REGISTER_SUBIF;
+			PR_INFO
+			    ("Succeed to register subitf %s dev port %d:dp_port %d subif %d\n",
+			     ifname, priv->dev_port, priv->dp_subif.port_id,
+			     priv->dp_subif.subif);
+		} else if (priv->f_dp == LOOPETH_F_REGISTER_SUBIF) {
+			PR_INFO("Subif %s already registered\n", ifname);
+			goto exit;
+		} else {
+			PR_INFO("Failed for uknown reason:%d\n", priv->f_dp);
+			goto exit;
+		}
+	} else
+	    if (((dp_strcmpi(param_list[0], "unregister") == 0) ||
+		 (dp_strcmpi(param_list[0], "unreg") == 0)) &&
+		(dp_strcmpi(param_list[1], "dev") == 0)) {
+		PR_INFO("Try to register dev %s from datapath\n", ifname);
+		priv = netdev_priv(g_loop_eth_dev[i]);
+		dp_port_id = priv->dp_subif.port_id;
+
+		for (k = 0; k < ARRAY_SIZE(g_loop_eth_dev); k++) {
+			if (g_loop_eth_dev[k]) {	/*unregister all devices with same port_id */
+				priv = netdev_priv(g_loop_eth_dev[k]);
+
+				if (priv->dp_subif.port_id != dp_port_id)
+					continue;
+
+				unregister_dev(k);
+			}
+		}
+	} else {
+		PR_INFO("Wrong command: %s %s\n", param_list[0],
+			param_list[1]);
+		goto help;
+	}
+
+ exit:
+	return count;
+ help:
+	/*     param_list[0]    [1]    [2]         [3]      [4]     [5]            */
+	PR_INFO
+	    ("echo register   dev   <Dev_name> <Dev_port> <Type> [DP_port] > /proc/loopeth/directpath\n");
+	PR_INFO
+	    ("echo unregister dev  <Dev_name>  > /proc/loopeth/directpath\n");
+	PR_INFO
+	    ("echo register   subif <Dev_name> [parent_dev_name] > /proc/loopeth/directpath\n");
+	PR_INFO("Note: parent_dev_name is for register different subif\n");
+	PR_INFO("Device Type:\n");
+
+	for (i = 1; i < get_dp_port_type_str_size(); i++)	/*skip i 0 */
+		PR_INFO("\t%s\n", dp_port_type_str[i]);
+
+	PR_INFO("----16 subifs test script-----\n");
+	PRINTK("\n \
+	echo add 0 > /proc/dp/loop/dev\n \
+	echo register dev   loopeth0 1 DIRECTPATH > /proc/dp/loop/directpath\n \
+	echo register subif loopeth0 > /proc/dp/loop/directpath\n \
+	\n \
+	for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n \
+		do \n \
+		echo add $i > /proc/dp/loop/dev\n \
+		echo register subif loopeth${i} loopeth0 > /proc/dp/loop/directpath\n \
+	done\n");
+
+	return count;
+}
+
+/*###################################
+*           Global Function
+* ####################################
+*/
+#define PROC_NAME		"loop"
+#define PROC_DBG		"dbg"
+#define PROC_READ_DEV		"dev"
+#define PROC_READ_MIB		"mib"
+#define PROC_READ_DP		"directpath"
+#define PROC_READ_CPUTX		"cputx"
+static struct dp_proc_entry proc_entries[] = {
+	/* name             single_callback_t    multi_callback_t    multi_callback_start    write_callback_t  */
+#if defined(ENABLE_DBG_PROC) && ENABLE_DBG_PROC
+	{PROC_DBG, proc_read_dbg, NULL, NULL, proc_write_dbg},
+#endif
+	{PROC_READ_DEV, NULL, proc_read_dev, NULL, proc_write_dev},
+	{PROC_READ_MIB, NULL, proc_read_mib, NULL, proc_write_mib},
+	{PROC_READ_DP, NULL, proc_read_dp, NULL, proc_write_directpath},
+
+	/*last one for place holder */
+	{NULL, NULL, NULL, NULL, NULL}
+};
+
+static struct proc_dir_entry *proc_node;
+
+static struct proc_dir_entry *proc_file_create(struct proc_dir_entry
+					       *parent)
+{
+	proc_node = proc_mkdir(PROC_NAME, parent);
+
+	if (proc_node != NULL) {
+		int i;
+
+		for (i = 0; i < ARRAY_SIZE(proc_entries); i++)
+			dp_proc_entry_create(proc_node, &proc_entries[i]);
+	} else {
+		PR_INFO("cannot create proc entry");
+		return NULL;
+	}
+
+	return proc_node;
+}
+
+/*####################################
+*           Init/Cleanup API
+* ####################################
+*/
+
+int dp_loop_eth_dev_init(struct proc_dir_entry *parent)
+{
+	PR_INFO("Loading loop_net_dev driver ...... ");
+	memset(g_loop_eth_dev, 0, sizeof(g_loop_eth_dev));
+	memset(g_loop_eth_module, 0, sizeof(g_loop_eth_module));
+
+	proc_file_create(parent);
+
+	PR_INFO("dp_loop_eth_dev_init Succeeded!\n");
+	return 0;
+}
+
+void dp_loop_eth_dev_exit(void)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(g_loop_eth_dev); i++)
+		if (g_loop_eth_dev[i]) {
+			delete_loopeth_dev(i);
+			free_netdev(g_loop_eth_dev[i]);
+		}
+}
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_mib.c b/drivers/net/ethernet/lantiq/datapath/datapath_mib.c
new file mode 100644
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_mib.c
@@ -0,0 +1,2140 @@
+/*
+ Reference: http://smartbear.lantiq.com/ui#review:id=1716
+*/
+#include<linux/init.h>
+#include<linux/module.h>
+#include <linux/kernel.h>	/* printk */
+#include <linux/types.h>	/* size_t */
+#include <linux/version.h>
+#include <linux/timer.h>
+#include <linux/skbuff.h>
+#include <linux/if_ether.h>
+#include <linux/ethtool.h>
+#include <linux/proc_fs.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+#include <linux/if_ether.h>
+#include <linux/clk.h>
+
+#include <lantiq.h>
+#include <lantiq_soc.h>
+#include <net/lantiq_cbm.h>
+#include <net/datapath_api.h>
+#include <net/datapath_proc_api.h>
+#include "datapath.h"
+#include "datapath_pmac.h"
+#include <net/lantiq_cbm_api.h>
+#include <xway/switch-api/lantiq_gsw_api.h>
+#include <xway/switch-api/lantiq_gsw_flow.h>
+#ifdef CONFIG_LTQ_TMU
+#include <net/drv_tmu_ll.h>
+#endif
+#include <linux/ltq_hwmcpy.h>
+#if defined(CONFIG_LTQ_PPA_TMU_MIB_SUPPORT) || defined(CONFIG_LTQ_PPA_TMU_MIB_SUPPORT_MODULE)
+#include <net/ltq_tmu_hal_api.h>
+#include <net/ltq_mpe_hal.h>
+#else
+#define CONFIG_LTQ_DATAPATH_DUMMY_TMU_MIB /*use local DUMMY TMU HAL MIB API */
+#endif
+
+#ifdef CONFIG_LTQ_DATAPATH_OLD_TMU_HAL
+/*workaround since TMU HAL implementation does not follow concept API */
+#define tmu_hal_get_csum_ol_mib_hook_fn tmu_hal_get_csum_ol_mib_hook
+#define tmu_hal_get_qos_mib_hook_fn tmu_hal_get_qos_mib_hook
+#define tmu_hal_clear_qos_mib_hook_fn tmu_hal_reset_qos_mib_hook
+int32_t (*tmu_hal_clear_csum_ol_mib_hook_fn)(uint32_t flag) = NULL;
+
+#endif
+
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+#ifdef CONFIG_LTQ_DATAPATH_DUMMY_TMU_MIB
+struct tmu_hal_qos_stats {
+uint32_t enqPkts; /* Enqueued packets Count */
+uint32_t enqBytes; /* Enqueued Bytes Count */
+uint32_t deqPkts; /* Dequeued packets Count */
+uint32_t deqBytes; /* Dequeued Bytes Count */
+uint32_t dropPkts; /* Dropped Packets Count */
+uint32_t dropBytes; /* Dropped Bytes Count - UNUSED for now */
+uint32_t qOccPkts; /* Queue Occupancy Packets Count - Only at Queue level */
+};
+
+int32_t(*tmu_hal_get_qos_mib_hook_fn) (struct net_device *dev,
+	dp_subif_t *subif_id,
+	int32_t queue_id,
+	struct tmu_hal_qos_stats *qos_mib,
+	uint32_t flag) =  NULL;
+
+int32_t (*tmu_hal_get_csum_ol_mib_hook_fn) (
+	struct tmu_hal_qos_stats *csum_mib, /* Output Arg : Checksum Offload */
+	uint32_t flag) = NULL;
+
+int32_t (*tmu_hal_clear_qos_mib_hook_fn) (struct net_device *dev,
+	dp_subif_t *subif,  int32_t queue_id, uint32_t flag) = NULL;
+
+int32_t (*tmu_hal_clear_csum_ol_mib_hook_fn)(uint32_t flag) = NULL;
+#endif /* end of CONFIG_LTQ_DATAPATH_DUMMY_MPE_MIB */
+
+#ifdef CONFIG_LTQ_DATAPATH_DUMMY_MPE_MIB
+struct mpe_hal_if_stats {
+	uint32_t txPkts; /* Transmitted packets Count */
+	uint32_t txBytes; /* Transmitted Bytes Count */
+	uint32_t dropPkts; /* Dropped packets count */
+	uint32_t dropBytes; /* Dropped packets bytes size count */
+	uint32_t rxPkts; /* Received packets Count - UNUSED FOR NOW */
+	uint32_t rxBytes; /* Received Bytes Count - UNUSED FOR NOW */
+};
+
+int32_t (*mpe_hal_get_netif_mib_hook_fn)(struct net_device *dev,
+	dp_subif_t *subif_id, struct mpe_hal_if_stats *mpe_mib,
+	uint32_t flag) = NULL;
+
+int32_t (*mpe_hal_clear_if_mib_hook_fn)(struct net_device *dev,
+	dp_subif_t *subif_id, uint32_t flag) = NULL;
+
+#endif
+#endif /* CONFIG_LTQ_DATAPATH_DUMMY_MPE_MIB */
+
+#define WRAPAROUND32   0xFFFFFFFF
+/*timer interval for mib wraparound handling:
+* Most mib counter is 32 bits, ie, maximu ix 0xFFFFFFFF
+* one pmac port maximum (cpu port) can support less than 3G, ie,
+* 1488096 * 3 packets for 64 bytes case. so the time to have 1 wrapround is:
+* 0xFFFFFFFF / (1488096 * 3) = 962 seconds
+* If each timer check one port and its subif, then 962/16 = 60 sec.
+*/
+#if 0
+#define POLL_INTERVAL (2 * HZ)
+#else
+#define POLL_INTERVAL (60 * HZ)
+#endif
+#define WAN_EP          15	/*WAN Interface's EP value */
+#define MAX_RMON_ITF    256	/*maximum 256 GSW RMON interface supported */
+
+struct mibs_port {
+	u64 rx_good_bytes;
+	u64 rx_bad_bytes;
+	u64 rx_good_pkts;
+	u64 rx_drop_pkts;
+	/*For eth0_x only, for all others, must keep it
+	* to zero in order to share same algo
+	*/
+	u64 rx_drop_pkts_pae;
+	u64 rx_disc_pkts_redir;	/*for eth1 only */
+	u64 rx_fcs_err_pkts;
+	u64 rx_undersize_good_pkts;
+	u64 rx_oversize_good_pkts;
+	u64 rx_undersize_err_pkts;
+	u64 rx_oversize_err_pkts;
+	u64 rx_align_err_pkts;
+	u64 rx_filter_pkts;
+
+	u64 tx_good_bytes;
+	u64 tx_good_pkts;
+	u64 tx_drop_pkts;
+	/*For eth0_x only, for all others, must keep it
+	*  to zero in order to share same algo
+	*/
+	u64 tx_drop_pkts_pae;
+	u64 tx_acm_drop_pkts;
+	u64 tx_acm_drop_pkts_pae;	/*for eth0_x only */
+	u64 tx_disc_pkts_redir;	/*for eth1 only */
+	u64 tx_coll_pkts;
+	u64 tx_coll_pkts_pae;	/*for eth0_x only */
+	u64 tx_pkts_redir;	/*for eth1 only */
+	u64 tx_bytes_redir;	/*for eth1 only */
+	u64 rx_fcs_err_pkts_pae;
+	u64 rx_undersize_err_pkts_pae;
+	u64 rx_oversize_err_pkts_pae;
+	u64 rx_align_err_pkts_pae;
+
+	/*tmu related */
+	u64 tx_tmu_drop_pkts;
+	u64 tx_mpe_drop_pkts;
+	u64 tx_tmu_csum_offload_pkts;
+	u64 tx_tmu_csum_offload_bytes;
+
+	/*driver related */
+	u64 rx_drv_drop_pkts;
+	u64 rx_drv_error_pkts;
+	u64 tx_drv_drop_pkts;
+	u64 tx_drv_error_pkts;
+
+	/*for DSL ATM only */
+	u64 tx_drv_pkts;
+	u64 rx_drv_pkts;
+	u64 tx_drv_bytes;
+	u64 rx_drv_bytes;
+};
+
+struct mib_vap {
+	u64 rx_pkts_itf;
+	u64 rx_disc_pkts_itf;
+	u64 rx_disc_pkts_drv;
+	u64 tx_pkts_itf;
+	u64 tx_disc_pkts_itf;
+	u64 tx_disc_pkts_tmu;
+	u64 tx_disc_pkts_mpe;
+	u64 tx_disc_pkts_drv;
+};
+
+struct port_mib {
+	struct mibs_port curr;	/*tmp variable used for mib counter calculation */
+	struct mib_vap curr_vap[MAX_SUBIF_PER_PORT];	/*for future */
+};
+
+struct mibs_low_lvl_port {
+	GSW_RMON_Port_cnt_t l;          /*only for ethernet LAN ports */
+	GSW_RMON_Port_cnt_t r;
+	GSW_RMON_Redirect_cnt_t redir; /*only for ethernet WAN port */
+	dp_drv_mib_t drv;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	struct tmu_hal_qos_stats tmu_qos[MAX_SUBIF_PER_PORT];
+	struct tmu_hal_qos_stats tmu_chksum;  /*only for ethernet WAN port */
+	struct mpe_hal_if_stats mpe;
+#endif
+};
+
+struct mibs_low_lvl_vap {
+	GSW_RMON_If_cnt_t gsw_if; /*for pae only since GSW-L not support interface mib*/
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	struct tmu_hal_qos_stats tmu_qos;
+	struct mpe_hal_if_stats mpe;
+#endif
+	dp_drv_mib_t drv;
+};
+
+static unsigned int proc_mib_vap_start_id = 1;
+static unsigned int proc_mib_vap_end_id = PMAC_MAX_NUM - 1;
+static spinlock_t dp_mib_lock;
+static unsigned long poll_interval = POLL_INTERVAL;
+
+/*save port based lower level last mib counter
+* for wraparound checking
+*/
+struct mibs_low_lvl_port last[PMAC_MAX_NUM];
+/*save vap/sub interface based lower level last mib counter
+* for wraparound checking
+*/
+struct mibs_low_lvl_vap last_vap[PMAC_MAX_NUM][MAX_SUBIF_PER_PORT];
+/*Save all necessary aggregated basic MIB */
+static struct port_mib aggregate_mib[PMAC_MAX_NUM];
+/*For PAE CPU port only */
+static struct port_mib aggregate_mib_r[1];
+
+#define THREAD_MODE
+
+#ifdef THREAD_MODE
+#include <linux/kthread.h>
+struct task_struct *thread;
+#else
+static struct timer_list exp_timer;	/*timer setting */
+#endif
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+static int32_t(*tmu_hal_get_qos_mib_hook_fn_local)(struct net_device *dev,
+	dp_subif_t *subif_id,
+	int32_t queue_id,
+	struct tmu_hal_qos_stats *qos_mib,
+	uint32_t flag);
+
+static int32_t (*tmu_hal_get_csum_ol_mib_hook_fn_local)(
+	struct tmu_hal_qos_stats *csum_mib, uint32_t flag);
+static int32_t (*tmu_hal_clear_qos_mib_hook_fn_local)(struct net_device *dev,
+	dp_subif_t *subif,  int32_t queue_id, uint32_t flag);
+static int32_t (*tmu_hal_clear_csum_ol_mib_hook_fn_local)(uint32_t flag);
+static int32_t (*mpe_hal_get_netif_mib_hook_fn_local)(struct net_device *dev,
+	dp_subif_t *subif_id, struct mpe_hal_if_stats *mpe_mib, uint32_t flag);
+static int32_t (*mpe_hal_clear_if_mib_hook_fn_local)(struct net_device *dev,
+	dp_subif_t *subif_id, uint32_t flag);
+#endif
+
+int dp_get_port_vap_mib(dp_subif_t *subif, void *priv,
+		   struct rtnl_link_stats64 *net_mib, u32 flag);
+
+/*internal API: update local net mib counters periodically */
+static int update_port_mib_lower_lvl(dp_subif_t *subif, u32 flag);
+static int update_vap_mib_lower_lvl(dp_subif_t *subif, u32 flag);
+
+/* ----- API implementation ------- */
+static u64 wraparound(u64 curr, u64 last, u32 size)
+{
+#define WRAPAROUND_MAX_32 0xFFFFFFFF
+
+	if ((size > 4) ||	/* for 8 bytes(64bit mib),no need to do wraparound */
+	    (curr >= last))
+		return curr - last;
+
+	return ((u64)WRAPAROUND_MAX_32) + (u64)curr - last;
+}
+
+static int port_mib_wraparound(u32 ep, struct mibs_low_lvl_port *curr,
+			       struct mibs_low_lvl_port *last)
+{
+/* RMON_PORT_WRAP: c-current, l-last x-size in bytes */
+#define RMON_PORT_WRAP(c, l, x) wraparound(c->x, l->x, sizeof(l->x))
+	GSW_RMON_Port_cnt_t *curr_tmp;
+	GSW_RMON_Port_cnt_t *last_tmp;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	int i;
+#endif
+
+	if (unlikely(ep >= PMAC_MAX_NUM))
+		return -1;
+	if (ep < PAMC_LAN_MAX_NUM) {
+		curr_tmp = &curr->l;
+		last_tmp = &last->l;
+	} else {
+		curr_tmp = &curr->r;
+		last_tmp = &last->r;
+	}
+	/*First handle common RMON mib */
+	spin_lock_bh(&dp_mib_lock);
+	aggregate_mib[ep].curr.rx_good_bytes +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxGoodBytes);
+	aggregate_mib[ep].curr.rx_bad_bytes +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxBadBytes);
+	aggregate_mib[ep].curr.rx_good_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxGoodPkts);
+	aggregate_mib[ep].curr.rx_drop_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxDroppedPkts);
+	aggregate_mib[ep].curr.rx_fcs_err_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFCSErrorPkts);
+	aggregate_mib[ep].curr.rx_undersize_good_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeGoodPkts);
+	aggregate_mib[ep].curr.rx_oversize_good_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeGoodPkts);
+	aggregate_mib[ep].curr.rx_undersize_err_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeErrorPkts);
+	aggregate_mib[ep].curr.rx_oversize_err_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeErrorPkts);
+	aggregate_mib[ep].curr.rx_align_err_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxAlignErrorPkts);
+	aggregate_mib[ep].curr.rx_filter_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFilteredPkts);
+	aggregate_mib[ep].curr.tx_good_bytes +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxGoodBytes);
+	aggregate_mib[ep].curr.tx_good_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxGoodPkts);
+	aggregate_mib[ep].curr.tx_drop_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxDroppedPkts);
+	aggregate_mib[ep].curr.tx_acm_drop_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxAcmDroppedPkts);
+	aggregate_mib[ep].curr.tx_coll_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxCollCount);
+
+	/*pae port 0 is not required by concept, for debugging only*/
+	if (ep == 0) {
+		curr_tmp = &curr->r;
+		last_tmp = &last->r;
+		aggregate_mib_r[0].curr.rx_good_bytes +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxGoodBytes);
+		aggregate_mib_r[0].curr.rx_bad_bytes +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxBadBytes);
+		aggregate_mib_r[0].curr.rx_good_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxGoodPkts);
+		aggregate_mib_r[0].curr.rx_drop_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxDroppedPkts);
+		aggregate_mib_r[0].curr.rx_fcs_err_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFCSErrorPkts);
+		aggregate_mib_r[0].curr.rx_undersize_good_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeGoodPkts);
+		aggregate_mib_r[0].curr.rx_oversize_good_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeGoodPkts);
+		aggregate_mib_r[0].curr.rx_undersize_err_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeErrorPkts);
+		aggregate_mib_r[0].curr.rx_oversize_err_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeErrorPkts);
+		aggregate_mib_r[0].curr.rx_align_err_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxAlignErrorPkts);
+		aggregate_mib_r[0].curr.rx_filter_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFilteredPkts);
+		aggregate_mib_r[0].curr.tx_good_bytes +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxGoodBytes);
+		aggregate_mib_r[0].curr.tx_good_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxGoodPkts);
+		aggregate_mib_r[0].curr.tx_drop_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxDroppedPkts);
+		aggregate_mib_r[0].curr.tx_acm_drop_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxAcmDroppedPkts);
+		aggregate_mib_r[0].curr.tx_coll_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxCollCount);
+
+		/*save */
+		*last = *curr;
+		spin_unlock_bh(&dp_mib_lock);
+		return 0;
+	}
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	/*TMU drop counters */
+	for (i = 0; i < MAX_SUBIF_PER_PORT; i++)
+		aggregate_mib[ep].curr.tx_tmu_drop_pkts +=
+		    wraparound(curr->tmu_qos[i].dropPkts, last->tmu_qos[i].dropPkts,
+			       sizeof(last->tmu_qos[i].dropPkts));
+	aggregate_mib[ep].curr.tx_mpe_drop_pkts +=
+	    wraparound(curr->mpe.dropPkts, last->mpe.dropPkts,
+		       sizeof(last->mpe.dropPkts));
+	aggregate_mib[ep].curr.tx_tmu_csum_offload_pkts +=
+	    wraparound(curr->tmu_chksum.deqPkts,
+		       last->tmu_chksum.deqPkts,
+		       sizeof(last->tmu_chksum.deqPkts));
+	aggregate_mib[ep].curr.tx_tmu_csum_offload_bytes +=
+	    wraparound(curr->tmu_chksum.deqBytes,
+		       last->tmu_chksum.deqBytes,
+		       sizeof(last->tmu_chksum.deqBytes));
+#endif
+	if (ep < PAMC_LAN_MAX_NUM) {
+		/*speical handling for eth0_x: */
+		/*   get drop cnt from its pae's mapped port,*/
+		/*   Don't save whole last as *last = *curr */
+		curr_tmp = &curr->r;
+		last_tmp = &last->r;
+		aggregate_mib[ep].curr.rx_drop_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxDroppedPkts);
+		aggregate_mib[ep].curr.tx_drop_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxDroppedPkts);
+		aggregate_mib[ep].curr.tx_coll_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxCollCount);
+
+
+		aggregate_mib[ep].curr.rx_fcs_err_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFCSErrorPkts);
+		aggregate_mib[ep].curr.rx_undersize_err_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeErrorPkts);
+		aggregate_mib[ep].curr.rx_oversize_err_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeErrorPkts);
+		aggregate_mib[ep].curr.rx_align_err_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxAlignErrorPkts);
+
+	} else if (ep == WAN_EP) {	/*redirect mib */
+		aggregate_mib[ep].curr.rx_disc_pkts_redir +=
+		    wraparound(curr->redir.nRxDiscPktsCount,
+			       last->redir.nRxDiscPktsCount,
+			       sizeof(last->redir.nRxDiscPktsCount));
+		aggregate_mib[ep].curr.tx_disc_pkts_redir +=
+		    wraparound(curr->redir.nTxDiscPktsCount,
+			       last->redir.nTxDiscPktsCount,
+			       sizeof(last->redir.nTxDiscPktsCount));
+		aggregate_mib[ep].curr.tx_pkts_redir +=
+		    wraparound(curr->redir.nTxPktsCount,
+			       last->redir.nTxPktsCount,
+			       sizeof(last->redir.nTxPktsCount));
+		aggregate_mib[ep].curr.tx_bytes_redir +=
+		    wraparound(curr->redir.nTxBytesCount,
+			       last->redir.nTxBytesCount,
+			       sizeof(last->redir.nTxBytesCount));
+	}
+	/*save */
+	*last = *curr;
+	spin_unlock_bh(&dp_mib_lock);
+	return 0;
+}
+
+static int vap_mib_wraparound(dp_subif_t *subif,
+			      struct mibs_low_lvl_vap *curr,
+			      struct mibs_low_lvl_vap *last)
+{
+#define VAP_RMON_WRAP_ITF(c, l, x) wraparound(c->gsw_if.x, l->gsw_if.x, sizeof(l->gsw_if.x))
+#define VAP_RMON_WRAP_TMU(c, l, x) wraparound(c->tmu_qos.x, l->tmu_qos.x, sizeof(l->tmu_qos.x))
+#define VAP_RMON_WRAP_MPE(c, l, x) wraparound(c->mpe.x, l->mpe.x, sizeof(l->mpe.x))
+#define VAP_RMON_WRAP_DRV(c, l, x) wraparound(c->drv.x, l->drv.x, sizeof(l->drv.x))
+
+	int ep = subif->port_id;
+	int vap = get_vap(subif->subif);
+
+	if ((ep <= 0) ||
+		ep >= PMAC_MAX_NUM)
+		return -1;
+	spin_lock_bh(&dp_mib_lock);
+	aggregate_mib[ep].curr_vap[vap].rx_pkts_itf +=
+	    VAP_RMON_WRAP_ITF(curr, last, nRxPktsCount);
+	aggregate_mib[ep].curr_vap[vap].rx_disc_pkts_itf +=
+	    VAP_RMON_WRAP_ITF(curr, last, nRxDiscPktsCount);
+	aggregate_mib[ep].curr_vap[vap].rx_disc_pkts_drv +=
+	    VAP_RMON_WRAP_ITF(curr, last, nRxDiscPktsCount);
+
+	aggregate_mib[ep].curr_vap[vap].tx_pkts_itf +=
+	    VAP_RMON_WRAP_ITF(curr, last, nTxPktsCount);
+	aggregate_mib[ep].curr_vap[vap].tx_disc_pkts_itf +=
+	    VAP_RMON_WRAP_ITF(curr, last, nTxDiscPktsCount);
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	aggregate_mib[ep].curr_vap[vap].tx_disc_pkts_tmu +=
+	    VAP_RMON_WRAP_TMU(curr, last, dropPkts);
+	aggregate_mib[ep].curr_vap[vap].tx_disc_pkts_mpe +=
+	    VAP_RMON_WRAP_MPE(curr, last, dropPkts);
+#endif
+	aggregate_mib[ep].curr_vap[vap].tx_disc_pkts_drv +=
+	    VAP_RMON_WRAP_DRV(curr, last, tx_drop_pkts);
+	/*save */
+	*last = *curr;
+	spin_unlock_bh(&dp_mib_lock);
+	return 0;
+}
+
+int get_gsw_port_rmon(u32 ep, char *gsw_drv_name, GSW_RMON_Port_cnt_t *mib)
+{
+	GSW_API_HANDLE gsw_handle = 0;
+	int ret;
+
+	if (!mib) {
+		PR_ERR("why mib pointer is %p\n", mib);
+		return -1;
+	}
+	if (ep >= PMAC_MAX_NUM)
+		return -1;
+	gsw_handle = gsw_api_kopen(gsw_drv_name);
+	if (gsw_handle == 0) {
+		PR_ERR("gsw_api_kopen %s FAILED !\n", gsw_drv_name);
+		return -1;
+	}
+	memset(mib, 0, sizeof(*mib));
+	mib->nPortId = ep;
+	ret = gsw_api_kioctl(gsw_handle, GSW_RMON_PORT_GET, (u32)mib);
+	if (ret) {
+		PR_ERR("GSW_RMON_PORT_GET failed(%d) from %s for port %d\n",
+		       ret, gsw_drv_name, ep);
+		return -1;
+	}
+
+	return 0;
+}
+
+static int get_gsw_redirect_rmon(u32 ep, char *gsw_drv_name,
+				 GSW_RMON_Redirect_cnt_t *mib)
+{
+	GSW_API_HANDLE gsw_handle = 0;
+	int ret;
+
+	if (!mib) {
+		PR_ERR("why mib pointer is %p\n", mib);
+		return -1;
+	}
+
+	memset(mib, 0, sizeof(*mib));
+	gsw_handle = gsw_api_kopen(gsw_drv_name);
+	if (gsw_handle == 0) {
+		PR_ERR("Open %s FAILED !\n", gsw_drv_name);
+		return -1;
+	}
+
+	ret = gsw_api_kioctl(gsw_handle, GSW_RMON_REDIRECT_GET, (u32)mib);
+
+	if (ret) {
+		PR_ERR("GSW_RMON_REDIRECT_GET failed from %s\n",
+		       gsw_drv_name);
+		return -1;
+	}
+
+	return 0;
+}
+
+static int get_gsw_itf_rmon(u32 index, char *gsw_drv_name,
+			    GSW_RMON_If_cnt_t *mib)
+{
+	GSW_API_HANDLE gsw_handle = 0;
+	int ret;
+
+	if (!mib) {
+		PR_ERR("why mib pointer is %p\n", mib);
+		return -1;
+	}
+	memset(mib, 0, sizeof(*mib));
+	gsw_handle = gsw_api_kopen(gsw_drv_name);
+	if (gsw_handle == 0) {
+		PR_ERR("Open %s FAILED !\n", gsw_drv_name);
+		return -1;
+	}
+	mib->nIfId = index;
+	ret = gsw_api_kioctl(gsw_handle, GSW_RMON_IF_GET, (u32)mib);
+	if (ret) {
+		PR_ERR
+		    ("GSW_RMON_PORT_GET GSW_RMON_IF_GET from %s: index %d\n",
+		     gsw_drv_name, index);
+		return -1;
+	}
+	return 0;
+}
+
+int get_gsw_interface_base(int port_id)
+{
+	struct pmac_port_info *port_info;
+
+	if ((port_id <= 0) || (port_id >= PMAC_MAX_NUM)) {
+		PR_ERR("Wrong subif\n");
+		return -1;
+	}
+
+	port_info = get_port_info(port_id);
+	if (!port_info)
+		return -1;
+	if (!port_info->itf_info)
+		return -1;
+	return (int)port_info->itf_info->start;
+}
+
+/* if ethernet WAN redirect is enabled, return 1,
+* else return 0
+*/
+int gsw_eth_wan_redirect_status(void)
+{
+	GSW_API_HANDLE gsw_handle = 0;
+	GSW_QoS_queuePort_t q_cfg;
+	int ret, i;
+	#define MAX_CLASS_NUM 16
+
+	gsw_handle = gsw_api_kopen(GSWIP_R_DEV_NAME);
+	if (gsw_handle == 0) {
+		PR_ERR("gsw_api_kopen %s FAILED !\n", GSWIP_R_DEV_NAME);
+		return -1;
+	}
+	memset(&q_cfg, 0, sizeof(q_cfg));
+	q_cfg.nPortId = WAN_EP;
+	for (i = 0; i <= MAX_CLASS_NUM; i++) {
+		q_cfg.nTrafficClassId = i;
+		ret = gsw_api_kioctl(gsw_handle, GSW_QOS_QUEUE_PORT_GET, (u32)&q_cfg);
+		if (ret) {
+			PR_ERR("GSW_QOS_QUEUE_PORT_GET failed(%d) from %s for port %d\n",
+			       ret, GSWIP_R_DEV_NAME, WAN_EP);
+			return -1;
+		}
+		if (q_cfg.nRedirectPortId == 0)
+			return 1;
+	}
+
+	return 0;
+}
+
+
+
+/*Note:
+* Update mib counter for physical port only
+* flag so far no much use only
+*/
+static int update_port_mib_lower_lvl(dp_subif_t *subif, u32 flag)
+{
+	int ret;
+	struct mibs_low_lvl_port *curr;
+	dp_subif_t tmp;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	int update_flag, i;
+	struct pmac_port_info *port;
+#endif
+
+	/*update struct pmac_port_info[subif->ep].net_mib */
+	if (!subif ||
+		(subif->port_id < 0) ||
+		(subif->port_id >= PMAC_MAX_NUM)) {
+		if (!subif)
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "update_port_mib_lower_lvl error with NULL subif\n");
+		else
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "update_port_mib_lower_lvl wrong port_id %d\n", subif->port_id);
+		return -1;
+	}
+	curr = kmalloc(sizeof(struct mibs_low_lvl_port), GFP_ATOMIC);
+	if (!curr) {
+		PR_ERR("kmalloc failed to get %d bytes of memory\n",
+			sizeof(struct mibs_low_lvl_port));
+		return -1;
+	}
+	memset(curr, 0, sizeof(*curr));
+	tmp = *subif;
+	if (tmp.port_id  == 0) {
+		/*not requried by concept, just for debugging purpose*/
+		ret = get_gsw_port_rmon(tmp.port_id, GSWIP_L_DEV_NAME,
+			&curr->l);
+		if (ret)	/*workaroud otherwise wrongly wrapround */
+			curr->l = last[tmp.port_id].l;
+		ret = get_gsw_port_rmon(tmp.port_id, GSWIP_R_DEV_NAME,
+			&curr->r);
+		if (ret)	/*workaroud otherwise wrongly wrapround */
+			curr->r = last[tmp.port_id].r;
+		goto HANDLE_WRAPWROUND;
+	} else if (tmp.port_id < PAMC_LAN_MAX_NUM) { /* For port_id: 1 ~ 6 */
+		ret =
+		    get_gsw_port_rmon(tmp.port_id, GSWIP_L_DEV_NAME,
+				      &curr->l);
+		if (ret)	/*workaroud otherwise wrongly wrapround */
+			curr->l = last[tmp.port_id].l;
+	}
+	/*common to all: pae mib still needs for eth0_x */
+	ret = get_gsw_port_rmon(tmp.port_id, GSWIP_R_DEV_NAME, &curr->r);
+	if (ret)		/*workaroud */
+		curr->r = last[tmp.port_id].r;
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	/* collect all mib per VAP for TMU and MPE MIB */
+	tmu_hal_get_qos_mib_hook_fn_local = tmu_hal_get_qos_mib_hook_fn;
+	port = get_port_info(tmp.port_id);
+	if (tmu_hal_get_qos_mib_hook_fn_local &&
+		port && port->status) { /*get all VAP's TMU MIB*/
+		for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+			DP_DEBUG(DP_DBG_FLAG_MIB, "tmu_hal_get_qos_mib_hook_fn_local: %d/%d\n",
+				tmp.port_id, tmp.subif);
+			if (!port->subif_info[i].flags)
+				ret = -1;
+			else {
+				tmp.subif = set_vap(i);
+				ret = tmu_hal_get_qos_mib_hook_fn_local(NULL, &tmp, -1,
+					&curr->tmu_qos[i], 0);
+			}
+			if (ret)
+				memcpy(&curr->tmu_qos[i], &last[tmp.port_id].tmu_qos[i],
+				sizeof(curr->tmu_qos[i])); /*workaround */
+		}
+	} else
+		memcpy(&curr->tmu_qos, &last[tmp.port_id].tmu_qos,
+				sizeof(curr->tmu_qos));
+	tmp = *subif;
+	mpe_hal_get_netif_mib_hook_fn_local = mpe_hal_get_netif_mib_hook_fn;
+	update_flag = 0;
+	if (mpe_hal_get_netif_mib_hook_fn_local) {
+		ret = mpe_hal_get_netif_mib_hook_fn_local(NULL, &tmp,
+				&curr->mpe, 0);
+		if (!ret)
+			update_flag  = 1; /*succeed */
+	}
+	if (!update_flag)
+		memcpy(&curr->mpe, &last[tmp.port_id].mpe,
+			sizeof(curr->mpe));
+#endif
+
+	/*get redirect mib for eth1 only */
+	if (tmp.port_id == WAN_EP) {
+		ret =
+		    get_gsw_redirect_rmon(tmp.port_id, GSWIP_R_DEV_NAME,
+					  &curr->redir);
+		if (ret)	/*workaroud */
+			curr->redir = last[tmp.port_id].redir;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+		tmu_hal_get_csum_ol_mib_hook_fn_local = tmu_hal_get_csum_ol_mib_hook_fn;
+		update_flag = 0;
+		if (tmu_hal_get_csum_ol_mib_hook_fn_local) {
+			ret = tmu_hal_get_csum_ol_mib_hook_fn_local(&curr->tmu_chksum, 0);
+			if (!ret)
+				update_flag = 1;
+		}
+		if (!update_flag)
+			memcpy(&curr->tmu_chksum, &last[tmp.port_id].tmu_chksum,
+				sizeof(curr->tmu_chksum));
+#endif
+	}
+	/*get drv mib */
+	ret = dp_get_drv_mib(subif, &curr->drv, 0);
+	if (ret)	/*workaroud */
+		curr->drv = last[tmp.port_id].drv;
+HANDLE_WRAPWROUND:
+	ret =
+	    port_mib_wraparound(tmp.port_id, curr, &last[tmp.port_id]);
+	kfree(curr);
+	return ret;
+}
+
+static void mib_wraparound_timer_poll(unsigned long data)
+{
+	int i;
+	dp_subif_t subif;
+#define START_PORT_ID 0
+	static int port = START_PORT_ID;	/*start from port 1, not 0 since 0 is no device registered */
+
+	subif.port_id = port;
+	subif.subif = 0;
+	/* update physical port mib only */
+	update_port_mib_lower_lvl(&subif, 0);
+	/* update vap if necessary */
+	if (port) {
+		for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+			subif.subif = set_vap(i);
+			/* update sub-interface/vap mib only */
+			if (update_vap_mib_lower_lvl(&subif, 0))
+				break;
+		}
+	}
+	port++;
+	if (port == PMAC_MAX_NUM)
+		port = START_PORT_ID;
+
+#ifndef THREAD_MODE
+	exp_timer.expires = jiffies + poll_interval;
+	add_timer(&exp_timer);
+#endif
+}
+
+static int update_vap_mib_lower_lvl(dp_subif_t *subif, u32 flag)
+{
+	int ret;
+	u8 vap;
+	int itf_index;
+	int itf_base;
+	struct mibs_low_lvl_vap *curr;
+	int port_id;
+
+	/*update struct pmac_port_info[subif->ep].net_mib */
+	if (!subif || (subif->port_id <= 0) || (subif->port_id >= PMAC_MAX_NUM))
+		return -1;
+
+	curr = kmalloc(sizeof(struct mibs_low_lvl_vap), GFP_ATOMIC);
+	if (!curr) {
+		PR_ERR("kmalloc failed to get %d bytes of memory\n",
+			sizeof(struct mibs_low_lvl_vap));
+		return -1;
+	}
+	memset(curr, 0, sizeof(*curr));
+	port_id = subif->port_id;
+	vap = get_vap(subif->subif);
+
+	/* get gsw PAE interface mib counter */
+	itf_base = get_gsw_interface_base(port_id);
+	if (itf_base < 0) {
+		ret = -1;
+		DP_DEBUG(DP_DBG_FLAG_MIB, "wrong itf_base(%d) for port %d\n",
+			itf_base, port_id);
+		goto EXIT;
+	}
+	itf_index = itf_base + vap;
+	if (itf_index >= MAX_RMON_ITF) {
+		ret = -1;
+		PR_ERR("wrong itf_index(%d) for port %d\n", itf_index,
+			port_id);
+		goto EXIT;
+	}
+	ret = get_gsw_itf_rmon(itf_index, GSWIP_R_DEV_NAME, &curr->gsw_if);
+	if (ret) {
+		curr->gsw_if = last_vap[port_id][vap].gsw_if; /*workaround first */
+		PR_ERR("get_gsw_itf_rmon failed for port/vap(%d/%d)", port_id,
+			vap);
+	}
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	/*get TMU mib */
+	tmu_hal_get_qos_mib_hook_fn_local = tmu_hal_get_qos_mib_hook_fn;
+	if (!tmu_hal_get_qos_mib_hook_fn_local) {
+		curr->tmu_qos = last_vap[port_id][vap].tmu_qos;
+	} else {
+		ret = tmu_hal_get_qos_mib_hook_fn_local(NULL, subif, -1, &curr->tmu_qos, 0);
+		if (ret) {
+			curr->tmu_qos = last_vap[port_id][vap].tmu_qos;
+			PR_ERR("tmu_hal_get_qos_mib_hook_fn failed for port.vap(%d.%d):%d\n",
+					port_id, vap, ret);
+		}
+	}
+	/*get MPE mib */
+	mpe_hal_get_netif_mib_hook_fn_local = mpe_hal_get_netif_mib_hook_fn;
+	if (!mpe_hal_get_netif_mib_hook_fn_local) {
+		curr->mpe = last_vap[port_id][vap].mpe;
+	} else {
+		ret = mpe_hal_get_netif_mib_hook_fn_local(NULL, subif, &curr->mpe, 0);
+		if (ret) {
+			curr->mpe = last_vap[port_id][vap].mpe;
+			PR_ERR("mpe_hal_get_netif_mib_hook_fn failed for port.vap(%d.%d):%d\n",
+					port_id, vap, ret);
+		}
+	}
+#endif
+	/*get driver mib */
+	ret = dp_get_drv_mib(subif, &curr->drv, DP_F_STATS_SUBIF);
+	if (ret)	/*workaroud */
+		curr->drv = last_vap[port_id][vap].drv;
+
+	ret = vap_mib_wraparound(subif, curr, &last_vap[port_id][vap]);
+EXIT:
+	kfree(curr);
+
+	return ret;
+}
+
+int dp_reset_sys_mib(u32 flag)
+{
+	dp_clear_netif_stats(NULL, NULL, 0);
+	return 0;
+}
+
+void proc_mib_timer_read(struct seq_file *s)
+{
+	SEQ_PRINTF(s, "\nMib timer interval is %u sec\n",
+		   (unsigned int)poll_interval / HZ);
+}
+
+ssize_t proc_mib_timer_write(struct file *file, const char *buf, size_t count,
+			     loff_t *ppos)
+{
+	int len, num;
+	char str[64];
+	char *param_list[2];
+#define MIN_POLL_TIME 2
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	poll_interval = dp_atoi(param_list[0]);
+
+	if (poll_interval < MIN_POLL_TIME)
+		poll_interval = MIN_POLL_TIME;
+
+	poll_interval *= HZ;
+#ifndef THREAD_MODE
+	mod_timer(&exp_timer, jiffies + poll_interval);
+#endif
+	PRINTK("new poll_interval=%u sec\n",
+	       (unsigned int)poll_interval / HZ);
+	return count;
+}
+
+static unsigned int proc_mib_port_start_id = 1;
+static unsigned int proc_mib_port_end_id = PMAC_MAX_NUM - 1;
+int proc_mib_inside_dump(struct seq_file *s, int pos)
+{
+	int ret;
+	dp_subif_t subif;
+	struct rtnl_link_stats64 net_mib;
+
+	SEQ_PRINTF(s, "EP=%d\n", pos);
+	/*l */
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxGoodPkts",
+		   last[pos].l.nRxGoodPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxFCSErrorPkts",
+		   last[pos].l.nRxFCSErrorPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxUnderSizeGoodPkts",
+		   last[pos].l.nRxUnderSizeGoodPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxOversizeGoodPkts",
+		   last[pos].l.nRxOversizeGoodPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxUnderSizeErrorPkts",
+		   last[pos].l.nRxUnderSizeErrorPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxOversizeErrorPkts",
+		   last[pos].l.nRxOversizeErrorPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxAlignErrorPkts",
+		   last[pos].l.nRxAlignErrorPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxDroppedPkts",
+		   last[pos].l.nRxDroppedPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxFilteredPkts",
+		   last[pos].l.nRxFilteredPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nRxGoodPkts",
+		   last[pos].l.nTxGoodPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nTxDroppedPkts",
+		   last[pos].l.nTxDroppedPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.l.nTxCollCount",
+		   last[pos].l.nTxCollCount);
+	/*r */
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxGoodPkts",
+		   last[pos].r.nRxGoodPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxFCSErrorPkts",
+		   last[pos].r.nRxFCSErrorPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxUnderSizeGoodPkts",
+		   last[pos].r.nRxUnderSizeGoodPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxOversizeGoodPkts",
+		   last[pos].r.nRxOversizeGoodPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxUnderSizeErrorPkts",
+		   last[pos].r.nRxUnderSizeErrorPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxOversizeErrorPkts",
+		   last[pos].r.nRxOversizeErrorPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxAlignErrorPkts",
+		   last[pos].r.nRxAlignErrorPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxDroppedPkts",
+		   last[pos].r.nRxDroppedPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.r.nRxFilteredPkts",
+		   last[pos].r.nRxFilteredPkts);
+	/*redirct */
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.redir.nRxPktsCount",
+		   last[pos].redir.nRxPktsCount);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.redir.nRxDiscPktsCount",
+		   last[pos].redir.nRxDiscPktsCount);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.redir.nTxPktsCount",
+		   last[pos].redir.nTxPktsCount);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.redir.nTxDiscPktsCount",
+		   last[pos].redir.nTxDiscPktsCount);
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	/*checksum */
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.tmu_chksum.deqPkts",
+		   last[pos].tmu_chksum.deqPkts);
+	SEQ_PRINTF(s, "  %-45s=%40u\n", "last.tmu_chksum.deqBytes",
+		   last[pos].tmu_chksum.deqBytes);
+#endif
+	/*mib array */
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_good_pkts",
+		   aggregate_mib[pos].curr.rx_good_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_drop_pkts_pae",
+		   aggregate_mib[pos].curr.rx_drop_pkts_pae);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_disc_pkts_redir",
+		   aggregate_mib[pos].curr.rx_disc_pkts_redir);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_drop_pkts",
+		   aggregate_mib[pos].curr.rx_drop_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_drop_pkts_pae",
+		   aggregate_mib[pos].curr.rx_drop_pkts_pae);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_disc_pkts_redir",
+		   aggregate_mib[pos].curr.rx_disc_pkts_redir);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_fcs_err_pkts",
+		   aggregate_mib[pos].curr.rx_fcs_err_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_undersize_good_pkts",
+		   aggregate_mib[pos].curr.rx_undersize_good_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_oversize_good_pkts",
+		   aggregate_mib[pos].curr.rx_oversize_good_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_undersize_err_pkts",
+		   aggregate_mib[pos].curr.rx_undersize_err_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_oversize_err_pkts",
+		   aggregate_mib[pos].curr.rx_oversize_err_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_align_err_pkts",
+		   aggregate_mib[pos].curr.rx_align_err_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.rx_filter_pkts",
+		   aggregate_mib[pos].curr.rx_filter_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_good_pkts",
+		   aggregate_mib[pos].curr.tx_good_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_drop_pkts",
+		   aggregate_mib[pos].curr.tx_drop_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_drop_pkts_pae",
+		   aggregate_mib[pos].curr.tx_drop_pkts_pae);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_acm_drop_pkts",
+		   aggregate_mib[pos].curr.tx_acm_drop_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_acm_drop_pkts_pae",
+		   aggregate_mib[pos].curr.tx_acm_drop_pkts_pae);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_disc_pkts_redir",
+		   aggregate_mib[pos].curr.tx_disc_pkts_redir);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_coll_pkts",
+		   aggregate_mib[pos].curr.tx_coll_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_coll_pkts_pae",
+		   aggregate_mib[pos].curr.tx_coll_pkts_pae);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_tmu_drop_pkts",
+		   aggregate_mib[pos].curr.tx_tmu_drop_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n",
+		   "a_mib.curr.tx_tmu_csum_offload_bytes",
+		   aggregate_mib[pos].curr.tx_tmu_csum_offload_bytes);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n",
+		   "a_mib.curr.tx_tmu_csum_offload_pkts",
+		   aggregate_mib[pos].curr.tx_tmu_csum_offload_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_drv_drop_pkts",
+		   aggregate_mib[pos].curr.tx_drv_drop_pkts);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "a_mib.curr.tx_drv_error_pkts",
+		   aggregate_mib[pos].curr.tx_drv_error_pkts);
+	subif.port_id = pos;
+	subif.subif = 0;
+
+	if (dp_get_port_vap_mib(&subif, NULL, &net_mib, 0)) {
+		seq_puts(s, "dp_get_port_vap_mib failed\n");
+		goto EXIT;
+	}
+
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "aggregated rx_packets",
+		   net_mib.rx_packets);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "aggregated rx_dropped",
+		   net_mib.rx_dropped);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "aggregated tx_packets",
+		   net_mib.tx_packets);
+	SEQ_PRINTF(s, "  %-45s=%40llu\n", "aggregated tx_dropped",
+		   net_mib.tx_dropped);
+	ret = seq_puts(s, "\n");
+
+	if (ret)		/*buffer over flow and don't increase pos */
+		return pos;
+
+ EXIT:
+
+	if ((pos >= PMAC_MAX_NUM - 1) || (pos >= proc_mib_port_end_id))
+		return -1;	/*loop finished */
+
+	pos++;
+	return pos;
+}
+
+int proc_mib_inside_start(void)
+{
+	return proc_mib_port_start_id;
+}
+
+ssize_t proc_mib_inside_write(struct file *file, const char *buf,
+			      size_t count, loff_t *ppos)
+{
+	int len;
+	char str[64];
+	char *s[2] = { 0 };
+	unsigned int num[2] = { -1 };
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	if (dp_split_buffer(str, s, 2) < 2)
+		goto help;
+
+	if (s[0] && strlen(s[0]))
+		num[0] = dp_atoi(s[0]);
+
+	if (s[1] && strlen(s[1]))
+		num[1] = dp_atoi(s[1]);
+
+	set_start_end_id(num[0], num[1], PMAC_MAX_NUM - 1, PMAC_MAX_NUM - 1,
+			 0, PMAC_MAX_NUM - 1, &proc_mib_port_start_id,
+			 &proc_mib_port_end_id);
+	PRINTK("proc_mib_port_start_id=%u, proc_mib_port_end_id=%u\n",
+	       proc_mib_port_start_id, proc_mib_port_end_id);
+	return count;
+
+ help:
+	PRINTK("ussage echo start_id end_id > /proc/dp/mib_inside\n");
+	PRINTK
+	    ("       then display the selected port info via cat /proc/dp/mib_inside\n");
+	return count;
+}
+
+/*Note:
+*  if (flag & DP_F_STATS_SUBIF), get sub-interface/vap mib only
+*  otherwise, get physical port's mib
+*/
+int dp_get_port_vap_mib(dp_subif_t *subif, void *priv,
+		   struct rtnl_link_stats64 *net_mib, u32 flag)
+{
+	dp_subif_t tmp_subif;
+	unsigned int port_id, vap;
+	struct pmac_port_info *port_info;
+
+	if (!subif || (subif->port_id < 0) ||
+		(subif->port_id >= PMAC_MAX_NUM) ||
+		!net_mib)
+		return -1;
+	port_id = subif->port_id;
+	vap = get_vap(subif->subif);
+	port_info = get_port_info(port_id);
+	memset(net_mib, 0, sizeof(*net_mib));
+
+	if ((flag & DP_F_STATS_SUBIF)) {	/*only sub-interface/VAP's mib mib only*/
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "dp_get_port_vap_mib for port.vap(%u.%u) with flag=0x%x\n",
+			 subif->port_id, vap, flag);
+		if (update_vap_mib_lower_lvl(subif, flag))
+			PR_ERR
+			    ("update_vap_mib_lower_lvl failed for port %d VAP=%d\n",
+			     port_id, subif->subif);
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr_vap[vap].rx_disc_pkts_itf +
+		    aggregate_mib[port_id].curr_vap[vap].rx_disc_pkts_drv;
+		net_mib->rx_packets =
+		    aggregate_mib[port_id].curr_vap[vap].rx_pkts_itf -
+		    net_mib->rx_dropped;
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_itf +
+		    aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_tmu +
+		    aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_mpe +
+		    aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_drv;
+		net_mib->tx_packets =
+		    aggregate_mib[port_id].curr_vap[vap].tx_pkts_itf;
+
+		return 0;
+	}
+
+	/*Get physical port's MIB only */
+	DP_DEBUG(DP_DBG_FLAG_MIB,
+		"dp_get_port_vap_mib for physical port %u with flag=0x%x\n",
+		 port_id, flag);
+	tmp_subif.port_id = port_id;
+	tmp_subif.subif = 0;	/*for dp_get_drv_mib to get all mib of all VAPs */
+
+	if (update_port_mib_lower_lvl(&tmp_subif, 0))
+		PR_ERR
+		    ("update_port_mib_lower_lvl failed for port %d VAP=%d\n",
+		     tmp_subif.port_id, tmp_subif.subif);
+	if (port_id == 0) { /*not required by concept, for debugging only */
+		struct mibs_port *aggregate_cpu;
+
+		if (flag & DP_F_STATS_PAE_CPU)/*pae cpu*/
+			aggregate_cpu = &aggregate_mib_r[0].curr;
+		else /*gsw-l cpu */
+			aggregate_cpu = &aggregate_mib[0].curr;
+		net_mib->tx_errors =
+		    aggregate_cpu->tx_coll_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_coll_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_cpu->tx_coll_pkts);
+		net_mib->tx_dropped =
+		    aggregate_cpu->tx_drop_pkts +
+		    aggregate_cpu->tx_acm_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_drop_pkts(%llu) + tx_acm_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_cpu->tx_drop_pkts,
+			 aggregate_cpu->tx_drv_drop_pkts);
+
+		net_mib->tx_packets = aggregate_cpu->tx_good_pkts + net_mib->tx_dropped + net_mib->tx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_good_pkts(%llu) + tx_dropped(%llu) + tx_errors(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_cpu->tx_good_pkts,
+			 net_mib->tx_dropped, net_mib->tx_errors);
+
+		net_mib->tx_bytes = aggregate_cpu->tx_good_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_good_pkts(%llu)\n", port_id,
+			 net_mib->tx_bytes,
+			 aggregate_cpu->tx_good_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_cpu->rx_drop_pkts +
+		    aggregate_cpu->rx_filter_pkts +
+		    aggregate_cpu->rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + aggregate_cpu->rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_cpu->rx_drop_pkts,
+			 aggregate_cpu->rx_filter_pkts,
+			 aggregate_cpu->rx_drv_drop_pkts);
+
+		net_mib->rx_errors =
+		    aggregate_cpu->rx_fcs_err_pkts +
+		    aggregate_cpu->rx_undersize_good_pkts +
+		    aggregate_cpu->rx_undersize_err_pkts +
+		    aggregate_cpu->rx_oversize_good_pkts +
+		    aggregate_cpu->rx_oversize_err_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_good_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_good_pkts(%llu) + rx_oversize_err_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_cpu->rx_fcs_err_pkts,
+			 aggregate_cpu->rx_undersize_good_pkts,
+			 aggregate_cpu->rx_undersize_err_pkts,
+			 aggregate_cpu->rx_oversize_good_pkts,
+			 aggregate_cpu->rx_oversize_err_pkts);
+
+		net_mib->rx_packets =
+		    aggregate_cpu->rx_good_pkts +
+		    net_mib->rx_dropped + net_mib->rx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_cpu->rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors);
+
+		net_mib->rx_bytes =
+		    aggregate_cpu->rx_good_bytes +
+		    aggregate_cpu->rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_cpu->rx_good_bytes,
+			 aggregate_cpu->rx_bad_bytes);
+	} else if (port_id == WAN_EP) {
+		/*tx mib */
+		net_mib->tx_errors =
+		    aggregate_mib[port_id].curr.tx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_mib[port_id].curr.tx_drv_error_pkts);
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr.tx_disc_pkts_redir +
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_disc_pkts_redir(%llu) + tx_tmu_drop_pkts(%llu) + tx_mpe_drop_pkts(%llu) + tx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_disc_pkts_redir,
+			 aggregate_mib[port_id].curr.tx_tmu_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_mpe_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drv_drop_pkts);
+
+		net_mib->tx_packets =
+			aggregate_mib[port_id].curr.tx_pkts_redir +
+			net_mib->tx_dropped -
+			aggregate_mib[port_id].curr.tx_tmu_csum_offload_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_pkts_redir(%llu) + tx_dropped(%llu) - tx_tmu_csum_offload_pkts(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_mib[port_id].curr.tx_pkts_redir,
+			 net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_tmu_csum_offload_pkts);
+
+		net_mib->tx_bytes = aggregate_mib[port_id].curr.tx_bytes_redir -
+			aggregate_mib[port_id].curr.tx_tmu_csum_offload_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_bytes_redir(%llu) - tx_tmu_csum_offload_bytes(%llu)\n",
+			 port_id,
+			 net_mib->tx_bytes,
+			 aggregate_mib[port_id].curr.tx_bytes_redir,
+			 aggregate_mib[port_id].curr.tx_tmu_csum_offload_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr.rx_drop_pkts +
+		    aggregate_mib[port_id].curr.rx_filter_pkts +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_mib[port_id].curr.rx_drop_pkts,
+			 aggregate_mib[port_id].curr.rx_filter_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		/*ErrPktsCount = nRxFCSErrorPkts + nRxUnderSizeErrorPkts + nRxOverSizeErrorPkts + nRxAlignErrorPkts.*/
+		net_mib->rx_errors =
+		    aggregate_mib[port_id].curr.rx_fcs_err_pkts +
+		    aggregate_mib[port_id].curr.rx_undersize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_oversize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_align_err_pkts +
+		    aggregate_mib[port_id].curr.rx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_err_pkts(%llu) + rx_align_err_pkts(%llu) + rx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_error_pkts);
+
+		net_mib->rx_packets =
+		    aggregate_mib[port_id].curr.rx_good_pkts +
+		    net_mib->rx_dropped + net_mib->rx_errors +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_mib[port_id].curr.rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		net_mib->rx_bytes =
+		    aggregate_mib[port_id].curr.rx_good_bytes +
+		    aggregate_mib[port_id].curr.rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_mib[port_id].curr.rx_good_bytes,
+			 aggregate_mib[port_id].curr.rx_bad_bytes);
+	} else if (port_id < PAMC_LAN_MAX_NUM) {
+		/*tx mib */
+		net_mib->tx_errors =
+		    aggregate_mib[port_id].curr.tx_coll_pkts +
+		    aggregate_mib[port_id].curr.tx_coll_pkts_pae +
+		    aggregate_mib[port_id].curr.tx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_coll_pkts(%llu) + tx_coll_pkts_pae(%llu) + tx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_mib[port_id].curr.tx_coll_pkts,
+			 aggregate_mib[port_id].curr.tx_coll_pkts_pae,
+			 aggregate_mib[port_id].curr.tx_drv_error_pkts);
+
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr.tx_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_acm_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drop_pkts_pae +
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_drop_pkts(%llu) + tx_acm_drop_pkts(%llu) + tx_drop_pkts_pae(%llu) + tx_tmu_drop_pkts(%llu) + tx_tmu_drop_pkts(%llu)+ tx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_acm_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drop_pkts_pae,
+			 aggregate_mib[port_id].curr.tx_tmu_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_mpe_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drv_drop_pkts);
+
+		net_mib->tx_packets =
+		    aggregate_mib[port_id].curr.tx_good_pkts +
+		    net_mib->tx_dropped + net_mib->tx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_good_pkts(%llu) + tx_dropped(%llu) + tx_errors(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_mib[port_id].curr.tx_good_pkts,
+			 net_mib->tx_dropped, net_mib->tx_errors);
+
+		net_mib->tx_bytes = aggregate_mib[port_id].curr.tx_good_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_good_bytes(%llu)\n",
+			 port_id, net_mib->tx_bytes,
+			 aggregate_mib[port_id].curr.tx_good_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr.rx_drop_pkts +
+		    aggregate_mib[port_id].curr.rx_filter_pkts +
+		    aggregate_mib[port_id].curr.rx_drop_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + rx_drop_pkts_pae(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_mib[port_id].curr.rx_drop_pkts,
+			 aggregate_mib[port_id].curr.rx_filter_pkts,
+			 aggregate_mib[port_id].curr.rx_drop_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		/*ErrPktsCount = nRxFCSErrorPkts + nRxUnderSizeErrorPkts + nRxOverSizeErrorPkts + nRxAlignErrorPkts */
+		net_mib->rx_errors =
+		    aggregate_mib[port_id].curr.rx_fcs_err_pkts +
+		    aggregate_mib[port_id].curr.rx_undersize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_oversize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_align_err_pkts +
+		    aggregate_mib[port_id].curr.rx_fcs_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_undersize_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_oversize_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_align_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_err_pkts(%llu) + rx_align_err_pkts(%llu) + rx_fcs_err_pkts_pae(%llu) + rx_undersize_err_pkts_pae(%llu) + rx_oversize_err_pkts_pae(%llu) + rx_align_err_pkts_pae(%llu)+  rx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_drv_error_pkts);
+
+		net_mib->rx_packets =
+		    aggregate_mib[port_id].curr.rx_good_pkts +
+		    net_mib->rx_dropped + net_mib->rx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_mib[port_id].curr.rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors);
+
+		net_mib->rx_bytes =
+		    aggregate_mib[port_id].curr.rx_good_bytes +
+		    aggregate_mib[port_id].curr.rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_mib[port_id].curr.rx_good_bytes,
+			 aggregate_mib[port_id].curr.rx_bad_bytes);
+	} else if (!(port_info->alloc_flags & DP_F_FAST_DSL)) {	/*WIFI/LTE Directpath */
+		/*tx mib */
+		net_mib->tx_errors =
+		    aggregate_mib[port_id].curr.tx_drv_error_pkts +
+		    aggregate_mib[port_id].curr.tx_coll_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_drv_error_pkts(%llu) + tx_coll_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_mib[port_id].curr.tx_drv_error_pkts,
+			 aggregate_mib[port_id].curr.tx_coll_pkts);
+
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr.tx_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_acm_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_drop_pkts(%llu) + tx_acm_drop_pkts(%llu) + tx_tmu_drop_pkts(%llu) + tx_mpe_drop_pkts(%llu) + tx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_acm_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_tmu_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_mpe_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drv_drop_pkts);
+
+		net_mib->tx_packets =
+		    aggregate_mib[port_id].curr.tx_good_pkts +
+		    net_mib->tx_dropped + net_mib->tx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_good_pkts(%llu) + tx_dropped(%llu) + tx_errors(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_mib[port_id].curr.tx_good_pkts,
+			 net_mib->tx_dropped, net_mib->tx_errors);
+
+		net_mib->tx_bytes = aggregate_mib[port_id].curr.tx_good_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_good_bytes(%llu)\n",
+			 port_id, net_mib->tx_bytes,
+			 aggregate_mib[port_id].curr.tx_good_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr.rx_drop_pkts +
+		    aggregate_mib[port_id].curr.rx_filter_pkts +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_mib[port_id].curr.rx_drop_pkts,
+			 aggregate_mib[port_id].curr.rx_filter_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		/*ErrPktsCount = nRxFCSErrorPkts + nRxUnderSizeErrorPkts + nRxOverSizeErrorPkts + nRxAlignErrorPkts */
+		net_mib->rx_errors =
+			aggregate_mib[port_id].curr.rx_fcs_err_pkts +
+			aggregate_mib[port_id].curr.rx_undersize_err_pkts +
+			aggregate_mib[port_id].curr.rx_oversize_err_pkts +
+			aggregate_mib[port_id].curr.rx_align_err_pkts +
+			aggregate_mib[port_id].curr.rx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_err_pkts(%llu) + rx_align_err_pkts(%llu)  + rx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_error_pkts);
+
+		net_mib->rx_packets =
+			aggregate_mib[port_id].curr.rx_good_pkts +
+			net_mib->rx_dropped + net_mib->rx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_mib[port_id].curr.rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors);
+
+		net_mib->rx_bytes =
+		    aggregate_mib[port_id].curr.rx_good_bytes +
+		    aggregate_mib[port_id].curr.rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_mib[port_id].curr.rx_good_bytes,
+			 aggregate_mib[port_id].curr.rx_bad_bytes);
+	} else {		/*DSL */
+		/*Here datapath follow PTM algo. For ATM it should be handled by VRX518 directly.*/
+		net_mib->tx_errors =
+		    aggregate_mib[port_id].curr.tx_drv_error_pkts +
+		    aggregate_mib[port_id].curr.tx_coll_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_drv_error_pkts(%llu) + tx_coll_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_mib[port_id].curr.tx_drv_error_pkts,
+			 aggregate_mib[port_id].curr.tx_coll_pkts);
+
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr.tx_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_acm_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_drop_pkts(%llu) + tx_acm_drop_pkts(%llu) + tx_tmu_drop_pkts(%llu) + tx_mpe_drop_pkts(%llu) +tx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_acm_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_tmu_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_mpe_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drv_drop_pkts);
+
+		net_mib->tx_packets =
+		    aggregate_mib[port_id].curr.tx_good_pkts +
+		    net_mib->tx_dropped + net_mib->tx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_good_pkts(%llu) + tx_dropped(%llu) tx_errors(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_mib[port_id].curr.tx_good_pkts,
+			 net_mib->tx_dropped, net_mib->tx_errors);
+
+		net_mib->tx_bytes = aggregate_mib[port_id].curr.tx_good_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_good_bytes(%llu)\n",
+			 port_id, net_mib->tx_bytes,
+			 aggregate_mib[port_id].curr.tx_good_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr.rx_drop_pkts +
+		    aggregate_mib[port_id].curr.rx_filter_pkts +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_mib[port_id].curr.rx_drop_pkts,
+			 aggregate_mib[port_id].curr.rx_filter_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		/*ErrPktsCount = nRxFCSErrorPkts + nRxUnderSizeErrorPkts + nRxOverSizeErrorPkts + nRxAlignErrorPkts */
+		net_mib->rx_errors =
+		    aggregate_mib[port_id].curr.rx_fcs_err_pkts +
+		    aggregate_mib[port_id].curr.rx_undersize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_oversize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_align_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_err_pkts(%llu) + rx_align_err_pkts_pae(%llu) + rx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_drv_error_pkts);
+
+		net_mib->rx_packets =
+		    aggregate_mib[port_id].curr.rx_good_pkts +
+		    net_mib->rx_dropped + net_mib->rx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_mib[port_id].curr.rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors);
+
+		net_mib->rx_bytes =
+		    aggregate_mib[port_id].curr.rx_good_bytes +
+		    aggregate_mib[port_id].curr.rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_mib[port_id].curr.rx_good_bytes,
+			 aggregate_mib[port_id].curr.rx_bad_bytes);
+	}
+
+	return 0;
+}
+
+/*Clear GSW Interface MIB: only for sub interface/vap only  */
+int clear_gsw_itf_mib(dp_subif_t *subif, u32 flag)
+{
+	int start, end;
+	union gsw_var tmp;
+	int i;
+	struct pmac_port_info *port_info;
+
+	if (!(flag & DP_F_STATS_SUBIF))
+		return 0;
+
+	if (!subif) { /* clear all */
+		start = 0;
+		end = MAX_RMON_ITF;
+	} else if ((subif->port_id < 0) || (subif->port_id >= PMAC_MAX_NUM)) {
+		DP_DEBUG(DP_DBG_FLAG_MIB, "wrong port_id %d\n",
+			subif->port_id);
+		return -1;
+	}
+	port_info = get_port_info(subif->port_id);
+	if (!port_info->itf_info)
+		return 0;
+	start = port_info->itf_info->start + get_vap(subif->subif);
+	end = start + 1;
+	tmp.rmon.eRmonType = GSW_RMON_IF_TYPE;
+	for (i = start; i < end; i++) {
+		tmp.rmon.nRmonId = i;
+		if (tmp.rmon.nRmonId >= MAX_RMON_ITF) {
+			PR_ERR("Why Port[%d]'s interface ID %d so big\n",
+			       subif->port_id, tmp.rmon.nRmonId);
+			return -1;
+		}
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_RMON_CLEAR, (u32)&tmp);
+	}
+
+	return 0;
+}
+
+int dp_clear_netif_mib(dp_subif_t *subif, void *priv, u32 flag)
+{
+	unsigned int port_id, vap;
+	union gsw_var tmp;
+	int i;
+	dp_subif_t tmp_subif;
+
+	if (!subif) { /*clear all */
+		gsw_mib_reset(0, 0);
+		gsw_mib_reset(1, 0);
+		tmu_reset_mib_all(flag);
+		dp_clear_all_mib_inside(flag);
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+		tmu_hal_clear_qos_mib_hook_fn_local =
+			tmu_hal_clear_qos_mib_hook_fn;
+		if (tmu_hal_clear_qos_mib_hook_fn_local)
+			tmu_hal_clear_qos_mib_hook_fn_local(NULL, NULL, -1, 0);
+		mpe_hal_clear_if_mib_hook_fn_local =
+			mpe_hal_clear_if_mib_hook_fn;
+		if (mpe_hal_clear_if_mib_hook_fn_local)
+			mpe_hal_clear_if_mib_hook_fn_local(NULL, NULL, 0);
+		tmu_hal_clear_csum_ol_mib_hook_fn_local = tmu_hal_clear_csum_ol_mib_hook_fn;
+		if (tmu_hal_clear_csum_ol_mib_hook_fn_local)
+			tmu_hal_clear_csum_ol_mib_hook_fn_local(0);
+#endif
+		memset(aggregate_mib, 0, sizeof(aggregate_mib));
+		memset(aggregate_mib_r, 0, sizeof(aggregate_mib_r));
+		memset(&last, 0, sizeof(last));
+		memset(&last_vap, 0, sizeof(last_vap));
+		return 0;
+	}
+
+	if ((subif->port_id <= 0) ||
+		subif->port_id >= PMAC_MAX_NUM)
+		return -1;
+	port_id = subif->port_id;
+	vap = get_vap(subif->subif);
+
+	if ((flag & DP_F_STATS_SUBIF)) {
+		/*clear the specific subif mib counter */
+		clear_gsw_itf_mib(subif, flag);
+		dp_clear_mib(subif, 0);
+
+		/*workaround for port TMU/MPE MIB counter since this VAP's mib is cleared */
+		DP_DEBUG(DP_DBG_FLAG_MIB, "Clear aggregate_mib: %d/%d\n",
+				port_id, vap);
+		if (aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_tmu <=
+			aggregate_mib[port_id].curr.tx_tmu_drop_pkts)
+			aggregate_mib[port_id].curr.tx_tmu_drop_pkts -=
+				aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_tmu;
+		if (aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_mpe <=
+			aggregate_mib[port_id].curr.tx_mpe_drop_pkts)
+			aggregate_mib[port_id].curr.tx_mpe_drop_pkts -=
+				aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_mpe;
+		memset(&aggregate_mib[port_id].curr_vap[vap], 0,
+		       sizeof(aggregate_mib[port_id].curr_vap[vap]));
+		memset(&last_vap[port_id][vap], 0, sizeof(last_vap[port_id][vap]));
+		/*how about last[] & last_vap[] */
+		return 0;
+	}
+
+	/*Clear port based RMON mib */
+	DP_DEBUG(DP_DBG_FLAG_MIB,
+		 "dp_clear_netif_mib port %u mib flag=0x%x\n", port_id, flag);
+
+	/*First we delete all its VAP mib counter first since TMU/MPE port mib
+	* counter is based on its VAP's
+	*/
+	tmp_subif = *subif;
+	for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+		DP_DEBUG(DP_DBG_FLAG_MIB, "dp_clear_netif_mib: %d/%d\n",
+				tmp_subif.port_id, i);
+		tmp_subif.subif = set_vap(i);
+		dp_clear_netif_mib(&tmp_subif, NULL, DP_F_STATS_SUBIF);
+	}
+
+	memset(&aggregate_mib[port_id], 0, sizeof(aggregate_mib[port_id]));
+	memset(&last[port_id], 0, sizeof(last[port_id]));
+
+	if (port_id == WAN_EP) {
+		/*reset GSWIP-R rmon counters */
+		tmp.rmon.eRmonType = GSW_RMON_PORT_TYPE;
+		tmp.rmon.nRmonId = port_id;
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_RMON_CLEAR, (u32)&tmp);
+
+		/*reset GSWIP-R redirect counters */
+		tmp.rmon.eRmonType = GSW_RMON_REDIRECT_TYPE;
+		tmp.rmon.nRmonId = 0;
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_RMON_CLEAR, (u32)&tmp);
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+		tmu_hal_clear_csum_ol_mib_hook_fn_local =
+			tmu_hal_clear_csum_ol_mib_hook_fn;
+		if (tmu_hal_clear_csum_ol_mib_hook_fn_local)
+			tmu_hal_clear_csum_ol_mib_hook_fn_local(0);
+#endif
+		/*how about last[] & last_vap[] */
+	} else if (port_id < PAMC_LAN_MAX_NUM) {
+		/*reset GSWIP-L/R rmon counters */
+		tmp.rmon.eRmonType = GSW_RMON_PORT_TYPE;
+		tmp.rmon.nRmonId = port_id;
+		dp_gsw_kioctl(GSWIP_L_DEV_NAME, GSW_RMON_CLEAR, (u32)&tmp);
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_RMON_CLEAR, (u32)&tmp);
+	} else {		/*port 7 ~ 14 */
+		tmp.rmon.eRmonType = GSW_RMON_PORT_TYPE;
+		tmp.rmon.nRmonId = port_id;
+		dp_gsw_kioctl(GSWIP_R_DEV_NAME, GSW_RMON_CLEAR, (u32)&tmp);
+	}
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	tmu_hal_clear_qos_mib_hook_fn_local = tmu_hal_clear_qos_mib_hook_fn;
+	if (tmu_hal_clear_qos_mib_hook_fn_local)
+		tmu_hal_clear_qos_mib_hook_fn_local(NULL, subif, -1, flag);
+	mpe_hal_clear_if_mib_hook_fn_local =
+		mpe_hal_clear_if_mib_hook_fn_local;
+	if (mpe_hal_clear_if_mib_hook_fn_local)
+		mpe_hal_clear_if_mib_hook_fn_local(NULL, subif, flag);
+#endif
+
+	/*reset datapath's all vap mib */
+	subif->subif = -1;
+	dp_clear_mib(subif, 0);
+
+	/*reset GSW interface mib */
+	subif->subif = -1;
+	clear_gsw_itf_mib(subif, 0);
+	memset(&last[port_id], 0, sizeof(last[port_id]));
+	return 0;
+}
+
+int dp_get_netif_stats(struct net_device *dev, dp_subif_t *subif_id,
+		       struct rtnl_link_stats64 *stats, uint32_t flags)
+{
+	dp_subif_t subif;
+	int res;
+
+	if (subif_id) {
+		subif = *subif_id;
+	} else if (dev) {
+		res = dp_get_port_subitf_via_dev(dev, &subif);
+		if (res) {
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				 "dp_get_netif_stats fail:%s not registered yet to datapath\n",
+				 dev->name);
+			return -1;
+		}
+	} else {
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "dp_get_netif_stats: dev/subif_id both NULL\n");
+		return -1;
+	}
+	res = dp_get_port_vap_mib(&subif, NULL, stats, flags);
+	return res;
+}
+EXPORT_SYMBOL(dp_get_netif_stats);
+
+/* This API clears the maintained RMON on given SubIf, Port or for entire ports
+* and queues of PAE, GSW-L, TMU and CBM.
+* When both dev and subif_id is passed as NULL this API will reset all
+* counters in GSWIP-L, PAE, TMU, MPE and CBM
+* The flag carries the information about type of netdevice - Physical Interface
+* (mapping to port Id only) or Logical Sub-Interface netdevice
+* (mapping to combination of Port Id and SubInterface Id). It is conveyed
+* through a value of DP_F_STATS_SUBIFL.
+*/
+int32_t dp_clear_netif_stats(struct net_device *dev, dp_subif_t *subif_id,
+			     uint32_t flag)
+{
+	dp_subif_t subif;
+	int res = -1;
+
+	if (subif_id) {
+		res = dp_clear_netif_mib(subif_id, NULL, flag);
+		if (flag & DP_F_STATS_SUBIF)
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				"dp_clear_netif_stats for physical port %d\n",
+				subif_id->port_id);
+		else
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				"dp_clear_netif_stats for port.subif %d.%d\n",
+				subif_id->port_id, get_vap(subif_id->subif));
+	} else if (dev) {
+		res = dp_get_port_subitf_via_dev(dev, &subif);
+		if (res) {
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				 "%s is not registered yet to dp_clear_netif_stats\n",
+				 dev->name);
+			return -1;
+		}
+		res = dp_clear_netif_mib(&subif, NULL, flag);
+		if (flag & DP_F_STATS_SUBIF)
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				"dp_clear_netif_stats for physical port %d\n",
+				subif.port_id);
+		else
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				"dp_clear_netif_stats for port.subif %d.%d\n",
+				subif.port_id, get_vap(subif.subif));
+	} else {
+		res = dp_clear_netif_mib(NULL, NULL, flag);
+		DP_DEBUG(DP_DBG_FLAG_MIB, "Clear all\n");
+	}
+
+	return res;
+}
+EXPORT_SYMBOL(dp_clear_netif_stats);
+
+int proc_mib_port_start(void)
+{
+	return 0;
+}
+
+int proc_mib_port_dump(struct seq_file *s, int pos)
+{
+	int i = 0;
+	dp_subif_t subif;
+	struct rtnl_link_stats64 stats_mib = {0};
+
+	if (pos == 0) {
+		memset(&subif, 0, sizeof(subif));
+		SEQ_PRINTF(s, "%-12s %20s %20s %20s %20s\n", "PORT",
+			   "Tx_Pkts/", "Tx_Bytes/", "Tx_Drop_Pkts/",
+			   "Tx_Err_Pkts/");
+		SEQ_PRINTF(s, "%-12s %20s %20s %20s %20s\n", "    ",
+			   "Rx_Pkts", "Rx_Bytes", "Rx_Drop_Pkts",
+			   "Rx_Err_Pkts");
+		seq_puts(s,
+			   "-------------------------------------------------------------------------------------------------------\n");
+	}
+
+	i = pos;
+	subif.port_id = i;
+	if (dp_get_port_vap_mib(&subif, NULL, &stats_mib, 0) == 0) {
+		if (pos == 0)
+			SEQ_PRINTF(s, "%-7d(L  ) %20llu %20llu %20llu %20llu\n",
+			   subif.port_id,
+			   stats_mib.tx_packets,
+			   stats_mib.tx_bytes,
+			   stats_mib.tx_dropped,
+			   stats_mib.tx_errors);
+		else
+			SEQ_PRINTF(s, "%-12d %20llu %20llu %20llu %20llu\n",
+			   subif.port_id,
+			   stats_mib.tx_packets,
+			   stats_mib.tx_bytes,
+			   stats_mib.tx_dropped,
+			   stats_mib.tx_errors);
+		SEQ_PRINTF(s, "             %20llu %20llu %20llu %20llu\n",
+			   stats_mib.rx_packets,
+			   stats_mib.rx_bytes,
+			   stats_mib.rx_dropped,
+			   stats_mib.rx_errors);
+		seq_puts(s, "\n");
+	}
+
+	if ((pos == 0) &&
+		(dp_get_port_vap_mib(&subif, NULL, &stats_mib,
+			DP_F_STATS_PAE_CPU) == 0)) {
+		SEQ_PRINTF(s, "%-7d(pae) %20llu %20llu %20llu %20llu\n",
+			   subif.port_id,
+			   stats_mib.tx_packets,
+			   stats_mib.tx_bytes,
+			   stats_mib.tx_dropped,
+			   stats_mib.tx_errors);
+		SEQ_PRINTF(s, "             %20llu %20llu %20llu %20llu\n",
+			   stats_mib.rx_packets,
+			   stats_mib.rx_bytes,
+			   stats_mib.rx_dropped,
+			   stats_mib.rx_errors);
+		seq_puts(s, "\n");
+	}
+
+	pos++;
+
+	if (pos > (PMAC_MAX_NUM - 1)) {
+		pos = -1;	/*end of the loop */
+		/* check GSWIP whether redirect enabled or not */
+		if (!gsw_eth_wan_redirect_status())
+			SEQ_PRINTF(s, "Note: Ethernet WAN redirect is not enabled. Its MIB algo not work\n");
+	}
+
+	return pos;
+}
+
+
+ssize_t proc_mib_port_write(struct file *file, const char *buf, size_t count,
+		      loff_t *ppos)
+{
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+	int len;
+	char str[64];
+	int i, num, res;
+	char *param_list[10];
+	struct pmac_port_info *port;
+	dp_subif_t tmp;
+	static struct tmu_hal_qos_stats qos_stats;
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 1)
+		goto help;
+	memset(&qos_stats, 0, sizeof(qos_stats));
+	if (dp_strcmpi(param_list[0], "qos_mib") == 0) {
+		tmu_hal_get_qos_mib_hook_fn_local = tmu_hal_get_qos_mib_hook_fn;
+		if (!tmu_hal_get_qos_mib_hook_fn_local) {
+			PRINTK("tmu_hal_get_qos_mib_hook_fn NULL\n");
+			return count;
+		}
+		tmp.port_id = 15;
+		port = get_port_info(tmp.port_id);
+		for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+			if (!port->subif_info[i].flags)
+				continue;
+			else {
+				tmp.subif = set_vap(i);
+				res = tmu_hal_get_qos_mib_hook_fn_local(NULL, &tmp, -1,
+					&qos_stats, 0);
+			}
+			if (res)
+				PRINTK("tmu_hal_get_qos_mib_hook_fn failed\n");
+			else
+				PRINTK("qos_mib[%d/%d]: drop_pkts=%u  drop_bytes=%u\n", tmp.port_id,
+					get_vap(tmp.subif),
+					qos_stats.dropPkts,
+					qos_stats.dropBytes);
+		}
+	} else if (dp_strcmpi(param_list[0], "csum_mib") == 0) {
+		tmu_hal_get_csum_ol_mib_hook_fn_local = tmu_hal_get_csum_ol_mib_hook_fn;
+		if (!tmu_hal_get_csum_ol_mib_hook_fn_local) {
+			PRINTK("tmu_hal_get_csum_ol_mib_hook_fn NULL\n");
+			return count;
+		}
+		res = tmu_hal_get_csum_ol_mib_hook_fn_local(&qos_stats, 0);
+		if (res)
+			PRINTK("tmu_hal_get_csum_ol_mib_hook_fn failed\n");
+		else
+			PRINTK("csum_mib: deqPkts=%u  deqBytes=%u\n",
+			qos_stats.deqPkts,
+			qos_stats.deqBytes);
+
+	} else if (dp_strcmpi(param_list[0], "qos_mib_clear") == 0) {
+		mpe_hal_clear_if_mib_hook_fn_local = mpe_hal_clear_if_mib_hook_fn;
+		if (!mpe_hal_clear_if_mib_hook_fn_local) {
+			PRINTK("mpe_hal_clear_if_mib_hook_fn NULL\n");
+			return count;
+		}
+		res = mpe_hal_clear_if_mib_hook_fn_local(NULL, NULL, -1);
+		if (res)
+			PRINTK("mpe_hal_clear_if_mib_hook_fn failed\n");
+		else
+			PRINTK("mpe_hal_clear_if_mib_hook_fn(NULL, NULL, -1) done\n");
+
+	} else if (dp_strcmpi(param_list[0], "csum_mib_clear") == 0) {
+		tmu_hal_clear_csum_ol_mib_hook_fn_local = tmu_hal_clear_csum_ol_mib_hook_fn;
+		if (!tmu_hal_clear_csum_ol_mib_hook_fn_local) {
+			PRINTK("tmu_hal_clear_csum_ol_mib_hook_fn NULL\n");
+			return count;
+		}
+		res = tmu_hal_clear_csum_ol_mib_hook_fn_local(0);
+		if (res)
+			PRINTK("tmu_hal_clear_csum_ol_mib_hook_fn failed\n");
+		else
+			PRINTK("tmu_hal_clear_csum_ol_mib_hook_fn(0) done\n");
+
+	} else
+		goto help;
+#else
+	return count;
+#endif
+	return count;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPW_MIB
+ help:
+	PRINTK("usage:\n");
+	PRINTK("  test qos_mib  api:      echo qos_mib        > /proc/dp/mib_port\n");
+	PRINTK("  test csum_mib api       echo csum_mib       > /proc/dp/mib_port\n");
+	PRINTK("  test cear_qos_mib  api  echo qos_mib_clear  > /proc/dp/mib_port\n");
+	PRINTK("  test csum_mib_clear api echo csum_mib_clear > /proc/dp/mib_port\n");
+
+	return count;
+#endif
+}
+
+
+int proc_mib_vap_dump(struct seq_file *s, int pos)
+{
+	int j = 0;
+	int ret = 0, f_newline = 0;
+	dp_subif_t subif;
+	struct rtnl_link_stats64 stats_mib;
+	int itf_base;
+	struct pmac_port_info *port;
+
+	if ((pos > (PMAC_MAX_NUM - 1)) || (pos > proc_mib_vap_end_id)) {
+		pos = -1;	/*end of the loop */
+		return pos;
+	}
+
+	if (pos == proc_mib_vap_start_id) {
+		memset(&subif, 0, sizeof(dp_subif_t));
+		memset(&stats_mib, 0, sizeof(stats_mib));
+		SEQ_PRINTF(s, "%5s/%3s %5s %22s %22s %22s %22s\n", "Port",
+			   "VAP", "IfID", "Rx_PKTS", "Tx_PKTS",
+			   "Rx_DROP_PKTS", "Tx_DROP_PKTS\n");
+	}
+	port = get_port_info(pos);
+
+	if (!port || !port->status)		/*not allocated yet*/
+		goto EXIT;
+
+	for (j = 0; j <= (MAX_SUBIF_PER_PORT - 1); j++) {
+		subif.port_id = pos;
+		subif.subif = set_vap(j);
+		itf_base = get_gsw_interface_base(pos);
+		if (itf_base < 0)	/*no GSW itf assigned*/
+			continue;
+		if (!port->subif_info[j].flags)	/*not registered yet*/
+			continue;
+		if (dp_get_port_vap_mib
+		    (&subif, NULL, &stats_mib,
+		     DP_F_STATS_SUBIF) == 0) {
+			SEQ_PRINTF(s,
+				   "%5d/%03d %5d %22llu %22llu %22llu %22llu\n",
+				   subif.port_id, j, itf_base + j,
+				   stats_mib.rx_packets, stats_mib.tx_packets,
+				   stats_mib.rx_dropped,
+				   stats_mib.tx_dropped);
+			seq_puts(s, "\n");
+			f_newline = 1;
+		} else
+			SEQ_PRINTF(s, "dp_get_port_vap_mib failed for port/vap %d/%d\n",
+					pos, j);
+
+	}
+
+	if (f_newline)
+		ret = seq_puts(s, "\n");
+
+	if (ret)		/*buffer over flow and don't increase pos */
+		return pos;
+
+ EXIT:
+	pos++;
+	return pos;
+}
+
+int proc_mib_vap_start(void)
+{
+	return proc_mib_vap_start_id;
+}
+
+ssize_t proc_mib_vap_write(struct file *file, const char *buf, size_t count,
+			   loff_t *ppos)
+{
+	int len;
+	char str[64];
+	char *param_list[2] = { 0 };
+	unsigned int num[2] = { -1 };
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	if (dp_split_buffer(str, param_list, ARRAY_SIZE(param_list)) < 2)
+		goto help;
+
+	if (param_list[0] && strlen(param_list[0]))
+		num[0] = dp_atoi(param_list[0]);
+
+	if (param_list[1] && strlen(param_list[1]))
+		num[1] = dp_atoi(param_list[1]);
+
+	set_start_end_id(num[0], num[1], MAX_SUBIF_PER_PORT - 1,
+			 MAX_SUBIF_PER_PORT - 1, 0, -1,
+			 &proc_mib_vap_start_id, &proc_mib_vap_end_id);
+	PRINTK("proc_mib_vap_start_id=%d, proc_mib_vap_end_id=%d\n",
+	       proc_mib_vap_start_id, proc_mib_vap_end_id);
+	return count;
+
+ help:
+	PRINTK("usage: echo start_id end_id > /proc/dp/mib_vap\n");
+	return count;
+}
+
+#ifdef THREAD_MODE
+int mib_wraparound_thread(void *data)
+{
+	while (1) {
+		mib_wraparound_timer_poll(0);
+		msleep(poll_interval / HZ * 1000 / PMAC_MAX_NUM / 2);
+		DP_DEBUG(DP_DBG_FLAG_MIB, "mib_wraparound_thread\n");
+	}
+}
+#endif
+
+int dp_mib_init(void)
+{
+	spin_lock_init(&dp_mib_lock);
+	memset(&aggregate_mib, 0, sizeof(aggregate_mib));
+	memset(&last, 0, sizeof(last));
+	memset(&last_vap, 0, sizeof(last_vap));
+
+#ifdef THREAD_MODE
+	thread = kthread_run(mib_wraparound_thread, 0, "dp_mib");
+#else
+	init_timer_on_stack(&exp_timer);
+	exp_timer.expires = jiffies + poll_interval;
+	exp_timer.data = 0;
+	exp_timer.function = mib_wraparound_timer_poll;
+	add_timer(&exp_timer);
+	PRINTK("dp_mib_init done\n");
+#endif
+	return 0;
+}
+
+void dp_mib_exit(void)
+{
+#ifdef THREAD_MODE
+	if (thread)
+		kthread_stop(thread);
+#else
+	del_timer(&exp_timer);
+#endif
+}
+
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_mib.h b/drivers/net/ethernet/lantiq/datapath/datapath_mib.h
new file mode 100644
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_mib.h
@@ -0,0 +1,6 @@
+#ifndef DATAPATH_MIB_H_XXX
+#define DATAPATH_MIB_H_XXX
+
+int dp_reset_mib(u32 flag);
+
+#endif
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_pmac.c b/drivers/net/ethernet/lantiq/datapath/datapath_pmac.c
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_pmac.c
@@ -0,0 +1,443 @@
+#include <linux/kernel.h>	/* printk() */
+#include <linux/types.h>	/* size_t */
+#include <linux/etherdevice.h>
+#include <net/lantiq_cbm.h>
+#include <net/lantiq_cbm_api.h>
+#include <net/datapath_api.h>
+#include "datapath.h"
+#include <asm/gic.h>
+
+int dp_gsw_kioctl(char *dev_name, u32 command, u32 arg)
+{
+	GSW_API_HANDLE handle;
+	int res;
+
+	handle = gsw_api_kopen(dev_name);
+	if (!handle) {
+		PR_ERR("Failed to call API gsw_api_kopen for %s\n", dev_name);
+		return -1;
+	}
+	res = gsw_api_kioctl(handle, command, arg);
+	if (res != GSW_statusOk) {
+		PR_ERR("Failed to call gsw_api_kioctl with return value %d\n",
+		       res);
+		return -1;
+	}
+	return 0;
+}
+
+/*This API is only for GSWIP-R PMAC modification, not for GSWIP-L */
+int32_t dp_pmac_set(uint32_t port, dp_pmac_cfg_t *pmac_cfg)
+{
+	GSW_PMAC_Eg_Cfg_t egcfg;
+	GSW_PMAC_Ig_Cfg_t igcfg;
+	int i, j, k;
+	uint32_t flag = 0;
+	cbm_dq_port_res_t dqport;
+	int32_t ret;
+	GSW_API_HANDLE gswr_r;
+	GSW_PMAC_Glbl_Cfg_t pmac_glb;
+
+	if (!pmac_cfg || !port) {
+		PR_ERR("dp_pmac_set:wrong parameter(pmac_cfg/port NULL)\n");
+		return -1;
+	}
+
+	if (!pmac_cfg->ig_pmac_flags && !pmac_cfg->eg_pmac_flags)
+		return 0;
+
+	memset(&dqport, 0, sizeof(cbm_dq_port_res_t));
+
+	/* Get GSWIP device hander */
+	if ((port >= 1) && (port <= 6))
+		gswr_r = gsw_api_kopen("/dev/switch_api/0");
+	else
+		gswr_r = gsw_api_kopen("/dev/switch_api/1");
+
+	if (gswr_r == 0) {
+		PR_ERR("dp_pmac_set:Failed to open %s!!\n", GSWIP_R_DEV_NAME);
+		return -1;
+	}
+
+	/*set ingress port via DMA tx channel */
+	if (pmac_cfg->ig_pmac_flags) {
+
+		/*Read back igcfg from gsw first */
+		ret = cbm_dequeue_port_resources_get(port, &dqport, flag);
+
+		if (ret == -1) {
+			PR_ERR("cbm_dequeue_port_resources_get failed\n");
+			return -1;
+		}
+
+		memset(&igcfg, 0, sizeof(GSW_PMAC_Ig_Cfg_t));
+
+		for (i = 0; i < dqport.num_deq_ports; i++) {
+			igcfg.nTxDmaChanId = dqport.deq_info[i].dma_tx_chan;
+			gsw_api_kioctl(gswr_r, GSW_PMAC_IG_CFG_GET,
+				       (u32) &igcfg);
+
+			/*update igcfg and write back to gsw */
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_ERR_DISC)
+				igcfg.bErrPktsDisc =
+				    pmac_cfg->ig_pmac.err_disc;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PRESENT)
+				igcfg.bPmacPresent = pmac_cfg->ig_pmac.pmac;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_SUBIF)
+				igcfg.bSubIdDefault =
+				    pmac_cfg->ig_pmac.def_pmac_subifid;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_SPID)
+				igcfg.bSpIdDefault =
+				    pmac_cfg->ig_pmac.def_pmac_src_port;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_CLASSENA)
+				igcfg.bClassEna =
+				    pmac_cfg->ig_pmac.def_pmac_en_tc;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_CLASS)
+				igcfg.bClassDefault =
+				    pmac_cfg->ig_pmac.def_pmac_tc;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMAPENA)
+				igcfg.bPmapEna =
+				    pmac_cfg->ig_pmac.def_pmac_en_pmap;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMAP)
+				igcfg.bPmapDefault =
+				    pmac_cfg->ig_pmac.def_pmac_pmap;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR1)
+				igcfg.defPmacHdr[0] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[0];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR2)
+				igcfg.defPmacHdr[1] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[1];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR3)
+				igcfg.defPmacHdr[2] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[2];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR4)
+				igcfg.defPmacHdr[3] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[3];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR5)
+				igcfg.defPmacHdr[4] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[4];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR6)
+				igcfg.defPmacHdr[5] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[5];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR7)
+				igcfg.defPmacHdr[6] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[6];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR8)
+				igcfg.defPmacHdr[7] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[7];
+
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "\nPMAC %d igcfg configuration:\n", port);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.nTxDmaChanId=%d\n",
+				 igcfg.nTxDmaChanId);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bErrPktsDisc=%d\n",
+				 igcfg.bErrPktsDisc);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bPmapDefault=%d\n",
+				 igcfg.bPmapDefault);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bPmapEna=%d\n",
+				 igcfg.bPmapEna);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bClassDefault=%d\n",
+				 igcfg.bClassDefault);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bClassEna=%d\n",
+				 igcfg.bClassEna);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bSubIdDefault=%d\n",
+				 igcfg.bSubIdDefault);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bSpIdDefault=%d\n",
+				 igcfg.bSpIdDefault);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bPmacPresent=%d\n",
+				 igcfg.bPmacPresent);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.defPmacHdr=");
+
+			for (k = 0;
+			     k <
+			     sizeof(igcfg.defPmacHdr) /
+			     sizeof(igcfg.defPmacHdr[0]); k++)
+				DP_DEBUG(DP_DBG_FLAG_DBG, "0x%x ",
+					 igcfg.defPmacHdr[k]);
+
+			DP_DEBUG(DP_DBG_FLAG_DBG, "\n");
+
+			gsw_api_kioctl(gswr_r, GSW_PMAC_IG_CFG_SET,
+				       (u32) &igcfg);
+		}
+
+		if (dqport.deq_info)
+			kfree(dqport.deq_info);
+	}
+
+	/*set egress port via pmac port id */
+	if (!pmac_cfg->eg_pmac_flags)
+		return 0;
+
+	for (i = 0; i <= 15; i++) {	/*traffic class */
+		for (j = 0; j <= 3; j++) {	/* flow */
+			/*read back egcfg first from gsw */
+			memset(&egcfg, 0, sizeof(GSW_PMAC_Eg_Cfg_t));
+			egcfg.nDestPortId = port;
+			egcfg.nTrafficClass = i;
+			egcfg.nFlowIDMsb = j;
+
+			memset(&pmac_glb, 0, sizeof(pmac_glb));
+			gsw_api_kioctl(gswr_r, GSW_PMAC_GLBL_CFG_GET,
+				       (u32) &pmac_glb);
+			egcfg.bProcFlagsSelect = pmac_glb.bProcFlagsEgCfgEna;
+			DP_DEBUG(DP_DBG_FLAG_DBG, "bProcFlagsSelect=%u\n",
+				 egcfg.bProcFlagsSelect);
+
+			/*update egcfg and write back to gsw */
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_FCS)
+				egcfg.bFcsEna = pmac_cfg->eg_pmac.fcs;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_L2HDR_RM) {
+				egcfg.bRemL2Hdr = pmac_cfg->eg_pmac.rm_l2hdr;
+				egcfg.numBytesRem =
+				    pmac_cfg->eg_pmac.num_l2hdr_bytes_rm;
+			}
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_PMAC)
+				egcfg.bPmacEna = pmac_cfg->eg_pmac.pmac;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_RXID)
+				egcfg.nRxDmaChanId =
+				    pmac_cfg->eg_pmac.rx_dma_chan;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_RESDW1)
+				egcfg.nResDW1 = pmac_cfg->eg_pmac.res_dw1;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_RES1DW0)
+				egcfg.nRes1DW0 = pmac_cfg->eg_pmac.res1_dw0;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_RES2DW0)
+				egcfg.nRes2DW0 = pmac_cfg->eg_pmac.res2_dw0;
+
+			/*if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_TCENA)
+			*  egcfg.bTCEnable = pmac_cfg->eg_pmac.tc_enable;
+			*/
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_DECFLG)
+				egcfg.bDecFlag = pmac_cfg->eg_pmac.dec_flag;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_ENCFLG)
+				egcfg.bEncFlag = pmac_cfg->eg_pmac.enc_flag;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_MPE1FLG)
+				egcfg.bMpe1Flag = pmac_cfg->eg_pmac.mpe1_flag;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_MPE2FLG)
+				egcfg.bMpe2Flag = pmac_cfg->eg_pmac.mpe2_flag;
+
+			if (dp_dbg_flag & DP_DBG_FLAG_DBG) {
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "\nPMAC %d egcfg configuration:\n",
+					 port);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nRxDmaChanId=%d\n",
+					 egcfg.nRxDmaChanId);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bRemL2Hdr=%d\n",
+					 egcfg.bRemL2Hdr);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.numBytesRem=%d\n",
+					 egcfg.numBytesRem);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bFcsEna=%d\n", egcfg.bFcsEna);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bPmacEna=%d\n",
+					 egcfg.bPmacEna);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nResDW1=%d\n", egcfg.nResDW1);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nRes1DW0=%d\n",
+					 egcfg.nRes1DW0);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nRes2DW0=%d\n",
+					 egcfg.nRes2DW0);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nDestPortId=%d\n",
+					 egcfg.nDestPortId);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bTCEnable=%d\n",
+					 egcfg.bTCEnable);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nTrafficClass=%d\n",
+					 egcfg.nTrafficClass);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nFlowIDMsb=%d\n",
+					 egcfg.nFlowIDMsb);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bDecFlag=%d\n",
+					 egcfg.bDecFlag);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bEncFlag=%d\n",
+					 egcfg.bEncFlag);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bMpe1Flag=%d\n",
+					 egcfg.bMpe1Flag);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bMpe2Flag=%d\n",
+					 egcfg.bMpe2Flag);
+			}
+
+			gsw_api_kioctl(gswr_r, GSW_PMAC_EG_CFG_SET,
+				       (u32) &egcfg);
+			;
+		}
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(dp_pmac_set);
+
+/*flag: bit 0 for cpu
+		bit 1 for mpe1,bit 2 for mpe2, bit 3 for mpe3;
+*/
+#define GSW_L_BASE_ADDR        (0xBC000000)
+#define GSW_R_BASE_ADDR        (0xBA000000)
+#define FDMA_PASR_ADDR         (0xA47)
+
+void dp_set_gsw_parser(uint8_t flag, uint8_t cpu, uint8_t mpe1, uint8_t mpe2,
+		       uint8_t mpe3)
+{
+	/*later it should use gsw_api_kioctl(gswl, GSW_CPU_PORT_CFG_SET,..) */
+	u32 v = REG32(GSW_R_BASE_ADDR + FDMA_PASR_ADDR * 4);
+
+	DP_DEBUG(DP_DBG_FLAG_DBG,
+		 "Old FDMA_PASR register (0x%x) value: 0x%x\n",
+		 FDMA_PASR_ADDR, v);
+	DP_DEBUG(DP_DBG_FLAG_DBG, "flag=0x%x cpu=%d mpe1/2/3=%d/%d/%d\n",
+		 flag, cpu, mpe1, mpe2, mpe3);
+
+	if (flag & F_MPE_NONE)
+		v = (v & ~(0x3 << 0)) | (cpu << 0);
+
+	if (flag & F_MPE1_ONLY)
+		v = (v & ~(0x3 << 2)) | (mpe1 << 2);
+
+	if (flag & F_MPE2_ONLY)
+		v = (v & ~(0x3 << 4)) | (mpe2 << 4);
+
+	if (flag & F_MPE1_MPE2)
+		v = (v & ~(0x3 << 6)) | (mpe3 << 6);
+
+	REG32(GSW_R_BASE_ADDR + FDMA_PASR_ADDR * 4) = v;
+	DP_DEBUG(DP_DBG_FLAG_DBG,
+		 "New FDMA_PASR register (0x%x) value: 0x%x\n",
+		 FDMA_PASR_ADDR, v);
+
+	dp_parser_info_refresh(v, 0);
+}
+EXPORT_SYMBOL(dp_set_gsw_parser);
+
+void dp_get_gsw_parser(uint8_t *cpu, uint8_t *mpe1, uint8_t *mpe2,
+		       uint8_t *mpe3)
+{
+	u32 v = REG32(GSW_R_BASE_ADDR + FDMA_PASR_ADDR * 4);
+
+	DP_DEBUG(DP_DBG_FLAG_DBG, "FDMA_PASR register (0x%x) value: 0x%x\n",
+		 FDMA_PASR_ADDR, v);
+	dp_parser_info_refresh(v, 1);
+
+	if (cpu) {
+		*cpu = (v >> 0) & 0x3;
+		DP_DEBUG(DP_DBG_FLAG_DBG, "  cpu=%d \n", *cpu);
+	}
+
+	if (mpe1) {
+		*mpe1 = (v >> 2) & 0x3;
+		DP_DEBUG(DP_DBG_FLAG_DBG, "  mpe1=%d \n", *mpe1);
+	}
+
+	if (mpe2) {
+		*mpe2 = (v >> 4) & 0x3;
+		DP_DEBUG(DP_DBG_FLAG_DBG, "  mpe2=%d \n", *mpe2);
+	}
+
+	if (mpe3) {
+		*mpe3 = (v >> 6) & 0x3;
+		DP_DEBUG(DP_DBG_FLAG_DBG, "  mpe3=%d \n", *mpe3);
+	}
+}
+EXPORT_SYMBOL(dp_get_gsw_parser);
+
+char *parser_flag_str(uint8_t f)
+{
+	if (f == DP_PARSER_F_DISABLE)
+		return "No Parser";
+	else if (f == DP_PARSER_F_HDR_ENABLE)
+		return "Parser Flag only";
+	else if (f == DP_PARSER_F_HDR_OFFSETS_ENABLE)
+		return "Parser Full";
+	else
+		return "Reserved";
+}
+
+int gsw_mib_reset(int dev, u32 flag)
+{
+	GSW_API_HANDLE gsw_handle = 0;
+	char *dev_name;
+	int ret;
+	GSW_RMON_clear_t rmon_clear;
+
+	if (dev == 0)
+		dev_name = GSWIP_L_DEV_NAME;
+
+	else
+		dev_name = GSWIP_R_DEV_NAME;
+
+	gsw_handle = gsw_api_kopen(dev_name);
+
+	if (gsw_handle == 0) {
+		PR_ERR("Open %s FAILED !!\n", dev_name);
+		return -1;
+	}
+
+	rmon_clear.eRmonType = GSW_RMON_ALL_TYPE;
+	ret = gsw_api_kioctl(gsw_handle, GSW_RMON_CLEAR, (u32) &rmon_clear);
+
+	if (ret != GSW_statusOk) {
+		PR_ERR("R:GSW_RMON_CLEAR failed for GSW_RMON_ALL_TYPE\n");
+		return -1;
+	}
+#if 0
+
+	for (i = 0; i < portn; i++) {
+		rmon_clear.eRmonType = GSW_RMON_PORT_TYPE;
+		rmon_clear.nRmonId = i;
+		ret =
+		    gsw_api_kioctl(gsw_handle, GSW_RMON_CLEAR,
+				   (u32) &rmon_clear);
+
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_RMON_CLEAR failed:GSW_RMON_PORT_TYPE\n");
+			return -1;
+		}
+	}
+
+	GSW_RMON_ALL_TYPE rmon_clear.eRmonType = GSW_RMON_REDIRECT_TYPE;
+	ret = gsw_api_kioctl(gsw_handle, GSW_RMON_CLEAR, (u32) &rmon_clear);
+
+	if (ret != GSW_statusOk) {
+		PR_ERR
+		    ("R:GSW_RMON_CLEAR failed for GSW_RMON_REDIRECT_TYPE\n");
+		return -1;
+	}
+#endif
+	gsw_api_kclose(gsw_handle);
+	return ret;
+}
+EXPORT_SYMBOL(gsw_mib_reset);
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_pmac.h b/drivers/net/ethernet/lantiq/datapath/datapath_pmac.h
new file mode 100644
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_pmac.h
@@ -0,0 +1,17 @@
+#ifndef DATAPATH_PMAC_H_XXX
+#define DATAPATH_PMAC_H_XXX
+
+union gsw_var {
+	GSW_register_t reg;
+	GSW_QoS_meterCfg_t meter_cfg;
+	GSW_QoS_meterPort_t meter_port;
+	GSW_QoS_WRED_PortCfg_t wred_p;
+	GSW_QoS_WRED_QueueCfg_t wred_q;
+	GSW_QoS_WRED_Cfg_t wred_cfg;
+	GSW_RMON_clear_t rmon;
+	GSW_portCfg_t port_cfg;
+	GSW_PCE_rule_t pce;
+};
+int dp_gsw_kioctl(char *dev_name, u32 command, u32 arg);
+
+#endif
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_proc.c b/drivers/net/ethernet/lantiq/datapath/datapath_proc.c
new file mode 100644
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_proc.c
@@ -0,0 +1,4040 @@
+#include <linux/module.h>
+#include <lantiq.h>
+#include <net/datapath_proc_api.h>	/*for proc api */
+#include <net/datapath_api.h>
+#include "datapath_pmac.h"
+#include <net/drv_tmu_ll.h>
+#include <net/lantiq_cbm.h>
+#include <net/lantiq_cbm_api.h>
+#include <asm/ltq_vmb.h>	/*vmb */
+#include <asm/ltq_itc.h>	/*mips itc */
+#include <linux/list.h>
+#include <xway/switch-api/lantiq_gsw_api.h>
+#include <xway/switch-api/lantiq_gsw_flow.h>
+
+#include "../cbm/reg/fsqm.h"	/* hardcoded path  */
+
+#include "datapath.h"
+#include "datapath_mib.h"
+
+#define DP_PROC_NAME       "dp"
+#define DP_PROC_BASE       "/proc/"DP_PROC_NAME"/"
+#define DP_PROC_PARENT     ""
+
+#define DP_PROC_FILE_DBG   "dbg"
+#define DP_PROC_FILE_PORT   "port"
+#define DP_PROC_FILE_PARSER "parser"
+#define DP_PROC_FILE_RMON_PORTS  "rmon"
+#define DP_PROC_FILE_MEM "mem"
+#define DP_PROC_FILE_EP "ep"	/*EP/port ID info */
+#define DP_PROC_FILE_DPORT "dport"	/*TMU dequeue port info */
+#define DP_PROC_PRINT_MODE "print_mode"
+#define DP_PROC_FILE_CHECKSUM "checksum"
+#define DP_PROC_FILE_MIB_TIMER "mib_timer"
+#define DP_PROC_FILE_MIB_INSIDE "mib_inside"
+#define DP_PROC_FILE_MIBPORT "mib_port"
+#define DP_PROC_FILE_MIBVAP "mib_vap"
+#define DP_PROC_FILE_COC "coc"
+#define DP_PROC_FILE_COMMON_CMD "cmd"
+#define DP_PROC_FILE_CBM_BUF_TEST   "cbm_buf"
+#define DP_PROC_FILE_PCE  "pce"
+#define DP_PROC_FILE_ROUTE  "route"
+#define DP_PROC_FILE_PMAC  "pmac"
+
+
+#undef NIPQUAD
+#define NIPQUAD(addr) (\
+	((unsigned char *)&addr)[0], \
+	((unsigned char *)&addr)[1], \
+	((unsigned char *)&addr)[2], \
+	((unsigned char *)&addr)[3])
+
+#undef NIPQUAD_FMT
+#define NIPQUAD_FMT ("%u.%u.%u.%u")
+
+#undef NIP6
+#define NIP6(addr) (\
+	ntohs(((unsigned short *)addr)[0]), \
+	ntohs(((unsigned short *)addr)[1]), \
+	ntohs(((unsigned short *)addr)[2]), \
+	ntohs(((unsigned short *)addr)[3]), \
+	ntohs(((unsigned short *)addr)[4]), \
+	ntohs(((unsigned short *)addr)[5]), \
+	ntohs(((unsigned short *)addr)[6]), \
+	ntohs(((unsigned short *)addr)[7]))
+
+#undef NIP6_FMT
+#define NIP6_FMT ("%04x:%04x:%04x:%04x:%04x:%04x:%04x:%04x")
+
+#define smart_proc_printf(s, fmt, arg...) \
+	do { \
+		if (!s) \
+			PRINTK(fmt, ##arg); \
+		else \
+			SEQ_PRINTF(s, fmt, ##arg); \
+	} while (0)
+
+static ssize_t proc_port_write(struct file *file, const char *buf,
+			       size_t count, loff_t *ppos);
+static void proc_dbg_read(struct seq_file *s);
+static int proc_port_dump(struct seq_file *s, int pos);
+static ssize_t proc_dbg_write(struct file *, const char *, size_t, loff_t *);
+static void proc_parser_read(struct seq_file *s);
+static ssize_t proc_parser_write(struct file *, const char *, size_t,
+				 loff_t *);
+static int proc_gsw_rmon_port_start(void);
+static int proc_gsw_port_rmon_dump(struct seq_file *s, int pos);
+static ssize_t proc_gsw_rmon_write(struct file *file, const char *buf,
+				   size_t count, loff_t *ppos);
+static int proc_write_mem(struct file *, const char *, size_t, loff_t *);
+static int proc_dport_dump(struct seq_file *s, int pos);
+static int proc_ep_dump(struct seq_file *s, int pos);
+static ssize_t ep_port_write(struct file *, const char *, size_t, loff_t *);
+static void proc_checksum_read(struct seq_file *s);
+static int proc_common_cmd_dump(struct seq_file *s, int pos);
+static int proc_common_cmd_start(void);
+static ssize_t proc_checksum_write(struct file *file, const char *buf,
+				   size_t count, loff_t *ppos);
+static ssize_t proc_cbm_buf_write(struct file *file, const char *buf,
+				  size_t count, loff_t *ppos);
+static void proc_cbm_buf_read(struct seq_file *s);
+static int proc_gsw_pce_dump(struct seq_file *s, int pos);
+static int proc_gsw_pce_start(void);
+static ssize_t proc_gsw_route_write(struct file *file, const char *buf,
+				    size_t count, loff_t *ppos);
+static ssize_t proc_gsw_pmac_write(struct file *file, const char *buf,
+				    size_t count, loff_t *ppos);
+static int inet_pton4(const char *src, u_char *dst);
+static int inet_pton6(const char *src, u_char *dst);
+static int proc_gsw_route_dump(struct seq_file *seq, int pos);
+
+static int rmon_display_tmu_mib = 1;
+static int rmon_display_port_full;
+static struct dp_proc_entry dp_proc_entries[] = {
+	/*name single_callback_t multi_callback_t/_start write_callback_t */
+	{DP_PROC_FILE_DBG, proc_dbg_read, NULL, NULL, proc_dbg_write},
+	{DP_PROC_FILE_PORT, NULL, proc_port_dump, NULL, proc_port_write},
+	{DP_PROC_FILE_PARSER, proc_parser_read, NULL, NULL,
+	 proc_parser_write},
+	{DP_PROC_FILE_RMON_PORTS, NULL, proc_gsw_port_rmon_dump,
+	 proc_gsw_rmon_port_start, proc_gsw_rmon_write},
+	{DP_PROC_FILE_MEM, NULL, NULL, NULL, proc_write_mem},
+	{DP_PROC_FILE_EP, NULL, proc_ep_dump, NULL, ep_port_write},
+	{DP_PROC_FILE_DPORT, NULL, proc_dport_dump, NULL, NULL},
+	{DP_PROC_PRINT_MODE, proc_print_mode_read, NULL, NULL,
+	 proc_print_mode_write},
+	{DP_PROC_FILE_CHECKSUM, proc_checksum_read, NULL, NULL,
+	 proc_checksum_write},
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+	{DP_PROC_FILE_MIB_TIMER, proc_mib_timer_read, NULL, NULL,
+	 proc_mib_timer_write},
+	{DP_PROC_FILE_MIB_INSIDE, NULL, proc_mib_inside_dump,
+	 proc_mib_inside_start, proc_mib_inside_write},
+	{DP_PROC_FILE_MIBPORT, NULL, proc_mib_port_dump,
+	 proc_mib_port_start, proc_mib_port_write},
+	{DP_PROC_FILE_MIBVAP, NULL, proc_mib_vap_dump, proc_mib_vap_start,
+	 proc_mib_vap_write},
+#endif
+#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+	{DP_PROC_FILE_COC, proc_coc_read, NULL, NULL, proc_coc_write},
+#endif
+	{DP_PROC_FILE_CBM_BUF_TEST, proc_cbm_buf_read, NULL, NULL,
+	 proc_cbm_buf_write},
+	{DP_PROC_FILE_COMMON_CMD, NULL, proc_common_cmd_dump,
+	 proc_common_cmd_start, NULL},
+	{DP_PROC_FILE_PCE, NULL, proc_gsw_pce_dump, proc_gsw_pce_start, NULL},
+	{DP_PROC_FILE_ROUTE, NULL, proc_gsw_route_dump, NULL,
+	 proc_gsw_route_write},
+	 {DP_PROC_FILE_PMAC, NULL, NULL, NULL,
+	 proc_gsw_pmac_write},
+
+	/*the last place holder */
+	{NULL, NULL, NULL, NULL, NULL}
+};
+
+static struct proc_dir_entry *dp_proc_node;
+
+struct proc_dir_entry *dp_proc_install(void)
+{
+
+	dp_proc_node = proc_mkdir(DP_PROC_PARENT DP_PROC_NAME, NULL);
+
+	if (dp_proc_node != NULL) {
+		int i;
+
+		for (i = 0; i < ARRAY_SIZE(dp_proc_entries); i++)
+			dp_proc_entry_create(dp_proc_node,
+					     &dp_proc_entries[i]);
+	} else {
+		PRINTK("cannot create proc entry");
+		return NULL;
+	}
+
+	return dp_proc_node;
+}
+
+int proc_port_dump(struct seq_file *s, int pos)
+{
+	int i;
+	int ret;
+	struct pmac_port_info *port = get_port_info(pos);
+
+	if (!port) {
+		PR_ERR("Why port is NULL\n");
+		return -1;
+	}
+
+	if (port->status == PORT_FREE) {
+		if (pos == 0) {
+			SEQ_PRINTF(s,
+				   "Reserved Port: rx_err_drop=0x%08x  tx_err_drop=0x%08x\n",
+				   port->rx_err_drop, port->tx_err_drop);
+
+		} else
+			SEQ_PRINTF(s,
+				   "%02d: rx_err_drop=0x%08x  tx_err_drop=0x%08x\n",
+				   pos, port->rx_err_drop, port->tx_err_drop);
+
+		goto EXIT;
+	}
+
+	SEQ_PRINTF(s,
+		   "%02d: module=0x0x%0x(name:%8s) dev_port=%02d dp_port=%02d itf_base=%d(%s)\n",
+		   pos, (u32) port->owner, port->owner->name, port->dev_port,
+		   port->port_id,
+		   port->itf_info ? port->itf_info->start : 0,
+	       port->itf_info ? "Enabled" : "Not Enabled");
+	SEQ_PRINTF(s, "    status:            %s\n",
+		   dp_port_status_str[port->status]);
+
+	SEQ_PRINTF(s, "    allocate_flags:    ");
+
+	for (i = 0; i < get_dp_port_type_str_size(); i++) {
+		if (port->alloc_flags & dp_port_flag[i])
+			SEQ_PRINTF(s, "%s ", dp_port_type_str[i]);
+	}
+
+	SEQ_PRINTF(s, "\n");
+
+	SEQ_PRINTF(s, "    cb->rx_fn:         0x%0x\n", (u32) port->cb.rx_fn);
+	SEQ_PRINTF(s, "    cb->restart_fn:    0x%0x\n",
+		   (u32) port->cb.restart_fn);
+	SEQ_PRINTF(s, "    cb->stop_fn:       0x%0x\n",
+		   (u32) port->cb.stop_fn);
+	SEQ_PRINTF(s, "    cb->get_subifid_fn:0x%0x\n",
+		   (u32) port->cb.get_subifid_fn);
+	SEQ_PRINTF(s, "    num_subif:         %02d\n", port->num_subif);
+
+	for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+		if (port->subif_info[i].flags) {
+			SEQ_PRINTF(s,
+				   "      [%02d]: subif=0x%04x(vap=%d) netif=0x%0x(name=%s), device_name=%s\n",
+				   i, port->subif_info[i].subif,
+				   (port->subif_info[i].subif >> VAP_OFFSET)
+				   & 0xF, (u32) port->subif_info[i].netif,
+				   port->subif_info[i].netif ? port->
+				   subif_info[i].netif->name : "NULL/DSL",
+				   port->subif_info[i].device_name);
+			SEQ_PRINTF(s, "          : rx_fn_rxif_pkt =0x%08x\n",
+				   port->subif_info[i].mib.rx_fn_rxif_pkt);
+			SEQ_PRINTF(s, "          : rx_fn_txif_pkt =0x%08x\n",
+				   port->subif_info[i].mib.rx_fn_txif_pkt);
+			SEQ_PRINTF(s, "          : rx_fn_dropped  =0x%08x\n",
+				   port->subif_info[i].mib.rx_fn_dropped);
+			SEQ_PRINTF(s, "          : tx_cbm_pkt     =0x%08x\n",
+				   port->subif_info[i].mib.tx_cbm_pkt);
+			SEQ_PRINTF(s, "          : tx_tso_pkt     =0x%08x\n",
+				   port->subif_info[i].mib.tx_tso_pkt);
+			SEQ_PRINTF(s, "          : tx_pkt_dropped =0x%08x\n",
+				   port->subif_info[i].mib.tx_pkt_dropped);
+			SEQ_PRINTF(s, "          : tx_clone_pkt   =0x%08x\n",
+				   port->subif_info[i].mib.tx_clone_pkt);
+			SEQ_PRINTF(s, "          : tx_hdr_room_pkt=0x%08x\n",
+				   port->subif_info[i].mib.tx_hdr_room_pkt);
+		}
+	}
+
+	ret =
+	    SEQ_PRINTF(s, "    rx_err_drop=0x%08x  tx_err_drop=0x%08x\n",
+		       port->rx_err_drop, port->tx_err_drop);
+
+	if (ret)
+		return pos;
+
+ EXIT:
+	pos++;
+
+	if (pos >= PMAC_MAX_NUM)
+		pos = -1;	/*end of the loop */
+
+	return pos;
+}
+
+int display_port_info(u8 pos, int start_vap, int end_vap, u32 flag)
+{
+	int i;
+	int ret;
+	struct pmac_port_info *port = get_port_info(pos);
+
+	if (!port) {
+		PR_ERR("Why port is NULL\n");
+		return -1;
+	}
+
+	if (port->status == PORT_FREE) {
+		if (pos == 0) {
+			PRINTK
+			    ("Reserved Port: rx_err_drop=0x%08x  tx_err_drop=0x%08x\n",
+			     port->rx_err_drop, port->tx_err_drop);
+
+		} else
+			PRINTK
+			    ("%02d: rx_err_drop=0x%08x  tx_err_drop=0x%08x\n",
+			     pos, port->rx_err_drop, port->tx_err_drop);
+
+		goto EXIT;
+	}
+
+	PRINTK("%02d: module=0x0x%0x(name:%8s) dev_port=%02d dp_port=%02d itf_base=%d(%s)\n",
+	       pos, (u32) port->owner, port->owner->name, port->dev_port,
+	       port->port_id,
+	       port->itf_info ? port->itf_info->start : 0,
+	       port->itf_info ? "Enabled" : "Not Enabled");
+	PRINTK("    status:            %s\n",
+	       dp_port_status_str[port->status]);
+
+	PRINTK("    allocate_flags:    ");
+
+	for (i = 0; i < get_dp_port_type_str_size(); i++) {
+		if (port->alloc_flags & dp_port_flag[i])
+			PRINTK("%s ", dp_port_type_str[i]);
+	}
+
+	PRINTK("\n");
+
+	if (!flag) {
+		PRINTK("    cb->rx_fn:         0x%0x\n",
+		       (u32) port->cb.rx_fn);
+		PRINTK("    cb->restart_fn:    0x%0x\n",
+		       (u32) port->cb.restart_fn);
+		PRINTK("    cb->stop_fn:       0x%0x\n",
+		       (u32) port->cb.stop_fn);
+		PRINTK("    cb->get_subifid_fn:0x%0x\n",
+		       (u32) port->cb.get_subifid_fn);
+		PRINTK("    num_subif:         %02d\n", port->num_subif);
+	}
+
+	for (i = start_vap; i < end_vap; i++) {
+		if (port->subif_info[i].flags) {
+			PRINTK
+			    ("      [%02d]: subif=0x%04x(vap=%d) netif=0x%0x(name=%s), device_name=%s\n",
+			     i, port->subif_info[i].subif,
+			     (port->subif_info[i].subif >> VAP_OFFSET)
+			     & 0xF, (u32) port->subif_info[i].netif,
+			     port->subif_info[i].netif ? port->subif_info[i].
+			     netif->name : "NULL/DSL",
+			     port->subif_info[i].device_name);
+			PRINTK("          : rx_fn_rxif_pkt =0x%08x\n",
+			       port->subif_info[i].mib.rx_fn_rxif_pkt);
+			PRINTK("          : rx_fn_txif_pkt =0x%08x\n",
+			       port->subif_info[i].mib.rx_fn_txif_pkt);
+			PRINTK("          : rx_fn_dropped  =0x%08x\n",
+			       port->subif_info[i].mib.rx_fn_dropped);
+			PRINTK("          : tx_cbm_pkt     =0x%08x\n",
+			       port->subif_info[i].mib.tx_cbm_pkt);
+			PRINTK("          : tx_tso_pkt     =0x%08x\n",
+			       port->subif_info[i].mib.tx_tso_pkt);
+			PRINTK("          : tx_pkt_dropped =0x%08x\n",
+			       port->subif_info[i].mib.tx_pkt_dropped);
+			PRINTK("          : tx_clone_pkt   =0x%08x\n",
+			       port->subif_info[i].mib.tx_clone_pkt);
+			PRINTK("          : tx_hdr_room_pkt=0x%08x\n",
+			       port->subif_info[i].mib.tx_hdr_room_pkt);
+		}
+	}
+
+	ret =
+	    PRINTK("    rx_err_drop=0x%08x  tx_err_drop=0x%08x\n",
+		   port->rx_err_drop, port->tx_err_drop);
+ EXIT:
+	return 0;
+}
+
+ssize_t proc_port_write(struct file *file, const char *buf, size_t count,
+			loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num, i;
+	u8 index_start = 0;
+	u8 index_end = PMAC_MAX_NUM;
+	u8 vap_start = 0;
+	u8 vap_end = MAX_SUBIF_PER_PORT;
+	char *param_list[10];
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 1)
+		goto help;
+	if (param_list[1]) {
+		index_start = dp_atoi(param_list[1]);
+		index_end = index_start + 1;
+	}
+
+	if (param_list[2]) {
+		vap_start = dp_atoi(param_list[2]);
+		vap_end = vap_start + 1;
+	}
+
+	if (index_start >= PMAC_MAX_NUM) {
+		PR_ERR("wrong index: 0 ~ 15\n");
+		return count;
+	}
+
+	if (vap_start >= MAX_SUBIF_PER_PORT) {
+		PR_ERR("wrong VAP: 0 ~ 15\n");
+		return count;
+	}
+
+	if (dp_strcmpi(param_list[0], "mib") == 0) {
+		for (i = index_start; i < index_end; i++)
+			display_port_info(i, vap_start, vap_end, 1);
+
+	} else if (dp_strcmpi(param_list[0], "port") == 0) {
+		for (i = index_start; i < index_end; i++)
+			display_port_info(i, vap_start, vap_end, 0);
+
+	} else
+		goto help;
+
+	return count;
+ help:
+	PRINTK("usage:\n");
+	PRINTK("  echo mib  [ep][vap] > /prooc/dp/port\n");
+	PRINTK("  echo port [ep][vap] > /prooc/dp/port\n");
+	return count;
+}
+
+void proc_dbg_read(struct seq_file *s)
+{
+	int i;
+
+	SEQ_PRINTF(s, "dp_dbg_flag=0x%08x\n", dp_dbg_flag);
+	SEQ_PRINTF(s, "Supported Flags =%d\n", get_dp_dbg_flag_str_size());
+	SEQ_PRINTF(s, "Enabled Flags(0x%0x):", dp_dbg_flag);
+
+	for (i = 0; i < get_dp_dbg_flag_str_size(); i++)
+		if ((dp_dbg_flag & dp_dbg_flag_list[i]) ==
+		    dp_dbg_flag_list[i])
+			SEQ_PRINTF(s, "%s ", dp_dbg_flag_str[i]);
+
+	SEQ_PRINTF(s, "\n\n");
+
+	SEQ_PRINTF(s, "dp_drop_all_tcp_err=%d @ 0x%p\n", dp_drop_all_tcp_err,
+		   &dp_drop_all_tcp_err);
+	SEQ_PRINTF(s, "dp_pkt_size_check=%d @ 0x%p\n", dp_pkt_size_check,
+		   &dp_pkt_size_check);
+
+	SEQ_PRINTF(s, "dp_rx_test_mode=%d @ 0x%p\n", dp_rx_test_mode,
+		   &dp_rx_test_mode);
+
+	SEQ_PRINTF(s, "dp_dbg_err(flat to print error or not)=%d @ 0x%p\n", dp_dbg_err,
+		   &dp_dbg_err);
+
+	print_parser_status(s);
+}
+
+ssize_t proc_dbg_write(struct file *file, const char *buf, size_t count,
+		       loff_t *ppos)
+{
+	int len, i, j;
+	char str[64];
+	int num;
+	char *param_list[20];
+	int f_enable;
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (dp_strcmpi(param_list[0], "enable") == 0)
+		f_enable = 1;
+	else if (dp_strcmpi(param_list[0], "disable") == 0)
+		f_enable = -1;
+	else
+		goto help;
+
+	if (!param_list[1]) {	/*no parameter after enable or disable */
+		set_ltq_dbg_flag(dp_dbg_flag, f_enable, -1);
+		goto EXIT;
+	}
+
+	for (i = 1; i < num; i++) {
+		for (j = 0; j < get_dp_dbg_flag_str_size(); j++)
+			if (dp_strcmpi(param_list[i], dp_dbg_flag_str[j]) ==
+			    0) {
+				set_ltq_dbg_flag(dp_dbg_flag, f_enable,
+						 dp_dbg_flag_list[j]);
+				break;
+			}
+	}
+
+ EXIT:
+	return count;
+ help:
+	PRINTK("echo <enable/disable> ");
+
+	for (i = 0; i < get_dp_dbg_flag_str_size(); i++)
+		PRINTK("%s ", dp_dbg_flag_str[i]);
+
+	PRINTK(" > /proc/dp/dbg\n");
+	PRINTK(" display command: cat /proc/dp/cmd\n");
+
+	return count;
+}
+
+static void proc_parser_read(struct seq_file *s)
+{
+	int8_t cpu, mpe1, mpe2, mpe3;
+
+	dp_get_gsw_parser(&cpu, &mpe1, &mpe2, &mpe3);
+	SEQ_PRINTF(s, "cpu : %s with parser size =%d bytes\n",
+		   parser_flag_str(cpu), parser_size_via_index(0));
+	SEQ_PRINTF(s, "mpe1: %s with parser size =%d bytes\n",
+		   parser_flag_str(mpe1), parser_size_via_index(1));
+	SEQ_PRINTF(s, "mpe2: %s with parser size =%d bytes\n",
+		   parser_flag_str(mpe2), parser_size_via_index(2));
+	SEQ_PRINTF(s, "mpe3: %s with parser size =%d bytes\n",
+		   parser_flag_str(mpe3), parser_size_via_index(3));
+}
+
+ssize_t proc_parser_write(struct file *file, const char *buf, size_t count,
+			  loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num, i;
+	char *param_list[20];
+	int8_t cpu = 0, mpe1 = 0, mpe2 = 0, mpe3 = 0, flag = 0;
+	static int pce_rule_id;
+	union gsw_var rule;
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (dp_strcmpi(param_list[0], "enable") == 0) {
+		for (i = 1; i < num; i++) {
+			if (dp_strcmpi(param_list[i], "cpu") == 0) {
+				flag |= 0x1;
+				cpu = 2;
+			}
+
+			if (dp_strcmpi(param_list[i], "mpe1") == 0) {
+				flag |= 0x2;
+				mpe1 = 2;
+			}
+
+			if (dp_strcmpi(param_list[i], "mpe2") == 0) {
+				flag |= 0x4;
+				mpe2 = 2;
+			}
+
+			if (dp_strcmpi(param_list[i], "mpe3") == 0) {
+				flag |= 0x8;
+				mpe3 = 2;
+			}
+		}
+
+		if (!flag) {
+			flag = 0x1 | 0x2 | 0x4 | 0x8;
+			cpu = mpe1 = mpe2 = mpe3 = 2;
+		}
+
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "flag=0x%x mpe3/2/1/cpu=%d/%d/%d/%d\n", flag, mpe3,
+			 mpe2, mpe1, cpu);
+		dp_set_gsw_parser(flag, cpu, mpe1, mpe2, mpe3);
+	} else if (dp_strcmpi(param_list[0], "disable") == 0) {
+		for (i = 1; i < num; i++) {
+			if (dp_strcmpi(param_list[i], "cpu") == 0) {
+				flag |= 0x1;
+				cpu = 0;
+			}
+
+			if (dp_strcmpi(param_list[i], "mpe1") == 0) {
+				flag |= 0x2;
+				mpe1 = 0;
+			}
+
+			if (dp_strcmpi(param_list[i], "mpe2") == 0) {
+				flag |= 0x4;
+				mpe2 = 0;
+			}
+
+			if (dp_strcmpi(param_list[i], "mpe3") == 0) {
+				flag |= 0x8;
+				mpe3 = 0;
+			}
+		}
+
+		if (!flag) {
+			flag = 0x1 | 0x2 | 0x4 | 0x8;
+			cpu = mpe1 = mpe2 = mpe3 = 0;
+		}
+
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "flag=0x%x mpe3/2/1/cpu=%d/%d/%d/%d\n", flag, mpe3,
+			 mpe2, mpe1, cpu);
+		dp_set_gsw_parser(flag, cpu, mpe1, mpe2, mpe3);
+	} else if (dp_strcmpi(param_list[0], "refresh") == 0) {
+		dp_get_gsw_parser(NULL, NULL, NULL, NULL);
+		PR_INFO("value:cpu=%d mpe1=%d mpe2=%d mpe3=%d\n", pinfo[0].v,
+			pinfo[1].v, pinfo[2].v, pinfo[3].v);
+		PR_INFO("size :cpu=%d mpe1=%d mpe2=%d mpe3=%d\n",
+			pinfo[0].size, pinfo[1].size, pinfo[2].size,
+			pinfo[3].size);
+		return count;
+	} else if (dp_strcmpi(param_list[0], "mark") == 0) {
+		int flag = dp_atoi(param_list[1]);
+		if (flag < 0)
+			flag = 0;
+		else if (flag > 3)
+			flag = 3;
+		PR_INFO("eProcessPath_Action set to %d\n", flag);
+		/*: All packets set to same mpe flag as specified */
+		memset(&rule, 0, sizeof(rule));
+		rule.pce.pattern.nIndex = pce_rule_id;
+		rule.pce.pattern.bEnable = 1;
+
+		rule.pce.pattern.bParserFlagMSB_Enable = 1;
+		/* rule.pce.pattern.nParserFlagMSB = 0x0021; */
+		rule.pce.pattern.nParserFlagMSB_Mask = 0xffff;
+		rule.pce.pattern.bParserFlagLSB_Enable = 1;
+		/* rule.pce.pattern.nParserFlagLSB = 0x0000; */
+		rule.pce.pattern.nParserFlagLSB_Mask = 0xffff;
+		/* rule.pce.pattern.eDstIP_Select = 2; */
+		/* in6_pton("ff00:0:0:0:0:0:0:0",-1,(void*)&rule.pce.pattern.nDstIP.nIPv6,-1,&end); */
+		rule.pce.pattern.nDstIP_Mask = 0xffffffff;
+		rule.pce.pattern.bDstIP_Exclude = 0;
+
+		rule.pce.action.bRtDstPortMaskCmp_Action = 1;
+		rule.pce.action.bRtSrcPortMaskCmp_Action = 1;
+		rule.pce.action.bRtDstIpMaskCmp_Action = 1;
+		rule.pce.action.bRtSrcIpMaskCmp_Action = 1;
+
+		rule.pce.action.bRoutExtId_Action = 1;
+		rule.pce.action.nRoutExtId = 0;	/*RT_EXTID_UDP; */
+		rule.pce.action.bRtAccelEna_Action = 1;
+		rule.pce.action.bRtCtrlEna_Action = 1;
+		rule.pce.action.eProcessPath_Action = flag;
+		rule.pce.action.bRMON_Action = 1;
+		rule.pce.action.nRMON_Id = 0;	/*RMON_UDP_CNTR; */
+
+		if (dp_gsw_kioctl
+		    (GSWIP_R_DEV_NAME, GSW_PCE_RULE_WRITE, (u32) &rule)) {
+			PRINTK("PCE rule add returned failure for GSW_PCE_RULE_WRITE\n");
+			return count;
+		}
+
+	} else if (dp_strcmpi(param_list[0], "unmark") == 0) {
+		/*: All packets set to same mpe flag as specified */
+		memset(&rule, 0, sizeof(rule));
+		rule.pce.pattern.nIndex = pce_rule_id;
+		rule.pce.pattern.bEnable = 0;
+		if (dp_gsw_kioctl
+		    (GSWIP_R_DEV_NAME, GSW_PCE_RULE_WRITE, (u32) &rule)) {
+			PRINTK("PCE rule add returned failure for GSW_PCE_RULE_WRITE\n");
+			return count;
+		}
+	} else {
+		PRINTK
+		    ("Usage: echo <enable/disable> [cpu] [mpe1] [mpe2] [mpe3] > parser\n");
+		PRINTK("Usage: echo <refresh> parser\n");
+
+		PRINTK
+		    ("Usage: echo mark eProcessPath_Action_value(0~3) > parser\n");
+		PRINTK("Usage: echo unmark > parser\n");
+		return count;
+	}
+
+	return count;
+}
+
+#define MAX_GSW_L_PMAC_PORT  7
+#define MAX_GSW_R_PMAC_PORT  16
+static GSW_RMON_Port_cnt_t gsw_l_rmon_mib[MAX_GSW_L_PMAC_PORT];
+static GSW_RMON_Port_cnt_t gsw_r_rmon_mib[MAX_GSW_R_PMAC_PORT];
+static GSW_RMON_Redirect_cnt_t gswr_rmon_redirect;
+enum RMON_MIB_TYPE {
+	RX_GOOD_PKTS = 0,
+	RX_FILTER_PKTS,
+	RX_DROP_PKTS,
+	RX_OTHERS,
+
+	TX_GOOD_PKTS,
+	TX_ACM_PKTS,
+	TX_DROP_PKTS,
+	TX_OTHERS,
+
+	REDIRECT_MIB,
+	DP_DRV_MIB,
+
+	/*last entry */
+	RMON_MAX
+};
+
+static char f_q_mib_title_proc;
+
+#define GSW_PORT_RMON_PRINT(res, title, var)  do { \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title, "L(0-6)", \
+				 gsw_l_rmon_mib[0].var, gsw_l_rmon_mib[1].var, \
+				 gsw_l_rmon_mib[2].var, gsw_l_rmon_mib[3].var, \
+				 gsw_l_rmon_mib[4].var, gsw_l_rmon_mib[5].var, \
+				 gsw_l_rmon_mib[6].var); \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title, "R(0-6,15)", \
+				 gsw_r_rmon_mib[0].var, gsw_r_rmon_mib[1].var, \
+				 gsw_r_rmon_mib[2].var, gsw_r_rmon_mib[3].var, \
+				 gsw_r_rmon_mib[4].var, gsw_r_rmon_mib[5].var, \
+				 gsw_r_rmon_mib[6].var, gsw_r_rmon_mib[15].var); \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title, "R(7-14)", \
+				 gsw_r_rmon_mib[7].var, gsw_r_rmon_mib[8].var, \
+				 gsw_r_rmon_mib[9].var, gsw_r_rmon_mib[10].var, \
+				 gsw_r_rmon_mib[11].var, gsw_r_rmon_mib[12].var, \
+				 gsw_r_rmon_mib[13].var, gsw_r_rmon_mib[14].var); \
+		res = SEQ_PRINTF(s, "------------------------------------------------------------------------------------------------------------------------------------\n"); \
+	} while (0)
+
+int low_10dec(u64 x)
+{
+	char buf[26];
+	char *p;
+	int len;
+
+	sprintf(buf, "%llu", x);
+	len = strlen(buf);
+	if (len >= 10)
+		p = buf + len - 10;
+	else
+		p = buf;
+
+	return dp_atoi(p);
+}
+
+int high_10dec(u64 x)
+{
+	char buf[26];
+	int len;
+
+	sprintf(buf, "%llu", x);
+	len = strlen(buf);
+	if (len >= 10)
+		buf[len - 10] = 0;
+	else
+		buf[0] = 0;
+
+	return dp_atoi(buf);
+}
+
+#define GSW_PORT_RMON64_PRINT(res, title, var)  do { \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title"(H)", "L(0-6)", \
+				 high_10dec(gsw_l_rmon_mib[0].var), high_10dec(gsw_l_rmon_mib[1].var), \
+				 high_10dec(gsw_l_rmon_mib[2].var), high_10dec(gsw_l_rmon_mib[3].var), \
+				 high_10dec(gsw_l_rmon_mib[4].var), high_10dec(gsw_l_rmon_mib[5].var), \
+				 high_10dec(gsw_l_rmon_mib[6].var)); \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title"(L)", "L(0-6)", \
+				 low_10dec(gsw_l_rmon_mib[0].var), low_10dec(gsw_l_rmon_mib[1].var), \
+				 low_10dec(gsw_l_rmon_mib[2].var), low_10dec(gsw_l_rmon_mib[3].var), \
+				 low_10dec(gsw_l_rmon_mib[4].var), low_10dec(gsw_l_rmon_mib[5].var), \
+				 low_10dec(gsw_l_rmon_mib[6].var)); \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title"(H)", "R(0-6,15)", \
+				 high_10dec(gsw_r_rmon_mib[0].var), high_10dec(gsw_r_rmon_mib[1].var), \
+				 high_10dec(gsw_r_rmon_mib[2].var), high_10dec(gsw_r_rmon_mib[3].var), \
+				 high_10dec(gsw_r_rmon_mib[4].var), high_10dec(gsw_r_rmon_mib[5].var), \
+				 high_10dec(gsw_r_rmon_mib[6].var), high_10dec(gsw_r_rmon_mib[15].var)); \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title"(L)", "R(0-6,15)", \
+				 low_10dec(gsw_r_rmon_mib[0].var), low_10dec(gsw_r_rmon_mib[1].var), \
+				 low_10dec(gsw_r_rmon_mib[2].var), low_10dec(gsw_r_rmon_mib[3].var), \
+				 low_10dec(gsw_r_rmon_mib[4].var), low_10dec(gsw_r_rmon_mib[5].var), \
+				 low_10dec(gsw_r_rmon_mib[6].var), low_10dec(gsw_r_rmon_mib[15].var)); \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title"(H)", "R(7-14)", \
+				 high_10dec(gsw_r_rmon_mib[7].var), high_10dec(gsw_r_rmon_mib[8].var), \
+				 high_10dec(gsw_r_rmon_mib[9].var), high_10dec(gsw_r_rmon_mib[10].var), \
+				 high_10dec(gsw_r_rmon_mib[11].var), high_10dec(gsw_r_rmon_mib[12].var), \
+				 high_10dec(gsw_r_rmon_mib[13].var), high_10dec(gsw_r_rmon_mib[14].var)); \
+		res = SEQ_PRINTF(s, \
+				 "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+				 title"(L)", "R(7-14)", \
+				 low_10dec(gsw_r_rmon_mib[7].var), low_10dec(gsw_r_rmon_mib[8].var), \
+				 low_10dec(gsw_r_rmon_mib[9].var), low_10dec(gsw_r_rmon_mib[10].var), \
+				 low_10dec(gsw_r_rmon_mib[11].var), low_10dec(gsw_r_rmon_mib[12].var), \
+				 low_10dec(gsw_r_rmon_mib[13].var), low_10dec(gsw_r_rmon_mib[14].var)); \
+		res = SEQ_PRINTF(s, "------------------------------------------------------------------------------------------------------------------------------------\n"); \
+	} while (0)
+
+int proc_gsw_port_rmon_dump(struct seq_file *s, int pos)
+{
+	int i;
+	int ret = 0;
+	GSW_API_HANDLE gsw_handle = 0;
+	char flag_buf[20];
+
+	if (pos == 0) {
+		memset(gsw_r_rmon_mib, 0, sizeof(gsw_r_rmon_mib));
+		memset(gsw_l_rmon_mib, 0, sizeof(gsw_l_rmon_mib));
+
+		/*read gswip-r rmon counter */
+		gsw_handle = gsw_api_kopen((char *)GSWIP_R_DEV_NAME);
+
+		if (gsw_handle == 0) {
+			PR_ERR("Open GSWIP-R device FAILED !\n");
+			return -1;
+		}
+
+		for (i = 0; i < ARRAY_SIZE(gsw_r_rmon_mib); i++) {
+			gsw_r_rmon_mib[i].nPortId = i;
+			ret =
+			    gsw_api_kioctl(gsw_handle, GSW_RMON_PORT_GET,
+					   (u32) &gsw_r_rmon_mib[i]);
+
+			if (ret != GSW_statusOk) {
+				PR_ERR("RMON_PORT_GET fail for Port %d\n", i);
+				return -1;
+			}
+		}
+
+		/*read pmac rmon redirect mib */
+		memset(&gswr_rmon_redirect, 0, sizeof(gswr_rmon_redirect));
+		ret =
+		    gsw_api_kioctl(gsw_handle, GSW_RMON_REDIRECT_GET,
+				   (u32) &gswr_rmon_redirect);
+
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_RMON_REDIRECT_GET fail for Port %d\n", i);
+			return -1;
+		}
+
+		gsw_api_kclose(gsw_handle);
+
+		/*read gswip-l rmon counter */
+		gsw_handle = gsw_api_kopen((char *)GSWIP_L_DEV_NAME);
+
+		if (gsw_handle == 0) {
+			PR_ERR("Open GSWIP-L FAILED !!\n");
+			return -1;
+		}
+
+		for (i = 0; i < ARRAY_SIZE(gsw_l_rmon_mib); i++) {
+			gsw_l_rmon_mib[i].nPortId = i;
+			ret =
+			    gsw_api_kioctl(gsw_handle, GSW_RMON_PORT_GET,
+					   (u32) &gsw_l_rmon_mib[i]);
+
+			if (ret != GSW_statusOk) {
+				PR_ERR("RMON_PORT_GET fail for Port %d\n", i);
+				return -1;
+			}
+		}
+
+		gsw_api_kclose(gsw_handle);
+
+		ret =
+		    SEQ_PRINTF(s,
+			       "%-24s %12u %12u %12u %12u %12u %12u %12u\n",
+			       "GSWIP-L", 0, 1, 2, 3, 4, 5, 6);
+		ret =
+		    SEQ_PRINTF(s,
+			       "%-24s %12u %12u %12u %12u %12u %12u %12u %12u\n",
+			       "GSWIP-R(Fixed)", 0, 1, 2, 3, 4, 5, 6, 15);
+		ret =
+		    SEQ_PRINTF(s,
+			       "%-24s %12u %12u %12u %12u %12u %12u %12u %12u\n",
+			       "GSWIP-R(Dynamic)", 7, 8, 9, 10, 11, 12, 13,
+			       14);
+		ret =
+		    SEQ_PRINTF(s,
+			       "------------------------------------------------------------------------------------------------------------------------------------\n");
+	}
+
+	if (pos == RX_GOOD_PKTS)
+		GSW_PORT_RMON_PRINT(ret, "RX_Good", nRxGoodPkts);
+	else if (pos == RX_FILTER_PKTS)
+		GSW_PORT_RMON_PRINT(ret, "RX_FILTER", nRxFilteredPkts);
+	else if (pos == RX_DROP_PKTS)
+		GSW_PORT_RMON_PRINT(ret, "RX_DROP", nRxDroppedPkts);
+	else if (pos == RX_OTHERS) {
+		if (!rmon_display_port_full)
+			goto NEXT;
+
+		GSW_PORT_RMON_PRINT(ret, "RX_UNICAST", nRxUnicastPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_BROADCAST", nRxBroadcastPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_MULTICAST", nRxMulticastPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_FCS_ERR", nRxFCSErrorPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_UNDER_GOOD",
+				    nRxUnderSizeGoodPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_OVER_GOOD", nRxOversizeGoodPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_UNDER_ERR",
+				    nRxUnderSizeErrorPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_OVER_ERR", nRxOversizeErrorPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_ALIGN_ERR", nRxAlignErrorPkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_64B", nRx64BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_127B", nRx127BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_255B", nRx255BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_511B", nRx511BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_1023B", nRx1023BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "RX_MAXB", nRxMaxBytePkts);
+		GSW_PORT_RMON64_PRINT(ret, "RX_BAD_b", nRxBadBytes);
+	} else if (pos == TX_GOOD_PKTS)
+		GSW_PORT_RMON_PRINT(ret, "TX_Good", nTxGoodPkts);
+	else if (pos == TX_ACM_PKTS)
+		GSW_PORT_RMON_PRINT(ret, "TX_ACM_DROP", nTxAcmDroppedPkts);
+	else if (pos == TX_DROP_PKTS)
+		GSW_PORT_RMON_PRINT(ret, "TX_Drop", nTxDroppedPkts);
+	else if (pos == TX_OTHERS) {
+		if (!rmon_display_port_full)
+			goto NEXT;
+
+		GSW_PORT_RMON_PRINT(ret, "TX_UNICAST", nTxUnicastPkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_BROADAST", nTxBroadcastPkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_MULTICAST", nTxMulticastPkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_SINGLE_COLL",
+				    nTxSingleCollCount);
+		GSW_PORT_RMON_PRINT(ret, "TX_MULT_COLL", nTxMultCollCount);
+		GSW_PORT_RMON_PRINT(ret, "TX_LATE_COLL", nTxLateCollCount);
+		GSW_PORT_RMON_PRINT(ret, "TX_EXCESS_COLL",
+				    nTxExcessCollCount);
+		GSW_PORT_RMON_PRINT(ret, "TX_COLL", nTxCollCount);
+		GSW_PORT_RMON_PRINT(ret, "TX_PAUSET", nTxPauseCount);
+		GSW_PORT_RMON_PRINT(ret, "TX_64B", nTx64BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_127B", nTx127BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_255B", nTx255BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_511B", nTx511BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_1023B", nTx1023BytePkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_MAX_B", nTxMaxBytePkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_UNICAST", nTxUnicastPkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_UNICAST", nTxUnicastPkts);
+		GSW_PORT_RMON_PRINT(ret, "TX_UNICAST", nTxUnicastPkts);
+		GSW_PORT_RMON64_PRINT(ret, "TX_GOOD_b", nTxGoodBytes);
+
+	} else if (pos == REDIRECT_MIB) {
+		/*GSWIP-R PMAC Redirect conter */
+		ret =
+		    SEQ_PRINTF(s, "%-24s %12s %12s %12s %12s\n",
+			       "GSW-R Redirect", "Rx_Pkts", "Tx_Pkts",
+			       "Rx_DropsPkts", "Tx_DropsPkts");
+
+		ret =
+		    SEQ_PRINTF(s, "%-24s %12d %12d %12d %12d\n", "",
+			       gswr_rmon_redirect.nRxPktsCount,
+			       gswr_rmon_redirect.nTxPktsCount,
+			       gswr_rmon_redirect.nRxDiscPktsCount,
+			       gswr_rmon_redirect.nTxDiscPktsCount);
+		ret =
+		    SEQ_PRINTF(s,
+			       "------------------------------------------------------------------------------------------------------------------------------------\n");
+	} else if (pos == DP_DRV_MIB) {
+		u64 eth0_rx = 0, eth0_tx = 0;
+		u64 eth1_rx = 0, eth1_tx = 0;
+		u64 dsl_rx = 0, dsl_tx = 0;
+		u64 other_rx = 0, other_tx = 0;
+		int i, j;
+		struct pmac_port_info *port;
+
+		for (i = 1; i < PMAC_MAX_NUM; i++) {
+			port = get_port_info(i);
+
+			if (!port)
+				continue;
+
+			if (i < 6) {
+				for (j = 0; j < 16; j++) {
+					eth0_rx +=
+					    port->subif_info[j].mib.
+					    rx_fn_rxif_pkt;
+					eth0_rx +=
+					    port->subif_info[j].mib.
+					    rx_fn_txif_pkt;
+					eth0_tx +=
+					    port->subif_info[j].mib.
+					    tx_cbm_pkt;
+					eth0_tx +=
+					    port->subif_info[j].mib.
+					    tx_tso_pkt;
+				}
+			} else if (i == 15) {
+				for (j = 0; j < 16; j++) {
+					eth1_rx +=
+					    port->subif_info[j].mib.
+					    rx_fn_rxif_pkt;
+					eth1_rx +=
+					    port->subif_info[j].mib.
+					    rx_fn_txif_pkt;
+					eth1_tx +=
+					    port->subif_info[j].mib.
+					    tx_cbm_pkt;
+					eth1_tx +=
+					    port->subif_info[j].mib.
+					    tx_tso_pkt;
+				}
+			} else if (port->alloc_flags & DP_F_FAST_DSL) {
+				for (j = 0; j < 16; j++) {
+					dsl_rx +=
+					    port->subif_info[j].mib.
+					    rx_fn_rxif_pkt;
+					dsl_rx +=
+					    port->subif_info[j].mib.
+					    rx_fn_txif_pkt;
+					dsl_tx +=
+					    port->subif_info[j].mib.
+					    tx_cbm_pkt;
+					dsl_tx +=
+					    port->subif_info[j].mib.
+					    tx_tso_pkt;
+				}
+			} else {
+				for (j = 0; j < 16; j++) {
+					other_rx +=
+					    port->subif_info[j].mib.
+					    rx_fn_rxif_pkt;
+					other_rx +=
+					    port->subif_info[j].mib.
+					    rx_fn_txif_pkt;
+					other_tx +=
+					    port->subif_info[j].mib.
+					    tx_cbm_pkt;
+					other_tx +=
+					    port->subif_info[j].mib.
+					    tx_tso_pkt;
+				}
+			}
+		}
+
+		ret =
+		    SEQ_PRINTF(s, "%-15s %22s %22s %22s %22s\n", "DP Drv Mib",
+			       "ETH_LAN", "ETH_WAN", "DSL", "Others");
+
+		ret =
+		    SEQ_PRINTF(s, "%15s %22llu %22llu %22llu %22llu\n",
+			       "Rx_Pkts", eth0_rx, eth1_rx, dsl_rx, other_rx);
+		ret =
+		    SEQ_PRINTF(s, "%15s %22llu %22llu %22llu %22llu\n",
+			       "Tx_Pkts", eth0_tx, eth1_tx, dsl_tx, other_tx);
+		ret =
+		    SEQ_PRINTF(s,
+			       "------------------------------------------------------------------------------------------------------------------------------------\n");
+	} else if ((pos >= RMON_MAX) &&
+		   (pos < (RMON_MAX + EGRESS_QUEUE_ID_MAX))) {
+		uint32_t qdc[4], enq_c, deq_c, index;
+		uint32_t wq, qrth, qocc, qavg;
+		struct tmu_equeue_link equeue_link;
+		char *flag_s;
+
+		if (!rmon_display_tmu_mib)
+			goto NEXT;
+
+		index = pos - RMON_MAX;
+		enq_c = get_enq_counter(index);
+		deq_c = get_deq_counter(index);
+		tmu_qdct_read(index, qdc);
+		tmu_qoct_read(index, &wq, &qrth, &qocc, &qavg);
+		tmu_equeue_link_get(index, &equeue_link);
+		flag_s =
+		    get_dma_flags_str(equeue_link.epn, flag_buf,
+				      sizeof(flag_buf));
+
+		if ((enq_c || deq_c || (qdc[0] + qdc[1] + qdc[2] + qdc[3]))
+		    || qocc || qavg) {
+			if (!f_q_mib_title_proc) {
+				ret =
+				    SEQ_PRINTF(s,
+					       "%-15s %10s %10s %10s (%10s %10s %10s %10s) %10s %10s %10s\n",
+					       "TMU MIB     QID", "enq",
+					       "deq", "drop", "No-Color",
+					       "Green", "Yellow", "Red",
+					       "qocc", "qavg", "  DMA  Flag");
+				f_q_mib_title_proc = 1;
+			}
+
+			ret =
+			    SEQ_PRINTF(s,
+				       "%15d %10u %10u %10u (%10u %10u %10u %10u) %10u %10u %10s\n",
+				       index, enq_c, deq_c,
+				       (qdc[0] + qdc[1] + qdc[2] + qdc[3]),
+				       qdc[0], qdc[1], qdc[2], qdc[3], qocc,
+				       (qavg >> 8), flag_s ? flag_s : "");
+
+		} else
+			goto NEXT;
+	} else
+		goto NEXT;
+
+	if (ret)		/*buffer over flow and don't increase pos */
+		return pos;
+
+ NEXT:
+	pos++;
+
+	if (pos - RMON_MAX + 1 >= EGRESS_QUEUE_ID_MAX)
+		return -1;
+
+	return pos;
+}
+
+int proc_gsw_rmon_port_start(void)
+{
+	f_q_mib_title_proc = 0;
+	return 0;
+}
+
+void dp_sys_mib_reset(uint32_t flag)
+{
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+	dp_reset_sys_mib(0);
+#else
+	gsw_mib_reset(0, 0); /* GSW L */
+	gsw_mib_reset(1, 0); /* GSW R */
+	dp_clear_all_mib_inside(0);
+	tmu_reset_mib_all(flag);
+#endif
+}
+
+ssize_t proc_gsw_rmon_write(struct file *file, const char *buf, size_t count,
+			    loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num;
+	char *param_list[10];
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 1)
+		goto help;
+
+	if (dp_strcmpi(param_list[0], "clear") == 0 ||
+	    dp_strcmpi(param_list[0], "c") == 0 ||
+	    dp_strcmpi(param_list[0], "rest") == 0 ||
+	    dp_strcmpi(param_list[0], "r") == 0) {
+		dp_sys_mib_reset(0);
+		goto EXIT_OK;
+	}
+
+	if (dp_strcmpi(param_list[0], "TMU") == 0) {
+		if (dp_strcmpi(param_list[1], "on") == 0) {
+			rmon_display_tmu_mib = 1;
+			goto EXIT_OK;
+		} else if (dp_strcmpi(param_list[1], "off") == 0) {
+			rmon_display_tmu_mib = 0;
+			goto EXIT_OK;
+		}
+	}
+
+	if (dp_strcmpi(param_list[0], "RMON") == 0) {
+		if (dp_strcmpi(param_list[1], "Full") == 0) {
+			rmon_display_port_full = 1;
+			goto EXIT_OK;
+		} else if (dp_strcmpi(param_list[1], "Basic") == 0) {
+			rmon_display_port_full = 0;
+			goto EXIT_OK;
+		}
+	}
+
+	/*unknow command */
+	goto help;
+
+ EXIT_OK:
+	return count;
+
+ help:
+	PRINTK("usage: echo clear > /proc/dp/rmon\n");
+	PRINTK("usage: echo TMU on > /proc/dp/rmon\n");
+	PRINTK("usage: echo TMU off > /proc/dp/rmon\n");
+	PRINTK("usage: echo RMON Full > /proc/dp/rmon\n");
+	PRINTK("usage: echo RMON Basic > /proc/dp/rmon\n");
+	return count;
+}
+
+/**
+* \brief directly read memory address with 4 bytes alignment.
+* \param  reg_addr memory address (it must be 4 bytes alignment)
+* \param  shift to the expected bits (its value is from 0 ~ 31)
+* \param  size the bits number (its value is from 1 ~ 32).
+*  Note: shift + size <= 32
+* \param  buffer destionation
+* \return on Success return 0
+*/
+int32_t dp_mem_read(uint32_t reg_addr, uint32_t shift, uint32_t size,
+		    uint32_t *buffer, uint32_t base)
+{
+	u32 v;
+	uint32_t mask = 0;
+	int i;
+
+	/*generate mask */
+	for (i = 0; i < size; i++)
+		mask |= 1 << i;
+
+	mask = mask << shift;
+
+	/*read data from specified address */
+	if (base == 4)
+		v = *(u32 *) reg_addr;
+	else if (base == 2)
+		v = *(u16 *) reg_addr;
+	else
+		v = *(u8 *) reg_addr;
+
+	v = dp_get_val(v, mask, shift);
+
+	*buffer = v;
+	return 0;
+}
+
+/**
+* \brief directly write memory address with
+* \param  reg_addr memory address (it must be 4 bytes alignment)
+* \param  shift to the expected bits (its value is from 0 ~ 31)
+* \param  size the bits number (its value is from 1 ~ 32)
+* \param  value value writen to
+* \return on Success return 0
+*/
+int32_t dp_mem_write(uint32_t reg_addr, uint32_t shift, uint32_t size,
+		     uint32_t value, uint32_t base)
+{
+	u32 tmp = 0;
+	uint32_t mask = 0;
+	int i;
+
+	/*generate mask */
+	for (i = 0; i < size; i++)
+		mask |= 1 << i;
+
+	mask = mask << shift;
+
+	/*read data from specified address */
+	if (base == 4)
+		tmp = *(u32 *) reg_addr;
+	else if (base == 2)
+		tmp = *(u16 *) reg_addr;
+	else if (base == 1)
+		tmp = *(u8 *) reg_addr;
+	else {
+		PR_ERR("wrong base in dp_mem_write\n");
+		return 0;
+	}
+
+	dp_set_val(tmp, value, mask, shift);
+
+	if (base == 4)
+		*(u32 *) reg_addr = tmp;
+	else if (base == 2)
+		*(u16 *) reg_addr = tmp;
+	else
+		*(u8 *) reg_addr = tmp;
+
+	return 0;
+}
+
+#define MODE_ACCESS_BYTE  1
+#define MODE_ACCESS_SHORT 2
+#define MODE_ACCESS_DWORD 4
+
+#define ACT_READ   1
+#define ACT_WRITE  2
+static int proc_write_mem(struct file *file, const char *buf, size_t count,
+			  loff_t *ppos)
+{
+	char str[100];
+	int num;
+	char *param_list[20] = { NULL };
+	int i, k, len;
+	u32 line_max_num = 32;	/* per line number printed */
+	u32 addr = 0;
+	u32 v = 0;
+	u32 act = ACT_READ;
+	u32 bit_offset = 0;
+	u32 bit_num = 32;
+	u32 repeat = 1;
+	u32 mode = MODE_ACCESS_DWORD;
+	int v_flag = 0;
+
+	len = sizeof(str) < count ? sizeof(str) - 1 : count;
+	len = len - copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 2)
+		goto proc_help;
+
+	if (dp_strncmpi(param_list[0], "w", 1) == 0)
+		act = ACT_WRITE;
+	else if (dp_strncmpi(param_list[0], "r", 1) == 0)
+		act = ACT_READ;
+	else
+		goto proc_help;
+
+	if (num < 3)
+		goto proc_help;
+
+	k = 1;
+
+	while (k < num) {
+		if (dp_strcmpi(param_list[k], "-s") == 0) {
+			addr = dp_atoi(param_list[k + 1]);
+			k += 2;
+		} else if (dp_strcmpi(param_list[k], "-o") == 0) {
+			bit_offset = dp_atoi(param_list[k + 1]);
+			k += 2;
+		} else if (dp_strcmpi(param_list[k], "-n") == 0) {
+			bit_num = dp_atoi(param_list[k + 1]);
+			k += 2;
+		} else if (dp_strcmpi(param_list[k], "-r") == 0) {
+			repeat = dp_atoi(param_list[k + 1]);
+			k += 2;
+		} else if (dp_strcmpi(param_list[k], "-v") == 0) {
+			v = dp_atoi(param_list[k + 1]);
+			k += 2;
+			v_flag = 1;
+		} else if (dp_strcmpi(param_list[k], "-b") == 0) {
+			mode = MODE_ACCESS_BYTE;
+			k += 1;
+		} else if (dp_strcmpi(param_list[k], "-w") == 0) {
+			mode = MODE_ACCESS_SHORT;
+			k += 1;
+		} else if (dp_strcmpi(param_list[k], "-d") == 0) {
+			mode = MODE_ACCESS_DWORD;
+			k += 1;
+		} else {
+			PR_INFO("unknown command option: %s\n",
+				param_list[k]);
+			break;
+		}
+	}
+
+	if (bit_num > mode * 8)
+		bit_num = mode * 8;
+
+	if (repeat == 0)
+		repeat = 1;
+
+	if (!addr) {
+		PR_ERR("addr cannot be zero\n");
+		goto EXIT;
+	}
+
+	if ((mode != MODE_ACCESS_DWORD) && (mode != MODE_ACCESS_SHORT) &&
+	    (mode != MODE_ACCESS_BYTE)) {
+		PR_ERR("wrong access mode: %d bytes\n", mode);
+		goto EXIT;
+	}
+
+	if ((act == ACT_WRITE) && !v_flag) {
+		PR_ERR("For write command it needs to provide -v\n");
+		goto EXIT;
+	}
+
+	if (bit_offset > mode * 8 - 1) {
+		PR_ERR("valid bit_offset range:0 ~ %d\n", mode * 8 - 1);
+		goto EXIT;
+	}
+
+	if ((bit_num > mode * 8) || (bit_num < 1)) {
+		PR_ERR("valid bit_num range:0 ~ %d. Current bit_num=%d\n",
+		       mode * 8, bit_num);
+		goto EXIT;
+	}
+
+	if ((bit_offset + bit_num) > mode * 8) {
+		PR_ERR("valid bit_offset+bit_num range:0 ~ %d\n", mode * 8);
+		goto EXIT;
+	}
+
+	if ((addr % mode) != 0) {	/*access alignment */
+		PR_ERR("Cannot access 0x%08x in %d bytes\n", addr, mode);
+		goto EXIT;
+	}
+
+	line_max_num /= mode;
+
+	if (act == ACT_WRITE)
+		PRINTK
+		    ("act=%s addr=0x%08x mode=%s bit_offset=%d bit_num=%d v=0x%08x\n",
+		     "write", addr,
+		     (mode ==
+		      MODE_ACCESS_DWORD) ? "dword" : ((mode ==
+						       MODE_ACCESS_SHORT) ?
+						      "short" : "DWORD"),
+		     bit_offset, bit_num, v);
+	else if (act == ACT_READ)
+		PRINTK
+		    ("act=%s addr=0x%08x mode=%s bit_offset=%d bit_num=%d\n",
+		     "Read", addr,
+		     (mode ==
+		      MODE_ACCESS_DWORD) ? "dword" : ((mode ==
+						       MODE_ACCESS_SHORT) ?
+						      "short" : "DWORD"),
+		     bit_offset, bit_num);
+
+	if (act == ACT_WRITE)
+		for (i = 0; i < repeat; i++)
+			dp_mem_write(addr + mode * i, bit_offset, bit_num, v,
+				     mode);
+	else {
+		for (i = 0; i < repeat; i++) {
+			v = 0;
+			dp_mem_read(addr + mode * i, bit_offset, bit_num, &v,
+				    mode);
+
+			/*print format control */
+			if ((i % line_max_num) == 0)
+				PRINTK("0x%08x: ", addr + mode * i);
+
+			if (mode == MODE_ACCESS_DWORD)
+				PRINTK("0x%08x ", v);
+			else if (mode == MODE_ACCESS_SHORT)
+				PRINTK("0x%04x ", v);
+			else
+				PRINTK("0x%02x ", v);
+
+			if ((i % line_max_num) == (line_max_num - 1))
+				PRINTK("\n");
+		}
+	}
+
+	PRINTK("\n");
+ EXIT:
+	return count;
+ proc_help:
+	PR_INFO
+	    ("echo <write/w> [-d/w/b] -s <start_v_addr> [-r <repeat_times>] -v <value> [-o <bit_offset>] [-n <bit_num>]\n");
+	PR_INFO
+	    ("echo <read/r>  [-d/w/b] -s <start_v_addr> [-r <repeat_times>] [-o <bit_offset>] [-n <bit_num>]\n");
+	PR_INFO("\t -d: default read/write in dwords, ie 4 bytes\n");
+	PR_INFO("\t -w: read/write in short, ie 2 bytes\n");
+	PR_INFO("\t -b: read/write in bytes, ie 1 bytes\n");
+
+	return count;
+}
+
+int proc_ep_dump(struct seq_file *s, int pos)
+{
+#if defined(NEW_CBM_API) && NEW_CBM_API
+	uint32_t num;
+	cbm_tmu_res_t *res = NULL;
+	uint32_t flag = 0;
+	int i;
+	struct pmac_port_info *port = get_port_info(pos);
+
+	if (cbm_dp_port_resources_get
+	    (&pos, &num, &res, port ? port->alloc_flags : flag) == 0) {
+		for (i = 0; i < num; i++) {
+			SEQ_PRINTF(s, "ep=%d tmu_port=%d queue=%d sid=%d\n",
+				   pos, res[i].tmu_port, res[i].tmu_q,
+				   res[i].tmu_sched);
+		}
+
+		kfree(res);
+	}
+#endif
+	pos++;
+
+	if (pos >= PMAC_MAX_NUM)
+		pos = -1;	/*end of the loop */
+
+	return pos;
+}
+
+typedef int (*ingress_pmac_set_callback_t) (dp_pmac_cfg_t *pmac_cfg,
+					    u32 value);
+typedef int (*egress_pmac_set_callback_t) (dp_pmac_cfg_t *pmac_cfg,
+					   u32 value);
+struct ingress_pmac_entry {
+	char *name;
+	ingress_pmac_set_callback_t ingress_callback;
+};
+struct egress_pmac_entry {
+	char *name;
+	egress_pmac_set_callback_t egress_callback;
+};
+static int ingress_err_disc_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.err_disc = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_ERR_DISC;
+	return 0;
+}
+
+static int ingress_pmac_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.pmac = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PRESENT;
+	return 0;
+}
+
+static int ingress_pmac_pmap_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_pmap = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMAP;
+	return 0;
+}
+
+static int ingress_pmac_en_pmap_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_en_pmap = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMAPENA;
+	return 0;
+}
+
+static int ingress_pmac_tc_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_tc = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_CLASS;
+	return 0;
+}
+
+static int ingress_pmac_en_tc_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_en_tc = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_CLASSENA;
+	return 0;
+}
+
+static int ingress_pmac_subifid_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_subifid = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_SUBIF;
+	return 0;
+}
+
+static int ingress_pmac_srcport_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_src_port = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_SPID;
+	return 0;
+}
+
+static int ingress_pmac_hdr1_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	uint8_t hdr;
+	hdr = (uint8_t) value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[0] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR1;
+	return 0;
+}
+
+static int ingress_pmac_hdr2_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	uint8_t hdr;
+	hdr = (uint8_t) value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[1] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR2;
+	return 0;
+}
+
+static int ingress_pmac_hdr3_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	uint8_t hdr;
+	hdr = (uint8_t) value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[2] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR3;
+	return 0;
+}
+
+static int ingress_pmac_hdr4_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	uint8_t hdr;
+	hdr = (uint8_t) value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[3] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR4;
+	return 0;
+}
+
+static int ingress_pmac_hdr5_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	uint8_t hdr;
+	hdr = (uint8_t) value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[4] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR5;
+	return 0;
+}
+
+static int ingress_pmac_hdr6_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	uint8_t hdr;
+	hdr = (uint8_t) value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[5] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR6;
+	return 0;
+}
+
+static int ingress_pmac_hdr7_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	uint8_t hdr;
+	hdr = (uint8_t) value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[6] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR7;
+	return 0;
+}
+
+static int ingress_pmac_hdr8_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	uint8_t hdr;
+	hdr = (uint8_t) value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[7] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR8;
+	return 0;
+}
+
+static int egress_fcs_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.fcs = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_FCS;
+	return 0;
+}
+
+static int egress_l2hdr_bytes_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.num_l2hdr_bytes_rm = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_L2HDR_RM;
+	return 0;
+}
+
+static int egress_rx_dma_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.rx_dma_chan = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_RXID;
+	return 0;
+}
+
+static int egress_pmac_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.pmac = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_PMAC;
+	return 0;
+}
+
+static int egress_res_dw_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.res_dw1 = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_RESDW1;
+	return 0;
+}
+
+static int egress_res1_dw_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.res1_dw0 = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_RES1DW0;
+	return 0;
+}
+
+static int egress_res2_dw_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.res2_dw0 = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_RES2DW0;
+	return 0;
+}
+
+static int egress_tc_ena_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.tc_enable = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_TCENA;
+	return 0;
+}
+
+static int egress_dec_flag_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.dec_flag = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_DECFLG;
+	return 0;
+}
+
+static int egress_enc_flag_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.enc_flag = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_ENCFLG;
+	return 0;
+}
+
+static int egress_mpe1_flag_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.mpe1_flag = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_MPE1FLG;
+	return 0;
+}
+
+static int egress_mpe2_flag_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.mpe2_flag = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_MPE2FLG;
+	return 0;
+}
+
+static struct ingress_pmac_entry ingress_entries[] = {
+	{"errdisc", ingress_err_disc_set},
+	{"pmac", ingress_pmac_set},
+	{"pmac_pmap", ingress_pmac_pmap_set},
+	{"pmac_en_pmap", ingress_pmac_en_pmap_set},
+	{"pmac_tc", ingress_pmac_tc_set},
+	{"pmac_en_tc", ingress_pmac_en_tc_set},
+	{"pmac_subifid", ingress_pmac_subifid_set},
+	{"pmac_srcport", ingress_pmac_srcport_set},
+	{"pmac_hdr1", ingress_pmac_hdr1_set},
+	{"pmac_hdr2", ingress_pmac_hdr2_set},
+	{"pmac_hdr3", ingress_pmac_hdr3_set},
+	{"pmac_hdr4", ingress_pmac_hdr4_set},
+	{"pmac_hdr5", ingress_pmac_hdr5_set},
+	{"pmac_hdr6", ingress_pmac_hdr6_set},
+	{"pmac_hdr7", ingress_pmac_hdr7_set},
+	{"pmac_hdr8", ingress_pmac_hdr8_set},
+	{NULL, NULL}
+};
+
+static struct egress_pmac_entry egress_entries[] = {
+	{"rx_dmachan", egress_rx_dma_set},
+	{"rm_l2hdr", egress_l2hdr_bytes_set},
+	{"fcs", egress_fcs_set},
+	{"pmac", egress_pmac_set},
+	{"res_dw1", egress_res_dw_set},
+	{"res1_dw0", egress_res1_dw_set},
+	{"res2_dw0", egress_res2_dw_set},
+	{"tc_enable", egress_tc_ena_set},
+	{"dec_flag", egress_dec_flag_set},
+	{"enc_flag", egress_enc_flag_set},
+	{"mpe1_flag", egress_mpe1_flag_set},
+	{"mpe2_flag", egress_mpe2_flag_set},
+	{NULL, NULL}
+};
+
+ssize_t ep_port_write(struct file *file, const char *buf, size_t count,
+		      loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num, i, j, ret;
+	u32 value;
+	uint32_t port;
+	char *param_list[10];
+	dp_pmac_cfg_t pmac_cfg;
+	memset(&pmac_cfg, 0, sizeof(dp_pmac_cfg_t));
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (dp_strcmpi(param_list[0], "ingress") == 0) {
+		port = dp_atoi(param_list[1]);
+
+		for (i = 2; i < num; i += 2) {
+			for (j = 0; j < ARRAY_SIZE(ingress_entries); j++) {
+				if (dp_strcmpi
+				    (param_list[i],
+				     ingress_entries[j].name) == 0) {
+					value = dp_atoi(param_list[i + 1]);
+					ingress_entries[j].
+					    ingress_callback(&pmac_cfg,
+							     value);
+					PR_INFO
+					    ("ingress pmac ep %s configured\n",
+					     ingress_entries[j].name);
+					break;
+				}
+			}
+		}
+
+		ret = dp_pmac_set(port, &pmac_cfg);
+
+		if (ret != 0) {
+			PR_INFO("pmac set configuration failed\n");
+			return -1;
+		}
+	} else if (dp_strcmpi(param_list[0], "egress") == 0) {
+		port = dp_atoi(param_list[1]);
+
+		for (i = 2; i < num; i += 2) {
+			for (j = 0; j < ARRAY_SIZE(egress_entries); j++) {
+				if (dp_strcmpi
+				    (param_list[i],
+				     egress_entries[j].name) == 0) {
+					if (dp_strcmpi
+					    (egress_entries[j].name,
+					     "rm_l2hdr") == 0) {
+						if (dp_atoi(param_list[i + 1])
+						    > 0) {
+							pmac_cfg.eg_pmac.
+							    rm_l2hdr = 1;
+							value =
+							    dp_atoi(param_list
+								    [i + 1]);
+							egress_entries[j].
+							    egress_callback
+							    (&pmac_cfg,
+							     value);
+							PR_INFO
+							    ("egress pmac ep %s configured successfully\n",
+							     egress_entries
+							     [j].name);
+							break;
+						}
+
+						pmac_cfg.eg_pmac.rm_l2hdr =
+						    dp_atoi(param_list
+							    [i + 1]);
+					} else {
+						value =
+						    dp_atoi(param_list
+							    [i + 1]);
+						egress_entries[j].
+						    egress_callback(&pmac_cfg,
+								    value);
+						PR_INFO
+						    ("egress pmac ep %s configured successfully\n",
+						     egress_entries[j].name);
+						break;
+					}
+				}
+			}
+		}
+
+		ret = dp_pmac_set(port, &pmac_cfg);
+
+		if (ret != 0) {
+			PR_INFO("pmac set configuration failed\n");
+			return -1;
+		}
+	} else {
+		PR_ERR("wrong command\n");
+		goto help;
+	}
+
+	return count;
+ help:
+	PR_INFO
+	    ("echo ingress/egress [ep_port] ['ingress/egress fields'] [value] > /proc/dp/ep\n");
+	PR_INFO("(eg) echo ingress 1 pmac 1 > /proc/dp/ep\n");
+	PR_INFO("(eg) echo egress 1 rm_l2hdr 2 > /proc/dp/ep\n");
+	PR_INFO
+	    ("echo ingress [ep_port] ['errdisc/pmac/pmac_pmap/pmac_en_pmap/pmac_tc");
+	PR_INFO
+	    ("                         /pmac_en_tc/pmac_subifid/pmac_srcport'] [value] > /proc/dp/ep\n");
+	PR_INFO
+	    ("echo egress [ep_port] ['rx_dmachan/fcs/pmac/res_dw1/res1_dw0/res2_dw0] [value] > /proc/dp/ep\n");
+	PR_INFO("echo egress [ep_port] ['rm_l2hdr'] [value] > /proc/dp/ep\n");
+	return count;
+}
+
+void dp_send_packet(u8 *pdata, int len, char *devname, u32 flag)
+{
+	struct sk_buff *skb;
+	dp_subif_t subif = { 0 };
+
+	skb = cbm_alloc_skb(len + 8, GFP_ATOMIC);
+
+	if (unlikely(!skb)) {
+		PR_ERR("allocate cbm buffer fail\n");
+		return;
+	}
+
+	skb->DW0 = 0;
+	skb->DW1 = 0;
+	skb->DW2 = 0;
+	skb->DW3 = 0;
+	memcpy(skb->data, pdata, len);
+	skb->len = 0;
+	skb_put(skb, len);
+	skb->dev = dev_get_by_name(&init_net, devname);
+
+	if (dp_get_netif_subifid(skb->dev, skb, NULL, skb->data, &subif, 0)) {
+		PR_ERR("dp_get_netif_subifid failed for %s\n",
+		       skb->dev->name);
+		dev_kfree_skb_any(skb);
+		return;
+	}
+
+	((struct dma_tx_desc_1 *)&(skb->DW1))->field.ep = subif.port_id;
+	((struct dma_tx_desc_0 *)&(skb->DW0))->field.dest_sub_if_id =
+	    subif.subif;
+
+	dp_xmit(skb->dev, &subif, skb, skb->len, flag);
+}
+
+static u8 ipv4_plain_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x08, 0x00,		/*type */
+	0x45, 0x00, 0x00, 0x3E, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x11,	/*ip header */
+	0x3A, 0x56, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x2A, 0x7A, 0x41, 0x00, 0x00,	/*udp header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00
+};
+
+static u8 ipv4_plain_tcp[1514] = {
+	0x00, 0x01, 0x01, 0x01, 0x01, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x08, 0x00,		/*type */
+	0x45, 0x00, 0x00, 0x3E, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x06,	/*ip header */
+	0x3A, 0x61, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03,	/*tcp header */
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0x9F, 0xD9, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,	/*data */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00
+};
+
+static u8 ipv6_plain_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x3E, 0x11, 0xFF, 0x20, 0x00,	/*ip header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x3E, 0xBB, 0x6F, 0x00, 0x00,	/*udp header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00
+};
+
+static u8 ipv6_plain_tcp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x46, 0x06, 0xFF, 0x20, 0x00,	/*ip header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03,	/*tcp header */
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0xE1, 0x13, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,	/*data */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 ipv6_extensions_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x8E, 0x00, 0xFF, 0x20, 0x00,	/*ip header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x3C, 0x00, 0x01, 0x04, 0x00, 0x00, 0x00, 0x00,	/*next extension:hop */
+	0x2B, 0x00, 0x01, 0x04, 0x00, 0x00, 0x00, 0x00,	/*next extension:Destination */
+	0x11, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,	/*next extension:Routing */
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x76, 0xBA, 0xFF, 0x00, 0x00,	/*udp header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 ipv6_extensions_tcp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x8E, 0x00, 0xFF, 0x20, 0x00,	/*ip header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x3C, 0x00, 0x01, 0x04, 0x00, 0x00, 0x00, 0x00,	/*next extension:hop */
+	0x2B, 0x00, 0x01, 0x04, 0x00, 0x00, 0x00, 0x00,	/*next extension:Destination */
+	0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,	/*next extension:Routing */
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03,	/*tcp header */
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0xE0, 0xE3, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 rd6_ip4_ip6_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x08, 0x00,		/*type */
+	0x45, 0x00, 0x00, 0x6E, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x29,	/*ip4 header */
+	0x3A, 0x0E, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x32, 0x11, 0xFF, 0x20, 0x00,	/*ip6 header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x32, 0xBB, 0x87, 0x00, 0x00,	/*udp header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 rd6_ip4_ip6_tcp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x08, 0x00,		/*type */
+	0x45, 0x00, 0x00, 0x6E, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x29,	/*ip4 header */
+	0x3A, 0x0E, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x32, 0x06, 0xFF, 0x20, 0x00,	/*ip6 header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03,	/*tcp header */
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0xE1, 0x27, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 dslite_ip6_ip4_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x46, 0x04, 0xFF, 0x20, 0x00,	/*ip6 header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x45, 0x00, 0x00, 0x46, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x11,	/*ip4 header */
+	0x3A, 0x4E, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x32, 0x7A, 0x31, 0x00, 0x00,	/*udp header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 dslite_ip6_ip4_tcp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x46, 0x04, 0xFF, 0x20, 0x00,	/*ip6 header */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x45, 0x00, 0x00, 0x46, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x06,	/*ip4 header */
+	0x3A, 0x59, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03,	/*tcp header */
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0x9F, 0xD1, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static int checksm_mode = 2;
+void proc_checksum_read(struct seq_file *s)
+{
+	char *devname = "eth0_4";
+
+	if (!checksm_mode) {
+		SEQ_PRINTF(s,
+			   "\nsend pmac checksum ipv4_plain_udp new via %s\n",
+			   devname);
+		dp_send_packet(ipv4_plain_udp, sizeof(ipv4_plain_udp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s,
+			   "\nsend pmac checksum ipv4_plain_tcp new via %s\n",
+			   devname);
+		dp_send_packet(ipv4_plain_tcp, sizeof(ipv4_plain_tcp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s,
+			   "\nsend pmac checksum ipv6_plain_udp new via %s\n",
+			   devname);
+		dp_send_packet(ipv6_plain_udp, sizeof(ipv6_plain_udp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s,
+			   "\nsend pmac checksum ipv6_plain_tcp new via %s\n",
+			   devname);
+		dp_send_packet(ipv6_plain_tcp, sizeof(ipv6_plain_tcp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s,
+			   "\nsend pmac checksum ipv6_extensions_udp new via %s\n",
+			   devname);
+		dp_send_packet(ipv6_extensions_udp,
+			       sizeof(ipv6_extensions_udp), devname,
+			       DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s,
+			   "\nsend pmac checksum ipv6_extensions_tcp via %s\n",
+			   devname);
+		dp_send_packet(ipv6_extensions_tcp,
+			       sizeof(ipv6_extensions_tcp), devname,
+			       DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s, "\nsend pmac checksum rd6_ip4_ip6_udp via %s\n",
+			   devname);
+		dp_send_packet(rd6_ip4_ip6_udp, sizeof(rd6_ip4_ip6_udp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s, "\nsend pmac checksum rd6_ip4_ip6_tcp via %s\n",
+			   devname);
+		dp_send_packet(rd6_ip4_ip6_tcp, sizeof(rd6_ip4_ip6_tcp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s,
+			   "\nsend pmac checksum dslite_ip6_ip4_udp via %s\n",
+			   devname);
+		dp_send_packet(dslite_ip6_ip4_udp, sizeof(dslite_ip6_ip4_udp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		SEQ_PRINTF(s,
+			   "\nsend pmac checksum dslite_ip6_ip4_tcp via %s\n",
+			   devname);
+		dp_send_packet(dslite_ip6_ip4_tcp, sizeof(dslite_ip6_ip4_tcp),
+			       devname, DP_TX_CAL_CHKSUM);
+	} else if (checksm_mode == 1) {
+#define MOD_V  32
+		int offset = 14 /*mac */ + 20 /*ip */ + 20 /*tcp */;
+#define IP_LEN_OFFSET 16
+		int i;
+		int numbytes = jiffies % 1515;
+
+		if (numbytes < 64)
+			numbytes = 64;
+		else if (numbytes >= 1514)
+			numbytes = 1514;
+
+		for (i = 0; i < sizeof(ipv4_plain_tcp) - offset; i++) {
+			if (i < (numbytes - offset))
+				ipv4_plain_tcp[offset + i] = (i % MOD_V) + 1;
+			else
+				ipv4_plain_tcp[offset + i] = 0;
+		}
+		*(unsigned short *)&ipv4_plain_tcp[IP_LEN_OFFSET] =
+		    numbytes - 14 /*MAC HDR */;
+
+		dp_send_packet(ipv4_plain_tcp, numbytes, devname,
+			       DP_TX_CAL_CHKSUM);
+	} else if (checksm_mode == 2) {
+#define MOD_V  32
+		int offset = 14 /*mac */  + 20 /*ip */  + 20 /*tcp */;
+		int i;
+		int numbytes = offset + 2 /*2 bytes payload */;
+
+		for (i = 0; i < sizeof(ipv4_plain_tcp) - offset; i++) {
+			if (i < (numbytes - offset))
+				ipv4_plain_tcp[offset + i] = (i % MOD_V) + 1;
+			else
+				ipv4_plain_tcp[offset + i] = 0;
+		}
+		*(unsigned short *)&ipv4_plain_tcp[IP_LEN_OFFSET] =
+		    numbytes - 14 /*MAC HDR */;
+		dp_send_packet(ipv4_plain_tcp, numbytes, devname,
+			       DP_TX_CAL_CHKSUM);
+	}
+}
+
+ssize_t proc_checksum_write(struct file *file, const char *buf, size_t count,
+			    loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num;
+	char *param_list[2];
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	if ((dp_strcmpi(param_list[0], "help") == 0) ||
+	    (dp_strcmpi(param_list[0], "h") == 0)) {
+		goto help;
+	} else
+		checksm_mode = dp_atoi(param_list[0]);
+
+	PRINTK("new checksm_mode=%d\n", checksm_mode);
+	return count;
+
+ help:
+	PRINTK("checksm_mode usage: current value=%d\n", checksm_mode);
+	PRINTK(" 0: common protocol test with HW checksum\n");
+	PRINTK(" 1: TCP random size with HW checksum\n");
+	PRINTK(" 2: 2 Bytes TCP packet with HW checksum\n");
+	PRINTK(" others: not supported value\n");
+
+	return count;
+}
+
+int proc_dport_dump(struct seq_file *s, int pos)
+{
+	int i;
+	cbm_dq_port_res_t res;
+	uint32_t flag = 0;
+	memset(&res, 0, sizeof(cbm_dq_port_res_t));
+
+	if (cbm_dequeue_port_resources_get(pos, &res, flag) == 0) {
+		SEQ_PRINTF(s, "Dequeue port=%d free_base=0x%x\n", pos,
+			   (u32) res.cbm_buf_free_base);
+
+		for (i = 0; i < res.num_deq_ports; i++) {
+			SEQ_PRINTF(s,
+				   "%d:deq_port_base=0x%x num_desc=%d port = %d tx chan %d\n",
+				   i, (u32) res.deq_info[i].cbm_dq_port_base,
+				   res.deq_info[i].num_desc,
+				   res.deq_info[i].port_no,
+				   res.deq_info[i].dma_tx_chan);
+		}
+
+		if (res.deq_info)
+			kfree(res.deq_info);
+	}
+
+	pos++;
+
+	if (pos >= PMAC_MAX_NUM)
+		pos = -1;	/*end of the loop */
+
+	return pos;
+}
+
+int proc_common_cmd_start(void)
+{
+	return 0;
+}
+
+int proc_common_cmd_dump(struct seq_file *s, int pos)
+{
+	struct cmd_list {
+		char *description;
+		char *cmd;
+	};
+	int res = 0;
+	static struct cmd_list cmd_list[] = {
+		{"Pecostat",
+		 "CPU utilization: pecostat -c pic0=0,pic1=1:EXL,K,S,U,IE 1"},
+		{"Check gsw consumed buffer seg",
+		 "dev=1; switch_cli  dev=$dev GSW_REGISTER_GET nRegAddr=0x47"},
+		{"Check gsw default Multicast map",
+		 "dev=1; switch_cli  dev=$dev GSW_REGISTER_GET nRegAddr=0x454"},
+		{"Check gsw default unknown map",
+		 "dev=1; switch_cli  dev=$dev GSW_REGISTER_GET nRegAddr=0x455"},
+		{"Check gsw backpressue", "\n     dev=0 \
+			\n     tx_channel=0   #DMA TX Channel, Range: 0~15 \
+			\n     switch_cli dev=$dev GSW_REGISTER_SET nRegAddr=0xD45 nData=$tx_channel \
+			\n     switch_cli dev=$dev GSW_REGISTER_SET nRegAddr=0xD46 nData=0x8000 \
+			\n     switch_cli dev=$dev GSW_REGISTER_GET nRegAddr=0xD42 #RX Port Congestion Mask (bit 15:0)\
+			\n     switch_cli dev=$dev GSW_REGISTER_GET nRegAddr=0xD43 #TX Queue Congestion Mask (bit 15:0)\
+			\n     switch_cli dev=$dev GSW_REGISTER_GET nRegAddr=0xD44 #TX Queue Congestion Mask (bit 31:16)"},
+		{"Disable gsw backpressue", "\n     dev=0 \
+			\n     tx_channel=0   #DMA TX Channel, Range: 0~15 \
+			\n     switch_cli dev=$dev GSW_REGISTER_SET nRegAddr=0xD42 nData=0x0     \
+			\n     switch_cli dev=$dev GSW_REGISTER_SET nRegAddr=0xD43 nData=0x0     \
+			\n     switch_cli dev=$dev GSW_REGISTER_SET nRegAddr=0xD44 nData=0x0     \
+			\n     switch_cli dev=$dev GSW_REGISTER_SET nRegAddr=0xD45 nData=$tx_channel \
+			\n     switch_cli dev=$dev GSW_REGISTER_SET nRegAddr=0xD46 nData=0x8020"},
+		{"Check egress pmac", "\n    dev=1 \
+			\n    nTrafficClass=1 #Range:0~15 \
+			\n    nFlowIDMsb=1 #Range:0~3 \
+			\n    nDestPortId=15 #Range:0~15 \
+			\n    switch_cli dev=$dev GSW_PMAC_EG_CFG_GET nTrafficClass=$nTrafficClass nFlowIDMsb=$nFlowIDMsb nDestPortId=$nDestPortId"},
+		{"Check ingress pmac", "\n    dev=1; \
+			\n    nTxDmaChanId=1 #Range:0~15 \
+			\n    switch_cli dev=$dev GSW_PMAC_IG_CFG_GET nTxDmaChanId=$nTxDmaChanId"},
+		{"Check gsw link status",
+		 "dev=0; nPortId=6; switch_cli dev=$dev GSW_PORT_LINK_CFG_GET nPortId=$nPortId"},
+		{"Check gsw queue map",
+		 "dev=1; nPortId=6; switch_cli  dev=$dev GSW_QOS_QUEUE_PORT_GET nPortId=$nPortId"},
+		{"Add static MAC addres",
+		 "\n    dev=1; nPortId=7; switch_cli dev=$dev GSW_MAC_TABLE_ENTRY_ADD nPortId=$nPortId nSubIfId=0x100 bStaticEntry=1 nMAC=00:10:94:00:00:01"},
+		{"Disable PMAC Checksum",
+		 "dev=0; switch_cli  dev=$dev GSW_REGISTER_SET nRegAddr=0xD03 nData=0x0C0"},
+		{"Debugger example",
+		 "\n    d.load.elf \"X:\\tmp2\\shaoguoh\\project\\ugw61_grx500\\openwrt\\core\\kernel_tree\\vmlinux\" /gnu /strippart \"/tmp2\" /path \"X:\\tmp2\" /nocode"},
+		{"While example 1",
+		 "\n     i=0 \n     while [ $i -lt 16 ] \n     do \n       xxxx \n     i=$((i+1)) \n     done"},
+		 {"While example 2",
+		 "\n     while true\n     do\n       xxxx\n     done\n"},
+		{"For example",
+		 "\n     for i in 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n     do  \n       xxxxxx \n    done"},
+
+		/*last place holder */
+		{NULL, NULL}
+	};
+
+	if (!cmd_list[pos].description)
+		return -1;
+
+	if (!cmd_list[pos].cmd) {
+		SEQ_PRINTF(s,
+			   "key in wrongly cmd for pos=%d with command: %s\n",
+			   pos, cmd_list[pos].cmd);
+	} else if (dp_strncmpi(cmd_list[pos].cmd, "\n    ", 5) == 0) {
+		res = SEQ_PRINTF(s, "---%s: ", cmd_list[pos].description);
+		res = SEQ_PRINTF(s, "%s\n\n", cmd_list[pos].cmd);
+	} else
+		res =
+		    SEQ_PRINTF(s, "---%s: %s\n\n", cmd_list[pos].description,
+			       cmd_list[pos].cmd);
+	if (res)
+		return pos;	/*repeat since proc buffer not enough*/
+
+	pos++;
+
+	if (pos >= ARRAY_SIZE(cmd_list))
+		pos = -1;	/*end of the loop */
+
+	return pos;
+}
+
+struct dp_skb_info {
+	struct list_head list;
+	struct sk_buff *skb;
+};
+
+static int cbm_skb_num;	/* for cbm buffer testing purpose */
+static struct dp_skb_info skb_list;
+#define get_val(val, mask, offset) (((val) & (mask)) >> (offset))
+int cbm_get_free_buf(int fsqm_index, uint32_t *free_num, uint32_t *head,
+		     uint32_t *tail)
+{
+	unsigned char *base;
+
+	if (!fsqm_index)
+		base = (unsigned char *)(FSQM0_MODULE_BASE + 0xa0000000);
+	else
+		base = (unsigned char *)(FSQM1_MODULE_BASE + 0xa0000000);
+	if (free_num)
+		*free_num =
+		    get_val(*(uint32_t *) (base + OFSC), OFSC_FSC_MASK,
+			    OFSC_FSC_POS);
+	if (head)
+		*head =
+		    get_val(*(uint32_t *) (base + OFSQ), OFSQ_HEAD_MASK,
+			    OFSQ_HEAD_POS);
+	if (tail)
+		*tail =
+		    get_val(*(uint32_t *) (base + OFSQ), OFSQ_TAIL_MASK,
+			    OFSQ_TAIL_POS);
+
+	return 0;
+}
+
+void proc_cbm_buf_read(struct seq_file *s)
+{
+	uint32_t free_fsqm_num[2], fsqm_head[2], fsqm_tail[2];
+	int i;
+
+	for (i = 0; i < 2; i++)
+		cbm_get_free_buf(i, &free_fsqm_num[i], &fsqm_head[i],
+				 &fsqm_tail[i]);
+	for (i = 0; i < 2; i++)
+		SEQ_PRINTF(s,
+			   "FSQM%d: free buffer-%04d, head-%04d, tail-%04d\n",
+			   i, free_fsqm_num[i], fsqm_head[i], fsqm_tail[i]);
+	if (cbm_skb_num)
+		SEQ_PRINTF(s,
+			   "Overall %d CBM buffer is allocated for testing purpose !\n",
+			   cbm_skb_num);
+	SEQ_PRINTF(s,
+		   "Note: use echo to display other commans: echo help > /proc/dp/%s\n",
+		   DP_PROC_FILE_CBM_BUF_TEST);
+}
+
+ssize_t proc_cbm_buf_write(struct file *file, const char *buf, size_t count,
+			   loff_t *ppos)
+{
+	int len;
+	char str[64];
+	char *param_list[2] = { 0 };
+	unsigned int num;
+	struct dp_skb_info *tmp = NULL;
+	uint32_t free_fsqm_num[2], fsqm_head[2], fsqm_tail[2], *check_list;
+	int i;
+	uint32_t idx, buf_ptr, val, head, tail, bits;
+	const uint32_t fsqm_buf_len[] = {9216, 1024};
+	void __iomem *base;
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	if (dp_split_buffer(str, param_list, ARRAY_SIZE(param_list)) < 2)
+		goto help;
+	if (!cbm_skb_num)
+		INIT_LIST_HEAD(&skb_list.list);
+	if (list_empty(&skb_list.list) && (cbm_skb_num != 0)) {
+		PR_ERR
+		    ("Why skb_list is empty but recorded value of cbm_skb_num=%d\n",
+		     cbm_skb_num);
+		goto exit;
+	}
+	if (cbm_skb_num < 0) {
+		PR_ERR("Why cbm_skb_num(%d) less than zero\n", cbm_skb_num);
+		goto exit;
+	}
+	num = dp_atoi(param_list[1]);
+	if (dp_strcmpi(param_list[0], "alloc") == 0) {
+		if (num == 0)
+			goto exit;
+			do {
+				tmp =
+				    (struct dp_skb_info *)
+				    kmalloc(sizeof(struct dp_skb_info), GFP_ATOMIC);
+				if (!tmp) {
+					PR_ERR("kmalloc failed\n");
+					goto exit;
+				}
+				INIT_LIST_HEAD(&tmp->list);
+				tmp->skb = cbm_alloc_skb(1000, 0);
+				if (!tmp->skb) {
+					goto exit;
+					kfree(tmp);
+				}
+				DP_DEBUG(DP_DBG_FLAG_CBM_BUF,
+					 "cbm_alloc_skb ok: %p (node=%p buffer=%p)\n",
+					 tmp->skb, &tmp->list, tmp);
+				list_add(&(tmp->list), &(skb_list.list));
+				num--;
+				cbm_skb_num++;
+			} while (num);
+	} else if (dp_strcmpi(param_list[0], "free") == 0) {
+		struct list_head *pos, *n;
+		struct dp_skb_info *p;
+		if (cbm_skb_num == 0 || num == 0)
+			goto exit;
+		list_for_each_safe(pos, n, &skb_list.list) {
+			if (!pos)
+				break;
+			p = list_entry(pos, struct dp_skb_info, list);
+			if (!pos) {
+				PR_ERR("why P NULL ???\n");
+				goto exit;
+			}
+			if (p->skb) {
+				if (!check_ptr_validation
+				    ((uint32_t) p->skb->data))
+					PR_ERR
+					    ("Wrong Free skb %p(node=%p buffer=%p) not CBM bffer\n",
+					     p->skb, pos, p);
+				else
+					DP_DEBUG(DP_DBG_FLAG_CBM_BUF,
+						 "Free skb %p(node=%p buffer=%p)\n",
+						 p->skb, pos, p);
+				dev_kfree_skb(p->skb);
+
+				p->skb = NULL;
+			} else
+				PR_ERR("why p->skb NULL ???\n");
+			list_del(pos);
+			kfree(p);
+			num--;
+			cbm_skb_num--;
+			if (!num)
+				break;
+		}
+	} else if (dp_strcmpi(param_list[0], "check") == 0) {
+		int good = 1;
+		idx = dp_atoi(param_list[1]);
+		if (idx >= 2) {
+			PR_ERR("FSQM idx must be 0 or 1\n");
+			return count;
+		}
+		num = idx;
+		PR_INFO("\nCBM link list check can only be performed with NO traffic on CBM!\n");
+		check_list = kmalloc(fsqm_buf_len[idx] >> 3, GFP_KERNEL);
+		if (!check_list) {
+			PR_ERR("Failed to allocate check list buffer\n");
+			return count;
+		}
+		memset(check_list, 0, fsqm_buf_len[idx] >> 3);
+		if (idx == 0) /* Fixme: Hardcoded mapping address */
+			base = (void __iomem *)FSQM0_MODULE_BASE + 0xa0000000;
+		else
+			base = (void __iomem *)FSQM1_MODULE_BASE + 0xa0000000;
+		val = readl(base + OFSQ);
+		head = val & 0x7FFF;
+		tail = (val >> 16) & 0x7FFF;
+		PR_INFO("FSQM Head: 0x%x, Tail: 0x%x\n", head, tail);
+		for (i = 0, buf_ptr = head;
+			i < fsqm_buf_len[num] && buf_ptr != tail;
+			i++) {
+			idx = buf_ptr / 32;
+			bits = buf_ptr % 32;
+			if (!(check_list[idx] & BIT(bits))) {
+				check_list[idx] |= BIT(bits);
+			} else {
+				PRINTK("FSQM[%d] ERROR: PTR:[0x%4x] is duplicated\n", num, buf_ptr);
+				good = 0;
+			}
+			buf_ptr = readl(base + RAM + (buf_ptr << 2));
+		}
+		PRINTK("Total freed buffers in link list: 0x%x, free buffer cnt in CBM OFSC REG: 0x%x---%s\n",
+			i + 1, readl(base + OFSC),
+			good ? "In Good State" : "In Wrong State");
+		kfree(check_list);
+		return count;
+	} else
+		goto help;
+
+ exit:
+	for (i = 0; i < 2; i++)
+		cbm_get_free_buf(i, &free_fsqm_num[i], &fsqm_head[i],
+				 &fsqm_tail[i]);
+	if (cbm_skb_num)
+		PR_ERR
+		    ("Overall %d CBM buffer is allocated for testing purpose\n",
+		     cbm_skb_num);
+	else
+		PR_ERR("All buffer already returned to CBM\n");
+	for (i = 0; i < 2; i++)
+		PR_ERR("FSQM%d: free buffer-%04d, head-%04d, tail-%04d\n", i,
+		       free_fsqm_num[i], fsqm_head[i], fsqm_tail[i]);
+	return count;
+
+ help:
+	PRINTK("usage: echo alloc [cbm buffer num] > /proc/dp/%s\n",
+	       DP_PROC_FILE_CBM_BUF_TEST);
+	PRINTK("usage: echo free  [cbm buffer num] > /proc/dp/%s\n",
+	       DP_PROC_FILE_CBM_BUF_TEST);
+	PRINTK("Check CBM buffer link list: echo check <fqsm_idx> > /proc/dp/%s\n",
+	       DP_PROC_FILE_CBM_BUF_TEST);
+	return count;
+}
+
+static int proc_gsw_pce_dump(struct seq_file *s, int pos)
+{
+	GSW_API_HANDLE gsw_handle = 0;
+	GSW_PCE_rule_t *rule;
+	int ret = 0, i;
+
+	rule =
+	    (GSW_PCE_rule_t *) kmalloc(sizeof(GSW_PCE_rule_t) + 1,
+				       GFP_ATOMIC);
+	if (!rule) {
+		PR_ERR("Failed to allocate %d bytes buffer\n",
+		       sizeof(GSW_PCE_rule_t) + 1);
+		pos = -1;
+		return pos;
+	}
+
+	/*read gswip-r rmon counter */
+	gsw_handle = gsw_api_kopen((char *)GSWIP_R_DEV_NAME);
+	if (gsw_handle == 0) {
+		PR_ERR("Open GSWIP-R device FAILED !\n");
+		pos = -1;
+		kfree(rule);
+		return pos;
+	}
+	rule->pattern.nIndex = pos;
+	ret =
+	    gsw_api_kioctl(gsw_handle, GSW_PCE_RULE_READ, (unsigned int)rule);
+	if (ret != GSW_statusOk) {
+		/*dbg("read_pce_entry returned Failure for index=%d\n", rule.index);*/
+		pos = -1;
+		return pos;
+	}
+	if (!rule->pattern.bEnable)
+		goto EXIT;
+
+	SEQ_PRINTF(s, "Pattern[%d]:-----\n", rule->pattern.nIndex);
+	if (rule->pattern.bPortIdEnable) {
+		SEQ_PRINTF(s, "  bPortIdEnable           =   %d\n",
+			   rule->pattern.bPortIdEnable);
+		SEQ_PRINTF(s, "  nPortId                 =   %d\n",
+			   rule->pattern.nPortId);
+		SEQ_PRINTF(s, "  bPortId_Exclude         =   %d\n",
+			   rule->pattern.bPortId_Exclude);
+	}
+	if (rule->pattern.bSubIfIdEnable) {
+		SEQ_PRINTF(s, "  bSubIfIdEnable          =   %d\n",
+			   rule->pattern.bSubIfIdEnable);
+		SEQ_PRINTF(s, "  nSubIfId                =   %d\n",
+			   rule->pattern.nSubIfId);
+		SEQ_PRINTF(s, "  bSubIfId_Exclude        =   %d\n",
+			   rule->pattern.bSubIfId_Exclude);
+	}
+	if (rule->pattern.bDSCP_Enable) {
+		SEQ_PRINTF(s, "  bDSCP_Enable            =   %d\n",
+			   rule->pattern.bDSCP_Enable);
+		SEQ_PRINTF(s, "  nDSCP                   =   %d\n",
+			   rule->pattern.nDSCP);
+		SEQ_PRINTF(s, "  bDSCP_Exclude           =   %d\n",
+			   rule->pattern.bDSCP_Exclude);
+	}
+	if (rule->pattern.bInner_DSCP_Enable) {
+		SEQ_PRINTF(s, "  bInner_DSCP_Enable      =   %d\n",
+			   rule->pattern.bInner_DSCP_Enable);
+		SEQ_PRINTF(s, "  nInnerDSCP              =   %d\n",
+			   rule->pattern.nInnerDSCP);
+		SEQ_PRINTF(s, "  bInnerDSCP_Exclude      =   %d\n",
+			   rule->pattern.bInnerDSCP_Exclude);
+	}
+	if (rule->pattern.bPCP_Enable) {
+		SEQ_PRINTF(s, "  bPCP_Enable             =   %d\n",
+			   rule->pattern.bPCP_Enable);
+		SEQ_PRINTF(s, "  nPCP                    =   %d\n",
+			   rule->pattern.nPCP);
+		SEQ_PRINTF(s, "  bCTAG_PCP_DEI_Exclude   =   %d\n",
+			   rule->pattern.bCTAG_PCP_DEI_Exclude);
+	}
+	if (rule->pattern.bSTAG_PCP_DEI_Enable) {
+		SEQ_PRINTF(s, "  bSTAG_PCP_DEI_Enable    =   %d\n",
+			   rule->pattern.bSTAG_PCP_DEI_Enable);
+		SEQ_PRINTF(s, "  nSTAG_PCP_DEI           =   %d\n",
+			   rule->pattern.nSTAG_PCP_DEI);
+		SEQ_PRINTF(s, "  bSTAG_PCP_DEI_Exclude   =   %d\n",
+			   rule->pattern.bSTAG_PCP_DEI_Exclude);
+	}
+	if (rule->pattern.bPktLngEnable) {
+		SEQ_PRINTF(s, "  bPktLngEnable           =   %d\n",
+			   rule->pattern.bPktLngEnable);
+		SEQ_PRINTF(s, "  nPktLng                 =   %d\n",
+			   rule->pattern.nPktLng);
+		SEQ_PRINTF(s, "  nPktLngRange            =   %d\n",
+			   rule->pattern.nPktLngRange);
+		SEQ_PRINTF(s, "  bPktLng_Exclude         =   %d\n",
+			   rule->pattern.bPktLng_Exclude);
+	}
+	if (rule->pattern.bMAC_DstEnable) {
+		SEQ_PRINTF(s, "  bMAC_DstEnable          =   %d\n",
+			   rule->pattern.bMAC_DstEnable);
+		SEQ_PRINTF(s,
+			   "  nMAC_Dst                =   %02x:%2x:%2x:%2x:%2x:%2x\n",
+			   rule->pattern.nMAC_Dst[0],
+			   rule->pattern.nMAC_Dst[1],
+			   rule->pattern.nMAC_Dst[2],
+			   rule->pattern.nMAC_Dst[3],
+			   rule->pattern.nMAC_Dst[4],
+			   rule->pattern.nMAC_Dst[5]);
+		SEQ_PRINTF(s, "  nMAC_DstMask            =   %x\n",
+			   rule->pattern.nMAC_DstMask);
+		SEQ_PRINTF(s, "  bDstMAC_Exclude         =   %d\n",
+			   rule->pattern.bDstMAC_Exclude);
+	}
+	if (rule->pattern.bMAC_SrcEnable) {
+		SEQ_PRINTF(s, "  bMAC_SrcEnable          =   %d\n",
+			   rule->pattern.bMAC_SrcEnable);
+		SEQ_PRINTF(s,
+			   "  nMAC_Src                =   %02x:%2x:%2x:%2x:%2x:%2x\n",
+			   rule->pattern.nMAC_Src[0],
+			   rule->pattern.nMAC_Src[1],
+			   rule->pattern.nMAC_Src[2],
+			   rule->pattern.nMAC_Src[3],
+			   rule->pattern.nMAC_Src[4],
+			   rule->pattern.nMAC_Src[5]);
+		SEQ_PRINTF(s, "  nMAC_SrcMask            =   %x\n",
+			   rule->pattern.nMAC_SrcMask);
+		SEQ_PRINTF(s, "  bSrcMAC_Exclude         =   %d\n",
+			   rule->pattern.bSrcMAC_Exclude);
+	}
+	if (rule->pattern.bAppDataMSB_Enable) {
+		SEQ_PRINTF(s, "  bAppDataMSB_Enable      =   %d\n",
+			   rule->pattern.bAppDataMSB_Enable);
+		SEQ_PRINTF(s, "  nAppDataMSB             =   %x\n",
+			   rule->pattern.nAppDataMSB);
+		SEQ_PRINTF(s, "  bAppMaskRangeMSB_Select =   %d\n",
+			   rule->pattern.bAppMaskRangeMSB_Select);
+		SEQ_PRINTF(s, "  nAppMaskRangeMSB        =   %x\n",
+			   rule->pattern.nAppMaskRangeMSB);
+		SEQ_PRINTF(s, "  bAppMSB_Exclude         =   %d\n",
+			   rule->pattern.bAppMSB_Exclude);
+	}
+	if (rule->pattern.bAppDataLSB_Enable) {
+		SEQ_PRINTF(s, "  bAppDataLSB_Enable      =   %d\n",
+			   rule->pattern.bAppDataLSB_Enable);
+		SEQ_PRINTF(s, "  nAppDataLSB             =   %x\n",
+			   rule->pattern.nAppDataLSB);
+		SEQ_PRINTF(s, "  bAppMaskRangeLSB_Select =   %d\n",
+			   rule->pattern.bAppMaskRangeLSB_Select);
+		SEQ_PRINTF(s, "  nAppMaskRangeLSB        =   %x\n",
+			   rule->pattern.nAppMaskRangeLSB);
+		SEQ_PRINTF(s, "  bAppLSB_Exclude         =   %d\n",
+			   rule->pattern.bAppLSB_Exclude);
+	}
+	if (rule->pattern.eDstIP_Select) {
+		SEQ_PRINTF(s, "  eDstIP_Select           =   %d\n",
+			   rule->pattern.eDstIP_Select);
+		SEQ_PRINTF(s, "  nDstIP                  =   %08x ",
+			   rule->pattern.nDstIP.nIPv4);
+		if (rule->pattern.eDstIP_Select == 2)
+			for (i = 2; i < 8; i++)
+				SEQ_PRINTF(s, "%04x ",
+					   rule->pattern.nDstIP.nIPv6[i]);
+		SEQ_PRINTF(s, "\n");
+		SEQ_PRINTF(s, "  nDstIP_Mask             =   %x\n",
+			   rule->pattern.nDstIP_Mask);
+		SEQ_PRINTF(s, "  bDstIP_Exclude          =   %d\n",
+			   rule->pattern.bDstIP_Exclude);
+	}
+	if (rule->pattern.eInnerDstIP_Select) {
+		SEQ_PRINTF(s, "  eInnerDstIP_Select      =   %d\n",
+			   rule->pattern.eInnerDstIP_Select);
+		SEQ_PRINTF(s, "  nInnerDstIP             =   %x\n",
+			   rule->pattern.nInnerDstIP.nIPv4);
+		SEQ_PRINTF(s, "  nInnerDstIP_Mask        =   %x\n",
+			   rule->pattern.nInnerDstIP_Mask);
+		SEQ_PRINTF(s, "  bInnerDstIP_Exclude     =   %d\n",
+			   rule->pattern.bInnerDstIP_Exclude);
+	}
+	if (rule->pattern.eSrcIP_Select) {
+		SEQ_PRINTF(s, "  eSrcIP_Select           =   %d\n",
+			   rule->pattern.eSrcIP_Select);
+		SEQ_PRINTF(s, "  nSrcIP                  =   %x\n",
+			   rule->pattern.nSrcIP.nIPv4);
+		SEQ_PRINTF(s, "  nSrcIP_Mask             =   %x\n",
+			   rule->pattern.nSrcIP_Mask);
+		SEQ_PRINTF(s, "  bSrcIP_Exclude          =   %d\n",
+			   rule->pattern.bSrcIP_Exclude);
+	}
+	if (rule->pattern.eInnerSrcIP_Select) {
+		SEQ_PRINTF(s, "  eInnerSrcIP_Select      =   %d\n",
+			   rule->pattern.eInnerSrcIP_Select);
+		SEQ_PRINTF(s, "  nInnerSrcIP             =   %x\n",
+			   rule->pattern.nInnerSrcIP.nIPv4);
+		SEQ_PRINTF(s, "  nInnerSrcIP_Mask        =   %x\n",
+			   rule->pattern.nInnerSrcIP_Mask);
+		SEQ_PRINTF(s, "  bInnerSrcIP_Exclude     =   %d\n",
+			   rule->pattern.bInnerSrcIP_Exclude);
+	}
+	if (rule->pattern.bEtherTypeEnable) {
+		SEQ_PRINTF(s, "  bEtherTypeEnable        =   %d\n",
+			   rule->pattern.bEtherTypeEnable);
+		SEQ_PRINTF(s, "  nEtherType              =   %x\n",
+			   rule->pattern.nEtherType);
+		SEQ_PRINTF(s, "  nEtherTypeMask          =   %x\n",
+			   rule->pattern.nEtherTypeMask);
+		SEQ_PRINTF(s, "  bEtherType_Exclude      =   %d\n",
+			   rule->pattern.bEtherType_Exclude);
+	}
+	if (rule->pattern.bProtocolEnable) {
+		SEQ_PRINTF(s, "  bProtocolEnable         =   %d\n",
+			   rule->pattern.bProtocolEnable);
+		SEQ_PRINTF(s, "  nProtocol               =   %x\n",
+			   rule->pattern.nProtocol);
+		SEQ_PRINTF(s, "  nProtocolMask           =   %x\n",
+			   rule->pattern.nProtocolMask);
+		SEQ_PRINTF(s, "  bProtocol_Exclude       =   %d\n",
+			   rule->pattern.bProtocol_Exclude);
+	}
+	if (rule->pattern.bInnerProtocolEnable) {
+		SEQ_PRINTF(s, "  bInnerProtocolEnable    =   %d\n",
+			   rule->pattern.bInnerProtocolEnable);
+		SEQ_PRINTF(s, "  nInnerProtocol          =   %x\n",
+			   rule->pattern.nInnerProtocol);
+		SEQ_PRINTF(s, "  nInnerProtocolMask      =   %x\n",
+			   rule->pattern.nInnerProtocolMask);
+		SEQ_PRINTF(s, "  bInnerProtocol_Exclude  =   %d\n",
+			   rule->pattern.bInnerProtocol_Exclude);
+	}
+	if (rule->pattern.bSessionIdEnable) {
+		SEQ_PRINTF(s, "  bSessionIdEnable        =   %d\n",
+			   rule->pattern.bSessionIdEnable);
+		SEQ_PRINTF(s, "  nSessionId              =   %x\n",
+			   rule->pattern.nSessionId);
+		SEQ_PRINTF(s, "  bSessionId_Exclude      =   %d\n",
+			   rule->pattern.bSessionId_Exclude);
+	}
+	if (rule->pattern.bPPP_ProtocolEnable) {
+		SEQ_PRINTF(s, "  bPPP_ProtocolEnable     =   %d\n",
+			   rule->pattern.bPPP_ProtocolEnable);
+		SEQ_PRINTF(s, "  nPPP_Protocol           =   %x\n",
+			   rule->pattern.nPPP_Protocol);
+		SEQ_PRINTF(s, "  nPPP_ProtocolMask       =   %x\n",
+			   rule->pattern.nPPP_ProtocolMask);
+		SEQ_PRINTF(s, "  bPPP_Protocol_Exclude   =   %d\n",
+			   rule->pattern.bPPP_Protocol_Exclude);
+	}
+	if (rule->pattern.bVid) {
+		SEQ_PRINTF(s, "  bVid                    =   %d\n",
+			   rule->pattern.bVid);
+		SEQ_PRINTF(s, "  nVid                    =   %d\n",
+			   rule->pattern.nVid);
+		SEQ_PRINTF(s, "  bVid_Exclude            =   %d\n",
+			   rule->pattern.bVid_Exclude);
+	}
+	if (rule->pattern.bSLAN_Vid) {
+		SEQ_PRINTF(s, "  bSLAN_Vid               =    %d\n",
+			   rule->pattern.bSLAN_Vid);
+		SEQ_PRINTF(s, "  nSLAN_Vid               =    %d\n",
+			   rule->pattern.nSLAN_Vid);
+		SEQ_PRINTF(s, "  bSLANVid_Exclude        =    %d\n",
+			   rule->pattern.bSLANVid_Exclude);
+	}
+	if (rule->pattern.bPayload1_SrcEnable) {
+		SEQ_PRINTF(s, "  bPayload1_SrcEnable     =   %d\n",
+			   rule->pattern.bPayload1_SrcEnable);
+		SEQ_PRINTF(s, "  nPayload1               =   %x\n",
+			   rule->pattern.nPayload1);
+		SEQ_PRINTF(s, "  nPayload1_Mask          =   %x\n",
+			   rule->pattern.nPayload1_Mask);
+		SEQ_PRINTF(s, "  bPayload1_Exclude       =   %d\n",
+			   rule->pattern.bPayload1_Exclude);
+	}
+	if (rule->pattern.bPayload2_SrcEnable) {
+		SEQ_PRINTF(s, "  bPayload2_SrcEnable     =   %d\n",
+			   rule->pattern.bPayload2_SrcEnable);
+		SEQ_PRINTF(s, "  nPayload2               =   %x\n",
+			   rule->pattern.nPayload2);
+		SEQ_PRINTF(s, "  nPayload2_Mask          =   %x\n",
+			   rule->pattern.nPayload2_Mask);
+		SEQ_PRINTF(s, "  bPayload2_Exclude       =   %d\n",
+			   rule->pattern.bPayload2_Exclude);
+	}
+	if (rule->pattern.bParserFlagLSB_Enable) {
+		SEQ_PRINTF(s, "  bParserFlagLSB_Enable   =   %d\n",
+			   rule->pattern.bParserFlagLSB_Enable);
+		SEQ_PRINTF(s, "  nParserFlagLSB          =   %x\n",
+			   rule->pattern.nParserFlagLSB);
+		SEQ_PRINTF(s, "  nParserFlagLSB_Mask     =   %x\n",
+			   rule->pattern.nParserFlagLSB_Mask);
+		SEQ_PRINTF(s, "  bParserFlagLSB_Exclude  =   %d\n",
+			   rule->pattern.bParserFlagLSB_Exclude);
+	}
+	if (rule->pattern.bParserFlagMSB_Enable) {
+		SEQ_PRINTF(s, "  bParserFlagMSB_Enable   =   %d\n",
+			   rule->pattern.bParserFlagMSB_Enable);
+		SEQ_PRINTF(s, "  nParserFlagMSB          =   %x\n",
+			   rule->pattern.nParserFlagMSB);
+		SEQ_PRINTF(s, "  nParserFlagMSB_Mask     =   %x\n",
+			   rule->pattern.nParserFlagMSB_Mask);
+		SEQ_PRINTF(s, "  bParserFlagMSB_Exclude  =   %d\n",
+			   rule->pattern.bParserFlagMSB_Exclude);
+	}
+
+	SEQ_PRINTF(s, "Action:\n");
+	if (rule->action.eTrafficClassAction) {
+		SEQ_PRINTF(s, "  eTrafficClassAction      =   %d\n",
+			   rule->action.eTrafficClassAction);
+		SEQ_PRINTF(s, "  nTrafficClassAlternate   =   %d\n",
+			   rule->action.nTrafficClassAlternate);
+	}
+	if (rule->action.eSnoopingTypeAction)
+		SEQ_PRINTF(s, "  eSnoopingTypeAction      =   %d\n",
+			   rule->action.eSnoopingTypeAction);
+	if (rule->action.eLearningAction)
+		SEQ_PRINTF(s, "  eLearningAction          =   %d\n",
+			   rule->action.eLearningAction);
+	if (rule->action.eIrqAction)
+		SEQ_PRINTF(s, "  eIrqAction               =   %d\n",
+			   rule->action.eIrqAction);
+	if (rule->action.eCrossStateAction)
+		SEQ_PRINTF(s, "  eCrossStateAction        =   %d\n",
+			   rule->action.eCrossStateAction);
+	if (rule->action.eCritFrameAction)
+		SEQ_PRINTF(s, "  eCritFrameAction         =   %d\n",
+			   rule->action.eCritFrameAction);
+	if (rule->action.eTimestampAction) {
+		SEQ_PRINTF(s, "  eTimestampAction         =   %d\n",
+			   rule->action.eTimestampAction);
+	}
+	if (rule->action.ePortMapAction) {
+		SEQ_PRINTF(s, "  ePortMapAction           =   %d\n",
+			   rule->action.ePortMapAction);
+		SEQ_PRINTF(s, "  nForwardPortMap          =   %d\n",
+			   rule->action.nForwardPortMap);
+		SEQ_PRINTF(s, "  nForwardSubIfId          =   %d\n",
+			   rule->action.nForwardSubIfId);
+	}
+	if (rule->action.bRemarkAction)
+		SEQ_PRINTF(s, "  bRemarkAction            =   %d\n",
+			   rule->action.bRemarkAction);
+	if (rule->action.bRemarkPCP)
+		SEQ_PRINTF(s, "  bRemarkPCP               =   %d\n",
+			   rule->action.bRemarkPCP);
+	if (rule->action.bRemarkSTAG_PCP)
+		SEQ_PRINTF(s, "  bRemarkSTAG_PCP          =   %d\n",
+			   rule->action.bRemarkSTAG_PCP);
+	if (rule->action.bRemarkSTAG_DEI)
+		SEQ_PRINTF(s, "  bRemarkSTAG_DEI          =   %d\n",
+			   rule->action.bRemarkSTAG_DEI);
+	if (rule->action.bRemarkDSCP)
+		SEQ_PRINTF(s, "  bRemarkDSCP              =   %d\n",
+			   rule->action.bRemarkDSCP);
+	if (rule->action.bRemarkClass) {
+		SEQ_PRINTF(s, "  bRemarkClass             =   %d\n",
+			   rule->action.bRemarkClass);
+	}
+	if (rule->action.eMeterAction) {
+		SEQ_PRINTF(s, "  eMeterAction             =   %d\n",
+			   rule->action.eMeterAction);
+		SEQ_PRINTF(s, "  nMeterId                 =   %d\n",
+			   rule->action.nMeterId);
+	}
+	if (rule->action.bRMON_Action) {
+		SEQ_PRINTF(s, "  bRMON_Action             =   %d\n",
+			   rule->action.bRMON_Action);
+		SEQ_PRINTF(s, "  nRMON_Id                 =   %d\n",
+			   rule->action.nRMON_Id);
+	}
+	if (rule->action.eVLAN_Action) {
+		SEQ_PRINTF(s, "  eVLAN_Action             =   %d\n",
+			   rule->action.eVLAN_Action);
+		SEQ_PRINTF(s, "  nVLAN_Id                 =   %d\n",
+			   rule->action.nVLAN_Id);
+	}
+	if (rule->action.eSVLAN_Action) {
+		SEQ_PRINTF(s, "  eSVLAN_Action            =   %d\n",
+			   rule->action.eSVLAN_Action);
+		SEQ_PRINTF(s, "  nSVLAN_Id                =   %d\n",
+			   rule->action.nSVLAN_Id);
+	}
+	if (rule->action.eVLAN_CrossAction)
+		SEQ_PRINTF(s, "  eVLAN_CrossAction        =   %d\n",
+			   rule->action.eVLAN_CrossAction);
+	if (rule->action.nFId)
+		SEQ_PRINTF(s, "  nFId                     =   %d\n",
+			   rule->action.nFId);
+	if (rule->action.bPortBitMapMuxControl)
+		SEQ_PRINTF(s, "  bPortBitMapMuxControl    =   %d\n",
+			   rule->action.bPortBitMapMuxControl);
+	if (rule->action.bPortTrunkAction)
+		SEQ_PRINTF(s, "  bPortTrunkAction         =   %d\n",
+			   rule->action.bPortTrunkAction);
+	if (rule->action.bPortLinkSelection)
+		SEQ_PRINTF(s, "  bPortLinkSelection       =   %d\n",
+			   rule->action.bPortLinkSelection);
+	if (rule->action.bCVLAN_Ignore_Control)
+		SEQ_PRINTF(s, "  bCVLAN_Ignore_Control    =   %d\n",
+			   rule->action.bCVLAN_Ignore_Control);
+	if (rule->action.bFlowID_Action) {
+		SEQ_PRINTF(s, "  bFlowID_Action           =   %d\n",
+			   rule->action.bFlowID_Action);
+		SEQ_PRINTF(s, "  nFlowID                  =   %d\n",
+			   rule->action.nFlowID);
+	}
+	if (rule->action.bRoutExtId_Action) {
+		SEQ_PRINTF(s, "  bRoutExtId_Action        =   %d\n",
+			   rule->action.bRoutExtId_Action);
+		SEQ_PRINTF(s, "  nRoutExtId               =   %d\n",
+			   rule->action.nRoutExtId);
+	}
+	if (rule->action.bRtDstPortMaskCmp_Action)
+		SEQ_PRINTF(s, "  bRtDstPortMaskCmp_Action =   %d\n",
+			   rule->action.bRtDstPortMaskCmp_Action);
+	if (rule->action.bRtSrcPortMaskCmp_Action)
+		SEQ_PRINTF(s, "  bRtSrcPortMaskCmp_Action =   %d\n",
+			   rule->action.bRtSrcPortMaskCmp_Action);
+	if (rule->action.bRtDstIpMaskCmp_Action)
+		SEQ_PRINTF(s, "  bRtDstIpMaskCmp_Action   =   %d\n",
+			   rule->action.bRtDstIpMaskCmp_Action);
+	if (rule->action.bRtSrcIpMaskCmp_Action)
+		SEQ_PRINTF(s, "  bRtSrcIpMaskCmp_Action   =   %d\n",
+			   rule->action.bRtSrcIpMaskCmp_Action);
+	if (rule->action.bRtInnerIPasKey_Action)
+		SEQ_PRINTF(s, "  bRtInnerIPasKey_Action   =   %d\n",
+			   rule->action.bRtInnerIPasKey_Action);
+	if (rule->action.bRtAccelEna_Action)
+		SEQ_PRINTF(s, "  bRtAccelEna_Action       =   %d\n",
+			   rule->action.bRtAccelEna_Action);
+	if (rule->action.bRtCtrlEna_Action)
+		SEQ_PRINTF(s, "  bRtCtrlEna_Action        =   %d\n",
+			   rule->action.bRtCtrlEna_Action);
+	if (rule->action.eProcessPath_Action)
+		SEQ_PRINTF(s, "  eProcessPath_Action      =   %d\n",
+			   rule->action.eProcessPath_Action);
+	if (rule->action.ePortFilterType_Action)
+		SEQ_PRINTF(s, "  ePortFilterType_Action   =   %d\n",
+			   rule->action.ePortFilterType_Action);
+	ret = SEQ_PRINTF(s, "\n");
+	if (ret) {
+		kfree(rule);
+		return pos;
+	}
+ EXIT:
+	kfree(rule);
+	pos++;
+
+	return pos;
+}
+
+int proc_gsw_pce_start(void)
+{
+	return 0;
+}
+
+#define NS_INT16SZ	 2
+#define NS_INADDRSZ	 4
+#define NS_IN6ADDRSZ	16
+
+/* int
+ * inet_pton(af, src, dst)
+ *	convert from presentation format (which usually means ASCII printable)
+ *	to network format (which is usually some kind of binary format).
+ * return:
+ *	4 if the address was valid and it is IPV4 format
+ *  6 if the address was valid and it is IPV6 format
+ *	0 if some other error occurred (`dst' is untouched in this case, too)
+ * author:
+ *	Paul Vixie, 1996.
+ */
+int pton(const char *src, void *dst)
+{
+	int ip_v = 0;
+
+	if (strstr(src, ":")) {	/* IPV6 */
+		if (inet_pton6(src, dst) == 1) {
+			ip_v = 6;
+			return ip_v;
+		}
+
+	} else {
+		if (inet_pton4(src, dst) == 1) {
+			ip_v = 4;
+			return ip_v;
+		}
+	}
+
+	return ip_v;
+}
+
+/* int
+ * inet_pton4(src, dst)
+ *	like inet_aton() but without all the hexadecimal and shorthand.
+ * return:
+ *	1 if `src' is a valid dotted quad, else 0.
+ * notice:
+ *	does not touch `dst' unless it's returning 1.
+ * author:
+ *	Paul Vixie, 1996.
+ */
+static int inet_pton4(const char *src, u_char *dst)
+{
+	static const char digits[] = "0123456789";
+	int saw_digit, octets, ch;
+	u_char tmp[NS_INADDRSZ], *tp;
+
+	saw_digit = 0;
+	octets = 0;
+	*(tp = tmp) = 0;
+	while ((ch = *src++) != '\0') {
+		const char *pch;
+
+		pch = strchr(digits, ch);
+		if (pch != NULL) {
+			u_int new = *tp * 10 + (u_int) (pch - digits);
+
+			if (new > 255)
+				return 0;
+			*tp = (u_char) new;
+			if (!saw_digit) {
+				if (++octets > 4)
+					return 0;
+				saw_digit = 1;
+			}
+		} else if (ch == '.' && saw_digit) {
+			if (octets == 4)
+				return 0;
+			*++tp = 0;
+			saw_digit = 0;
+		} else
+			return 0;
+	}
+	if (octets < 4)
+		return 0;
+
+	memcpy(dst, tmp, NS_INADDRSZ);
+	return 1;
+}
+
+/* int
+ * inet_pton6(src, dst)
+ *	convert presentation level address to network order binary form.
+ * return:
+ *	1 if `src' is a valid [RFC1884 2.2] address, else 0.
+ * notice:
+ *	(1) does not touch `dst' unless it's returning 1.
+ *	(2) :: in a full address is silently ignored.
+ * credit:
+ *	inspired by Mark Andrews.
+ * author:
+ *	Paul Vixie, 1996.
+ */
+static int inet_pton6(const char *src, u_char *dst)
+{
+	static const char xdigits_l[] = "0123456789abcdef", xdigits_u[] =
+	    "0123456789ABCDEF";
+	u_char tmp[NS_IN6ADDRSZ], *tp, *endp, *colonp;
+	const char *xdigits, *curtok;
+	int ch, saw_xdigit;
+	u_int val;
+
+	memset((tp = tmp), '\0', NS_IN6ADDRSZ);
+	endp = tp + NS_IN6ADDRSZ;
+	colonp = NULL;
+	/* Leading :: requires some special handling. */
+	if (*src == ':')
+		if (*++src != ':')
+			return 0;
+	curtok = src;
+	saw_xdigit = 0;
+	val = 0;
+	while ((ch = *src++) != '\0') {
+		const char *pch;
+
+		pch = strchr((xdigits = xdigits_l), ch);
+		if (pch == NULL)
+			pch = strchr((xdigits = xdigits_u), ch);
+		if (pch != NULL) {
+			val <<= 4;
+			val |= (pch - xdigits);
+			if (val > 0xffff)
+				return 0;
+			saw_xdigit = 1;
+			continue;
+		}
+		if (ch == ':') {
+			curtok = src;
+			if (!saw_xdigit) {
+				if (colonp)
+					return 0;
+				colonp = tp;
+				continue;
+			}
+			if (tp + NS_INT16SZ > endp)
+				return 0;
+			*tp++ = (u_char) (val >> 8) & 0xff;
+			*tp++ = (u_char) val & 0xff;
+			saw_xdigit = 0;
+			val = 0;
+			continue;
+		}
+		if (ch == '.' && ((tp + NS_INADDRSZ) <= endp) &&
+		    inet_pton4(curtok, tp) > 0) {
+			tp += NS_INADDRSZ;
+			saw_xdigit = 0;
+			break;	/* '\0' was seen by inet_pton4(). */
+		}
+		return 0;
+	}
+	if (saw_xdigit) {
+		if (tp + NS_INT16SZ > endp)
+			return 0;
+		*tp++ = (u_char) (val >> 8) & 0xff;
+		*tp++ = (u_char) val & 0xff;
+	}
+	if (colonp != NULL) {
+		/*
+		 * Since some memmove()'s erroneously fail to handle
+		 * overlapping regions, we'll do the shift by hand.
+		 */
+		const int n = (int)(tp - colonp);
+		int i;
+
+		for (i = 1; i <= n; i++) {
+			endp[-i] = colonp[n - i];
+			colonp[n - i] = 0;
+		}
+		tp = endp;
+	}
+	if (tp != endp)
+		return 0;
+	memcpy(dst, tmp, NS_IN6ADDRSZ);
+	return 1;
+}
+
+static int mac_stob(const char *mac, u8 bytes[6])
+{
+	int values[6];
+	int i;
+	int f = 0;
+
+	if (!mac || !bytes)
+		return -1;
+
+	if (6 ==
+	    sscanf(mac, "%x:%x:%x:%x:%x:%x", &values[0], &values[1],
+		   &values[2], &values[3], &values[4], &values[5]))
+		f = 1;
+	else if (6 ==
+		 sscanf(mac, "%x-%x-%x-%x-%x-%x", &values[0], &values[1],
+			&values[2], &values[3], &values[4], &values[5]))
+		f = 1;
+
+	if (f) {		/* convert to uint8_t */
+		for (i = 0; i < 6; ++i)
+			bytes[i] = (u8) values[i];
+		return 0;
+	}
+	return -1;
+
+}
+
+char *get_pae_ip_type(int type)
+{
+	if (type == GSW_RT_IP_V4)
+		return "IPV4";
+	if (type == GSW_RT_IP_V6)
+		return "IPV6";
+	return "Unknown";
+}
+
+char *get_pae_tunnel_type(int type)
+{
+	if (type == GSW_ROUTE_TUNL_NULL)
+		return "NULL";
+	if (type == GSW_ROUTE_TUNL_6RD)
+		return "6RD";
+	if (type == GSW_ROUTE_TUNL_DSLITE)
+		return "Dslite";
+	if (type == GSW_ROUTE_TUNL_L2TP)
+		return "L2TP";
+	if (type == GSW_ROUTE_TUNL_IPSEC)
+		return "IPSEC";
+	return "Unknown";
+}
+
+char *get_pae_ext_type(int type)
+{
+	if (type == 100)
+		return "UDP";
+	if (type == 0)
+		return "TCP";
+	return "Unknown";
+}
+
+char *get_pae_dir_type(int type)
+{
+	if (type == GSW_ROUTE_DIRECTION_DNSTREAM)
+		return "DownStream";
+	if (type == GSW_ROUTE_DIRECTION_UPSTREAM)
+		return "UpStream";
+	return "Unknown";
+}
+
+char *get_pae_pppoe_mode_type(int type)
+{
+	if (type == 0)
+		return "Transparent";
+	if (type == GSW_ROUTE_DIRECTION_UPSTREAM)
+		return "Termination";
+	return "Unknown";
+}
+
+char *get_pae_route_mode_type(int type)
+{
+	if (type == GSW_ROUTE_MODE_NULL)
+		return "NULL";
+	if (type == GSW_ROUTE_MODE_ROUTING)
+		return "Basic Routing";
+	if (type == GSW_ROUTE_MODE_NAT)
+		return "NAT";
+	if (type == GSW_ROUTE_MODE_NAPT)
+		return "NAPT";
+	return "Unknown";
+}
+
+char *get_pae_out_dscp_type(int type)
+{
+	if (type == GSW_ROUTE_OUT_DSCP_NULL)
+		return "No Outer DSCP Marking";
+	if (type == GSW_ROUTE_OUT_DSCP_INNER)
+		return "Outer DSCP from Inner IP header";
+	if (type == GSW_ROUTE_OUT_DSCP_SESSION)
+		return "Outer DSCP from Session action";
+	return "Unknown";
+}
+
+
+/* For proc only, no protection */
+
+char *get_pae_port_list(u32 port)
+{
+	int i, k;
+	static char list[PMAC_MAX_NUM * 2 + 1];
+
+	k = 0;
+	list[0] = 0;
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		if (port & (1 << i)) {
+			if (k)
+				sprintf(list + strlen(list), "/");
+			sprintf(list + strlen(list), "%d", i);
+			k++;
+		}
+	}
+	return list;
+}
+
+/* return 0 -- ok,
+   return 1 -- buffer overfolow */
+static int dp_route_dump(struct seq_file *seq, GSW_ROUTE_Entry_t *rt_entry)
+{
+	smart_proc_printf(seq, "Index[%04d] Hash=%u: %s(%u)\n",
+			  rt_entry->nRtIndex, rt_entry->nHashVal,
+			  (rt_entry->routeEntry.pattern.bValid ==
+			   LTQ_TRUE) ? "Valid" : "Not Valid",
+			  rt_entry->routeEntry.pattern.bValid);
+	smart_proc_printf(seq, " Compare:\n");
+	smart_proc_printf(seq, "   IP Type         = %d (%s)\n",
+			  rt_entry->routeEntry.pattern.eIpType,
+			  get_pae_ip_type(rt_entry->routeEntry.pattern.
+					  eIpType));
+	if (rt_entry->routeEntry.action.eIpType == GSW_RT_IP_V6)
+		smart_proc_printf(seq, "   Src IP          = %pI6\n",
+				  rt_entry->routeEntry.pattern.nSrcIP.nIPv6);
+	else
+		smart_proc_printf(seq, "   Src IP          = %pI4\n",
+				  &rt_entry->routeEntry.pattern.nSrcIP.nIPv4);
+
+	if (rt_entry->routeEntry.pattern.eIpType == GSW_RT_IP_V6)
+		smart_proc_printf(seq, "   Dest IP         = %pI6\n",
+				  rt_entry->routeEntry.pattern.nDstIP.nIPv6);
+	else
+		smart_proc_printf(seq, "   Dest IP         = %pI4\n",
+				  &rt_entry->routeEntry.pattern.nDstIP.nIPv4);
+
+	smart_proc_printf(seq, "   Src Port        = %d\n",
+			  rt_entry->routeEntry.pattern.nSrcPort);
+	smart_proc_printf(seq, "   Dest Port       = %d\n",
+			  rt_entry->routeEntry.pattern.nDstPort);
+	smart_proc_printf(seq, "   Extn Id         = %d (%s)\n",
+			  rt_entry->routeEntry.pattern.nRoutExtId,
+			  get_pae_ext_type(rt_entry->routeEntry.pattern.
+					   nRoutExtId));
+	smart_proc_printf(seq, " Action:\n");
+	smart_proc_printf(seq, "   Dst PMAC List   = 0x%0x (%s)\n",
+			  rt_entry->routeEntry.action.nDstPortMap,
+			  get_pae_port_list(rt_entry->routeEntry.action.
+					    nDstPortMap));
+	smart_proc_printf(seq, "   Subif           = 0x%0x\n",
+			  rt_entry->routeEntry.action.nDstSubIfId);
+	smart_proc_printf(seq, "   IP Type         = %d (%s)\n",
+			  rt_entry->routeEntry.action.eIpType,
+			  get_pae_ip_type(rt_entry->routeEntry.action.
+					  eIpType));
+	if (rt_entry->routeEntry.action.eIpType == GSW_RT_IP_V6)
+		smart_proc_printf(seq, "   NAT IP          = %pI6\n",
+				  rt_entry->routeEntry.action.nNATIPaddr.
+				  nIPv6);
+	else
+		smart_proc_printf(seq, "   NAT IP          = %pI4\n",
+				  &rt_entry->routeEntry.action.nNATIPaddr.
+				  nIPv4);
+	smart_proc_printf(seq, "   NAT Port        = %d\n",
+			  rt_entry->routeEntry.action.nTcpUdpPort);
+	smart_proc_printf(seq, "   MTU             = %d\n",
+			  rt_entry->routeEntry.action.nMTUvalue);
+	smart_proc_printf(seq, "   Src MAC         = %pM (%s)\n",
+			  rt_entry->routeEntry.action.nSrcMAC,
+			  rt_entry->routeEntry.action.
+			  bMAC_SrcEnable ? "Enabled" : "Disabled");
+	smart_proc_printf(seq, "   Dst MAC         = %pM (%s)\n",
+			  rt_entry->routeEntry.action.nDstMAC,
+			  rt_entry->routeEntry.action.
+			  bMAC_DstEnable ? "Enabled" : "Disabled");
+	smart_proc_printf(seq, "   PPPoE Mode      = %u (%s)\n",
+			  rt_entry->routeEntry.action.bPPPoEmode,
+			  get_pae_pppoe_mode_type(rt_entry->routeEntry.action.
+						  bPPPoEmode));
+	smart_proc_printf(seq, "   PPPoE SessID    = %u\n",
+			  rt_entry->routeEntry.action.nPPPoESessId);
+	smart_proc_printf(seq, "   Dir             = %u (%s)\n",
+			  rt_entry->routeEntry.action.eSessDirection,
+			  get_pae_dir_type(rt_entry->routeEntry.action.
+					   eSessDirection));
+	smart_proc_printf(seq, "   Class           = %u (%s)\n",
+			  rt_entry->routeEntry.action.nTrafficClass,
+			  rt_entry->routeEntry.action.
+			  bTCremarking ? "Enabled" : "Disabled");
+	smart_proc_printf(seq, "   Routing Mode    = %u (%s)\n",
+			  rt_entry->routeEntry.action.eSessRoutingMode,
+			  get_pae_route_mode_type(rt_entry->routeEntry.action.
+						  eSessRoutingMode));
+	smart_proc_printf(seq, "   Tunnel Type     = %u (%s: %s\n",
+			  rt_entry->routeEntry.action.eTunType,
+			  get_pae_tunnel_type(rt_entry->routeEntry.action.
+					      eTunType),
+			  rt_entry->routeEntry.action.
+			  bTunnel_Enable ? "Enabled" : "Disabled");
+	smart_proc_printf(seq, "   Tunnel Index    = %u\n",
+			  rt_entry->routeEntry.action.nTunnelIndex);
+	smart_proc_printf(seq, "   MeterID         = %u (%s)\n",
+			  rt_entry->routeEntry.action.nMeterId,
+			  rt_entry->routeEntry.action.
+			  bMeterAssign ? "Enabled" : "Disabled");
+	smart_proc_printf(seq, "   TTL  Decrease   = %u (%s)\n",
+			  rt_entry->routeEntry.action.bTTLDecrement,
+			  rt_entry->routeEntry.action.
+			  bTTLDecrement ? "Enabled" : "Disabled");
+	smart_proc_printf(seq, "   OutDSCP         = %u (%s)\n",
+			  rt_entry->routeEntry.action.eOutDSCPAction,
+			  get_pae_out_dscp_type(rt_entry->routeEntry.action.eOutDSCPAction));
+	smart_proc_printf(seq, "   InDSCP          = %u (%s)\n",
+			  rt_entry->routeEntry.action.bInnerDSCPRemark,
+			  rt_entry->routeEntry.action.
+			  bInnerDSCPRemark ? "Enabled" : "Disabled");
+	smart_proc_printf(seq, "   DSCP            = %u\n",
+			  rt_entry->routeEntry.action.nDSCP);
+	smart_proc_printf(seq, "   RTP             = %s (seq=%u roll=%u)\n",
+			  rt_entry->routeEntry.action.
+			  bRTPMeasEna ? "Enabled" : "Disabled",
+			  rt_entry->routeEntry.action.nRTPSeqNumber,
+			  rt_entry->routeEntry.action.nRTPSessionPktCnt);
+	smart_proc_printf(seq, "   FID             = %u\n",
+			  rt_entry->routeEntry.action.nFID);
+	smart_proc_printf(seq, "   Flow ID         = %u\n",
+			  rt_entry->routeEntry.action.nFlowId);
+	smart_proc_printf(seq, "   Hit Status      = %u\n",
+			  rt_entry->routeEntry.action.bHitStatus);
+	smart_proc_printf(seq, "   Session Counters= %u\n",
+			  rt_entry->routeEntry.action.nSessionCtrs);
+	if (seq && SEQ_PRINTF(seq, "\n"))
+		return 1;
+
+	return 0;
+}
+
+#define EXT1_UP   "ext(up)  : echo add SrcIP 192.168.1.100 DstIP 192.168.0.100 SrcPort 1024 DstPort 1024 ExtId 100 SrcMac 11:11:11:11:11:11 DstMac 11:11:11:11:11:22 NatIP 192.168.0.1   NatPort 3000 MTU 1500 DstPmac 0x8000 subif 0 dir 1"
+#define EXT2_DOWN "ext(down): echo add SrcIP 192.168.0.100 DstIP 192.168.0.1   SrcPort 1024 DstPort 3000 ExtId 100 SrcMac 11:11:11:11:11:33 DstMac 11:11:11:11:11:44 NatIP 192.168.1.100 NatPort 1024 MTU 1500 DstPmac 0x2    subif 0 dir 0"
+
+ssize_t proc_gsw_route_write(struct file *file, const char *buf,
+			     size_t count, loff_t *ppos)
+{
+	u16 len, i, tmp, start_param;
+	int ret = 0;
+	char *str = NULL;
+	char *param_list[30 * 2];
+	unsigned int num;
+	GSW_ROUTE_Entry_t *rt_entry;
+	GSW_API_HANDLE gsw_handle;
+	u8 dscp_f = 0;
+
+	gsw_handle = gsw_api_kopen((char *)GSWIP_R_DEV_NAME);
+	if (gsw_handle == 0) {
+		PR_ERR("Open GSWIP-R device FAILED !\n");
+		return count;
+	}
+	str = kmalloc(count + 1, GFP_ATOMIC);
+	if (!str) {
+		PR_ERR("Failed to allocate %d bytes buffer\n", count);
+		return count;
+	}
+	rt_entry = (GSW_ROUTE_Entry_t *) kmalloc(sizeof(GSW_ROUTE_Entry_t) + 1,
+					  GFP_ATOMIC);
+	if (!rt_entry) {
+		PR_ERR("Failed to allocate %d bytes buffer\n",
+			sizeof(GSW_ROUTE_Entry_t) + 1);
+		kfree(str);
+		return count;
+	}
+
+	len = count;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	if (num < 2) {
+		PRINTK("parameter %d not enough. count=%d\n", num, count);
+		goto help;
+	}
+	if (dp_strcmpi(param_list[0], "help") == 0)	/* help */
+		goto help;
+
+	/* delete an entry */
+	if (dp_strcmpi(param_list[0], "del") == 0) {
+		rt_entry->nRtIndex = dp_atoi(param_list[1]);
+		DP_DEBUG(DP_DBG_FLAG_PAE, "Delete pae entry %d\n",
+			 rt_entry->nRtIndex);
+		ret =
+		    gsw_api_kioctl(gsw_handle, GSW_ROUTE_ENTRY_DELETE,
+				   (unsigned int)rt_entry);
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_ROUTE_ENTRY_DELETE returned failure\n");
+			goto exit;
+		}
+		kfree(str);
+		kfree(rt_entry);
+		return count;
+	}
+
+	/* dump an entry */
+	if (dp_strcmpi(param_list[0], "dump") == 0) {
+		rt_entry->nRtIndex = dp_atoi(param_list[1]);
+		DP_DEBUG(DP_DBG_FLAG_PAE, "Dump pae entry %d\n",
+			 rt_entry->nRtIndex);
+		ret = gsw_api_kioctl(gsw_handle, GSW_ROUTE_ENTRY_READ,
+				(unsigned int)rt_entry);
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_ROUTE_ENTRY_DELETE returned failure\n");
+			goto exit;
+		}
+		dp_route_dump(NULL, rt_entry);
+		kfree(str);
+		kfree(rt_entry);
+		return count;
+	}
+
+	/* Modify an entry */
+	if (dp_strcmpi(param_list[0], "modify") == 0) {
+		rt_entry->nRtIndex = dp_atoi(param_list[1]);
+		/*read back before delete and add it new */
+		DP_DEBUG(DP_DBG_FLAG_PAE, "Dump pae entry %d\n",
+			 rt_entry->nRtIndex);
+		ret = gsw_api_kioctl(gsw_handle, GSW_ROUTE_ENTRY_READ,
+			(unsigned int)rt_entry);
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_ROUTE_ENTRY_DELETE returned failure\n");
+			goto exit;
+		}
+		ret =
+		    gsw_api_kioctl(gsw_handle, GSW_ROUTE_ENTRY_DELETE,
+				   (unsigned int)rt_entry);
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_ROUTE_ENTRY_DELETE returned failure\n");
+			goto exit;
+		}
+		rt_entry->nHashVal = -1;	/*since GSWAPI no modify support, here switch to add command */
+		start_param = 2;
+		goto ADD_Modify_BOTH;
+	}
+
+	/* add a new entry */
+	if (dp_strcmpi(param_list[0], "add") != 0) {
+		PR_ERR("wrong command: %s\n", param_list[0]);
+		goto help;
+	}
+	memset(rt_entry, 0, sizeof(*rt_entry));
+	rt_entry->nHashVal = -1;
+	rt_entry->bPrio = 1;
+	rt_entry->routeEntry.action.nMTUvalue = 1501;
+	rt_entry->routeEntry.pattern.bValid = LTQ_TRUE;
+	start_param = 1;
+ ADD_Modify_BOTH:
+	for (i = start_param; i < num; i += 2) {
+		/*compare table */
+		if (dp_strcmpi(param_list[i], "SrcIP") == 0) {
+			tmp =
+			    pton(param_list[i + 1],
+				 &rt_entry->routeEntry.pattern.nSrcIP);
+			if (tmp == 4)
+				rt_entry->routeEntry.pattern.eIpType =
+				    GSW_RT_IP_V4;
+			else if (tmp == 6)
+				rt_entry->routeEntry.pattern.eIpType =
+				    GSW_RT_IP_V6;
+			else {
+				PRINTK("Wong IP format for SrcIP\n");
+				goto exit;
+			}
+		} else if (dp_strcmpi(param_list[i], "DstIP") == 0) {
+			tmp =
+			    pton(param_list[i + 1],
+				 &rt_entry->routeEntry.pattern.nDstIP);
+			if (tmp == 4)
+				rt_entry->routeEntry.pattern.eIpType =
+				    GSW_RT_IP_V4;
+			else if (tmp == 6)
+				rt_entry->routeEntry.pattern.eIpType =
+				    GSW_RT_IP_V6;
+			else {
+				PRINTK("Wong IP format for DstIP\n");
+				goto exit;
+			}
+		} else if (dp_strcmpi(param_list[i], "SrcPort") == 0)
+			rt_entry->routeEntry.pattern.nSrcPort =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "DstPort") == 0)
+			rt_entry->routeEntry.pattern.nDstPort =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "ExtId") == 0)
+			rt_entry->routeEntry.pattern.nRoutExtId =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "SrcMac") == 0) {
+			rt_entry->routeEntry.action.bMAC_SrcEnable = 1;
+			mac_stob(param_list[i + 1],
+				 rt_entry->routeEntry.action.nSrcMAC);
+
+			if (rt_entry->routeEntry.action.eSessRoutingMode < GSW_ROUTE_MODE_ROUTING)	/*normally only routing mode will change mac */
+				rt_entry->routeEntry.action.eSessRoutingMode =
+				    GSW_ROUTE_MODE_ROUTING;
+		} /*below is all actions */
+		else if (dp_strcmpi(param_list[i], "DstMac") == 0) {
+			rt_entry->routeEntry.action.bMAC_DstEnable = 1;
+			mac_stob(param_list[i + 1],
+				 rt_entry->routeEntry.action.nDstMAC);
+
+			if (rt_entry->routeEntry.action.eSessRoutingMode < GSW_ROUTE_MODE_ROUTING)	/*normally only routing mode will change mac */
+				rt_entry->routeEntry.action.eSessRoutingMode =
+				    GSW_ROUTE_MODE_ROUTING;
+		} else if (dp_strcmpi(param_list[i], "NatIP") == 0) {
+
+			tmp =
+			    pton(param_list[i + 1],
+				 &rt_entry->routeEntry.action.nNATIPaddr);
+			if (tmp == 4)
+				rt_entry->routeEntry.action.eIpType =
+				    GSW_RT_IP_V4;
+			else if (tmp == 6)
+				rt_entry->routeEntry.action.eIpType =
+				    GSW_RT_IP_V6;
+			else {
+				PRINTK("Wong IP format for NatIP\n");
+				goto exit;
+			}
+			if (rt_entry->routeEntry.action.eSessRoutingMode <
+			    GSW_ROUTE_MODE_NAT)
+				rt_entry->routeEntry.action.eSessRoutingMode = GSW_ROUTE_MODE_NAT;	/* NAT */
+		} else if (dp_strcmpi(param_list[i], "NatPort") == 0) {
+			rt_entry->routeEntry.action.nTcpUdpPort =
+			    dp_atoi(param_list[i + 1]);
+			if (rt_entry->routeEntry.action.eSessRoutingMode <
+			    GSW_ROUTE_MODE_NAPT)
+				rt_entry->routeEntry.action.eSessRoutingMode = GSW_ROUTE_MODE_NAPT;	/* NAPT */
+		} else if (dp_strcmpi(param_list[i], "MTU") == 0)
+			rt_entry->routeEntry.action.nMTUvalue =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "PPPoEmode") == 0)
+			rt_entry->routeEntry.action.bPPPoEmode =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "PPPoEId") == 0)
+			rt_entry->routeEntry.action.nPPPoESessId =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "TunType") == 0) {
+			rt_entry->routeEntry.action.bTunnel_Enable = 1;
+			rt_entry->routeEntry.action.eTunType =
+			    dp_atoi(param_list[i + 1]);
+		} else if (dp_strcmpi(param_list[i], "TunIndex") == 0) {
+			rt_entry->routeEntry.action.bTunnel_Enable = 1;
+			rt_entry->routeEntry.action.eTunType =
+			    dp_atoi(param_list[i + 1]);
+
+		} else if (dp_strcmpi(param_list[i], "MeterId") == 0) {
+			rt_entry->routeEntry.action.bMeterAssign = 1;
+			rt_entry->routeEntry.action.nMeterId =
+			    dp_atoi(param_list[i + 1]);
+
+		} else if (dp_strcmpi(param_list[i], "FID") == 0)
+			rt_entry->routeEntry.action.nFID =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "FlowId") == 0)
+			rt_entry->routeEntry.action.nFlowId =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "OutDscp") == 0)
+			rt_entry->routeEntry.action.eOutDSCPAction =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "InDscp") == 0)
+			rt_entry->routeEntry.action.bInnerDSCPRemark =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "Dscp") == 0) {
+			rt_entry->routeEntry.action.nDSCP =
+			    dp_atoi(param_list[i + 1]);
+			dscp_f = 1;
+		} else if (dp_strcmpi(param_list[i], "class") == 0) {
+			rt_entry->routeEntry.action.bTCremarking = 1;
+			rt_entry->routeEntry.action.nTrafficClass =
+			    dp_atoi(param_list[i + 1]);
+		} else if (dp_strcmpi(param_list[i], "ttl") == 0)
+			rt_entry->routeEntry.action.bTTLDecrement =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "dir") == 0)
+			rt_entry->routeEntry.action.eSessDirection =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "DstPmac") == 0)
+			rt_entry->routeEntry.action.nDstPortMap =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strcmpi(param_list[i], "Subif") == 0)
+			rt_entry->routeEntry.action.nDstSubIfId =
+			    dp_atoi(param_list[i + 1]);
+		else {
+			PRINTK("wrong parameter[%d]: %s\n", i, param_list[i]);
+			goto exit;
+		}
+
+		if (!rt_entry->routeEntry.action.bTTLDecrement &&
+		    (rt_entry->routeEntry.action.eSessRoutingMode >
+		     GSW_ROUTE_MODE_NULL))
+			rt_entry->routeEntry.action.bTTLDecrement = 1;
+
+		/* if key in dscp but no inner/outer dscp action enabled,
+		* then auto enable indscp action
+		*/
+		if (dscp_f &&
+			!rt_entry->routeEntry.action.eOutDSCPAction &&
+			!rt_entry->routeEntry.action.bInnerDSCPRemark)
+			rt_entry->routeEntry.action.bInnerDSCPRemark = 1;
+		/*nSessionCtrs ??*/
+	}
+	ret =
+	    gsw_api_kioctl(gsw_handle, GSW_ROUTE_ENTRY_ADD,
+			   (unsigned int)rt_entry);
+	if (ret < GSW_statusOk) {
+		PR_ERR("GSW_ROUTE_ENTRY_ADD returned failure\n");
+		goto exit;
+	}
+	DP_DEBUG(DP_DBG_FLAG_PAE, "pae entry %d updated\n",
+		 rt_entry->nRtIndex);
+
+	dp_route_dump(NULL, rt_entry);
+
+ exit:
+	kfree(str);
+	kfree(rt_entry);
+	return count;
+
+ help:
+	PRINTK("usage:\n");
+	PRINTK("  echo del	<entry-index> > /prooc/dp/%s\n",
+	       DP_PROC_FILE_ROUTE);
+	PRINTK("  echo show <entry-index> > /prooc/dp/%s\n",
+	       DP_PROC_FILE_ROUTE);
+	PRINTK
+	    ("  echo add [SrcIP] [IP-value] [DstIP] [IP-value] [SrcPort] [Port-value] [DstPort] [Port-value] [ExtId] [ExtId-value]\n");
+	PRINTK
+	    ("           [dir] [dir-value] [SrcMAC] [MAC-value] [DstMAC] [MAC-value] [NatIP] [IP-value] [NatPort] [Port-value]\n");
+	PRINTK
+	    ("           [MTU] [MTU-value] [PPPoEmode] [PPPoEmode-value] [PPPoEId] [PPPoEId-value] [TunType] [Tunnel-value]\n");
+	PRINTK
+	    ("           [TunIndex] [Tunnel-index-value] [MeterId] [MeterId-value] [FID] [FID-value] [FlowId] [FlowId-value]\n");
+	PRINTK
+	    ("           [InDscp] [InDscp-value] [Dscp] [Dscp-value] [OutDscp] [OutDscp-value] [class] [class-value]\n");
+	PRINTK
+	    ("           [DstPmac] [DstPmac-value] [Subif] [Subif-value]\n");
+	PRINTK("		> /prooc/dp/%s\n", DP_PROC_FILE_ROUTE);
+	PRINTK
+	    ("  echo modify <entry-index> [followed by paramers as add command] > /prooc/dp/%s\n",
+	     DP_PROC_FILE_ROUTE);
+
+	PRINTK(" Take note:\n");
+	PRINTK
+	    ("     Only MAC address learned session will be accelerated by HW\n");
+	PRINTK
+	    ("     After modify entry, its entry index maybe changed to new one for lower API limitation\n");
+	PRINTK("     ExtId: %d(%s)/%d(%s)\n", 0, get_pae_ext_type(0), 100,
+	       get_pae_ext_type(100));
+	PRINTK("     Dir: %d(%s)/%d(%s)\n", GSW_ROUTE_DIRECTION_DNSTREAM,
+	       get_pae_dir_type(GSW_ROUTE_DIRECTION_DNSTREAM),
+	       GSW_ROUTE_DIRECTION_UPSTREAM,
+	       get_pae_dir_type(GSW_ROUTE_DIRECTION_UPSTREAM));
+	PRINTK("     OutDscp: %d(%s)/%d(%s)/%d(%s)\n",
+		GSW_ROUTE_OUT_DSCP_NULL,
+		get_pae_dir_type(GSW_ROUTE_OUT_DSCP_NULL),
+		GSW_ROUTE_OUT_DSCP_INNER,
+		get_pae_out_dscp_type(GSW_ROUTE_OUT_DSCP_INNER),
+		GSW_ROUTE_OUT_DSCP_SESSION,
+		get_pae_out_dscp_type(GSW_ROUTE_OUT_DSCP_SESSION));
+	PRINTK("     Tunnel: %d(%s)/%d(%s)/%d(%s)/%d(%s)/%d(%s)\n",
+	       GSW_ROUTE_TUNL_NULL, get_pae_tunnel_type(GSW_ROUTE_TUNL_NULL),
+	       GSW_ROUTE_TUNL_6RD, get_pae_tunnel_type(GSW_ROUTE_TUNL_6RD),
+	       GSW_ROUTE_TUNL_DSLITE,
+	       get_pae_tunnel_type(GSW_ROUTE_TUNL_DSLITE),
+	       GSW_ROUTE_TUNL_L2TP, get_pae_tunnel_type(GSW_ROUTE_TUNL_L2TP),
+	       GSW_ROUTE_TUNL_IPSEC,
+	       get_pae_tunnel_type(GSW_ROUTE_TUNL_IPSEC));
+	PRINTK("     PPPoEmode: %d(%s)/%d(%s)\n", 0,
+	       get_pae_pppoe_mode_type(0), 1, get_pae_pppoe_mode_type(1));
+	PRINTK
+	    ("     TTL/Route Mode/IPV4/6 type will be auto handled inside the proc\n");
+	PRINTK("     DstPmac: bit 0 for pmac port 0, bit 1 for pmac port 1 and so on\n");
+	PRINTK("     Subif(ATM bit format): ATM-QID[6:3] Mpoa_pt[2] Mpoa_mode[1:0]\n");
+
+
+	PRINTK("     %s > /proc/dp/%s\n", EXT1_UP, DP_PROC_FILE_ROUTE);
+	PRINTK("     %s > /proc/dp/%s\n", EXT2_DOWN, DP_PROC_FILE_ROUTE);
+
+	goto exit;
+}
+
+int proc_gsw_route_dump(struct seq_file *seq, int pos)
+{
+	GSW_API_HANDLE gsw_handle;
+	GSW_ROUTE_Entry_t *rt_entry;
+	int ret = 0;
+
+	rt_entry =
+	    (GSW_ROUTE_Entry_t *) kmalloc(sizeof(GSW_ROUTE_Entry_t) + 1,
+					  GFP_ATOMIC);
+	if (!rt_entry) {
+		PR_ERR("Failed to allocate %d bytes buffer\n",
+		       sizeof(GSW_ROUTE_Entry_t) + 1);
+		return -1;
+	}
+	/* read gswip-r rmon counter */
+	gsw_handle = gsw_api_kopen((char *)GSWIP_R_DEV_NAME);
+	if (gsw_handle == 0) {
+		PR_ERR("Open GSWIP-R device FAILED !\n");
+		kfree(rt_entry);
+		return -1;
+	}
+	memset(rt_entry, 0, sizeof(*rt_entry));
+	rt_entry->nRtIndex = pos;
+	ret =
+	    gsw_api_kioctl(gsw_handle, GSW_ROUTE_ENTRY_READ,
+			   (unsigned int)rt_entry);
+	if (ret != GSW_statusOk) {
+		PR_ERR("GSW_ROUTE_ENTRY_READ returned Failure for index=%d\n",
+			rt_entry->nRtIndex);
+		pos = -1;
+		kfree(rt_entry);
+		return pos;
+	}
+	if (rt_entry->routeEntry.pattern.bValid != LTQ_TRUE)
+		goto EXIT;
+
+	if (dp_route_dump(seq, rt_entry))
+		return pos;	/*need report*/
+
+ EXIT:
+	pos++;
+	kfree(rt_entry);
+	if (pos >= 4096)	/*GSWIP API does not check the maximum entry and it will hang */
+		pos = -1;
+	return pos;
+}
+
+#define PMAC_EG_SET(x, y) (pmac.eg.x = dp_atoi(y))
+#define PMAC_IG_SET(x, y) (pmac.ig.x = dp_atoi(y))
+
+ssize_t proc_gsw_pmac_write(struct file *file, const char *buf,
+			     size_t count, loff_t *ppos)
+{
+	u16 len, i, k, start_param;
+	int ret = 0;
+	char *str = NULL;
+	char *param_list[20 * 2];
+	unsigned int num;
+	union {
+		GSW_PMAC_Eg_Cfg_t eg;
+		GSW_PMAC_Ig_Cfg_t ig;
+	} pmac;
+	GSW_API_HANDLE gsw_handle;
+	int class_s = 0, class_e = 0;
+	int flow_s = 0, flow_e = 0;
+	char *gsw_name;
+
+	str = kmalloc(count + 1, GFP_ATOMIC);
+	if (!str) {
+		PR_ERR("Failed to allocate %d bytes buffer\n", count);
+		return count;
+	}
+	len = count;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	if (num < 2) {
+		PRINTK("parameter %d not enough. count=%d\n", num, count);
+		goto help;
+	}
+	if (dp_strcmpi(param_list[0], "help") == 0)	/* help */
+		goto help;
+	/* set pmac */
+	if (dp_strcmpi(param_list[0], "set") != 0) {
+		PR_ERR("wrong command: %s\n", param_list[0]);
+		goto help;
+	}
+	if (dp_strcmpi(param_list[1], "L") == 0)
+		gsw_name = GSWIP_L_DEV_NAME;
+	else if (dp_strcmpi(param_list[1], "R") == 0)
+		gsw_name = GSWIP_R_DEV_NAME;
+	else {
+		PR_ERR("wrong switch: %s. It should be L or R only\n", param_list[0]);
+		goto exit;
+	}
+	gsw_handle = gsw_api_kopen(gsw_name);
+	if (gsw_handle == 0) {
+		PR_ERR("Open GSWIP-R device FAILED !\n");
+		goto exit;
+	}
+	memset(&pmac, 0, sizeof(pmac));
+	start_param = 3;
+
+	if (dp_strcmpi(param_list[start_param - 1], "EG") == 0) { /*ingress pmac */
+		ret = gsw_api_kioctl(gsw_handle,
+			GSW_PMAC_EG_CFG_GET, (unsigned int)&pmac);
+		for (i = start_param; i < num; i += 2) {
+			if (dp_strcmpi(param_list[i], "Class") == 0) {
+				char *p = param_list[i+1];
+				char *tail = p + strlen(p);
+				char *tmp;
+				tmp = strstr(p, ":");
+				if (!tmp || (tmp >= tail)) {
+					PRINTK("Wrong format for Class, it should be like xx:xx\n");
+					goto exit;
+				}
+				*tmp = 0;
+				class_s = dp_atoi(p);
+				class_e = dp_atoi(tmp + 1);
+			} else if (dp_strcmpi(param_list[i], "FlowID") == 0) {
+				char *p = param_list[i+1];
+				char *tail = p + strlen(p);
+				char *tmp;
+				tmp = strstr(p, ":");
+				if (!tmp || (tmp >= tail)) {
+					PRINTK("Wrong format for FlowID, it should be like xx:xx\n");
+					goto exit;
+				}
+				*tmp = 0;
+				flow_s = dp_atoi(p);
+				flow_e = dp_atoi(tmp + 1);
+			} else if (dp_strcmpi(param_list[i], "DestPort") == 0)
+				PMAC_EG_SET(nDestPortId, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "RxDmaCH") == 0)
+				PMAC_EG_SET(nRxDmaChanId, param_list[i + 1]);
+			/*
+			else if (dp_strcmpi(param_list[i], "MPE1") == 0)
+				PMAC_EG_SET(bMpe1Flag, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "MPE2") == 0)
+				PMAC_EG_SET(bMpe2Flag, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "DEC") == 0)
+				PMAC_EG_SET(bDecFlag, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "ENC") == 0)
+				PMAC_EG_SET(bEncFlag, param_list[i + 1]); */
+			/*else if (dp_strcmpi(param_list[i], "ProcFlag") == 0)
+				PMAC_EG_SET(bProcFlagsSelect, param_list[i + 1]);*/ /*global flag*/
+			else if (dp_strcmpi(param_list[i], "RemL2Hdr") == 0)
+				PMAC_EG_SET(bRemL2Hdr, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "RemNum") == 0)
+				PMAC_EG_SET(numBytesRem, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "FCS") == 0)
+				PMAC_EG_SET(bFcsEna, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "PmacEna") == 0)
+				PMAC_EG_SET(bPmacEna, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "TcEnable") == 0)
+				PMAC_EG_SET(bTCEnable, param_list[i + 1]);
+			else {
+				PRINTK("wrong parameter[%d]: %s\n", i, param_list[i]);
+				goto exit;
+			}
+		}
+		for (i = class_s; i < class_e; i++) {
+			for (k = flow_s; k < flow_e; k++) {
+				pmac.eg.nTrafficClass = i;
+				/*Note: bProcFlagsSelect zero, just nTrafficClass,
+				else use MPE1/2/ENC/DEC flag instead */
+				pmac.eg.bMpe1Flag = (pmac.eg.nTrafficClass >> 0) & 1;
+				pmac.eg.bMpe2Flag = (pmac.eg.nTrafficClass >> 1) & 1;
+				pmac.eg.bEncFlag = (pmac.eg.nTrafficClass >> 2) & 1;
+				pmac.eg.bDecFlag = (pmac.eg.nTrafficClass >> 3) & 1;
+				pmac.eg.nFlowIDMsb = k;
+				ret = gsw_api_kioctl(gsw_handle,
+					GSW_PMAC_EG_CFG_SET, (unsigned int)&pmac);
+			}
+		}
+		if (ret < GSW_statusOk) {
+			PR_ERR("GSW_PMAC_EG_CFG_SET returned failure\n");
+			goto exit;
+		}
+	} else if (dp_strcmpi(param_list[start_param - 1], "IG") == 0) { /*ingress pmac1 */
+		ret = gsw_api_kioctl(gsw_handle,
+			GSW_PMAC_IG_CFG_GET, (unsigned int)&pmac);
+		for (i = start_param; i < num; i += 2) {
+			if (dp_strcmpi(param_list[i], "TxDmaCH") == 0)
+				PMAC_IG_SET(nTxDmaChanId, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "ErrDrop") == 0)
+				PMAC_IG_SET(bErrPktsDisc, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "ClassEna") == 0) /*class from*/
+				PMAC_IG_SET(bClassEna, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "ClassDefault") == 0)
+				PMAC_IG_SET(bClassDefault, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "PmacEna") == 0) /*pmac from*/
+				PMAC_IG_SET(bPmapEna, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "PmacDefault") == 0)
+				PMAC_IG_SET(bPmapDefault, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "SubIdDefault") == 0)
+				PMAC_IG_SET(bSubIdDefault, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "SpIdDefault") == 0)
+				PMAC_IG_SET(bSpIdDefault, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "PmacPresent") == 0)
+				PMAC_IG_SET(bPmacPresent, param_list[i + 1]);
+			else if (dp_strcmpi(param_list[i], "DefaultPmacHdr") == 0) {
+				char *p = param_list[i+1];
+				char *tail = p + strlen(p);
+				char *tmp;
+				for (k = 0; k < 8; k++) {
+					if (k < (8 - 1)) {
+						tmp = strstr(p, ":");
+						if (!tmp || ((u32)tmp >= (u32)tail)) {
+							PRINTK("Wrong format for DefaultPmacHdr, it should be like xx:xx:xx:xx:xx:xx:xx:xx\n");
+							goto exit;
+						}
+						*tmp = 0; /*replace : with zero */
+					}
+					pmac.ig.defPmacHdr[k] = dp_atoi(p);
+
+					p = tmp + 1; /* move to next value */
+				}
+			} else {
+				PRINTK("wrong parameter[%d]: %s\n", i, param_list[i]);
+				goto exit;
+			}
+		}
+		ret = gsw_api_kioctl(gsw_handle,
+			GSW_PMAC_IG_CFG_SET, (unsigned int)&pmac);
+		if (ret < GSW_statusOk) {
+			PR_ERR("GSW_PMAC_IG_CFG_SET returned failure\n");
+			goto exit;
+		}
+	} else {
+		PRINTK("wrong parameter not supported: %s\n", param_list[start_param - 1]);
+		goto exit;
+	}
+exit:
+	kfree(str);
+	return count;
+
+ help:
+	PRINTK("usage:\n");
+	PRINTK("  echo set <L/R> EG\n");
+	PRINTK("    [DestPort] [Dst-PMAC-Port-value]\n");
+	PRINTK("    [Class] [Class-start:end](0~15)\n");
+	PRINTK("    [FlowID] [FlowID-start:end](0~3)\n");
+	PRINTK("\n");
+	PRINTK("    [PmacEna] [Enable PMAC HDR (1) or not(0)]\n");
+	PRINTK("    [RxDmaCH] [RxDmaCH-value]\n");
+	/* PRINTK("    [MPE1] [value] [MPE2] [value] [DEC] [value] [ENC] [value]\n");*/
+	PRINTK("    [TcEnable] [TcEnable-value(0/1)] [FCS] [FCS-value(0/1]\n");
+	PRINTK("    [RemL2Hdr] [RemL2Hdr-value(0/1)] [RemNum] [RemNum-value]\n");
+	PRINTK("     > /prooc/dp/%s\n", DP_PROC_FILE_PMAC);
+	/*
+	PRINTK("Note: only if bProcFlagsSelect is 1, then MPE1/2/DEC/ENC will be used.\n");
+	PRINTK("      Otherwise it use Class only (Defautl setting)\n");*/
+
+	PRINTK("  echo set IG [TxDmaCH] [TX-DMA-CH-value]\n");
+	PRINTK("\n");
+	PRINTK("    [ErrDrop] [Error-Drop-value(0/1)]\n");
+	PRINTK("    [ClassEna] [Class Enable info from default PMAC header(1) or incoming PMAC header(0)]\n");
+	PRINTK("    [ClassDefault] [Class Default info from default PMAC header(1) or incoming PMAC header(0)]\n");
+	PRINTK("    [PmacEna] [Port Map Enable info from default PMAC header(1) or incoming PMAC header(0)]\n");
+	PRINTK("    [PmacDefault] [Port Map info from default PMAC header(1) or incoming PMAC header(0)]\n");
+	PRINTK("    [SubIdDefault] [Sub_Interface Id Info from default PMAC header(1) or in packet descriptor (0)]\n");
+	PRINTK("    [SpIdDefault] [Source port id from default PMAC header(1) or incoming PMAC header (False)]\n");
+	PRINTK("    [PmacPresent] [Packet PMAC header is present (1) or not (0)]\n");
+	PRINTK("    [DefaultPmacHdr] [Default PMAC HDR(8 bytes: xx:xx:xx:xx:xx:xx:xx:xx]\n");
+	PRINTK("     > /prooc/dp/%s\n", DP_PROC_FILE_PMAC);
+	PRINTK("  ext1: echo set R IG TxDmaCH 1 ErrDrop 0 PmacDefault 0 PmacEna 0 ClassEna 1 ClassDefault 1 SubIdDefault 1 SpIdDefault 1 PmacPresent 0  DefaultPmacHdr 0x11:0x22:0x33:0x44:0x55:0x66:0x77:0x88 > /proc/dp/pmac\n");
+	PRINTK("  ext2: echo set R EG DestPort 15 class 0:15 FlowID 0:3 RxDmaCH 4 TcEnable 1 RemL2Hdr 1 RemNum 8 PmacEna 0 FCS 1 > /proc/dp/pmac\n");
+	goto exit;
+}
+
+
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_proc_api.c b/drivers/net/ethernet/lantiq/datapath/datapath_proc_api.c
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_proc_api.c
@@ -0,0 +1,433 @@
+#include <linux/fs.h>
+#include<linux/slab.h>
+#include <linux/kernel.h>
+#include <net/datapath_proc_api.h>
+#include <net/datapath_api.h>
+#include "datapath.h"
+
+static int mode;
+/* 0-seq_printf mode, not -1 printk mode, -1: no print */
+/* remove  comemnts to enable debug feature for proc_api */
+#undef local_dbg
+#if 1
+#define local_dbg(fmt, arg...) pr_debug(fmt, ##arg)
+#else
+#define local_dbg(fmt, arg...) do { pr_info(fmt, ##arg); } while (0)
+#endif
+static inline int lower_ch(int ch)
+{
+	if (ch >= 'A' && ch <= 'Z')
+		return ch + 'a' - 'A';
+	return ch;
+}
+
+int dp_strcmpi(char const *s1, char const *s2)
+{
+	int c1, c2;
+
+	if (!s1 || !s2)
+		return 1;
+	while (*s1 && *s2) {	/*same length */
+		c1 = lower_ch(*s1);
+		c2 = lower_ch(*s2);
+		s1++;
+		s2++;
+
+		if (c1 != c2)
+			return c1 - c2;
+	}
+	return *s1 - *s2;
+}
+EXPORT_SYMBOL(dp_strcmpi);
+
+int dp_strncmpi(const char *s1, const char *s2, size_t n)
+{
+	int c1, c2;
+
+	if (!s1 || !s2)
+		return 1;
+	for (; n > 0; s1++, s2++, --n) {
+		c1 = lower_ch(*s1);
+		c2 = lower_ch(*s2);
+		if (c1 != c2)
+			return c1 - c2;
+		else if (c1 == '\0')
+			return 0;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(dp_strncmpi);
+
+char *dp_strstri(char *string, char *substring)
+{
+	register char *a, *b;
+
+/* First scan quickly through the two strings looking for a
+* single-character match.  When it's found, then compare the
+* rest of the substring.
+*/
+	if (!string || !substring)
+		return (char *)0;
+	b = substring;
+	if (*b == 0)
+		return string;
+
+	for (; *string != 0; string += 1) {
+		if (lower_ch(*string) != lower_ch(*b))
+			continue;
+		a = string;
+		while (1) {
+			if (*b == 0)
+				return string;
+			if (lower_ch(*a++) != lower_ch(*b++))
+				break;
+		}
+		b = substring;
+	}
+	return (char *)0;
+}
+EXPORT_SYMBOL(dp_strstri);
+
+void dp_replace_ch(char *p, int len, char orig_ch, char new_ch)
+{
+	int i;
+
+	if (p)
+		for (i = 0; i < len; i++) {
+			if (p[i] == orig_ch)
+				p[i] = new_ch;
+		}
+}
+EXPORT_SYMBOL(dp_replace_ch);
+
+static unsigned int btoi(char *str)
+{
+	unsigned int sum = 0;
+	signed len = 0, i = 0;
+
+	len = strlen(str);
+	len = len - 1;
+	while (len >= 0) {
+		if (*(str + len) == '1')
+			sum = (sum | (1 << i));
+		i++;
+		len--;
+	}
+	return sum;
+}
+
+int dp_atoi(unsigned char *str)
+{
+	unsigned int n = 0;
+	int i = 0;
+	int nega_sign = 0;
+
+	if (!str)
+		return 0;
+	dp_replace_ch(str, strlen(str), '.', 0);
+	dp_replace_ch(str, strlen(str), ' ', 0);
+	dp_replace_ch(str, strlen(str), '\r', 0);
+	dp_replace_ch(str, strlen(str), '\n', 0);
+	if (str[0] == 0)
+		return 0;
+
+	if (str[0] == 'b' || str[0] == 'B') {	/*binary format */
+		n = btoi(str + 1);
+	} else if ((str[0] == '0') && ((str[1] == 'x') || (str[1] == 'X'))) {
+		/*hex format */
+		str += 2;
+
+		while (str[i]) {
+			n = n * 16;
+			if (('0' <= str[i] && str[i] <= '9')) {
+				n += str[i] - '0';
+			} else if (('A' <= str[i] && str[i] <= 'F')) {
+				n += str[i] - 'A' + 10;
+				;
+			} else if (('a' <= str[i] && str[i] <= 'f')) {
+				n += str[i] - 'a' + 10;
+				;
+			} else
+				PRINTK(KERN_ERR "Wrong value:%u\n", str[i]);
+
+			i++;
+		}
+
+	} else {
+		if (str[i] == '-') {	/*negative sign */
+			nega_sign = 1;
+			i++;
+		}
+		while (str[i]) {
+			n *= 10;
+			n += str[i] - '0';
+			i++;
+		}
+	}
+	if (nega_sign)
+		n = -(int)n;
+	return n;
+}
+EXPORT_SYMBOL(dp_atoi);
+
+void dp_remove_leading_whitespace(char **p, int *len)
+{
+	while (*len && ((**p == ' ') || (**p == '\r') || (**p == '\r'))) {
+		(*p)++;
+		(*len)--;
+	}
+}
+EXPORT_SYMBOL(dp_remove_leading_whitespace);
+
+/*Split buffer to multiple segment with seperator space.
+And put pointer to array[].
+By the way, original buffer will be overwritten with '\0' at some place.
+*/
+int dp_split_buffer(char *buffer, char *array[], int max_param_num)
+{
+	int i, set_copy = 0;
+	int res = 0;
+	int len;
+
+	for (i = 0; i < max_param_num; i++)
+		array[i] = NULL;
+	if (!buffer)
+		return 0;
+	len = strlen(buffer);
+	for (i = 0; i < max_param_num;) {
+		dp_remove_leading_whitespace(&buffer, &len);
+		for (;
+		     *buffer != ' ' && *buffer != '\0' && *buffer != '\r' &&
+		     *buffer != '\n' && *buffer != '\t'; buffer++, len--) {
+			/*Find first valid charactor */
+			set_copy = 1;
+			if (!array[i])
+				array[i] = buffer;
+		}
+
+		if (set_copy == 1) {
+			i++;
+			if (*buffer == '\0' || *buffer == '\r' ||
+			    *buffer == '\n') {
+				*buffer = 0;
+				break;
+			}
+			*buffer = 0;
+			buffer++;
+			len--;
+			set_copy = 0;
+
+		} else {
+			if (*buffer == '\0' || *buffer == '\r' ||
+			    *buffer == '\n')
+				break;
+			buffer++;
+			len--;
+		}
+	}
+	res = i;
+
+	return res;
+}
+EXPORT_SYMBOL(dp_split_buffer);
+
+void set_start_end_id(unsigned int new_start, unsigned int new_end,
+		      unsigned int max_start, unsigned int max_end,
+		      unsigned int default_start, unsigned int default_end,
+		      unsigned int *start, unsigned int *end)
+{
+	if (!start || !end)
+		return;
+
+	if (new_start > new_end) {
+		*start = default_start;
+		*end = default_end;
+	} else {
+		*start = new_start;
+		*end = new_end;
+	}
+
+	if (*start > max_start)
+		*start = default_start;
+
+	if (*end > max_end)
+		*end = default_end;
+}
+EXPORT_SYMBOL(set_start_end_id);
+
+static void *dp_seq_start(struct seq_file *s, loff_t *pos)
+{
+	struct dp_proc_file_entry *p = s->private;
+
+	if (p->pos < 0)
+		return NULL;
+
+	return p;
+}
+
+static void *dp_seq_next(struct seq_file *s, void *v, loff_t *pos)
+{
+	struct dp_proc_file_entry *p = s->private;
+
+	*pos = p->pos;
+
+	if (p->pos >= 0)
+		return p;
+	else
+		return NULL;
+}
+
+static void dp_seq_stop(struct seq_file *s, void *v)
+{
+}
+
+static int dp_seq_show(struct seq_file *s, void *v)
+{
+	struct dp_proc_file_entry *p = s->private;
+
+	if (p->pos >= 0) {
+		if (p->multi_callback) {
+			local_dbg("multiple call");
+			p->pos = p->multi_callback(s, p->pos);
+		} else if (p->single_callback) {
+			local_dbg("single call: %p", p->single_callback);
+			p->single_callback(s);
+			p->pos = -1;
+		}
+	}
+	return 0;
+}
+
+static const struct seq_operations dp_seq_ops = {
+	.start = dp_seq_start,
+	.next = dp_seq_next,
+	.stop = dp_seq_stop,
+	.show = dp_seq_show
+};
+
+void dummy_single_show(struct seq_file *s)
+{
+	SEQ_PRINTF(s, "Cat Not implemented yet !\n");
+}
+
+static int dp_proc_open(struct inode *inode, struct file *file)
+{
+	struct seq_file *s;
+	struct dp_proc_file_entry *p;
+	struct dp_proc_entry *entry;
+	int ret;
+
+	ret = seq_open(file, &dp_seq_ops);
+	if (ret)
+		return ret;
+
+	s = file->private_data;
+	p = kmalloc(sizeof(struct dp_proc_file_entry), GFP_KERNEL);
+
+	if (!p) {
+		(void)seq_release(inode, file);
+		return -ENOMEM;
+	}
+	memset(p, 0, sizeof(*p));
+
+	entry = PDE_DATA(inode);
+
+	if (entry->multi_callback)
+		p->multi_callback = entry->multi_callback;
+	if (entry->single_callback)
+		p->single_callback = entry->single_callback;
+	else
+		p->single_callback = dummy_single_show;
+
+	if (entry->init_callback)
+		p->pos = entry->init_callback();
+	else
+		p->pos = 0;
+
+	s->private = p;
+
+	return 0;
+}
+
+static int dp_proc_release(struct inode *inode, struct file *file)
+{
+	struct seq_file *s;
+
+	s = file->private_data;
+	kfree(s->private);
+
+	return seq_release(inode, file);
+}
+
+static char *get_print_mode_string(void)
+{
+	if (mode == 0)
+		return "seq_printf";
+	else if (mode != -1)
+		return "printk";
+	else
+		return "no print";
+
+}
+
+void proc_print_mode_read(struct seq_file *s)
+{
+	SEQ_PRINTF(s, "mode=%d: %s\n", mode, get_print_mode_string());
+}
+
+ssize_t proc_print_mode_write(struct file *file, const char *buf,
+			      size_t count, loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num;
+	char *param_list[2];
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	mode = dp_atoi(param_list[0]);
+	PRINTK("new mode=%d: %s\n", mode, get_print_mode_string());
+	return count;
+}
+
+static int dp_seq_single_show(struct seq_file *s, void *v)
+{
+	struct dp_proc_entry *p = s->private;
+	p->single_callback(s);
+	return 0;
+}
+
+static int dp_proc_single_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, dp_seq_single_show, PDE_DATA(inode));
+}
+
+void dp_proc_entry_create(struct proc_dir_entry *parent_node,
+			  struct dp_proc_entry *proc_entry)
+{
+	if (!proc_entry || !proc_entry->name)
+		return;
+	memset(&proc_entry->ops, 0, sizeof(struct file_operations));
+	proc_entry->ops.owner = THIS_MODULE;
+
+	if (proc_entry->single_callback) {
+		proc_entry->ops.open = dp_proc_single_open;
+		proc_entry->ops.release = single_release;
+	} else if (proc_entry->multi_callback) {
+		proc_entry->ops.open = dp_proc_open;
+		proc_entry->ops.release = dp_proc_release;
+	} else {
+		proc_entry->ops.open = dp_proc_single_open;
+		proc_entry->ops.release = single_release;
+		proc_entry->single_callback = dummy_single_show;
+	}
+
+	proc_entry->ops.read = seq_read;
+	proc_entry->ops.llseek = seq_lseek;
+	proc_entry->ops.write = proc_entry->write_callback;
+	proc_create_data(proc_entry->name, (S_IFREG | S_IRUGO), parent_node,
+			 &proc_entry->ops, proc_entry);
+}
+EXPORT_SYMBOL(dp_proc_entry_create);
diff --git a/include/net/datapath_api.h b/include/net/datapath_api.h
new file mode 100644
--- /dev/null
+++ b/include/net/datapath_api.h
@@ -0,0 +1,957 @@
+#ifndef DATAPATH_API_H
+#define DATAPATH_API_H
+
+#include <linux/skbuff.h>
+#include <linux/etherdevice.h>	/* eth_type_trans */
+#include <linux/atmdev.h>  /*atm_vcc*/
+#include <xway/switch-api/lantiq_gsw_api.h> /*Switch related structures */
+#include <cpufreq/ltq_cpufreq.h>
+#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#include <linux/cpufreq.h>
+#include <cpufreq/ltq_cpufreq.h>
+#endif /* CONFIG_LTQ_DATAPATH_CPUFREQ*/
+
+/*! \file datapath_api.h
+\brief This file contains all the API for datapath library on the GRX500 system.
+This will actually be split into different header files,
+but collected together for understanding here.
+*/
+
+/** \defgroup GRX500_Datapath_Library GRX500 Datapath Library
+\brief All API and defines exported by Datapath Library of GRX500
+*/
+/* @{ */
+/** \defgroup Datapath_Driver_Defines Datapath Driver Defines
+\brief Defines used in the Datapath Driver
+*/
+/** \defgroup Datapath_Driver_Structures Datapath Driver Structures
+\brief Datapath Configuration Structures
+*/
+/** \defgroup Datapath_Driver_API Datapath Driver Library API
+\brief  Datapath Driver Library API
+*/
+/** \defgroup PPA_Accel_API PPA Acceleration Driver API
+\brief PPA Acceleration Driver API used for learning and getting
+the information necessary to accelerate a flow
+*/
+/* @} */
+#define UNUSED(x) ((void)(x))
+
+#define DP_TX_CAL_CHKSUM     1	/*! Need calculate PMAC. \n
+				   Note, make sure pmac place holder already have \n
+				   or set flag DP_TX_INSERT_PMAC to insert it
+				 */
+#define DP_TX_DSL_FCS        2	/*! Only for DSL FCS Checksum calculation */
+#define DP_TX_INSERT_PMAC    4	/*! It only for special test purpose so far */
+#define DP_TX_OAM            8	/*! OAM packet */
+#define DP_TX_TO_DL_MPEFW    0x10/*! Send Pkt directly to DL FW */
+
+/*Default, here define each enum member's value.
+  Later it will be overridden to define its mapped string array
+*/
+#define DP_DBG_ENUM_OR_STRING(name, value, short_name) name = value
+
+/*Note: per bit one variable */
+#define DP_DBG_FLAG_LIST {\
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DBG, 0x1, "dbg"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_RX_DATA,   0x10, "rx_data"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_RX_DESCRIPTOR,   0x20, "rx_desc"),\
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_RX_PASER,      0x40, "rx_parse"),\
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_RX_PMAC,       0x80, "rx_pmac"),\
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_RX,  (0x10 | 0x20 | 0x40 | 0x80), "rx"),\
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_TX_DATA,         0x100, "tx_data"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_TX_DESCRIPTOR,       0x200, "tx_desc"),\
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_TX_PMAC,  0x400, "tx_pmac"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_TX_SUM,   0x800, "tx_sum"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_DUMP_TX,  (0x100 | 0x200 | 0x400 | 0x800), "tx"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_COC,       0x1000, "coc"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_MIB,       0x2000, "mib"),\
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_MIB_ALGO,  0x4000, "mib_algo"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_CBM_BUF,   0x8000, "cbm_buf"), \
+	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_PAE,  0x10000, "pae") \
+}
+
+enum DP_DBG_FLAG DP_DBG_FLAG_LIST;
+
+
+#define MAX_ETH_ALEN 6
+#define PMAC_LEN     8
+
+enum PMAC_TCP_TYPE {
+	TCP_OVER_IPV4 = 0,
+	UDP_OVER_IPV4,
+	TCP_OVER_IPV6,
+	UDP_OVER_IPV6,
+	TCP_OVER_IPV6_IPV4,
+	UDP_OVER_IPV6_IPV4,
+	TCP_OVER_IPV4_IPV6,
+	UDP_OVER_IPV4_IPV6
+};
+
+/** \addtogroup Datapath_Driver_Structures */
+/* @{ */
+/*! \brief  PPA Sub-interface Data structure
+\param port_id  Datapath Port Id corresponds to PMAC Port Id
+\param subif    Sub-interface Id info. In GRX500, this 15 bits,
+		only 13 bits in PAE are handled [14, 11:0]
+\note
+*/
+
+#ifdef CONFIG_LITTLE_ENDIAN
+struct dma_rx_desc_0 {
+	/* DWORD 0 */
+	union {
+		struct {
+			uint32_t dest_sub_if_id:15;
+			uint32_t eth_type:2;
+			uint32_t flow_id:8;
+			uint32_t tunnel_id:4;
+			uint32_t resv0:3;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_rx_desc_1 {
+	/* DWORD 1 */
+	union {
+		struct {
+			uint32_t classid:4;
+			uint32_t resv1:4;
+			uint32_t ep:4;
+			uint32_t color:2;
+			uint32_t mpe1:1;
+			uint32_t mpe2:1;
+			uint32_t enc:1;
+			uint32_t dec:1;
+			uint32_t nat:1;
+			uint32_t tcp_err:1;
+			uint32_t session_id:12;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_rx_desc_2 {
+	/*DWORD 2 */
+	union {
+		struct {
+			uint32_t data_ptr;
+		} __packed field;
+		uint32_t all;
+	};
+
+} __packed;
+
+struct dma_rx_desc_3 {
+	/*DWORD 3 */
+	union {
+		struct {
+			uint32_t data_len:16;
+			uint32_t mpoa_mode:2;
+			uint32_t mpoa_pt:1;
+			uint32_t qid:4;
+			uint32_t byte_offset:3;
+			uint32_t pdu_type:1;
+			uint32_t dic:1;
+			uint32_t eop:1;
+			uint32_t sop:1;
+			uint32_t c:1;
+			uint32_t own:1;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_tx_desc_0 {
+	/* DWORD 0 */
+	union {
+		struct {
+			uint32_t dest_sub_if_id:15;
+			uint32_t eth_type:2;
+			uint32_t flow_id:8;
+			uint32_t tunnel_id:4;
+			uint32_t resv0:3;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_tx_desc_1 {
+	/* DWORD 1 */
+	union {
+		struct {
+			uint32_t classid:4;
+			uint32_t resv1:4;
+			uint32_t ep:4;
+			uint32_t color:2;
+			uint32_t mpe1:1;
+			uint32_t mpe2:1;
+			uint32_t enc:1;
+			uint32_t dec:1;
+			uint32_t nat:1;
+			uint32_t tcp_err:1;
+			uint32_t session_id:12;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_tx_desc_2 {
+	/*DWORD 2 */
+	union {
+		struct {
+			uint32_t data_ptr;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_tx_desc_3 {
+	/*DWORD 3 */
+	union {
+		struct {
+			uint32_t data_len:16;
+			uint32_t mpoa_mode:2;
+			uint32_t mpoa_pt:1;
+			uint32_t qid:4;
+			uint32_t byte_offset:3;
+			uint32_t pdu_type:1;
+			uint32_t dic:1;
+			uint32_t eop:1;
+			uint32_t sop:1;
+			uint32_t c:1;
+			uint32_t own:1;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+#else				/*big endian */
+
+struct dma_rx_desc_0 {
+	/* DWORD 0 */
+	union {
+		struct {
+			uint32_t resv0:3;
+			uint32_t tunnel_id:4;
+			uint32_t flow_id:8;
+			uint32_t eth_type:2;
+			uint32_t dest_sub_if_id:15;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_rx_desc_1 {
+	/* DWORD 1 */
+	union {
+		struct {
+			uint32_t session_id:12;
+			uint32_t tcp_err:1;
+			uint32_t nat:1;
+			uint32_t dec:1;
+			uint32_t enc:1;
+			uint32_t mpe2:1;
+			uint32_t mpe1:1;
+			uint32_t color:2;
+			uint32_t ep:4;
+			uint32_t resv1:4;
+			uint32_t classid:4;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_rx_desc_2 {
+	/*DWORD 2 */
+	union {
+		struct {
+			uint32_t data_ptr;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_rx_desc_3 {
+	/*DWORD 3 */
+	union {
+		struct {
+			uint32_t own:1;
+			uint32_t c:1;
+			uint32_t sop:1;
+			uint32_t eop:1;
+			uint32_t dic:1;
+			uint32_t pdu_type:1;
+			uint32_t byte_offset:3;
+			uint32_t qid:4;
+			uint32_t mpoa_pt:1;
+			uint32_t mpoa_mode:2;
+			uint32_t data_len:16;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_tx_desc_0 {
+	union {
+		struct {
+			/* DWORD 0 */
+			uint32_t resv0:3;
+			uint32_t tunnel_id:4;
+			uint32_t flow_id:8;
+			uint32_t eth_type:2;
+			uint32_t dest_sub_if_id:15;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_tx_desc_1 {
+	/* DWORD 1 */
+	union {
+		struct {
+			uint32_t session_id:12;
+			uint32_t tcp_err:1;
+			uint32_t nat:1;
+			uint32_t dec:1;
+			uint32_t enc:1;
+			uint32_t mpe2:1;
+			uint32_t mpe1:1;
+			uint32_t color:2;
+			uint32_t ep:4;
+			uint32_t resv1:4;
+			uint32_t classid:4;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_tx_desc_2 {
+	/*DWORD 2 */
+	union {
+		struct {
+			uint32_t data_ptr;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+struct dma_tx_desc_3 {
+	/*DWORD 3 */
+	union {
+		struct {
+			uint32_t own:1;
+			uint32_t c:1;
+			uint32_t sop:1;
+			uint32_t eop:1;
+			uint32_t dic:1;
+			uint32_t pdu_type:1;
+			uint32_t byte_offset:3;
+			uint32_t qid:4;
+			uint32_t mpoa_pt:1;
+			uint32_t mpoa_mode:2;
+			uint32_t data_len:16;
+		} __packed field;
+		uint32_t all;
+	};
+} __packed;
+
+#endif
+#ifdef CONFIG_CPU_BIG_ENDIAN
+/*Note:pmac normally not DWORD aligned. Most time 2 bytes aligment */
+struct pmac_rx_hdr {
+	/*byte 0 */
+	uint8_t res1:1;
+	uint8_t ver_done:1;
+	uint8_t ip_offset:6;
+
+	/*byte 1 */
+	uint8_t tcp_h_offset:5;
+	uint8_t tcp_type:3;
+
+	/*byte 2 */
+	uint8_t sppid:4;
+	uint8_t class:4;
+
+	/*byte 3 */
+	uint8_t res2:6;
+	uint8_t pkt_type:2;
+
+	/*byte 4 */
+	uint8_t res3:1;
+	uint8_t redirect:1;
+	uint8_t res4:1;
+	uint8_t src_sub_inf_id:5;	/*high:mc:1 + vap:4 */
+
+	/*byte 5 */
+	uint8_t src_sub_inf_id2:8;	/*low:mc:1 + vap:4 */
+
+	/*byte 6 */
+	uint8_t port_map:8;	/*high:port map */
+
+	/*byte 7 */
+	uint8_t port_map2:8;	/*low:port map */
+} __packed;
+
+struct pmac_tx_hdr {
+	/*byte 0 */
+	uint8_t tcp_chksum:1;
+	uint8_t res1:1;
+	uint8_t ip_offset:6;
+
+	/*byte 1 */
+	uint8_t tcp_h_offset:5;
+	uint8_t tcp_type:3;
+
+	/*byte 2 */
+	uint8_t sppid:4;
+	uint8_t res:4;
+
+	/*byte 3 */
+	uint8_t port_map_en:1;
+	uint8_t res2:1;
+	uint8_t time_dis:1;
+	uint8_t class_en:1;
+	uint8_t res3:2;
+	uint8_t pkt_type:2;
+
+	/*byte 4 */
+	uint8_t fcs_ins_dis:1;
+	uint8_t redirect:1;
+	uint8_t time_stmp:1;
+	uint8_t src_sub_inf_id:5;	/*high:mc:1 + vap:4 */
+
+	/*byte 5 */
+	uint8_t src_sub_inf_id2:8;	/*low:mc:1 + vap:4 */
+
+	/*byte 6 */
+	uint8_t port_map:8;	/*high:port map */
+
+	/*byte 7 */
+	uint8_t port_map2:8;	/*low:port map */
+} __packed;
+
+#else
+
+/*Note:pmac normally not DWORD aligned. Most time 2 bytes aligment */
+struct pmac_rx_hdr {
+	/*byte 0 */
+	uint8_t ip_offset:6;
+	uint8_t ver_done:1;
+	uint8_t res1:1;
+
+	/*byte 1 */
+	uint8_t tcp_type:3;
+	uint8_t tcp_h_offset:5;
+
+	/*byte 2 */
+	uint8_t class:4;
+	uint8_t sppid:4;
+
+	/*byte 3 */
+	uint8_t pkt_type:2; /* refer to PMAC_TCP_TYPE */
+	uint8_t res2:6;
+
+	/*byte 4 */
+	uint8_t src_sub_inf_id:5;	/*high:mc:1 + vap:4 */
+	uint8_t res4:1;
+	uint8_t redirect:1;
+	uint8_t res3:1;
+
+	/*byte 5 */
+	uint8_t src_sub_inf_id2:8;	/*low:mc:1 + vap:4 */
+
+	/*byte 6 */
+	uint8_t port_map:8;	/*high:port map */
+
+	/*byte 7 */
+	uint8_t port_map2:8;	/*low:port map */
+} __packed;
+
+struct pmac_tx_hdr {
+	/*byte 0 */
+	uint8_t ip_offset:6;
+	uint8_t res1:1;
+	uint8_t tcp_chksum:1;
+
+	/*byte 1 */
+	uint8_t tcp_type:3;
+	uint8_t tcp_h_offset:5;
+
+	/*byte 2 */
+	uint8_t res:4;
+	uint8_t sppid:4;
+
+	/*byte 3 */
+	uint8_t pkt_type:2; /* refer to PMAC_TCP_TYPE */
+	uint8_t res3:2;
+	uint8_t class_en:1;
+	uint8_t time_dis:1;
+	uint8_t res2:1;
+	uint8_t port_map_en:1;
+
+	/*byte 4 */
+	uint8_t src_sub_inf_id:5;	/*high:mc:1 + vap:4 */
+	uint8_t time_stmp:1;
+	uint8_t redirect:1;
+	uint8_t fcs_ins_dis:1;
+
+	/*byte 5 */
+	uint8_t src_sub_inf_id2:8;	/*low:mc:1 + vap:4 */
+
+	/*byte 6 */
+	uint8_t port_map:8;	/*high:port map */
+
+	/*byte 7 */
+	uint8_t port_map2:8;	/*low:port map */
+} __packed;
+
+#endif
+
+enum DP_DEV_TYPE {
+	PMAC_CPU_ID = 0,
+	PMAC_ETH_LAN_START_ID = 1,
+	PMAC_ETH_LAN_END_ID = 6,
+	PMAC_ALLOC_START_ID = 7,
+	PMAC_ALLOC_END_ID = 14,
+	PMAC_TUNNEL_DECAP_ID = 14,
+	PMAC_ETH_WAN_ID = 15,
+	PMAC_END_ID = 16,
+};
+
+enum DP_API_STATUS {
+	DP_FAILURE = -1,
+	DP_SUCCESS = 0,
+};
+
+#define DP_F_ENUM_OR_STRING(name, value, short_name) name = value
+
+/*Note:per bit one variable */
+#define DP_F_FLAG_LIST  { \
+	DP_F_ENUM_OR_STRING(DP_F_DEREGISTER, 0x00000001, "De-Register"), \
+	DP_F_ENUM_OR_STRING(DP_F_FAST_ETH_LAN,   0x00000002, "ETH_LAN"), \
+	DP_F_ENUM_OR_STRING(DP_F_FAST_ETH_WAN,   0x00000004, "ETH_WAN"),\
+	DP_F_ENUM_OR_STRING(DP_F_FAST_WLAN,      0x00000008, "FAST_WLAN"),\
+	DP_F_ENUM_OR_STRING(DP_F_FAST_DSL,       0x00000010, "DSL"),\
+	DP_F_ENUM_OR_STRING(DP_F_DIRECT,         0x00000020, "DirectPath"), \
+	DP_F_ENUM_OR_STRING(DP_F_LOOPBACK,       0x00000040, "Tunne_loop"),\
+	DP_F_ENUM_OR_STRING(DP_F_DIRECTPATH_RX,  0x00000080, "Directpath_RX"), \
+	DP_F_ENUM_OR_STRING(DP_F_MPE_ACCEL,      0x00000100, "MPE_FW"), \
+	DP_F_ENUM_OR_STRING(DP_F_CHECKSUM,       0x00000200, "Checksum"),\
+	DP_F_ENUM_OR_STRING(DP_F_DONTCARE,       0x00000400, "DontCare"),\
+	DP_F_ENUM_OR_STRING(DP_F_DIRECTLINK,     0x00000800, "DirectLink"),\
+	DP_F_ENUM_OR_STRING(DP_F_SUBIF_LOGICAL, 0x00001000, "LogicalIf"), \
+	DP_F_ENUM_OR_STRING(DP_F_LRO,           0x00002000, "LRO"), \
+	DP_F_ENUM_OR_STRING(DP_F_FAST_DSL_DOWNSTREAM, 0x00004000, "DSL_Down"), \
+	DP_F_ENUM_OR_STRING(DP_F_DSL_BONDING, 0x00008000, "DSL_Bonding") \
+}
+
+enum DP_F_FLAG DP_F_FLAG_LIST;
+
+
+#define DP_F_PORT_TUNNEL_DECAP  DP_F_LOOPBACK   /*Note:CBM is using old macro DP_F_PORT_TUNNEL_DECAP */
+
+
+#define DP_COC_REQ_DP    	1 /*COC request from Datapath itself */
+#define DP_COC_REQ_ETHERNET   	2 /*COC request from ethernet */
+#define DP_COC_REQ_VRX318   	4 /*COC request from vrx318 */
+
+typedef struct dp_subif {
+	int32_t port_id;	/*!< Datapath Port Id corresponds to PMAC Port Id */
+	int32_t subif:15;	/*!< Sub-interface Id info. In GRX500,
+				   this is 15 bits, only 13 bits in PAE are handled [14, 11:0].\n
+				   DMA subif format is mc_flag[14:14]  Res[13:12] VAP[11:8]
+				   GRP[7:7] Index/StationID[6:0] \n
+				 */
+} dp_subif_t;
+
+typedef dp_subif_t PPA_SUBIF;
+
+typedef struct dp_drv_mib {
+	u64 rx_drop_pkts;
+	u64 rx_error_pkts;
+	u64 tx_drop_pkts;
+	u64 tx_error_pkts;
+	u64 tx_pkts; /* for VRX318 case. \n
+				Note, for bonding tx, also difficult to get its mib counter from its shared queue mapping */
+	u64 tx_bytes; /* for for VRX318 case */
+} dp_drv_mib_t;
+
+typedef int32_t(*dp_rx_fn_t)(struct net_device *rxif, struct net_device *txif, struct sk_buff *skb, int32_t len);	/*! Device Receive
+															   Function callback for packets
+															 */
+typedef int32_t(*dp_stop_tx_fn_t)(struct net_device *dev);	/*! The Driver Stop
+								   Tx function callback
+								 */
+typedef int32_t(*dp_restart_tx_fn_t)(struct net_device *dev);	/*! Driver
+								   Restart Tx function callback
+								 */
+typedef int32_t(*dp_reset_mib_fn_t)(dp_subif_t *subif, int32_t flag); /*! Driver reset its mib counter callback */
+typedef int32_t(*dp_get_mib_fn_t)(dp_subif_t *subif, dp_drv_mib_t *, int32_t flag); /*! Driver get mib counter of the specified subif interface.*/
+typedef int32_t(*dp_get_netif_subifid_fn_t)(struct net_device *netif, struct sk_buff *skb, void *subif_data, uint8_t dst_mac[MAX_ETH_ALEN], dp_subif_t *subif, uint32_t flags);	/*! get subifid */
+typedef int32_t(*dp_coc_confirm_stat)(enum ltq_cpufreq_state new_state, enum ltq_cpufreq_state old_state, uint32_t flags); /*! Confirmed state by COC */
+
+/*!
+\brief Datapath Library Registration Callback
+\param rx_fn  Rx function callback
+\param stop_fn    Stop Tx function callback for flow control
+\param restart_fn    Start Tx function callback for flow control
+\param get_subifid_fn    Get Sub Interface Id of netif
+\note
+*/
+typedef struct dp_cb {
+	dp_rx_fn_t rx_fn;	/*!< Rx function callback */
+	dp_stop_tx_fn_t stop_fn;	/*!< Stop Tx function callback for
+					   flow control
+					 */
+	dp_restart_tx_fn_t restart_fn;	/*!< Start Tx function callback
+					   for flow control
+					 */
+	dp_get_netif_subifid_fn_t get_subifid_fn;	/*!< Get Sub Interface Id
+							   of netif/netdevice
+							 */
+	dp_reset_mib_fn_t reset_mib_fn;  /*!< reset registered device's network mib counters */
+	dp_get_mib_fn_t get_mib_fn;  /*!< reset registered device's network mib counters */
+	dp_coc_confirm_stat dp_coc_confirm_stat_fn; /*!< once COC confirm the state changed, Datatpath will notify Ethernet/VRX318 driver.
+							Ethernet/VRX318 driver need to enable/disable interrupt or change threshold accordingly */
+} dp_cb_t;
+
+/*!
+\brief Ingress PMAC port configuration from Datapath Library
+\param tx_dma_chan  Tx DMA channel Number for which PMAC
+		configuration is to be done
+\param err_disc     Is Discard Error Enable
+\param pmac    Is Ingress PMAC Hdr Present
+\param def_pmac   Is Default PMAC Header configured for Tx DMA Channel
+\param def_pmac_pmap Is PortMap to be used from Default PMAC hdr (else use
+		Ingress PMAC hdr)
+\param def_pmac_en_pmap Is PortMap Enable to be used from Default PMAC hrd
+		(else use Ingress PMAC hdr)
+\param def_pmac_tc  Is TC (class) to be used from Default PMAC hdr
+		(else use Ingress PMAC hdr)
+\param def_pmac_en_tc  Are TC bits to be used for TC from Default PMAC hdr
+		(else use Ingress PMAC hdr)
+		Alternately, EN/DE/MPE1/MPE2 bits can be used for TC
+\param def_pmac_subifid  Is Sub-interfaceId to be taken from Default PMAC hdr
+		(else use Ingress PMAC hdr)
+\param def_pmac_src_port Packet Source Port determined from Default PMAC hdr
+		(else use Ingress PMAC hdr)
+\param res_ing	Reserved bits
+\param def_pmac_hdr Default PMAC header configuration for the Tx DMA channel
+		Useful if Src Port does not send PMAC header with packet
+\note
+*/
+typedef struct ingress_pmac {
+	uint32_t tx_dma_chan:8;	/*!< Tx DMA channel Number for which PMAC
+				   configuration is to be done
+				 */
+	uint32_t err_disc:1;	/*!< Is Discard Error Enable */
+	uint32_t pmac:1;	/*!< Is Ingress PMAC Hdr Present */
+	uint32_t def_pmac:1;	/*!< Is Ingress PMAC Hdr Present */
+	uint32_t def_pmac_pmap:1;	/*!< Is Default PMAC Header configured
+					   for Tx DMA Channel
+					 */
+	uint32_t def_pmac_en_pmap:1;	/*!< Is PortMap Enable to be used from
+					   Default PMAC hrd (else use Ingress PMAC hdr)
+					 */
+	uint32_t def_pmac_tc:1;	/*!< Is TC (class) to be used from Default PMAC
+				   hdr (else use Ingress PMAC hdr)
+				 */
+	uint32_t def_pmac_en_tc:1;	/*!< Are TC bits to be used for TC from
+					   Default PMAC hdr (else use Ingress PMAC hdr)
+					   Alternately, EN/DE/MPE1/MPE2 bits can be used for TC
+					 */
+	uint32_t def_pmac_subifid:1;	/*!< Is Sub-interfaceId to be taken from
+					   Default PMAC hdr (else use Ingress PMAC hdr)
+					 */
+	uint32_t def_pmac_src_port:1;	/*!< Packet Source Port determined from
+					   Default PMAC hdr (else use Ingress PMAC hdr)
+					 */
+	uint32_t res_ing:15;	/*!< Reserved bits */
+	uint8_t def_pmac_hdr[PMAC_LEN];	/*!< Default PMAC header configuration
+					   for the Tx DMA channel. Useful if Src Port
+					   does not send PMAC header with packet
+					 */
+} ingress_pmac_t;
+
+/*!
+\brief Egress PMAC port configuration from Datapath Library
+\param rx_dma_chan  Rx DMA channel Number for which PMAC configuration
+		is to be done
+\param rm_l2hdr	If Layer 2 Header is to be removed before Egress
+		(for eg. for IP interfaces like LTE)
+\param num_l2hdr_bytes_rm If rm_l2hdr=1,then number of L2 hdr bytes to be
+		removed
+\param fcs	If FCS is enabled on the port
+\param pmac If PMAC header is enabled on the port
+\param dst_port  Destination Port Identifier
+\param res_eg  Reserved bits
+\note
+*/
+typedef struct egress_pmac {
+	uint32_t rx_dma_chan:8;	/*!< Rx DMA channel Number for which PMAC
+				   configuration is to be done
+				 */
+	uint32_t rm_l2hdr:1;	/*!< If Layer 2 Header is to be removed
+				   before Egress (for eg. for IP interfaces like LTE)
+				 */
+
+	uint32_t num_l2hdr_bytes_rm:8;	/*!< If rm_l2hdr=1,
+					   then number of L2 hdr bytes to be removed
+					 */
+	uint32_t fcs:1;		/*!< If FCS is enabled on the port */
+	uint32_t pmac:1;	/*!< If PMAC header is enabled on the port */
+	uint32_t dst_port:8;	/*!< Destination Port Identifier */
+	uint32_t res_dw1:4;	/*!< reserved field in DMA descriptor - DW1*/
+	uint32_t res1_dw0:3;	/*!< reserved field in DMA descriptor - DW0*/
+	uint32_t res2_dw0:2;	/*!< reserved field in DMA descriptor - DW0*/
+	uint32_t tc_enable:1;	/*!<Selector for traffic class bits */
+	uint32_t traffic_class:8;	/*!< If tc_enable=true,sets egress queue
+					traffic class*/
+	uint32_t flow_id:8;	/*!< flow id msb*/
+	uint32_t dec_flag:1;	/*!< If tc_enable=false,sets decryption flag*/
+	uint32_t enc_flag:1;	/*!< If tc_enable=false,sets encryption flag*/
+	uint32_t mpe1_flag:1;	/*!< If tc_enable=false,mpe1 marked flag valid*/
+	uint32_t mpe2_flag:1;	/*!< If tc_enable=false,mpe1 marked flag valid*/
+	uint32_t res_eg:5;	/*!< Reserved bits */
+} egress_pmac_t;
+
+typedef struct dp_subif_stats_t {
+	u64 rx_bytes;
+	u64 rx_pkts;
+	u64 rx_disc_pkts;
+	u64 rx_err_pkts;
+	u64 tx_bytes;
+	u64 tx_pkts;
+	u64 tx_disc_pkts;
+	u64 tx_err_pkts;
+} dp_subif_stats_t;
+
+enum EG_PMAC_F {
+	/*1 bit one flag */
+	EG_PMAC_F_L2HDR_RM = 0x1,  /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.numBytesRem and bRemL2Hdr valid */
+	EG_PMAC_F_FCS = 0x2, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.bFcsEna valid*/
+	EG_PMAC_F_PMAC = 0x4, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.bPmacEna valid */
+	EG_PMAC_F_RXID = 0x8, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.nRxDmaChanId valid */
+	EG_PMAC_F_RESDW1 = 0x10, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.nResDW1 valid */
+	EG_PMAC_F_RES1DW0 = 0x20, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.nRes1DW0 valid */
+	EG_PMAC_F_RES2DW0 = 0x40, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.nRes2DW0 valid */
+	EG_PMAC_F_TCENA = 0x80, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.bTCEnable valid */
+	EG_PMAC_F_DECFLG = 0x100, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.bDecFlag valid */
+	EG_PMAC_F_ENCFLG = 0x200, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.bEncFlag valid */
+	EG_PMAC_F_MPE1FLG = 0x400, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.bMpe1Flag valid */
+	EG_PMAC_F_MPE2FLG = 0x800, /*!< Once this bit is set in eg_pmac_flags,it means pmac_cfg.eg_pmac.bMpe2Flag valid */
+};
+
+/*! EG_PMAC Flags */
+enum IG_PMAC_F {
+	/*1 bit one flag */
+	IG_PMAC_F_ERR_DISC = 0x1, /*!< Once this bit is set in ig_pmac_flags, it means pmac_cfg.ig_pmac.bErrPktsDisc valid */
+	IG_PMAC_F_PRESENT = 0x2,  /*!< Once this bit is set in ig_pmac_flags, it means pmac_cfg.ig_pmac.bPmacPresent valid */
+	IG_PMAC_F_SUBIF = 0x4,  /*!< Once this bit is set in ig_pmac_flags, it means pmac_cfg.ig_pmac.bSubIdDefault valid */
+	IG_PMAC_F_SPID = 0x8,  /*!< Once this bit is set in ig_pmac_flags, it means pmac_cfg.ig_pmac.bSpIdDefault valid */
+	IG_PMAC_F_CLASSENA = 0x10,  /*!< Once this bit is set in ig_pmac_flags, it means pmac_cfg.ig_pmac.bClassEna valid */
+	IG_PMAC_F_CLASS = 0x20,  /*!< Once this bit is set in ig_pmac_flags, it means pmac_cfg.ig_pmac.bClassDefault valid */
+	IG_PMAC_F_PMAPENA = 0x40,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.bPmapEna valid */
+	IG_PMAC_F_PMAP = 0x80,  /*!< Once this bit is set in ig_pmac_flags, it means pmac_cfg.ig_pmac.bPmapDefault valid */
+	IG_PMAC_F_PMACHDR1 = 0x100,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.defPmacHdr[1] valid */
+	IG_PMAC_F_PMACHDR2 = 0x200,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.defPmacHdr[2] valid */
+	IG_PMAC_F_PMACHDR3 = 0x400,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.defPmacHdr[3] valid */
+	IG_PMAC_F_PMACHDR4 = 0x800,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.defPmacHdr[4] valid */
+	IG_PMAC_F_PMACHDR5 = 0x1000,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.defPmacHdr[5] valid */
+	IG_PMAC_F_PMACHDR6 = 0x2000,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.defPmacHdr[6] valid */
+	IG_PMAC_F_PMACHDR7 = 0x4000,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.defPmacHdr[7] valid */
+	IG_PMAC_F_PMACHDR8 = 0x8000,  /*!< Once this bit is set in ig_pmac_flags,it means pmac_cfg.ig_pmac.defPmacHdr[8] valid */
+};
+
+enum PASER_FLAG {
+	F_MPE_NONE = 0x1, /*Need set MPE1=0 and MPE2=0 case's parser header configuration */
+	F_MPE1_ONLY = 0x2, /*Need set MPE1=1 and MPE2=0 case's parser header configuration  */
+	F_MPE2_ONLY = 0x4, /*Need set MPE1=0 and MPE2=1 case's parser header configuration  */
+	F_MPE1_MPE2 = 0x8, /*Need set MPE1=1 and MPE2=1 case's parser header configuration  */
+};
+enum PASER_VALUE {
+	DP_PARSER_F_DISABLE = 0,  /*Without Paser Header and Offset */
+	DP_PARSER_F_HDR_ENABLE = 1,/*With Paser Header, but without Offset */
+	DP_PARSER_F_HDR_OFFSETS_ENABLE = 2,  /*with Paser Header and Offset */
+};
+/*!
+\brief Datapath Library Port PMAC configuration structure
+\param ig_pmac  Ingress PMAC configuration
+\param eg_pmac  Egress PMAC configuration
+\note GSW_PMAC_Ig_Cfg_t/GSW_PMAC_Eg_Cfg_t defined in GSWIP driver:
+	<xway/switch-api/lantiq_gsw_api.h>
+*/
+typedef struct dp_pmac_cfg {
+	uint32_t ig_pmac_flags;	/*!< one bit for one ingress_pmac_t fields */
+	uint32_t eg_pmac_flags;	/*!< one bit for one egress_pmac_t fields */
+	ingress_pmac_t ig_pmac;	/*!< Ingress PMAC configuration */
+	egress_pmac_t eg_pmac;	/*!< Egress PMAC configuration */
+} dp_pmac_cfg_t;
+/* @} */
+
+/** \addtogroup Datapath_Driver_API */
+/* @{ */
+/*! \brief  Datapath Allocate Datapath Port aka PMAC port
+	port may map to an exclusive netdevice like in the case of
+	ethernet LAN ports. In other cases like WLAN, the physical port is a
+	Radio port, while netdevices are Virtual Access Points (VAPs)
+	In this case, the  AP netdevice can be passed
+Alternately, driver_port & driver_id will be used to identify this port
+\param[in] owner  Kernel module pointer which owns the port
+\param[in] dev pointer to Linux netdevice structure (optional), can be NULL
+\param[in] dev_port Physical Port Number of this device managed by the driver
+\param[in] port_id Optional port_id number requested. Usually, 0 and
+	allocated by driver
+\param[in] pmac_cfg PMAC related configuration parameters
+\param[in] flags :Various special Port flags like WAVE500, VRX318 etc ...
+	-  DP_F_DEALLOC_PORT :Deallocate the already allocated port
+\return  Returns PMAC Port number, -1 on ERROR
+*/
+int32_t dp_alloc_port(struct module *owner, struct net_device *dev,
+		      uint32_t dev_port, int32_t port_id,
+		      dp_pmac_cfg_t *pmac_cfg, uint32_t flags);
+
+/*! \brief  Higher layer Driver Datapath registration API
+\param[in] owner  Kernel module pointer which owns the port
+\param[in] port_id Port Id returned by alloc() function
+\param[in] dp_cb  Datapath driver callback structure
+\param[in] flags :Special input flags to alloc routine
+		- F_DEREGISTER :Deregister the device
+\return 0 - OK / -1 - Correct Return Value
+\note
+*/
+
+int32_t dp_register_dev(struct module *owner, uint32_t port_id,
+			dp_cb_t *dp_cb, uint32_t flags);
+
+/*! \brief  Allocates datapath subif number to a sub-interface netdevice
+* Sub-interface value must be passed to the driver
+port may map to an exclusive netdevice like in the case of ethernet LAN ports
+\param[in] owner  Kernel module pointer which owns the port
+\param[in] dev pointer to Linux netdevice structure, only for VRX318 driver,\n
+it can be NULL. All other driver's, must provide valid dev pointer.
+\param[in] port_id Optional port_id number requested. Usually, 0 and
+		allocated by driver
+\param[in,out] subif_id pointer to subif_id structure including port_id
+\param[in] flags :
+	DP_F_DEREGISTER - De-register already registered subif/vap
+\return Port Id  / IFX_FAILURE
+\note
+*/
+int32_t dp_register_subif(struct module *owner, struct net_device *dev,
+			  char *subif_name, dp_subif_t *subif_id,
+			  uint32_t flags);
+
+/*! \brief  Transmit packet to low-level Datapath driver
+\param[in] rx_if  Rx If netdevice pointer - optional
+\param[in] buf   pointer to packet buffer like sk_buff
+\param[in] len    Length of packet to transmit
+\param[in] flags :Reserved
+\return 0 if OK  / -1 if error
+\note
+*/
+int32_t dp_xmit(struct net_device *rx_if, dp_subif_t *rx_subif,
+		struct sk_buff *skb, int32_t len, uint32_t flags);
+
+/*! \brief  Check if network interface like WLAN is a fastpath interface
+Sub-interface value must be passed to the driver
+	port may map to an exclusive netdevice like in the case of
+	ethernet LAN ports.
+\param[in] netif  pointer to stack network interface structure
+\param[in] ifname  Interface Name
+\param[in] flags :Reserved
+\return 1 if WLAN fastpath interface like WAVE500 / 0 otherwise
+\note  Prototype of PPA_DP_CHECK_IF_NETIF_FASTPATH part of the callback
+		structure. Such a function needs to be defined by client driver
+		like the WAVE500 WLAN driver. This API is used by the PPA Stack
+		AL to check during acceleration learning and configuration
+*/
+
+int32_t dp_check_if_netif_fastpath_fn(struct net_device *netif,
+				      dp_subif_t *subif, char *ifname,
+				      uint32_t flags);
+
+/*! \brief  Get Pkt dst-if Sub-if value
+	Sub-interface value must be passed to the driver
+	port may map to an exclusive netdevice like in the case of ethernet
+	LAN ports.
+\param[in] port_id Datapath/PMAC Port Id on which to search for subifid
+	(optional)
+\param[in] netif  pointer to stack network interface structure through
+		which packet to be Tx
+\param[in] skb pointer to sk_buff structure that carries packet destination
+		info
+\param[in] dst_mac  Destiantion MAC address to which packet is addressed
+\param[in] flags :Reserved
+\return 0 if subifid found; -1 otherwise
+\note  Prototype of PPA_DP_GET_NETIF_SUBIF function. Not implemented in PPA
+	Datapath, but in client driver like WAVE500 WLAN driver
+\note  Either skbuff parameters to be used  or dst_mac to determine subifid
+	For WAVE500 driver, this will be the StationId + VAP on the basis of
+	the dst mac. This function is only to be used by the PPA to program
+	acceleration entries. The client driver is still expected to fill
+	in Sub-interface id when transmitting to the underlying datapath driver
+*/
+int32_t dp_get_netif_subifid(struct net_device *netif, struct sk_buff *skb,
+			     void *subif_data, uint8_t dst_mac[MAX_ETH_ALEN],
+			     dp_subif_t *subif, uint32_t flags);
+/*!
+\brief  The API is for CBM to send received packets(skb) to dp lib. Datapath lib
+	will do basic packet parsing and forwards it to related drivers,\n
+	like ethernet driver, wifi and lte and so on. Noted.
+	It is a chained skb and dp lib will split it before send it to
+	related drivers
+\param[in] skb  pointer to packet buffer like sk_buffer
+\param[in] flag  reserved for futures
+\return 0 if OK / -1 if error
+*/
+int32_t dp_rx(struct sk_buff *skb, uint32_t flags);
+/*!
+\brief  The API is for configuing PMAC based on deque port
+\param[in] port  Egress Port
+\param[in] pmac_cfg Structure of ingress/egress parameters for setting PMAC
+	   configuration
+\return 0 if OK / -1 if error
+*/
+int32_t dp_pmac_set(uint32_t port, dp_pmac_cfg_t *pmac_cfg);
+
+struct pmac_port_info *get_port_info(int index);
+struct pmac_port_info *get_port_info_via_dp_port(int dp_port);
+
+void set_dp_dbg_flag(uint32_t flags);
+uint32_t get_dp_dbg_flag(void);
+struct module *dp_get_module_owner(int ep);
+void dp_dump_raw_data(char *buf, int len, char *prefix_str);
+
+#ifdef CONFIG_LTQ_TOE_DRIVER
+#undef LTQ_TSO_SW_WORKAROUND
+extern int ltq_tso_xmit(struct sk_buff *skb, int egress_port, int flags);
+#endif
+
+enum DP_F_STATS_ENUM {
+	DP_F_STATS_SUBIF = 1 << 0,
+	DP_F_STATS_PAE_CPU = 1 << 1
+};
+extern void dp_set_gsw_parser(uint8_t flag, uint8_t cpu, uint8_t mpe1, uint8_t mpe2, uint8_t mpe3);
+#define get_gsw_parser  dp_get_gsw_parser /*backcompatible since PPA is already calling it */
+extern void dp_get_gsw_parser(uint8_t *cpu, uint8_t *mpe1, uint8_t *mpe2, uint8_t *mpe3);
+extern void dp_parser_info_refresh(u32 v, u32 verify);
+extern int dp_reset_itf_mib(u32 flag);
+extern int dp_get_netif_stats(struct net_device *dev, dp_subif_t *subif_id, struct rtnl_link_stats64 *path_stats, uint32_t flags);
+int32_t dp_clear_netif_stats(struct net_device *dev, dp_subif_t *subif_id, uint32_t flag);
+extern int dp_get_port_subitf_via_ifname(char *ifname, dp_subif_t *subif);
+extern int dp_get_port_subitf_via_dev(struct net_device *dev, dp_subif_t *subif);
+#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+extern int dp_coc_new_stat_req(enum ltq_cpufreq_state new_state, uint32_t flag); /*DP's submodule to call it */
+extern int dp_set_rmon_threshold(struct ltq_cpufreq_threshold *threshold, uint32_t flags);
+#endif /* CONFIG_LTQ_DATAPATH_CPUFREQ*/
+
+enum ltq_cpufreq_state;
+int dp_set_meter_rate(enum ltq_cpufreq_state stat, unsigned int rate);
+char *dp_skb_csum_str(struct sk_buff *skb);
+
+
+/* @} */
+#endif				/*DATAPATH_API_H */
diff --git a/include/net/datapath_proc_api.h b/include/net/datapath_proc_api.h
new file mode 100755
--- /dev/null
+++ b/include/net/datapath_proc_api.h
@@ -0,0 +1,79 @@
+#ifndef DATAPATH_PROC_H
+#define DATAPATH_PROC_H
+
+#include <linux/kernel.h>	/*kmalloc */
+#include <linux/ctype.h>
+#include <linux/proc_fs.h>	/*file_operations */
+#include <linux/seq_file.h>	/*seq_file */
+#include <linux/uaccess.h>	/*copy_from_user */
+
+#define set_ltq_dbg_flag(v, e, f) do {;\
+	if (e > 0)\
+		v |= (uint32_t)(f);\
+	else\
+		v &= (uint32_t) (~f); } \
+	while (0)
+
+typedef void (*dp_proc_single_callback_t) (struct seq_file *);
+typedef int (*dp_proc_callback_t) (struct seq_file *, int);
+typedef int (*dp_proc_init_callback_t) (void);
+typedef ssize_t(*dp_proc_write_callback_t) (struct file *file,
+					     const char __user *input,
+					     size_t size, loff_t *loff);
+
+struct dp_proc_file_entry {
+	dp_proc_callback_t multi_callback;
+	dp_proc_single_callback_t single_callback;
+	int pos;
+	int single_call_only;
+};
+
+struct dp_proc_entry {
+	char *name;
+	dp_proc_single_callback_t single_callback;
+	dp_proc_callback_t multi_callback;
+	dp_proc_init_callback_t init_callback;
+	dp_proc_write_callback_t write_callback;
+	struct file_operations ops;
+};
+
+void dp_proc_entry_create(struct proc_dir_entry *parent_node,
+			   struct dp_proc_entry *proc_entry);
+
+int dp_atoi(unsigned char *str);
+char *dp_strstri(char *string, char *substring);
+int dp_strncmpi(const char *s1, const char *s2, size_t n);
+int dp_strcmpi(char const *s1, char const *s2);
+void dp_replace_ch(char *p, int len, char orig_ch, char new_ch);
+void dp_remove_leading_whitespace(char **p, int *len);
+
+/*Split buffer to multiple segment with seperator space.
+And put pointer to array[].
+By the way, original buffer will be overwritten with '\0' at some place.
+*/
+int dp_split_buffer(char *buffer, char *array[], int max_param_num);
+
+#ifdef CONFIG_LTQ_DP_MPE_FASTHOOK_TEST
+/*add the macro in order to be back-compatible with old MPE FW HOOK */
+#define ltq_proc_entry dp_proc_entry
+#define ltq_proc_file_entry dp_proc_file_entry
+
+#define ltq_proc_entry_create dp_proc_entry_create
+
+#define ltq_atoi dp_atoi
+#define ltq_strstri dp_strstri
+#define ltq_strncmpi dp_strncmpi
+#define ltq_strcmpi dp_strcmpi
+#define ltq_replace_ch dp_replace_ch
+#define ltq_remove_leading_whitespace dp_remove_leading_whitespace
+#define ltq_split_buffer dp_split_buffer
+#endif /*CONFIG_LTQ_DP_MPE_FASTHOOK_TEST*/
+
+void set_start_end_id(unsigned int new_start, unsigned int new_end,
+		      unsigned int max_start, unsigned int max_end,
+		      unsigned int default_start, unsigned int default_end,
+		      unsigned int *start, unsigned int *end);
+
+
+
+#endif				/*DATAPATH_PROC_H */
diff --git a/include/net/mpe_fast_hook_test.h b/include/net/mpe_fast_hook_test.h
new file mode 100644
--- /dev/null
+++ b/include/net/mpe_fast_hook_test.h
@@ -0,0 +1,108 @@
+#ifndef MPE_FW_FAST_HOOK_TEST_H
+#define MPE_FW_FAST_HOOK_TEST_H
+
+#include <generated/autoconf.h>
+
+enum LTQ_MPE_FASTHOOK_SKB_FLAG {
+	ACC_HOOK_RX,/*hook point: device rx hook */
+	ACC_HOOK_NETFILTER,/*hook point: netfilter hook */
+	ACC_HOOK_TX	/*hook point: device tx hook */
+};
+
+enum LTQ_MPE_FASTHOOK_SKB_ACT {
+	ACC_HOOK_CONTINUE,/*continue next hook */
+	ACC_HOOK_DONE /* current packet is soft ware accelerated alreadys */
+};
+
+enum LTQ_MPE_FASTHOOK_RETURN_VALUE {
+	PKT_CONTINUE,/*continue next hook */
+	PKT_CONSUMED,
+	PKT_DONE/* current packet is soft ware accelerated alreadys */
+};
+
+/* Note, since there is multiple accelertion engineer with different capability,
+   suggest to use MACRO in the hook for different learning, otherwise, it needs to check MPE HAL layer and affects performace
+ */
+enum LTQ_MPE_FASTHOOK_SKB_ACC_RES_FLAG {
+	ACC_UNKNOWN = 0,/* Don't know whether can be accelerated or not */
+	ACC_CANNOT = 1,/* Cannot be acclerated by any accelerator engineer */
+	ACC_DONOT_ = 2,/* Can be accelerated, but Dont do accleration for Session management purpose, or for session relearn, esp for tos,... */
+	ACC_SOFTWARE_OK = 4,/* Can be accelerated by software acceleration */
+	ACC_SWITCH_OK = 8,/* Can be accelerated by Switch Accelerator, mainly for future URX500 */
+	ACC_MPE_OK = 16,/* Can be accelerated by MPE accelerator, mainly for future URX500 */
+	ACC_PAE_OK = 32,/* Can be accelerated by PPE FW, for existing product, like AR10, VE9,.... */
+
+};
+
+typedef union {
+	u32 ip; /*!< the storage buffer for ipv4 */
+#ifdef CONFIG_IPV6
+	u32 ip6[4];/*!< the storage buffer for ipv6 */
+#endif
+} LTQ_MPE_FASTHOOK_IPADDR;
+
+#define MAX_FASTHOOK_PHYDEV 10
+
+struct ltq_mpe_fasthook_session_info {
+	/* buffer for parsing skb during rx_hook and tx_hook */
+	u32 vlan_num: 2; /* for vlan header number: for both rx/tx_hook */
+	u32 ppp_flag: 1; /* pppoe header: for both rx/tx_hook */
+
+	u32 dslite_flag: 1; /*dslite header flag: for both rx/tx_hook */
+	u32 rd_flag: 1;
+	u32 gre_flag: 1;
+	u32 route_flag: 1; /* 1 means it is routing packet */
+	u32 tcp_flag: 1; /* 1 means tcp packet */
+	u32 tcp_establish_flag: 1; /* 1 means tcp fully estabilished */
+	u32 multicast_flag: 1;
+	u32 l2tp_flag: 1;
+	u32 l2tp_controlmsg_flag: 1;
+	u8 ip_proto: 8;
+
+	LTQ_MPE_FASTHOOK_IPADDR src_ip, dst_ip;
+	u16 src_port, dst_port;
+	u16 tos;
+
+	/* buffer for parsing skb during tx_hook */
+	u32 inner_vid;/* inner_vid: for tx_hook only */
+	u32 outer_vid;/* outer_vid: for tx_hook only */
+	u32 pppheader_offset;
+	u32 dsliteheader_offset;
+	u32 rdheader_offset;
+	u32 inneripheader_offset;
+	u32 greheader_offset;
+	u32 grekey_en;
+	u32 previous_ipheadertype; /*Incase of gre and l2tp*/
+	u32 eogre_inner_macheader_offset;/*Incase of gre*/
+	u32 l2tpheader_offset; /*Incase of l2tp*/
+	u32 l2tpheader_udp_offset; /*Incase of l2tp*/
+	u32 l2tpversion; /*Incase of l2tp*/
+	u16 pppoe_session_id;/* pppoe_session_id */
+	u32 ttl;
+	u8 src_mac[6], dst_mac[6];
+	u8 ip_version;
+	struct net_device *phydev[MAX_FASTHOOK_PHYDEV];
+
+	/* Mainly for multicast or bridging learning */
+	u8 tx_count;/* how many times mpe_fasthook_info pass ltq_mpe_fasthook_info for skb_clone/copy to different interface forwarding. Mainly for multicast learning or bridging learning */
+	u8 referece_count;/* When it becomes zero, it means need to delte this structure memory. Also means need to start learn multicast/bridging destiniation interface list and its action */
+};
+
+#define FASTHOOK_KEY_SIZE  64
+struct ltq_mpe_fasthook_info {
+	struct ltq_mpe_fasthook_session_info *rx_info;
+	struct ltq_mpe_fasthook_session_info *tx_info;
+	struct ltq_mpe_fasthook_session_info *tmp_tx_info;
+	char key[FASTHOOK_KEY_SIZE];
+
+	/*learning decision */
+	u32 acc_hook_point: 2; /* Refer to enum LTQ_MPE_FASTHOOK_SKB_HOOK_FLAG */
+	u32 acc_hook_action: 2; /* Need skip next hooks or not */
+	u8 acc_learn_result;/* Multiple bit may be set  */
+};
+
+extern int (*ltq_mpe_fasthook_free_fn) (struct sk_buff *);
+extern int (*ltq_mpe_fasthook_tx_fn) (struct sk_buff *, u32 , void *);
+extern int (*ltq_mpe_fasthook_rx_fn) (struct sk_buff *, u32 , void *);
+
+#endif				/*MPE_FW_FAST_HOOK_TEST_H */
