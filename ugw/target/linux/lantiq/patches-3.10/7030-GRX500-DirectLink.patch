# HG changeset patch
# Parent 5009e34be290c8e0369b7f9a5249f5154e11a243

diff --git a/drivers/net/ethernet/lantiq/Kconfig b/drivers/net/ethernet/lantiq/Kconfig
--- a/drivers/net/ethernet/lantiq/Kconfig
+++ b/drivers/net/ethernet/lantiq/Kconfig
@@ -18,6 +18,13 @@ config LANTIQ_VRX318
 	---help---
 	Supported VRX318 smartPHY PCIe EP
 
+config ACCL_11AC
+    tristate "Support DirectLink 11AC QCA"
+    depends on LTQ_PPA_GRX500
+    default n
+    ---help---
+    Supported DirectLink for QCA 11AC
+
 config LANITQ_VRX318_PCIE_SWITCH_DSL_BONDING
 	tristate "VRX318 SmartPHY DSL bonding with PCIe Switch"
 	depends on LANTIQ_VRX318
diff --git a/drivers/net/ethernet/lantiq/Makefile b/drivers/net/ethernet/lantiq/Makefile
--- a/drivers/net/ethernet/lantiq/Makefile
+++ b/drivers/net/ethernet/lantiq/Makefile
@@ -7,3 +7,6 @@ obj-$(CONFIG_LTQ_ETH_XRX500) += ltq_eth_
 obj-$(CONFIG_LTQ_TOE_DRIVER) += ltq_toe_drv.o
 obj-$(CONFIG_VRX318_DATAPATH) += vrx318/
 obj-$(CONFIG_LTQ_DIRECTCONNECT_DP) += directconnect_dp/
+ifeq ($(CONFIG_LTQ_PPA_GRX500),y)
+obj-$(CONFIG_ACCL_11AC) += directlink/
+endif
diff --git a/drivers/net/ethernet/lantiq/directlink/Makefile b/drivers/net/ethernet/lantiq/directlink/Makefile
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/Makefile
@@ -0,0 +1,3 @@
+obj-$(CONFIG_ACCL_11AC) += ltqmips_dtlk.o
+
+ltqmips_dtlk-objs = dtlk_main.o dtlk_api.o
diff --git a/drivers/net/ethernet/lantiq/directlink/dtlk_api.c b/drivers/net/ethernet/lantiq/directlink/dtlk_api.c
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/dtlk_api.c
@@ -0,0 +1,2557 @@
+/******************************************************************************
+
+				Copyright (c) 2012, 2014, 2015
+				Lantiq Deutschland GmbH
+
+  For licensing information, see the file 'LICENSE' in the root folder of
+  this software module.
+
+******************************************************************************/
+
+
+
+/*************************************************
+ *	This file provide all the APIs that need export to DLRX_FW or 11AC driver
+ *************************************************/
+
+/*************************************************
+ *			Head File
+ *************************************************/
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/types.h>
+#include <linux/ctype.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <linux/miscdevice.h>
+#include <linux/init.h>
+#include <linux/etherdevice.h>	/*	eth_type_trans	*/
+#include <linux/ethtool.h>		/*	ethtool_cmd 	*/
+#include <linux/if_ether.h>
+#include <linux/if_arp.h>
+#include <asm/uaccess.h>
+#include <asm/unistd.h>
+#include <asm/irq.h>
+#include <asm/delay.h>
+#include <asm/io.h>
+#include <asm/gic.h>
+#include <linux/skbuff.h>
+#include <linux/dma-mapping.h>
+#include <linux/list.h>
+
+#include <net/ppa_ppe_hal.h>
+#include <net/ppa_stack_al.h>
+#include <linux/dma-mapping.h>
+
+/* FW header files */
+#include "./include/11ac_acc_data_structure_tx_be.h"
+#include "./include/dlrx_fw_data_structure_be.h"
+#include "./include/dlrx_fw_def.h"
+#include "./include/dlrx_fw_version.h"
+/*DLRX driver header files */
+#include "./include/dlrx_drv.h"
+#include "./include/dlrx_memory_lyt.h"
+#include "./include/dlrx_dre_api.h"
+#include "./include/dlrx_wlan_api.h"
+
+#include "./include/directlink_tx_cfg.h"
+#include "./include/ltqmips_hal.h"
+#include <net/lantiq_cbm.h>
+#include <net/lantiq_cbm_api.h>
+#include <net/ltq_mpe_api.h>
+#include <net/ppa_stack_al.h>
+#include <net/ppa_api.h>
+#include <net/ppa_api_directpath.h>
+#include <net/ppa_hook.h>
+#include <net/ppa_ppe_hal.h>
+
+#include "../cbm/cbm.h"
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+#include "./include/dltx_fw_data_structure_be.h"
+#include "./include/Dltx_fw_def.h"
+
+#endif
+
+#define dl_kseg0 KSEG0
+#define dl_kseg1 KSEG1
+
+#define RX_NOT_WRITEBACK 1
+#define RX_NOT_SKB 1
+
+/*************************************************
+ *			Definition
+ *************************************************/
+
+/*************************************************
+ *			Global Variable
+ *************************************************/
+uint32_t g_dlrx_max_inv_header_len;
+uint32_t g_dlrx_cfg_offset_atten;
+void *g_dlrx_handle;
+PPA_QCA_DL_RX_CB g_dlrx_qca_cb = {0};
+dre_regfn_set_t g_dre_fnset    = {0};
+spinlock_t g_vap2int_tbl_lock;
+spinlock_t g_prid2pr_tbl_lock;
+spinlock_t g_pr2vap_tbl_lock;
+spinlock_t g_pr2handler_tbl_lock;
+
+extern PPA_SUBIF gQuickRefSubIfFromVAPID[];
+#if 1
+extern struct device *g_mpe_dev;
+#endif
+extern struct dl_buf_info g_dl_buf_info;
+
+LIST_HEAD(g_dlrx_skblist);
+
+#ifdef PROFILING
+extern void *CycleCounter_Create(char *);
+extern void CycleCounter_Start(void *);
+extern void CycleCounter_End(void *);
+void *profiling_alloc;
+void *profiling_enqueue;
+void *profiling_writeback;
+void *profiling_cmb_alloc;
+void *profiling_cmb_enqueue;
+
+void initProfiling()
+{
+	dtlk_debug(DBG_INIT, "%s: Init profiling\n", __func__);
+	profiling_alloc = CycleCounter_Create("Allocation");
+	profiling_enqueue = CycleCounter_Create("Enqueue");
+	profiling_writeback = CycleCounter_Create("Writeback");
+	profiling_cmb_alloc = CycleCounter_Create("CBM Allocation");
+	profiling_cmb_enqueue = CycleCounter_Create("CBM Enqueue");
+}
+#endif
+
+
+int set_peer_id_to_peer_table(
+	uint32_t dlrx_peer_reg_handle,
+	uint32_t peer_id,
+	uint32_t *peer,
+	unsigned int vap_id,
+	unsigned int pn_chk_type
+	);
+int remove_peer_id_from_table(
+	uint32_t peer,
+	uint32_t peer_id
+	);
+int remove_peer_from_table(
+	uint32_t peer,
+	uint32_t peer_id
+	);
+int get_handler_index(
+	uint32_t index
+	);
+int get_free_peer_number(
+	unsigned int *peer
+	);
+#define DL_DIRECT_ENQ_CBM 1
+
+/*************************************************
+ *			Static functions
+ *************************************************/
+/*
+* Function: alloc_skb_tx
+* Purpose: alloc CBM skb buffer
+*/
+extern	void *cbm_buffer_alloc(uint32_t pid, uint32_t flag);
+extern int cbm_buffer_free(uint32_t pid, uint32_t buf, uint32_t flag);
+
+#define RX_RESERVE_BYTES 128
+#define RX_OPTIMIZE 1
+#ifdef DL_DIRECT_ENQ_CBM
+struct sk_buff *my_alloc_skb_head(gfp_t gfp_mask)
+{
+	struct sk_buff *skb;
+
+	/* Get the HEAD */
+	skb = kzalloc(sizeof (struct sk_buff), gfp_mask);
+#ifndef RX_OPTIMIZE
+	if (!skb)
+		goto out;
+
+	/*
+	 * Only clear those fields we need to clear, not those that we will
+	 * actually initialise below. Hence, don't put any more fields after
+	 * the tail pointer in struct sk_buff!
+	 */
+	memset(skb, 0, offsetof(struct sk_buff, tail));
+	skb->head = NULL;
+	skb->truesize = sizeof(struct sk_buff);
+	atomic_set(&skb->users, 1);
+
+#ifdef NET_SKBUFF_DATA_USES_OFFSET
+	skb->mac_header = ~0U;
+#endif
+out:
+#endif
+
+	return skb;
+}
+
+struct sk_buff *dl_cbm_build_skb(void *data, unsigned int frag_size, gfp_t priority)
+{
+	struct sk_buff *skb;
+	unsigned int size;
+	size = frag_size;
+	/*dtlk_debug(DBG_TX, "%s data 0x%x size %d\r\n",__func__, data, frag_size);*/
+	skb = my_alloc_skb_head(GFP_ATOMIC);
+	if (!skb) {
+		dtlk_debug(DBG_ERR, "%s: SKB head alloc failed\r\n", __func__);
+		return NULL;
+	}
+
+	/* size -= SKB_DATA_ALIGN(sizeof(struct skb_shared_info)); */
+#ifndef RX_OPTIMIZE
+	memset(skb, 0, offsetof(struct sk_buff, tail));
+	skb->truesize = SKB_TRUESIZE(size);
+	skb->head_frag = 0;
+	atomic_set(&skb->users, 1);
+#endif
+	skb->head = data;
+	skb->data = data;
+	skb_reset_tail_pointer(skb);
+	skb->end = skb->tail + size;
+#ifndef RX_OPTIMIZE
+#ifdef NET_SKBUFF_DATA_USES_OFFSET
+	skb->mac_header = ~0U;
+	skb->transport_header = ~0U;
+#endif
+#endif
+	return skb;
+}
+void dealloc_skb_tx(struct sk_buff *skb)
+{
+	#ifndef RX_NOT_SKB
+	cbm_buffer_free(smp_processor_id(), (uint32_t)skb->head, 0);
+	#else
+	cbm_buffer_free(smp_processor_id(), (uint32_t)skb, 0);
+	#endif
+	#ifndef RX_NOT_WRITEBACK
+	/* free skb */
+	kfree(skb);
+	#endif
+}
+
+static struct sk_buff *alloc_skb_tx(
+	int len
+	)
+{
+#ifndef RX_NOT_SKB
+	struct sk_buff *skb = NULL;
+#endif
+	#ifndef RX_NOT_WRITEBACK
+	dma_addr_t phy_addr;
+	#endif
+	void *buf = NULL;
+#ifdef PROFILING
+	CycleCounter_Start(profiling_cmb_alloc);
+#endif
+	buf = cbm_buffer_alloc(smp_processor_id(), CBM_PORT_F_STANDARD_BUF);
+#ifdef PROFILING
+	CycleCounter_End(profiling_cmb_alloc);
+#endif
+
+#ifndef RX_NOT_SKB
+	if (buf) {
+		skb = dl_cbm_build_skb((void *)buf,
+			len, GFP_ATOMIC);
+	}
+	if (skb) {
+		skb_reserve(skb, RX_RESERVE_BYTES);
+		*((u32 *)skb->data - 1) = (u32)skb;
+		/* Debug Clear Attention bit. */
+		*((uint32_t *)skb->data + 1) = 0;
+		/* write back to real memory */
+		#ifndef RX_NOT_WRITEBACK
+		phy_addr = dma_map_single(
+			g_mpe_dev,
+			(u32)skb->data - sizeof(u32),
+			sizeof(u32) + 3,
+			DMA_TO_DEVICE
+			);
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "DMA error");
+		}
+		#endif
+	} else {
+		dtlk_debug(DBG_ERR, "%s: cannot create skb\n", __func__);
+		/* cbm_buffer_free(smp_processor_id(),(uint32_t) buf, 0); */
+		dealloc_skb_tx(skb);
+	}
+	return skb;
+#else
+	#if 0 /* 240Jun2015 no need now, for testing */
+	#ifdef PROFILING
+	CycleCounter_Start(profiling_writeback);
+	#endif
+	phy_addr = dma_map_single(
+			g_mpe_dev,
+			buf,
+			2048,
+			DMA_FROM_DEVICE
+			);
+	if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+		dtlk_debug(DBG_ERR, "DMA error");
+	}
+	#ifdef PROFILING
+		CycleCounter_End(profiling_writeback);
+	#endif
+	#endif
+	return buf;
+
+#endif
+}
+#else
+static struct sk_buff *alloc_skb_tx(
+	int len
+	)
+{
+	struct sk_buff *skb = NULL;
+	dma_addr_t phy_addr;
+	void *buf = NULL;
+
+	len = (len + DTLK_ALIGNMENT - 1) & ~(DTLK_ALIGNMENT - 1);
+	len += RX_RESERVE_BYTES;
+
+	skb = dev_alloc_skb(len);
+	if (skb) {
+		skb_reserve(skb, RX_RESERVE_BYTES);
+		ASSERT(((u32)skb->data & (DTLK_ALIGNMENT - 1)) == 0, "skb->data (%#x) is not 8 DWORDS aligned", (u32)skb->data);
+
+		*((u32 *)skb->data - 1) = (u32)skb;
+		/* Debug Clear Attention bit. */
+		*((uint32_t *)skb->data + 1) = 0;
+
+		phy_addr = dma_map_single(
+			g_mpe_dev,
+			(u32)skb->data - sizeof(u32),
+			/* sizeof(u32) + 3, */
+			sizeof(u32) + (skb->end - skb->data),
+			DMA_TO_DEVICE
+			);
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "DMA error");
+		}
+		/*
+		dma_unmap_single(
+			g_mpe_dev,
+			phy_addr,
+			sizeof(u32) + 3,
+			DMA_TO_DEVICE
+			);
+			*/
+	}
+
+	if (skb->prev || skb->next) {
+		dtlk_debug(DBG_ERR, "%s:==============SKB PREV[0x%x] or NEXT[0x%x]============\n", __func__, skb->prev, skb->next);
+	}
+	return skb;
+}
+#endif
+static struct sk_buff *__get_skb_pointer(
+	uint32_t dataptr,
+	const char *func_name,
+	unsigned int line_num
+	)
+{
+	unsigned int skb_dataptr;
+	struct sk_buff *skb;
+
+	if (dataptr == 0) {
+		dtlk_debug(DBG_ERR, "dataptr is 0, it's supposed to be invalid pointer");
+		return NULL;
+	}
+	/* dtlk_debug(DBG_RX, "%s: skb[0x%x]\n", __func__, dataptr); */
+	/* skb_dataptr = KSEG1ADDR(dataptr - 4); */
+	#ifndef RX_NOT_WRITEBACK
+	skb_dataptr = KSEG1 | (0x0fffffff & (dataptr - 4));
+	#else
+	skb_dataptr = KSEG0 | (0x0fffffff & (dataptr - 4));
+	#endif
+	/* skb_dataptr = dataptr - 4; */
+	skb = *(struct sk_buff **)skb_dataptr;
+	if ((uint32_t)skb < KSEG0 || (uint32_t)skb >= KSEG1)
+		dtlk_debug(DBG_ERR, "%s:%d: invalid skb - skb = %#08x, dataptr = %#08x\n",
+			func_name, line_num, (unsigned int)skb, dataptr
+		);
+	return skb;
+}
+
+static inline struct sk_buff *dlrx_get_skb_ptr(
+	unsigned int dataptr
+	)
+{
+	return __get_skb_pointer(dataptr, __FUNCTION__, __LINE__);
+}
+
+/*
+*  Get the DRE FW API pointer
+*/
+static void *dlrx_get_dre_fn(
+	unsigned int fntype
+	)
+{
+	switch (fntype) {
+	case DRE_MAIN_FN:
+		return g_dre_fnset.dre_dl_main_fn;
+	case DRE_GET_VERSION_FN:
+		return g_dre_fnset.dre_dl_getver_fn;
+	case DRE_RESET_FN:
+		return g_dre_fnset.dre_dl_reset_fn;
+	case DRE_GET_MIB_FN:
+		return g_dre_fnset.dre_dl_getmib_fn;
+	case DRE_GET_CURMSDU_FN:
+		return g_dre_fnset.dre_dl_getmsdu_fn;
+	case DRE_SET_MEMBASE_FN:
+		return g_dre_fnset.dre_dl_set_membase_fn;
+	case DRE_SET_RXPN_FN:
+		return g_dre_fnset.dre_dl_set_rxpn_fn;
+	case DRE_SET_DLRX_UNLOAD:
+		return g_dre_fnset.dre_dl_set_dlrx_unload_t;
+	default:
+		return NULL;
+	}
+
+	return NULL;
+
+}
+
+/*
+ *	Extract and Setup the skb structure
+ */
+static struct sk_buff *dlrx_skb_setup(
+	unsigned int rxpb_ptr,
+	unsigned int data_ptr,
+	unsigned int data_len
+	)
+{
+	struct sk_buff *skb;
+#ifndef RX_NOT_SKB
+	skb = dlrx_get_skb_ptr(rxpb_ptr);
+
+	dtlk_debug(DBG_RX, "skb:0x%x, rxpb_ptr:0x%x, data_ptr:0x%x, data_len:0x%x\n",
+		(uint32_t)skb, rxpb_ptr, data_ptr, data_len);
+
+	/* adjust skb */
+	skb->data = (unsigned char *)CACHE_ADDR(data_ptr);
+	skb->len  = data_len;
+	skb->tail = skb->data + data_len;
+#else
+	int header_len = data_ptr - rxpb_ptr;
+	ppa_dl_dre_dma_invalidate(rxpb_ptr , header_len + data_len);
+	skb = alloc_skb(header_len + data_len, GFP_KERNEL);
+	if (skb == NULL) {
+		dtlk_debug(DBG_ERR, "Can not allocate memory for DLRX\n");
+		return NULL;
+	}
+	memcpy(skb_put(skb, header_len + data_len),
+		(void *)rxpb_ptr, header_len + data_len);
+	skb_pull(skb, header_len);
+	/* free old cbm */
+	cbm_buffer_free(smp_processor_id(), rxpb_ptr, 0);
+#endif
+	return skb;
+}
+
+static void dump_skb(
+	struct sk_buff *skb,
+	uint32_t len,
+	char *title
+	)
+{
+	int i;
+
+	if (skb->len < len)
+		len = skb->len;
+
+	if (len > DTLK_PACKET_SIZE) {
+		dtlk_debug(DBG_ERR, "Too big:skb=%08x,skb->data=%08x,skb->len=%d\n",
+			(u32)skb, (u32)skb->data, skb->len);
+		return;
+	}
+
+	dtlk_debug(DBG_RX, "%s\n", title);
+	dtlk_debug(DBG_RX, "skb=0x%x,skb->data=%08X,skb->tail=%08X,skb->len=%d\n",
+		(u32)skb, (u32)skb->data, (u32)skb->tail, (int)skb->len);
+	for (i = 1; i <= len; i++) {
+		if ((i % 16) == 1)
+			dtlk_debug(DBG_RX, "  %4d:", i - 1);
+		dtlk_debug(DBG_RX, " %02X", (int)(*((char *)skb->data + i - 1) & 0xFF));
+		if ((i % 16) == 0)
+			dtlk_debug(DBG_RX, "\n");
+	}
+	if (((i - 1) % 16) != 0)
+		dtlk_debug(DBG_RX, "\n");
+}
+
+#define REP_SKB_NUM 256
+
+void skb_list_replenish(
+	struct list_head *head
+	)
+{
+#ifndef RX_NOT_SKB
+	int i;
+	struct sk_buff *skb;
+	dma_addr_t phy_addr;
+	/* dtlk_debug(DBG_RX, "%s: ===========NEED MORE GAS===========\n", __func__); */
+	for (i = 0; i < REP_SKB_NUM; i++) {
+		/* create new CBM skb */
+		skb = alloc_skb_rx();
+		if (!skb) {
+			dtlk_debug(DBG_ERR, "Alloc SKB fail!!!\n");
+			return;
+		}
+		/* dma_cache_inv((u32)skb->data, skb->end - skb->data); */
+		#if 0
+		phy_addr = dma_map_single(g_mpe_dev,
+					(void *)skb->data,
+					skb->end - skb->data,
+					DMA_FROM_DEVICE
+					);
+		dma_unmap_single(g_mpe_dev,
+			phy_addr,
+			skb->end - skb->data,
+			DMA_FROM_DEVICE
+			);
+		#endif
+		list_add((struct list_head *)skb, head);
+	}
+#endif
+}
+
+unsigned int skb_list_get_skb(
+	unsigned int rxpb_ptr
+	)
+{
+	struct list_head *pos, *q;
+	list_for_each_safe(pos, q, &g_dlrx_skblist) {
+		if (pos) {
+			struct sk_buff *buff = (struct sk_buff *)pos;
+			if (buff != NULL) {
+				if ((unsigned int)(buff->data) == rxpb_ptr) {
+					list_del(pos);
+					return 1;
+				}
+			}
+		}
+	}
+	return 0;
+}
+/*
+* Free all skb buffers in the recycle list
+*/
+void skb_list_exhaust(
+	struct list_head *head
+	)
+{
+	struct list_head *pos, *q;
+	int count = 0;
+	list_for_each_safe(pos, q, head) {
+		list_del(pos);
+		if (pos) {
+			struct sk_buff *buff = (struct sk_buff *)pos;
+			if (buff != NULL) {
+				dtlk_debug(DBG_ERR,
+					"%s: %p shoudl be the same %x\n",
+					__func__, buff, (unsigned int)(*((u32 *)buff->data - 1)));
+				/* free the data */
+				#if 0
+				dev_kfree_skb_any((struct skb_buff *)pos);
+				#else
+				/* cbm_buffer_free(smp_processor_id(), buff->head, 0); */
+				dealloc_skb_tx(buff);
+				#endif
+				count++;
+			}
+		}
+	}
+	dtlk_debug(DBG_RX,
+		"%s: release %d in list\n", __func__, count);
+}
+
+void dlrx_skb_recycle(
+	struct sk_buff *skb
+	)
+{
+	if (unlikely(!skb))
+		return;
+
+	/* TODO: James test DMA */
+	/* dma_cache_inv((u32)skb->data, g_dlrx_max_inv_header_len); */
+	#if 0
+	phy_addr = dma_map_single(g_mpe_dev,
+					(void *)skb->data,
+					g_dlrx_max_inv_header_len,
+					DMA_FROM_DEVICE
+					);
+	dma_unmap_single(g_mpe_dev,
+		phy_addr,
+		g_dlrx_max_inv_header_len,
+		DMA_FROM_DEVICE
+		);
+	#endif
+	list_add((struct list_head *)skb, &g_dlrx_skblist);
+}
+
+/*************************************************
+ *			Global Functions
+ *************************************************/
+struct sk_buff *alloc_skb_rx(void)
+{
+	struct sk_buff *result;
+#ifdef PROFILING
+	CycleCounter_Start(profiling_alloc);
+#endif
+	result = alloc_skb_tx(DTLK_PACKET_SIZE);
+#ifdef PROFILING
+	CycleCounter_End(profiling_alloc);
+#endif
+	return result;
+}
+
+/*
+* This function is called when DTLK driver is unloaded.
+*/
+void dtlk_rx_api_exit(void)
+{
+	skb_list_exhaust(&g_dlrx_skblist);
+	*DLRX_SKB_POOL_CTXT = 0;
+}
+
+void dtlk_rx_api_init(void)
+{
+	spin_lock_init(&g_vap2int_tbl_lock);
+	spin_lock_init(&g_prid2pr_tbl_lock);
+	spin_lock_init(&g_pr2vap_tbl_lock);
+	spin_lock_init(&g_prid2pr_tbl_lock);
+	spin_lock_init(&g_pr2handler_tbl_lock);
+
+	skb_list_replenish(&g_dlrx_skblist);
+	*DLRX_SKB_POOL_CTXT = (unsigned int)&g_dlrx_skblist;
+	return;
+}
+
+/*************************************************
+ *			APIs for DLRX FW
+ *************************************************/
+/*
+ * Function: dlrx_dl_dre_rxpb_buf_alloc
+ * Purpose: Allocate a new rxpb ring pkt buffer for DLRX FW
+ * Return: return skb->data pointer. DLRX FW from this pointer
+ *     can get original skb pointer.
+ */
+unsigned int dlrx_dl_dre_rxpb_buf_alloc(void)
+{
+#ifndef RX_NOT_SKB
+	struct sk_buff *skb;
+
+	if (unlikely(list_empty(&g_dlrx_skblist))) {
+		skb_list_replenish(&g_dlrx_skblist);
+		/* dtlk_debug(DBG_RX, "%s: R\n", __func__ ); */
+	}
+
+
+	skb = (struct sk_buff *)g_dlrx_skblist.next;
+	if (!skb) {
+		dtlk_debug(DBG_ERR, "No resource for RX");
+		return 0;
+	}
+	list_del((struct list_head *)skb);
+	/* dtlk_debug(DBG_RX, "%s: return 0x%x\n", __func__, skb->data); */
+	if (skb->prev || skb->next) {
+		/*
+		dtlk_debug(DBG_RX, "%s: ========SKB[0x%x]==========NEXT[0x%x] PREV[0x%x]=========\n",
+			__func__, skb, skb->next, skb->prev);
+			*/
+		skb->prev = NULL;
+		skb->next = NULL;
+	}
+	return (unsigned int)skb->data;
+#else
+	struct sk_buff *skb;
+
+	skb = alloc_skb_rx();
+	if (!skb) {
+		dtlk_debug(DBG_ERR, "%s:It's realy bad SKB fail!!!\n", __func__);
+		return 0;
+	}
+	return (unsigned int)((unsigned char *)skb + RX_RESERVE_BYTES);
+#endif
+
+}
+EXPORT_SYMBOL(dlrx_dl_dre_rxpb_buf_alloc);
+
+
+/*
+ * Free a  rxpb ring pkt buffer,called by DLRX firmware.
+ */
+int ppa_dl_dre_rxpb_buf_free(
+	unsigned int rxpb_ptr
+	)
+{
+	struct sk_buff *skb;
+
+	/* sanity check */
+	/*
+	dtlk_debug(DBG_RX, "%s: going to free 0x%x\n",
+		__func__,
+		rxpb_ptr
+		); */
+	if (rxpb_ptr < KSEG0) {
+		rxpb_ptr = 	CACHE_ADDR(rxpb_ptr);
+	}
+	if (!rxpb_ptr) {
+		dtlk_debug(DBG_ERR, "%s: rxpb_ptr is NULL\n", __func__);
+		return DTLK_FAILURE;
+	}
+	rxpb_ptr = 	CACHE_ADDR(rxpb_ptr);
+	#ifndef RX_NOT_SKB
+	skb = dlrx_get_skb_ptr(rxpb_ptr);
+	if (!skb) {
+		dtlk_debug(DBG_ERR, "%s: rxpb_ptr[%x] skb is NULL\n", __func__, rxpb_ptr);
+		return DTLK_FAILURE;
+	}
+	#else
+	skb = (struct sk_buff *)rxpb_ptr;
+	#endif
+	/*
+	if (skb_list_get_skb(rxpb_ptr) == 1)
+		dtlk_debug(DBG_ERR, "%s: Inside replenish \n", __func__);
+		*/
+	if (skb) {
+		/* dtlk_debug(DBG_RX, "%s: rxpb[%x] skb[%x] cbm[%x]\n", __func__, rxpb_ptr, skb, skb->head); */
+#ifdef DL_DIRECT_ENQ_CBM
+		/* cbm_buffer_free(smp_processor_id(),skb->head, 0); */
+		/* free the cbm */
+		dealloc_skb_tx(skb);
+#else
+		dev_kfree_skb_any(skb);
+#endif
+	} else
+		dtlk_debug(DBG_ERR, "%s: freed by replenish or invalid\n", __func__);
+
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_dre_rxpb_buf_free);
+
+extern int dtlk_get_subif_from_vap_id(
+	PPA_SUBIF *subIf, int vap_id
+	);
+#ifndef RX_NOT_WRITEBACK
+static uint32_t oldPointer;
+#endif
+#ifdef DL_DIRECT_ENQ_CBM
+struct dma_rx_desc_1 dma_rx_desc_mask1;
+struct dma_rx_desc_3 dma_rx_desc_mask3;
+struct dma_rx_desc_0 dma_tx_desc_mask0;
+struct dma_rx_desc_1 dma_tx_desc_mask1;
+#define MY_SET_PMAC_SUBIF(pmac, subif) do {;\
+	pmac->src_sub_inf_id2 = (subif) & 0xff; \
+	pmac->src_sub_inf_id =  ((subif) >> 8) & 0x1f; } \
+	while (0)
+#define MY_SET_PMAC_PORTMAP(pmac, port_id) do { if (port_id <= 7)\
+			pmac->port_map2 = 1 << (port_id); \
+			else \
+				pmac->port_map = (1 << (port_id-8)); } \
+			while (0)
+
+extern uint8_t get_lookup_qid_via_index(uint32_t index);
+void my_dump_tx_dma_desc(struct dma_tx_desc_0 *desc_0,
+					  struct dma_tx_desc_1 *desc_1,
+					  struct dma_tx_desc_2 *desc_2,
+					  struct dma_tx_desc_3 *desc_3)
+{
+	int lookup;
+
+	if (!desc_0 || !desc_1 || !desc_2 || !desc_3) {
+		dtlk_debug(DBG_ERR, "tx desc_0/1/2/3 NULL\n");
+		return;
+	}
+
+	dtlk_debug(DBG_TX, " DMA Descripotr:D0=0x%08x D1=0x%08x D2=0x%08x D3=0x%08x\n",
+			*(uint32_t *) desc_0, *(uint32_t *) desc_1,
+			*(uint32_t *) desc_2, *(uint32_t *) desc_3);
+	dtlk_debug(DBG_TX,
+		"  DW0:resv0=%d tunnel_id=%02d flow_id=%d eth_type=%d dest_sub_if_id=0x%04x\n",
+	 desc_0->field.resv0, desc_0->field.tunnel_id,
+	 desc_0->field.flow_id, desc_0->field.eth_type,
+	 desc_0->field.dest_sub_if_id);
+	dtlk_debug(DBG_TX,
+	"  DW1:session_id=0x%03x tcp_err=%d nat=%d dec=%d enc=%d mpe2=%d mpe1=%d \n",
+	 desc_1->field.session_id, desc_1->field.tcp_err,
+	 desc_1->field.nat, desc_1->field.dec, desc_1->field.enc,
+	 desc_1->field.mpe2, desc_1->field.mpe1);
+	dtlk_debug(DBG_TX, "  color=%02d ep=%02d resv1=%d classid=%02d\n",
+			desc_1->field.color, desc_1->field.ep, desc_1->field.resv1,
+			desc_1->field.classid);
+	dtlk_debug(DBG_TX, "  DW2:data_ptr=0x%08x\n", desc_2->field.data_ptr);
+	dtlk_debug(DBG_TX, "  DW3:own=%d c=%d sop=%d eop=%d dic=%d pdu_type=%d\n",
+			desc_3->field.own, desc_3->field.c, desc_3->field.sop,
+			desc_3->field.eop, desc_3->field.dic, desc_3->field.pdu_type);
+	dtlk_debug(DBG_TX,
+	"  byte_offset=%d atm_qid=%d mpoa_pt=%d mpoa_mode=%d data_len=% 4d\n",
+	 desc_3->field.byte_offset, desc_3->field.qid,
+	 desc_3->field.mpoa_pt, desc_3->field.mpoa_mode,
+	 desc_3->field.data_len);
+	lookup = ((desc_0->field.flow_id >> 6) << 12) |
+			 ((desc_1->field.dec) << 11) |
+			 ((desc_1->field.enc) << 10) |
+			 ((desc_1->field.mpe2) << 9) |
+			 ((desc_1->field.mpe1) << 8) |
+			 ((desc_1->field.ep) << 4) |
+			 ((desc_1->field.classid) << 0);
+	dtlk_debug(DBG_TX, "  lookup index=0x%x qid=%d\n", lookup,
+			get_lookup_qid_via_index(lookup));
+}
+void my_dump_tx_pmac(struct pmac_tx_hdr *pmac)
+{
+	int i;
+	unsigned char *p = (char *)pmac;
+
+	if (!pmac) {
+		dtlk_debug(DBG_ERR, "dump_tx_pmac pmac NULL ??\n");
+		return ;
+	}
+
+	dtlk_debug(DBG_TX, " PMAC at 0x%p:", p);
+
+	for (i = 0; i < 8; i++)
+		dtlk_debug(DBG_TX, "0x%02x ", p[i]);
+
+	dtlk_debug(DBG_TX, "\n");
+	/*byte 0 */
+	dtlk_debug(DBG_TX, "  byte 0:tcp_chksum=%d res=%d ip_offset=%d\n",
+			pmac->tcp_chksum, pmac->res1, pmac->ip_offset);
+	/*byte 1 */
+	dtlk_debug(DBG_TX, "  byte 1:tcp_h_offset=%d tcp_type=%d\n", pmac->tcp_h_offset,
+			pmac->tcp_type);
+	/*byte 2 */
+	dtlk_debug(DBG_TX, "  byte 2:ppid=%d res=%d\n", pmac->sppid, pmac->res);
+	/*byte 3 */
+	dtlk_debug(DBG_TX,
+	"  byte 3:port_map_en=%d res=%d time_dis=%d class_en=%d res=%d pkt_type=%d\n",
+	 pmac->port_map_en, pmac->res2, pmac->time_dis, pmac->class_en,
+	 pmac->res3, pmac->pkt_type);
+	/*byte 4 */
+	dtlk_debug(DBG_TX,
+	"  byte 4:fcs_ins_dis=%d redirect=%d time_stmp=%d src_sub_inf_id=%d\n",
+	 pmac->fcs_ins_dis, pmac->redirect, pmac->time_stmp,
+	 pmac->src_sub_inf_id);
+	/*byte 5 */
+	dtlk_debug(DBG_TX, "  byte 5:src_sub_inf_id2=%d\n", pmac->src_sub_inf_id2);
+	/*byte 6 */
+	dtlk_debug(DBG_TX, "  byte 6:port_map=%d\n", pmac->port_map);
+	/*byte 7 */
+	dtlk_debug(DBG_TX, "  byte 7:port_map2=%d\n", pmac->port_map2);
+}
+extern void dp_dump_raw_data(char *buf, int len, char *prefix_str);
+
+extern int cbm_setup_desc(struct cbm_desc *desc, uint32_t data_ptr, uint32_t data_len,
+uint32_t DW0, uint32_t DW1);
+extern int cbm_cpu_enqueue(uint32_t pid, struct cbm_desc *desc);
+extern int cbm_cpu_enqueue_dl(uint32_t pid, struct cbm_desc *desc);
+#ifndef RX_NOT_WRITEBACK
+int32_t
+dl_cbm_cpu_pkt_tx(
+	struct sk_buff *skb,
+	int ep,
+	int subif,
+	unsigned int data_ptr,
+	unsigned int pmac_header_ptr,
+	int flags
+	)
+{
+	struct cbm_desc desc;
+	uint32_t tmp_data_ptr;
+	unsigned int txLen = skb->len + 8;
+	unsigned int subIf = (subif << 8);
+	struct pmac_tx_hdr *pmac = NULL;
+	struct dma_tx_desc_0 *desc_0;
+	struct dma_tx_desc_1 *desc_1;
+	struct dma_tx_desc_2 *desc_2;
+	struct dma_tx_desc_3 *desc_3;
+	tmp_data_ptr = pmac_header_ptr;
+	pmac = pmac_header_ptr;
+	memset(pmac, 0, sizeof(struct pmac_tx_hdr));
+
+	desc_0 = (struct dma_tx_desc_0 *)&skb->DW0;
+	desc_1 = (struct dma_tx_desc_1 *)&skb->DW1;
+	desc_2 = (struct dma_tx_desc_2 *)&skb->DW2;
+	desc_3 = (struct dma_tx_desc_3 *)&skb->DW3;
+	/* step1 : set pmac */
+	if (flags == 0) {
+		pmac->port_map_en = 0;
+		pmac->port_map = 0xff;
+		pmac->port_map2 = 0xff;
+		pmac->sppid = ep;
+
+		MY_SET_PMAC_SUBIF(pmac, subIf);
+	} else {
+		pmac->port_map_en = 1;
+		MY_SET_PMAC_PORTMAP(pmac, (ep));
+		pmac->sppid = PMAC_CPU_ID;
+		MY_SET_PMAC_SUBIF(pmac, subIf);
+	}
+	/* step 2: set DMA */
+	/*reset all descriptors as SWAS required since SWAS 3.7 */
+	/*As new SWAS 3.7 required, MPE1/Color/FlowID is set by applications */
+	desc_0->all &=  dma_tx_desc_mask0.all;
+	desc_1->all &=  dma_tx_desc_mask1.all;
+	desc_2->all = 0;
+	desc_3->all = 0;
+
+	desc_1->field.classid = 0;
+	desc_2->field.data_ptr = tmp_data_ptr;
+	if (flags == 0) {
+		desc_1->field.enc = 1;
+		desc_1->field.dec = 1;
+		desc_1->field.mpe2 = 0;
+	} else {
+		desc_1->field.enc = 0;
+		desc_1->field.dec = 0;
+		desc_1->field.mpe2 = 0;
+	}
+	desc_1->field.ep = ep;
+
+	desc_0->all = subIf;
+	/* len */
+	desc_3->field.data_len = txLen;
+	ppa_dl_dre_dma_writeback(pmac, 8);
+	#if 0
+	if (flags) {
+		dtlk_debug(DBG_RX, "==========================Forward==========================");
+		}
+	else
+		dtlk_debug(DBG_RX, "==========================Not Forward==========================");
+	my_dump_tx_dma_desc((struct dma_tx_desc_0 *)&skb->DW0,
+							 (struct dma_tx_desc_1 *)&skb->DW1,
+							 (struct dma_tx_desc_2 *)&skb->DW2,
+							 (struct dma_tx_desc_3 *)&skb->DW3);
+	my_dump_tx_pmac(pmac);
+
+	dp_dump_raw_data(tmp_data_ptr,
+							 (txLen > 256) ? txLen : 256,
+							 "Tx Orig Data");
+
+	#endif
+	if (cbm_setup_desc ((struct cbm_desc *) &desc, tmp_data_ptr,
+			(txLen < (ETH_ZLEN + 8)) ? (ETH_ZLEN + 8) : txLen,
+			skb->DW1, skb->DW0)) {
+		dtlk_debug(DBG_ERR, "cbm setup desc failed..\n");
+		/* cbm_buffer_free(smp_processor_id(), skb->head, 0); */
+		dealloc_skb_tx(skb);
+		/*spin_unlock_irqrestore(&cbm_tx_lock, sys_flag);*/
+		return -1;
+	}
+	if (cbm_cpu_enqueue_dl(smp_processor_id(), &desc) == CBM_FAILURE) {
+		dtlk_debug(DBG_ERR, "cpu enqueue failed..\n");
+		/* cbm_buffer_free(smp_processor_id(), skb->head, 0); */
+		dealloc_skb_tx(skb);
+		return -1;
+	}
+	/* free this skb. */
+	kfree(skb);
+	return 0;
+}
+#else
+
+inline int32_t
+dl_cbm_cpu_pkt_tx_no_skb(
+	int data_len,
+	int ep,
+	int subif,
+	unsigned int rxpb_ptr,
+	unsigned int pmac_header_ptr,
+	int flags
+	)
+{
+	struct cbm_desc desc;
+	uint32_t tmp_data_ptr;
+	unsigned int txLen = data_len + 8;
+	unsigned int subIf = (subif << 8);
+	struct pmac_tx_hdr *pmac = NULL;
+	struct dma_tx_desc_0 desc_0;
+	struct dma_tx_desc_1 desc_1;
+	/* struct dma_tx_desc_2 desc_2; */
+	/* struct dma_tx_desc_3 desc_3; */
+	/*
+	dtlk_debug(DBG_TX, "<%s>: ep[%d] subif[%d] [%x] rxpb_ptr[0x%x] pmac_header_ptr[0x%x]\n",
+	__func__, ep, subif, subIf, rxpb_ptr, pmac_header_ptr);
+	*/
+	/*pmac_header_ptr = (pmac_header_ptr & 0x0fffffff) | KSEG0;*/
+	tmp_data_ptr = pmac_header_ptr;
+	pmac = (struct pmac_tx_hdr *)pmac_header_ptr;
+	memset(pmac, 0, sizeof(struct pmac_tx_hdr));
+	/* step1 : set pmac */
+	if (flags == 0) {
+		/*pmac->port_map_en = 0;*/
+		pmac->port_map = 0xff;
+		pmac->port_map2 = 0xff;
+		pmac->sppid = ep;
+
+		MY_SET_PMAC_SUBIF(pmac, subIf);
+	} else {
+		pmac->port_map_en = 1;
+		MY_SET_PMAC_PORTMAP(pmac, (ep));
+		pmac->sppid = PMAC_CPU_ID;
+		MY_SET_PMAC_SUBIF(pmac, subIf);
+	}
+	/* step 2: set DMA */
+	/*reset all descriptors as SWAS required since SWAS 3.7 */
+	/*As new SWAS 3.7 required, MPE1/Color/FlowID is set by applications */
+	/*desc_0.all &=  dma_tx_desc_mask0.all;*/
+	desc_1.all &=  dma_tx_desc_mask1.all;
+	/* desc_2.all = 0; */
+	/* desc_3.all = 0; */
+
+	/*desc_1.field.classid = 0;*/
+	/*desc_2.field.data_ptr = tmp_data_ptr;*/
+	if (flags == 0) {
+		desc_1.field.enc = 1;
+		desc_1.field.dec = 1;
+		/*desc_1.field.mpe2 = 0;*/
+	} else {
+		/*desc_1.field.enc = 0;*/
+		/*desc_1.field.dec = 0;*/
+		/*desc_1.field.mpe2 = 0;*/
+	}
+	desc_1.field.ep = ep;
+
+	desc_0.all = subIf;
+	/*len*/
+	/*desc_3.field.data_len = txLen;*/
+	/*ppa_dl_dre_dma_writeback(pmac,8);*/
+	/*rxpb_ptr = (rxpb_ptr & 0x0fffffff) | KSEG0;*/
+	/*dtlk_debug(DBG_RX, "%s: writeback rxpb_ptr[%x] pmac[%x] len[%d]\n",
+		__func__,
+		rxpb_ptr,
+		pmac,
+		(pmac_header_ptr - rxpb_ptr) + 8);*/
+	ppa_dl_dre_dma_writeback(rxpb_ptr, (pmac_header_ptr - rxpb_ptr) + 8);
+
+	if (cbm_setup_desc ((struct cbm_desc *) &desc, tmp_data_ptr,
+			(txLen < (ETH_ZLEN + 8)) ? (ETH_ZLEN + 8) : txLen,
+			desc_1.all, desc_0.all)) {
+		dtlk_debug(DBG_ERR, "cbm setup desc failed..\n");
+		/* cbm_buffer_free(smp_processor_id(), skb->head, 0);*/
+		dealloc_skb_tx((struct sk_buff *)rxpb_ptr);
+		/*spin_unlock_irqrestore(&cbm_tx_lock, sys_flag);*/
+		return -1;
+	}
+	#if 0
+	if (cbm_cpu_enqueue_dl(smp_processor_id(), &desc) == CBM_FAILURE) {
+		dtlk_debug(DBG_ERR, "cpu enqueue failed..\n");
+		/*cbm_buffer_free(smp_processor_id(), skb->head, 0);*/
+		dealloc_skb_tx(data_ptr);
+		return -1;
+	}
+	#else
+	if (1) {
+		uint32_t data_pointer, pointer_to_wb;
+		pointer_to_wb = desc.desc2 & 0xfffff800;
+		data_pointer = ((pointer_to_wb & 0x0fffffff) | 0x20000000);
+		data_pointer += desc.desc2 - pointer_to_wb;
+		#if 0
+	if (flags) {
+		dtlk_debug(DBG_TX, "==========================Forward==========================");
+		}
+	else
+		dtlk_debug(DBG_TX, "==========================Not Forward==========================");
+
+	my_dump_tx_dma_desc((struct dma_tx_desc_0 *)&(desc.desc0),
+							 (struct dma_tx_desc_1 *)&(desc.desc1),
+							 (struct dma_tx_desc_2 *)&(desc.desc2),
+							 (struct dma_tx_desc_3 *)&(desc.desc3));
+	my_dump_tx_pmac(pmac);
+/*
+	dp_dump_raw_data(tmp_data_ptr,
+							 (txLen > 256) ? txLen : 256,
+							 "Tx Orig Data");
+	*/
+	#endif
+#ifdef PROFILING
+		CycleCounter_Start(profiling_cmb_enqueue);
+#endif
+		if (cbm_cpu_enqueue_hw(smp_processor_id(),
+			&desc,
+			(void *)data_pointer, 0) ==
+			CBM_FAILURE) {
+			dtlk_debug(DBG_ERR, "cpu enqueue failed..\n");
+			/*cbm_buffer_free(smp_processor_id(), skb->head, 0);*/
+			dealloc_skb_tx((struct sk_buff *)rxpb_ptr);
+			return -1;
+		}
+#ifdef PROFILING
+		CycleCounter_End(profiling_cmb_enqueue);
+#endif
+	}
+	#endif
+	/*free this skb.*/
+	/*kfree(skb);*/
+	return 0;
+}
+
+#endif
+
+#endif
+
+int ppa_dl_dre_gswip_dma_send(
+	unsigned int vap_id,
+	unsigned int rxpb_ptr,
+	unsigned int data_ptr,
+	unsigned int data_len,
+	unsigned int release_flag,
+	unsigned int pmac_hdr_ptr,
+	unsigned int unmap_type
+	)
+{
+#ifndef RX_NOT_WRITEBACK
+	struct sk_buff *skb, *skb2;
+#endif
+	PPA_SUBIF dp_sub_if;
+	struct net_device *dev;
+	int32_t res = 0;
+	uint32_t flags = 0;
+
+	int header_len;
+
+	/*dtlk_debug(DBG_RX, "%s: rxpb_ptr[%x] data_ptr[0x%x]\n",__func__, rxpb_ptr, data_ptr);*/
+#ifdef PROFILING
+	CycleCounter_Start(profiling_enqueue);
+#endif
+	/* get Datapath sub interface for this VAP ID */
+	dp_sub_if = gQuickRefSubIfFromVAPID[vap_id & 0xffff];
+	/* get original skb pointer */
+	#ifndef RX_NOT_WRITEBACK
+	skb = dlrx_get_skb_ptr(rxpb_ptr);
+	/* Fix Klockwork check */
+	if (skb == NULL)
+		return DTLK_FAILURE;
+	if ((uint32_t)skb < KSEG0 || (uint32_t)skb >= KSEG1) {
+		dtlk_debug(DBG_ERR, "%s:invalid skb - skb = %#08x, rxpb_ptr = %#08x\n", __func__,
+			(unsigned int)skb, rxpb_ptr
+		);
+		return DTLK_FAILURE;
+	}
+	#endif
+	/*dtlk_debug(DBG_RX, "%s: release_flag[%d] data_ptr[0x%x]\n",__func__, release_flag, data_ptr);*/
+	/*dev = dtlk_dev_from_vapid((uint32_t)vap_id);*/
+	header_len = data_ptr - rxpb_ptr;
+	/*dtlk_debug(DBG_RX, "%s: header[%d] rxpb_ptr[%x] data_ptr[%x]\n", __func__, header_len,rxpb_ptr , data_ptr);*/
+	if (!release_flag) {
+		#if 0
+		/* do not release the packet
+		*
+		* */
+		unsigned int real_data_ptr = rxpb_ptr + g_dlrx_cfg_offset_atten;
+		unsigned padding = (vap_id >> 16);
+		real_data_ptr = real_data_ptr + padding;
+		ppa_dl_dre_dma_invalidate(rxpb_ptr, header_len + data_len);
+
+		/* Get new CBM skb buffer */
+		skb2 = alloc_skb_rx();
+		if (!skb2) {
+			dtlk_debug(DBG_ERR, "alloc_skb_rx failed");
+			return DTLK_FAILURE;
+		}
+		new_buf = skb2;
+
+		header_len = header_len - padding;
+		/* Copy header and data, don't copy padding */
+		memcpy(new_buf + RX_RESERVE_BYTES, rxpb_ptr, header_len);
+		memcpy(new_buf + RX_RESERVE_BYTES + header_len, data_ptr, data_len);
+		flags = DP_TX_TO_DL_MPEFW;
+		new_data_buf = new_buf + RX_RESERVE_BYTES + header_len;
+		ppa_dl_dre_dma_writeback(new_buf + RX_RESERVE_BYTES, header_len + data_len);
+		dtlk_debug(DBG_RX, "    NOT REL: data 0x%x 0x%x %d %d padding[%d]\n", new_buf + RX_RESERVE_BYTES, rxpb_ptr, header_len, data_len, padding);
+		#else
+
+		#endif
+	}
+	#ifndef RX_NOT_WRITEBACK
+	else {
+		skb2 = skb;
+		/* Fix Klockwork check */
+		if (skb2 == NULL)
+			return DTLK_FAILURE;
+		if (oldPointer == skb2) {
+			dtlk_debug(DBG_ERR, "Oh my, the same pointer with release 1,EXIT\n");
+			return DTLK_FAILURE;
+			}
+		else
+			oldPointer = skb2;
+		if (data_len < 60) {
+			/* dtlk_debug(DBG_ERR, "%s: small packet -> 60\n", __func__); */
+			data_len = 60;
+			}
+		/*dtlk_debug(DBG_RX, "%s: 1 skb2->data[0x%x] data_len[%d]\n",
+			__func__, skb2->data, data_len);*/
+		/*skb2->data_len = data_len;*/
+		#if 0
+		flags = 0;
+		skb2->ip_summed = CHECKSUM_UNNECESSARY;
+		skb2->dev = dev;
+		#endif
+		skb2->data = data_ptr;
+		skb2->tail = data_ptr;
+		skb_put(skb2, data_len);
+		/*16/6/2015: performance here*/
+		/*ppa_dl_dre_dma_invalidate(data_ptr, data_len);*/
+	}
+	#endif
+	vap_id = vap_id & 0xffff;
+	if (!dtlk_get_subif_from_vap_id(&dp_sub_if, vap_id)) {
+		/*dtlk_debug(DBG_RX, "%s: shift skb2->data[0x%x] vap_id[%d]  p[%d] if[%d]\n",
+			__func__, skb2->data,
+			vap_id, dp_sub_if.port_id,
+			dp_sub_if.subif);*/
+		/* Using datapath driver to send packet to switch */
+		/* SET EP */
+#if 0 /*16/6/2015: performance here*/
+		skb2->DW1 = (skb->DW1 & (~0xF00)) |
+			((dp_sub_if.port_id & 0xF) << 8);
+		/* SET SUBIFID */
+		skb2->DW0 = (skb->DW0 & ~0x7FFF) | (dp_sub_if.subif << 8);
+#ifndef CONFIG_MIPS_UNCACHED
+		ppa_dl_dre_dma_writeback((u32)skb2->data, skb2->len);
+#endif
+#endif
+		/*+3 to invalidate attention config change as well.*/
+		/*dma_cache_wback(skb2->data, skb2->len);*/
+		if (release_flag) {
+			/*
+			if (skb2->prev || skb2->next){
+				dtlk_debug(DBG_RX, "%s: skb[0x%x] has next[0x%x] prev[0x%x]\n",
+				__func__, skb2,
+				skb2->next, skb2->prev);
+				skb2->next = 0;
+				skb2->prev = 0;
+				}
+				*/
+#ifndef DL_DIRECT_ENQ_CBM
+			res = ppa_hook_directpath_ex_send_fn(
+				&dp_sub_if,
+				skb2,
+				data_len,
+				0);
+#else
+			/*direct enqueue to CBM buffer*/
+			#ifndef RX_NOT_WRITEBACK
+			if (dl_cbm_cpu_pkt_tx(skb, dp_sub_if.port_id,
+				dp_sub_if.subif,
+				data_ptr,
+				data_ptr - 8,
+				0) == -1) {
+				dtlk_debug(DBG_ERR, "Cannot send to dl_cbm_cpu_pkt_tx");
+				return DTLK_FAILURE;
+			}
+			#else
+			if (dl_cbm_cpu_pkt_tx_no_skb(data_len,
+				dp_sub_if.port_id,
+				dp_sub_if.subif,
+				rxpb_ptr,
+				data_ptr - 8,
+				flags) == -1) {
+				dtlk_debug(DBG_ERR, "Cannot send to dl_cbm_cpu_pkt_tx");
+				return DTLK_FAILURE;
+			}
+			#endif
+#endif
+		} else {
+#if 1
+			/* create new skb data */
+			unsigned char *skb_data;
+			struct sk_buff *skb2;
+			dev = dtlk_dev_from_vapid(vap_id & 0xffff);
+			if (!dev)
+				dtlk_debug(DBG_ERR, "%s: Invalid device for vap id[0x%x]\n", __func__, vap_id);
+			else {
+				skb2 = alloc_skb(data_len, GFP_KERNEL);
+				if (!skb2) {
+					dtlk_debug(DBG_ERR, "alloc_skb_rx failed");
+					return DTLK_FAILURE;
+				}
+				skb_data = skb_put(skb2, data_len);
+				memset(skb_data, 0, data_len);
+				memcpy(skb_data, (void *)data_ptr, data_len);
+				skb2->dev = dev;
+				res = ppa_hook_directpath_ex_send_fn(&dp_sub_if, skb2, data_len, 1);
+			}
+#else
+			/*direct enqueue to CBM buffer*/
+			#ifndef RX_NOT_WRITEBACK
+			if (dl_cbm_cpu_pkt_tx(skb2, dp_sub_if.port_id, dp_sub_if.subif, skb2->data, skb2->data - 8, flags) == -1) {
+				dtlk_debug(DBG_ERR, "Cannot send to dl_cbm_cpu_pkt_tx");
+				return DTLK_FAILURE;
+			}
+			#else
+			if (dl_cbm_cpu_pkt_tx_no_skb(data_len, dp_sub_if.port_id, dp_sub_if.subif, new_buf + RX_RESERVE_BYTES, new_data_buf - 8, flags) == -1) {
+				dtlk_debug(DBG_ERR, "Cannot send to dl_cbm_cpu_pkt_tx");
+				return DTLK_FAILURE;
+			}
+			#endif
+#endif
+		}
+
+		if (res == DP_SUCCESS) {
+		} else {
+			dtlk_debug(DBG_ERR, "Cannot send to Datapath");
+			return DTLK_FAILURE;
+		}
+	} else {
+		dtlk_debug(DBG_ERR, "Cannot get sub interface of VAP[%d]\n", vap_id);
+		return DTLK_FAILURE;
+	}
+#ifdef PROFILING
+	CycleCounter_End(profiling_enqueue);
+#endif
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_dre_gswip_dma_send);
+
+int ppa_dl_dre_ps_send(
+	unsigned int rxpb_ptr,
+	unsigned int data_ptr,
+	unsigned int data_len,
+	unsigned int vap_id
+	)
+{
+	struct sk_buff *skb;
+	struct net_device *dev;
+	skb = dlrx_skb_setup(rxpb_ptr, data_ptr, data_len);
+
+	if (!skb)
+		return DTLK_FAILURE;
+
+	dev = dtlk_dev_from_vapid((uint32_t)vap_id);
+	/* sanity check */
+	if (!dev) {
+		dtlk_debug(DBG_ERR, "No valid device pointer!!!\n");
+		dev_kfree_skb_any(skb);
+		return DTLK_FAILURE;
+	}
+	skb->protocol = eth_type_trans(skb, dev);
+	dtlk_debug(DBG_RX, "%s - skb: 0x%x, dev_name: %s, rxpb_ptr: 0x%x, data_ptr: 0x%x, data_len: 0x%x, vap_id: 0x%x, protocol: %d\n",
+		__func__, (uint32_t)skb, dev->name, rxpb_ptr,
+		(uint32_t)skb->data, skb->len, vap_id, skb->protocol);
+
+	dump_skb(skb, skb->len, "Send To Protocol Stack");
+	if (netif_rx(skb) == NET_RX_DROP) {
+		dtlk_debug(DBG_ERR, "Cannot send to Protocol Stack\n");
+		dev_kfree_skb_any(skb);
+		return DTLK_FAILURE;
+	}
+
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_dre_ps_send);
+
+/*
+ *	DLRX FW send pkt to WLAN driver
+ */
+int ppa_dl_dre_wlan_pkt_send(
+	unsigned int rxpb_ptr,
+	unsigned int data_len,
+	unsigned int pkt_status,
+	unsigned int msg_ptr,
+	unsigned int vap_id,
+	unsigned int flags
+	)
+{
+	struct sk_buff *skb;
+	int ret = DTLK_FAILURE;
+	unsigned padding = (flags >> 16);
+	/* TODO: James add ( 23Jun) */
+	skb = dlrx_skb_setup(rxpb_ptr,
+			rxpb_ptr + padding,
+			data_len + g_dlrx_cfg_offset_atten
+			);
+	/* skb = dlrx_skb_setup(rxpb_ptr, rxpb_ptr, data_len); */
+	if (!skb)
+		return DTLK_FAILURE;
+
+
+#ifndef CONFIG_MIPS_UNCACHED
+	/*dma_cache_inv((u32)skb->data, data_len);*/
+	ppa_dl_dre_dma_invalidate((u32)skb->data, data_len);
+#endif
+	dtlk_debug(DBG_CPU, "%s, rxpb_ptr: 0x%x, data_len: 0x%x, pkt_status: 0x%x, msg_ptr: 0x%x, flags: 0x%x\n",
+		__func__, rxpb_ptr, data_len, pkt_status, msg_ptr, flags);
+	/* QCA will consume the CBM skb */
+	if (likely(g_dlrx_qca_cb.rx_splpkt_fn))
+		ret = g_dlrx_qca_cb.rx_splpkt_fn(g_dlrx_handle,
+				pkt_status,
+				data_len,
+				skb,
+				(uint32_t *)msg_ptr,
+				flags
+				);
+	else {
+		dtlk_debug(DBG_ERR, "No Special PKT fn handler!");
+		dev_kfree_skb_any(skb);
+	}
+	/*
+	   * The QCA does not pass the packet to protocol stack.
+	   * DTLK will create new skb buffer for good packet and send it to protocol stack.
+	   */
+	if (flags) {
+		/* Get the data pointer */
+		unsigned int data_ptr = rxpb_ptr + g_dlrx_cfg_offset_atten;
+		struct net_device *dev;
+		struct sk_buff *skb3 = dev_alloc_skb(data_len + 32);
+
+		data_ptr += padding;
+
+		if (skb3 == NULL)
+			dtlk_debug(DBG_ERR, "%s: Cannot alloc [%d]\n",
+				__func__,
+				data_len + 32);
+		else {
+			dev = dtlk_dev_from_vapid((uint32_t)vap_id);
+			if (dev) {
+				memcpy(skb_put(skb3, data_len), (void *)data_ptr, data_len);
+				skb3->dev = dev;
+				skb3->protocol = eth_type_trans(skb3, dev);
+				skb3->ip_summed = CHECKSUM_UNNECESSARY;
+				if (netif_rx(skb3) != NET_RX_DROP) {
+					dtlk_debug(DBG_CPU, "%s: Send PS successfully\n",
+						__func__);
+				} else {
+					dev_kfree_skb_any(skb3);
+					dtlk_debug(DBG_ERR, "%s: Cannot send to PS\n",
+						__func__);
+				}
+			}
+		}
+	}
+	return ret;
+}
+EXPORT_SYMBOL(ppa_dl_dre_wlan_pkt_send);
+
+/*
+ *	DLRX FW send msg to WLAN driver
+ */
+int ppa_dl_dre_wlan_msg_send(
+	unsigned int msg_type,
+	unsigned int msg_ptr,
+	unsigned int msg_len,
+	unsigned int flags
+	)
+{
+	int ret = DTLK_FAILURE;
+	if (likely(g_dlrx_qca_cb.rx_msg_fn)) {
+		/*
+		dtlk_debug(DBG_CPU, "%s, msg_type: %d, msg_len: %d, msg_ptr: 0x%x, flags: 0x%x\n",
+		__func__, msg_type, msg_len, msg_ptr, flags);
+		*/
+		ret = g_dlrx_qca_cb.rx_msg_fn(g_dlrx_handle,
+				msg_type,
+				msg_len,
+				(uint32_t *)msg_ptr,
+				flags
+				);
+	} else
+		dtlk_debug(DBG_ERR, "No Message fn handler!");
+
+	return ret;
+}
+EXPORT_SYMBOL(ppa_dl_dre_wlan_msg_send);
+
+void ppa_dl_dre_peer_act_fn(unsigned int peer_id)
+{
+	if (g_dlrx_qca_cb.peer_act_fn)
+		g_dlrx_qca_cb.peer_act_fn(g_dlrx_handle, peer_id);
+}
+EXPORT_SYMBOL(ppa_dl_dre_peer_act_fn);
+
+/*
+*  DLRX register function
+*/
+int ppa_dl_dre_fn_register(unsigned int fntype, void *func)
+{
+	switch (fntype) {
+	case DRE_MAIN_FN:
+		g_dre_fnset.dre_dl_main_fn = func;
+		break;
+
+	case DRE_GET_VERSION_FN:
+		g_dre_fnset.dre_dl_getver_fn = func;
+		break;
+
+	case DRE_RESET_FN:
+		g_dre_fnset.dre_dl_reset_fn = func;
+		break;
+
+	case DRE_GET_MIB_FN:
+		g_dre_fnset.dre_dl_getmib_fn = func;
+		break;
+
+	case DRE_GET_CURMSDU_FN:
+		g_dre_fnset.dre_dl_getmsdu_fn = func;
+		break;
+
+	case DRE_SET_MEMBASE_FN:
+		g_dre_fnset.dre_dl_set_membase_fn = func;
+		break;
+
+	case DRE_SET_RXPN_FN:
+		g_dre_fnset.dre_dl_set_rxpn_fn = func;
+		break;
+
+	case DRE_SET_DLRX_UNLOAD:
+		g_dre_fnset.dre_dl_set_dlrx_unload_t = func;
+		break;
+	case DRE_MAX_FN:
+	default:
+		dtlk_debug(DBG_ERR, "Register NO is Not valid:%d", fntype);
+		return DTLK_FAILURE;
+	}
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_dre_fn_register);
+
+/*
+ * Get Peer value from PeerID
+ * Return Peer Valid
+ */
+int ppa_dl_dre_peer_from_peerid(
+	unsigned int peerid,
+	unsigned int *peer
+	)
+{
+	volatile unsigned int *pid2p_tbl = DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(0);
+	unsigned int idx = peerid >> 2;
+	unsigned int offset = peerid % 4;
+	unsigned int peer_val;
+	int result;
+
+	if (peerid >= MAX_PEERID_NUM)
+		return PEER_INVALID;
+
+	spin_lock_bh(&g_prid2pr_tbl_lock);
+	peer_val = *(pid2p_tbl + idx);
+	spin_unlock_bh(&g_prid2pr_tbl_lock);
+
+	peer_val = (peer_val >> (offset << 3));
+	*peer = peer_val & 0x7F;
+	result = ((peer_val >> 7) & 0x1);
+	return result;
+}
+EXPORT_SYMBOL(ppa_dl_dre_peer_from_peerid);
+
+extern void mpe_hal_dl_enable_gic(int irq_no);
+
+void ppa_dl_qca_ipi_interrupt(void)
+{
+#if 0
+	dtlk_debug(DBG_TX, "%s:ipi irq [%d]\n", __func__, g_dl_buf_info.DlCommmIpi);
+	if (gTestIPI == 0)
+		mpe_hal_dl_enable_gic(g_dl_buf_info.DlCommmIpi);
+	else {
+		dtlk_debug(DBG_TX, "%s:Test disable ipi irq [%d]\n", __func__, g_dl_buf_info.DlCommmIpi);
+	}
+#else
+	/*dtlk_debug(DBG_TX, "%s:ipi irq [%d]\n", __func__, g_dl_buf_info.DlCommmIpi);*/
+	mpe_hal_dl_enable_gic(g_dl_buf_info.DlCommmIpi);
+#endif
+}
+EXPORT_SYMBOL(ppa_dl_qca_ipi_interrupt);
+
+int32_t ppa_dl_qca_clear_stats(
+	uint32_t vapId,
+	uint32_t flags
+	)
+{
+	dre_dl_reset_fn_t dre_dl_reset_fn;
+	dre_dl_reset_fn = dlrx_get_dre_fn(DRE_RESET_FN);
+	return DTLK_FAILURE;
+}
+EXPORT_SYMBOL(ppa_dl_qca_clear_stats);
+
+/*
+ * Set VAP info
+ * Return -1 if peer or vapid out of range
+ */
+int ppa_dl_dre_vapinfo_set(
+	unsigned int peer,
+	unsigned int vapid,
+	unsigned int sec_type,
+	unsigned int acc_dis
+	)
+{
+	volatile unsigned int *vapinfo_tbl = DLRX_CFG_PEER_TO_VAP_PN_BASE(0);
+	unsigned int vapinfo;
+
+	if (vapid >= MAX_VAP_NUM || peer >= MAX_PEER_NUM)
+		return DTLK_FAILURE;
+
+	vapinfo = ((acc_dis & 0x1) << 6) |
+				((sec_type & 0x3) << 4) |
+				(vapid & 0xF);
+	spin_lock_bh(&g_pr2vap_tbl_lock);
+	*(vapinfo_tbl + peer) = vapinfo;
+	spin_unlock_bh(&g_pr2vap_tbl_lock);
+
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_dre_vapinfo_set);
+
+
+/*
+ *	Get VAP info from Peer
+ *	Return -1 if peer or vap id out of range
+ */
+int ppa_dl_dre_vapinfo_from_peer(
+	unsigned int peer,
+	unsigned int *vapid,
+	unsigned int *sec_type,
+	unsigned int *acc_dis
+	)
+{
+	volatile unsigned int *vapinfo_tbl = DLRX_CFG_PEER_TO_VAP_PN_BASE(0);
+	unsigned int vapinfo;
+
+	if (peer >= MAX_PEER_NUM)
+		return DTLK_FAILURE;
+
+	spin_lock_bh(&g_pr2vap_tbl_lock);
+	vapinfo = *(vapinfo_tbl + peer);
+	spin_unlock_bh(&g_pr2vap_tbl_lock);
+
+	*vapid	  = vapinfo & 0xf;
+	*sec_type = (vapinfo >> 4) & 0x3;
+	*acc_dis  = (vapinfo >> 6) & 0x1;
+
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_dre_vapinfo_from_peer);
+
+/*
+ * Get interface id from VAP id
+ */
+unsigned int ppa_dl_dre_itf_from_vapid(
+	unsigned int vap_id
+	)
+{
+	volatile unsigned int *itf_tbl;
+	volatile unsigned int itf_id;
+
+	if (vap_id >= MAX_VAP_NUM)
+		return DTLK_INVALID_ITFID;
+	/* Range is defined in the spec */
+	if (vap_id <= 7)
+		itf_tbl = DLRX_CFG_VAP2INT_MAP1_BASE;
+	else
+		itf_tbl = DLRX_CFG_VAP2INT_MAP2_BASE;
+
+	vap_id = vap_id % 8;
+	spin_lock_bh(&g_vap2int_tbl_lock);
+	itf_id = (*itf_tbl >> (vap_id<<2)) & 0xF;
+	spin_unlock_bh(&g_vap2int_tbl_lock);
+
+	return itf_id;
+
+}
+EXPORT_SYMBOL(ppa_dl_dre_itf_from_vapid);
+
+
+
+/*************************************************
+ *			APIs for 11AC Driver
+ *************************************************/
+void ppa_dl_qca_register(
+	void *dl_rx_handle,
+	PPA_QCA_DL_RX_CB *dl_qca_rxcb,
+	uint32_t flags
+	)
+{
+	ASSERT((dl_rx_handle != NULL && dl_qca_rxcb != NULL),
+		"dl_rx_handle or dl_qca_rxcb is NULL");
+	ASSERT((flags == PPA_F_REGISTER) || (flags == PPA_F_DEREGISTER),
+		"flag is not expected: %d\n",
+		flags);
+	dtlk_debug(DBG_INIT, "%s, dl_rx_handle: 0x%x, dl_qca_rxcb: 0x%x, flags: 0x%d\n",
+		__func__, (uint32_t)dl_rx_handle, (uint32_t)dl_qca_rxcb, flags);
+	g_dlrx_handle = dl_rx_handle;
+	/* Fix Klockwork's check */
+	if (dl_qca_rxcb == NULL)
+		return;
+	switch (flags) {
+	case PPA_F_REGISTER:
+		{
+		dre_dl_set_dlrx_unload_t dre_dl_set_dlrx_unload_fn;
+		dre_dl_set_dlrx_unload_fn =
+			g_dre_fnset.dre_dl_set_dlrx_unload_t;
+		ASSERT((dl_rx_handle != NULL &&  dl_qca_rxcb != NULL),
+			"dl_rx_handle or dl_qca_rxcb is NULL");
+		g_dlrx_handle = dl_rx_handle;
+		g_dlrx_qca_cb.rx_msg_fn	=
+			dl_qca_rxcb->rx_msg_fn;
+		g_dlrx_qca_cb.rx_splpkt_fn =
+			dl_qca_rxcb->rx_splpkt_fn;
+		g_dlrx_qca_cb.vap_stats_fn =
+			dl_qca_rxcb->vap_stats_fn;
+		g_dlrx_qca_cb.peer_act_fn =
+			dl_qca_rxcb->peer_act_fn;
+		}
+		break;
+	case PPA_F_DEREGISTER:
+		{
+			dre_dl_set_dlrx_unload_t dre_dl_set_dlrx_unload_fn;
+			dtlk_debug(DBG_INIT, "%s: deregister from QCA\n",
+				__func__);
+			dre_dl_set_dlrx_unload_fn =
+				g_dre_fnset.dre_dl_set_dlrx_unload_t;
+			/* we stop dlrx firmware here */
+			if (likely(dre_dl_set_dlrx_unload_fn)) {
+				dtlk_debug(DBG_INIT, "%s: inform DRE to stop\n",
+					__func__);
+				dre_dl_set_dlrx_unload_fn();
+			}
+		}
+		break;
+	default:
+		break;
+	}
+	return;
+}
+EXPORT_SYMBOL(ppa_dl_qca_register);
+
+/*
+* These functions need to merge with DL TX
+* QCA Name: "QCA-11AC"
+*/
+void ppa_directlink_manage(
+	char *name,
+	uint32_t flags
+	)
+{
+	/* Update the global structure cfg_global */
+	dlrx_cfg_global_t *dlrx_global =
+		(dlrx_cfg_global_t *)DLRX_CFG_GLOBAL_BASE;
+
+	if (flags == PPA_F_INIT) {
+		dlrx_global->dlrx_enable = TRUE;
+		dlrx_global->dltx_enable = TRUE;
+	} else if (flags == PPA_F_UNINIT) {
+		dlrx_global->dlrx_enable = FALSE;
+		dlrx_global->dltx_enable = FALSE;
+	}
+
+	/* ppa_directlink_enable(flags); */
+
+	return;
+}
+EXPORT_SYMBOL(ppa_directlink_manage);
+#ifdef SUPPORT_11AC_MULTICARD
+
+/*API to get 11AC wireless card type */
+extern int ppa_dl_detect_11ac_card(void);
+#endif
+
+/*
+* This function initializes Target-to-Host (t2h) CE-5 Destination Ring
+* in Direct Link between Target WLAN and PPE.
+*/
+void ppa_dl_qca_t2h_ring_init(
+	uint32_t *t2h_ring_sz,
+	uint32_t *dst_ring_base,
+	uint32_t pcie_baddr,
+	uint32_t flags
+	)
+{
+	dre_dl_set_membase_fn_t  dre_dl_set_mb_fn;
+	volatile dlrx_cfg_ctxt_ce5des_t *dlrx_cfg_ctxt_ce5des_ptr;
+	volatile dlrx_cfg_ctxt_ce5buf_t *dlrx_cfg_ctxt_ce5buf_ptr;
+	dlrx_cfg_global_t *dlrx_cfg_global_ptr;
+
+	dtlk_debug(DBG_INIT, "%s:ddr base:0x%08x,cfg_ctxt_base:0x%x,pcie base:0x%08x\n",
+		 __func__,
+		 (uint32_t)ddr_base,
+		 (uint32_t)cfg_ctxt_base,
+		 (uint32_t)pcie_baddr
+		 );
+
+	/* pcie_base = (unsigned int *)KSEG1ADDR(pcie_baddr); */
+	pcie_base = (unsigned int *)(0xF0000000 | pcie_baddr);
+	dtlk_debug(DBG_INIT, "pcie base(virtual): 0x%x\n", (unsigned int)pcie_base);
+	dtlk_debug(DBG_INIT, "pcie base(virtual): 0x%p\n", (unsigned int *)KSEG1ADDR(pcie_baddr));
+	dlrx_cfg_global_ptr = (dlrx_cfg_global_t *)DLRX_CFG_GLOBAL_BASE;
+	dlrx_cfg_global_ptr->dlrx_pcie_base = (unsigned int)pcie_base;
+
+	dlrx_cfg_ctxt_ce5des_ptr =
+		(dlrx_cfg_ctxt_ce5des_t *)DLRX_CFG_CTXT_CE5DES_BASE;
+	#if 1
+	*dst_ring_base = dma_map_single(
+				g_mpe_dev,
+				(void *)dlrx_cfg_ctxt_ce5des_ptr->cfg_badr_ce5des,
+				512 * 2 * 4,
+				DMA_FROM_DEVICE
+				);
+	if (unlikely(dma_mapping_error(g_mpe_dev, (u64)*dst_ring_base))) {
+		dtlk_debug(DBG_ERR, "DMA error");
+	}
+	/*
+			dma_unmap_single(
+				g_mpe_dev,
+				*dst_ring_base,
+				4,
+				DMA_FROM_DEVICE
+				);
+				*/
+	#else
+	*dst_ring_base = MY_CPHYSADDR(dlrx_cfg_ctxt_ce5des_ptr->cfg_badr_ce5des);
+	#endif
+	*t2h_ring_sz = dlrx_cfg_ctxt_ce5des_ptr->cfg_num_ce5des;
+	dtlk_debug(DBG_INIT, "dst_ring_base: 0x%x\n", *dst_ring_base);
+	dtlk_debug(DBG_INIT, "t2h_ring_sz: 0x%x\n", *t2h_ring_sz);
+
+	/*
+	QCA will update the HW register
+	*DLRX_TARGET_CE5_READ_INDEX  = 0;
+	*DLRX_TARGET_CE5_WRITE_INDEX = dlrx_cfg_ctxt_ce5buf_ptr->cfg_num_ce5buf - 1;
+	*/
+	dlrx_cfg_ctxt_ce5buf_ptr =
+		(dlrx_cfg_ctxt_ce5buf_t *)DLRX_CFG_CTXT_CE5BUF_BASE;
+#ifdef SUPPORT_11AC_MULTICARD
+	if (ppa_dl_detect_11ac_card() == PEREGRINE_BOARD) {
+		dtlk_debug(DBG_INIT, "%s: PEREGRINE_BOARD\n", __func__);
+		dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_target_ce5_read_index =
+			(unsigned int)DLRX_TARGET_CE5_READ_INDEX(DLRX_TARGET_CE5_PEREGRINE);
+		dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_target_ce5_write_index =
+			(unsigned int)DLRX_TARGET_CE5_WRITE_INDEX(DLRX_TARGET_CE5_PEREGRINE);
+	} else {
+		dtlk_debug(DBG_INIT, "%s: BEELINER_BOARD\n", __func__);
+		dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_target_ce5_read_index =
+			(unsigned int)DLRX_TARGET_CE5_READ_INDEX(DLRX_TARGET_CE5_BEELINER);
+		dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_target_ce5_write_index =
+			(unsigned int)DLRX_TARGET_CE5_WRITE_INDEX(DLRX_TARGET_CE5_BEELINER);
+	}
+	dtlk_debug(DBG_INIT, "%s: ce5 read 0x%x\n",
+		__func__,
+		dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_target_ce5_read_index);
+	dtlk_debug(DBG_INIT, "%s: ce5 write 0x%x\n",
+		__func__,
+		dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_target_ce5_write_index);
+#else
+	dtlk_debug(DBG_ERR, "%s: why come here\n", __func__);
+	dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_target_ce5_read_index =
+		(unsigned int)DLRX_TARGET_CE5_READ_INDEX(DLRX_TARGET_CE5_PEREGRINE);
+	dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_target_ce5_write_index =
+		(unsigned int)DLRX_TARGET_CE5_WRITE_INDEX(DLRX_TARGET_CE5_PEREGRINE);
+#endif
+
+	dre_dl_set_mb_fn = dlrx_get_dre_fn(DRE_SET_MEMBASE_FN);
+	if (dre_dl_set_mb_fn) {
+		dre_dl_set_mb_fn((unsigned int)ddr_base,
+			(unsigned int)cfg_ctxt_base,
+			(unsigned int)pcie_base
+			);
+	} else
+		dtlk_debug(DBG_ERR, "Not register function: set membase!!!");
+
+	return;
+}
+EXPORT_SYMBOL(ppa_dl_qca_t2h_ring_init);
+
+
+/*
+* This function gets called from QCA driver
+* to initialize or free the Rx packet buffers pool.
+*/
+void ppa_dl_qca_t2h_pktbuf_pool_manage(
+	uint32_t *alloc_idx_ptr,
+	uint32_t *t2h_rxpb_ring_sz,
+	uint32_t *rxpb_ring_base,
+	uint32_t flags
+	)
+{
+	volatile dlrx_cfg_ctxt_rxpb_ptr_ring_t *dlrx_cfg_rxpb_ring;
+	dlrx_cfg_rxpb_ring =
+		(dlrx_cfg_ctxt_rxpb_ptr_ring_t *)DLRX_CFG_CTXT_RXPB_PTR_RING_BASE;
+
+	if (flags == PPA_F_INIT) {
+		/*dlrx_cfg_rxpb_ring->_dw_res0[1] = 255;*/
+		/*RX_PKT_BUF_PTR_RING_ALLOC_NUM;, my test only*/
+		/*dlrx_cfg_rxpb_ring->rxpb_ptr_write_index = 2;*/
+		/*dlrx_cfg_rxpb_ring->rxpb_ptr_write_index =
+			dlrx_cfg_rxpb_ring->rxpb_ptr_write_index - 1;*/
+		#if 1
+		/*my test only, system crash with + 1*/
+		*alloc_idx_ptr =
+			(uint32_t)((unsigned int)&dlrx_cfg_rxpb_ring->rxpb_ptr_write_index | 0x20000000);
+			/* (uint32_t)(&dlrx_cfg_rxpb_ring->rxpb_ptr_write_index); */
+			/*(uint32_t)(&dlrx_cfg_rxpb_ring->_dw_res0[1]);*/
+		#else
+		*(uint32_t *)g_dl_buf_info.uncached_addr_base =
+			dlrx_cfg_rxpb_ring->rxpb_ptr_write_index + 1;
+		/*my test only, system crash with + 1*/
+		*alloc_idx_ptr =
+			(uint32_t)(g_dl_buf_info.uncached_addr_base);
+		#endif
+		*t2h_rxpb_ring_sz =
+			dlrx_cfg_rxpb_ring->cfg_num_rxpb_ptr_ring;
+		#if 0
+		*rxpb_ring_base =
+			CPHYSADDR(dlrx_cfg_rxpb_ring->cfg_badr_rxpb_ptr_ring);
+		#else
+		#if 1
+		*rxpb_ring_base = dma_map_single(
+				g_mpe_dev,
+				(void *)dlrx_cfg_rxpb_ring->cfg_badr_rxpb_ptr_ring,
+				4096 * 4,
+				DMA_FROM_DEVICE
+				);
+		if (unlikely(dma_mapping_error(g_mpe_dev, (u64)*rxpb_ring_base))) {
+			dtlk_debug(DBG_ERR, "DMA error");
+		}
+		/*
+			dma_unmap_single(
+				g_mpe_dev,
+				*rxpb_ring_base,
+				4,
+				DMA_FROM_DEVICE
+				); */
+		#else
+		*rxpb_ring_base = CPHYSADDR(dlrx_cfg_rxpb_ring->cfg_badr_rxpb_ptr_ring);
+		#endif
+		#endif
+		dtlk_debug(DBG_INIT, "%s: return to QCA:\n   alloc_idx_ptr[%x]\n   t2h_rxpb_ring_sz[%d]   rxpb_ring_base[0x%x]\n",
+			__func__,
+			*alloc_idx_ptr,
+			*t2h_rxpb_ring_sz,
+			*rxpb_ring_base);
+	}
+
+	return;
+}
+EXPORT_SYMBOL(ppa_dl_qca_t2h_pktbuf_pool_manage);
+
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+
+extern int dl_m2c_add_peer(
+	uint32_t *dlrx_peer_reg_handle,
+	uint16_t peer_id,
+	uint16_t vap_id
+	);
+extern int dl_m2c_remove_peer(
+	uint32_t *dlrx_peer_reg_handle,
+	uint16_t peer_id,
+	uint16_t vap_id
+	);
+#endif /* SUPPORT_MULTICAST_TO_UNICAST */
+
+
+/*
+* This hook function is invoked by QCA WLAN
+* Driver for addition or deletion of peer.
+*/
+int32_t ppa_dl_qca_set_peer_cfg(
+	uint32_t *dlrx_peer_reg_handle,
+	uint16_t peer_id,
+	uint16_t vap_id,
+	PPA_WLAN_PN_CHECK_Type_t pn_chk_type,
+	uint32_t *rxpn,
+	uint32_t flags
+	#ifdef SUPPORT_MULTICAST_TO_UNICAST
+	, uint8_t *mac_addr
+	#endif
+	)
+{
+	/* Each Peer_id can have 8 peer values */
+	unsigned int peer;
+	unsigned int temp_acc_dis;
+	unsigned int temp_vap_id;
+	unsigned int temp_sec_type;
+	dre_dl_set_rxpn_fn_t dre_dl_set_rxpn_fn;
+	struct _dl_peer_mac_mapping_table dl_peer_mac_mapping;
+	char *temp, *tempDL;
+
+	dtlk_debug(DBG_RX, "peer handler: 0x%x, peer id: %d, flags: %d\n",
+		(unsigned int)dlrx_peer_reg_handle,
+		peer_id,
+		flags
+		);
+	#ifdef SUPPORT_MULTICAST_TO_UNICAST
+	temp = mac_addr;
+	#else
+	temp = (char *)(dlrx_peer_reg_handle + 6);
+	#endif
+	tempDL = (char *)&dl_peer_mac_mapping + 2;
+	memcpy((char *)tempDL, temp, 6);
+	dl_peer_mac_mapping.valid = 1;
+	dl_peer_mac_mapping.vap_id = vap_id;
+	printk("%s: %d %x:%x:%x:%x:%x:%x\n", __func__,
+		dl_peer_mac_mapping.vap_id,
+		dl_peer_mac_mapping.mac5,
+		dl_peer_mac_mapping.mac4,
+		dl_peer_mac_mapping.mac3,
+		dl_peer_mac_mapping.mac2,
+		dl_peer_mac_mapping.mac1,
+		dl_peer_mac_mapping.mac0
+		);
+	switch (flags) {
+	case PPA_WLAN_ADD_PEER_ID:
+		/* Set peer ID to peer */
+		if (vap_id >= MAX_VAP_NUM)
+			return DTLK_FAILURE;
+
+		if (set_peer_id_to_peer_table(
+				(uint32_t)dlrx_peer_reg_handle,
+				peer_id,
+				&peer,
+				(unsigned int)vap_id,
+				(unsigned int)pn_chk_type
+				) != DTLK_SUCCESS)
+			return DTLK_FAILURE;
+
+		dtlk_debug(DBG_ERR, "peer: %d, peer_id: %d, vap_id %d, pn_chk_type: %d\n",
+			peer,
+			peer_id, vap_id, pn_chk_type);
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+		dl_m2c_add_peer((unsigned int *)mac_addr, peer, vap_id);
+#endif /* SUPPORT_MULTICAST_TO_UNICAST */
+
+	break;
+
+	case PPA_WLAN_REMOVE_PEER:/* FOR DELETE PEER */
+		if (remove_peer_from_table(
+				(uint32_t)dlrx_peer_reg_handle,
+				(uint32_t)peer_id) != DTLK_SUCCESS)
+			return DTLK_FAILURE;
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+		dtlk_debug(DBG_ERR, "remove peer: peer_id: %d, vap_id %d\n",
+			peer_id, vap_id);
+		dl_m2c_remove_peer((unsigned int *)mac_addr,
+			peer_id + 1, vap_id);
+#endif /* SUPPORT_MULTICAST_TO_UNICAST */
+	break;
+
+	case PPA_WLAN_REMOVE_PEER_ID:/* For Delete PEER_ID */
+		dtlk_debug(DBG_ERR, "remove peer_id: peer_id: %d, vap_id %d\n",
+			peer_id, vap_id);
+		if (remove_peer_id_from_table(
+			(uint32_t)dlrx_peer_reg_handle,
+			(uint32_t)peer_id) != DTLK_SUCCESS)
+			return DTLK_FAILURE;
+	break;
+
+	case PPA_WLAN_SET_PN_CHECK:/* To Update PN SEC TYPE */
+		peer = get_handler_index(
+			(uint32_t)dlrx_peer_reg_handle
+			);
+		if (peer == HANDLER_NOT_FOUND)
+			return DTLK_FAILURE;
+
+		ppa_dl_dre_vapinfo_from_peer(
+			peer,
+			&temp_vap_id,
+			&temp_sec_type,
+			&temp_acc_dis
+			);
+		if (ppa_dl_dre_vapinfo_set(
+				peer,
+				temp_vap_id,
+				(unsigned int)pn_chk_type,
+				temp_acc_dis) == DTLK_SUCCESS) {
+			/*
+			* Peer may still store old information
+			* from previous connection.
+			* Reset Peer information as well as PNs value.
+			*/
+			dlrx_ro_mainlist_t *dlrx_ro_mainlist_ptr;
+			int seqid = 0;
+			int tid = 0;
+			dlrx_ro_mainlist_ptr =
+				(dlrx_ro_mainlist_t *)DLRX_DDR_RO_MAINLIST_BASE;
+			dlrx_ro_mainlist_ptr += (peer*NUM_TID);
+			for (tid = 0; tid < NUM_TID; tid++) {
+				dlrx_ro_mainlist_ptr->last_pn_dw0 = 0;
+				dlrx_ro_mainlist_ptr->last_pn_dw1 = 0;
+				dlrx_ro_mainlist_ptr->last_pn_dw2 = 0;
+				dlrx_ro_mainlist_ptr->last_pn_dw3 = 0;
+				dlrx_ro_mainlist_ptr->first_ptr = NULL_PTR;
+				for (seqid = 1; seqid < 64; seqid++)
+					dlrx_ro_mainlist_ptr->_dw_res0[seqid-1] = NULL_PTR;
+				dlrx_ro_mainlist_ptr++;
+			}
+		}
+		dtlk_debug(DBG_RX, "peer:%d,peer_id:%d,vap_id:%d,sec_type:%d,acc_dis:%d\n",
+			peer,
+			peer_id,
+			temp_vap_id,
+			pn_chk_type,
+			temp_acc_dis
+			);
+	break;
+
+	case PPA_WLAN_SET_PN_CHECK_WITH_RXPN:
+		peer = get_handler_index(
+			(uint32_t)dlrx_peer_reg_handle
+			);
+		if (peer == HANDLER_NOT_FOUND) {
+			dtlk_debug(DBG_ERR, "Invalid peer");
+			return DTLK_FAILURE;
+		}
+		ppa_dl_dre_vapinfo_from_peer(
+			peer,
+			&temp_vap_id,
+			&temp_sec_type,
+			&temp_acc_dis
+			);
+		ppa_dl_dre_vapinfo_set(
+			peer,
+			temp_vap_id,
+			(unsigned int)pn_chk_type,
+			temp_acc_dis
+			);
+		dtlk_debug(DBG_RX, "SET PN:peer:%d,peer_id:%d,vap_id:%d,sec_type:%d,acc_dis:%d,rxpn:0x%x\n",
+			peer,
+			peer_id,
+			temp_vap_id,
+			pn_chk_type,
+			temp_acc_dis,
+			(uint32_t)rxpn
+			);
+		dre_dl_set_rxpn_fn = dlrx_get_dre_fn(DRE_SET_RXPN_FN);
+		if (likely(dre_dl_set_rxpn_fn))
+			dre_dl_set_rxpn_fn(peer, rxpn);
+		else
+			dtlk_debug(DBG_ERR, "Function set_rxpn is not registered!");
+
+	break;
+	}
+
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_qca_set_peer_cfg);
+
+int set_peer_id_to_peer_table(
+	uint32_t dlrx_peer_reg_handle,
+	uint32_t peer_id,
+	uint32_t *peer,
+	unsigned int vap_id,
+	unsigned int pn_chk_type
+	)
+{
+	unsigned int vld;
+	unsigned int peer_val;
+	unsigned int peer_index;
+	unsigned int peer_offset;
+	unsigned int mask_value;
+	unsigned int peerinfo;
+	unsigned int temp_peerinfo;
+	int handler_index;
+	volatile unsigned int *pid2p_tbl =
+		DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(0);
+	volatile dlrx_cfg_ctxt_peer_handler_t *peer_handler_tbl = NULL;
+
+	handler_index = get_handler_index(dlrx_peer_reg_handle);
+	dtlk_debug(DBG_RX,
+		"%s: peer: %d, peer_id:%d\n",
+		__func__,
+		handler_index,
+		peer_id
+		);
+
+	if (handler_index == HANDLER_NOT_FOUND) {
+		if (get_free_peer_number(&peer_val) == DTLK_FAILURE)
+			return DTLK_FAILURE;
+
+		/* Get the handler index address by using the base address */
+		peer_handler_tbl =
+			(dlrx_cfg_ctxt_peer_handler_t *)DLRX_CFG_CTXT_PEER_HANDLER_BASE(peer_val);
+		/* Send the handler table data */
+		peer_handler_tbl->cfg_peer_count++;
+		peer_handler_tbl->cfg_peer_handler = dlrx_peer_reg_handle;
+	} else {
+		/* Get the handler index address by using the base address */
+		peer_handler_tbl =
+			(dlrx_cfg_ctxt_peer_handler_t *)DLRX_CFG_CTXT_PEER_HANDLER_BASE(handler_index);
+		peer_handler_tbl->cfg_peer_count++;
+		peer_val = (unsigned int)handler_index;
+	}
+
+	ppa_dl_dre_vapinfo_set(peer_val, vap_id, pn_chk_type, 0);
+
+	vld = VALID;
+	peerinfo = ((vld << 7) | (peer_val & 0x7F));
+
+	peer_index = peer_id >> 2;
+	peer_offset = peer_id % 4;
+
+	mask_value = ~(0xFF << (peer_offset * 8));
+
+	spin_lock_bh(&g_prid2pr_tbl_lock);
+	temp_peerinfo = *(pid2p_tbl + peer_index);
+	temp_peerinfo &= mask_value;
+	*(pid2p_tbl + peer_index) =
+		(temp_peerinfo | (peerinfo << (peer_offset << 3)));
+	spin_unlock_bh(&g_prid2pr_tbl_lock);
+
+	*peer = peer_val;
+	return DTLK_SUCCESS;
+}
+
+int remove_peer_from_table(
+	uint32_t dlrx_peer_reg_handle,
+	uint32_t peer_id
+	)
+{
+	int handler_index;
+	unsigned int peer;
+	unsigned int loop_index_1;
+	unsigned int loop_index_2;
+	unsigned int peer_id_loop_num;
+	unsigned int temp_peerinfo;
+	unsigned int peerinfo;
+	unsigned int temp_peer;
+	unsigned int temp_peer_vld;
+	unsigned int mask_value;
+	volatile dlrx_cfg_ctxt_peer_handler_t *peer_handler_tbl = NULL;
+	volatile unsigned int *pid2p_tbl = DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(0);
+	dre_dl_reset_fn_t dre_dl_reset_fn;
+	unsigned int *peer_bit_field;
+	unsigned int peer_bit_field_offset;
+	unsigned int peer_bit_field_index;
+
+	peer_bit_field = (unsigned int *)DLRX_CFG_CTXT_PEER_BITMAP_BASE(0);
+	/* have 4 element */
+
+	handler_index = get_handler_index(dlrx_peer_reg_handle);
+
+	if (handler_index == HANDLER_NOT_FOUND)
+		return DTLK_FAILURE;
+	else {
+		peer = (unsigned int)handler_index;
+		/* Get the handler index address by using the base address */
+		peer_handler_tbl =
+			(dlrx_cfg_ctxt_peer_handler_t *)DLRX_CFG_CTXT_PEER_HANDLER_BASE(peer);
+		/* Send the handler table data */
+		peer_handler_tbl->cfg_peer_handler = 0;
+
+		peer_id_loop_num = MAX_PEERID_NUM >> 2;
+
+		if (peer_handler_tbl->cfg_peer_count) {
+			spin_lock_bh(&g_prid2pr_tbl_lock);
+			for (loop_index_1 = 0;
+					loop_index_1 < peer_id_loop_num;
+					loop_index_1++) {
+				temp_peerinfo = *(pid2p_tbl + loop_index_1);
+				for (loop_index_2 = 0;
+					loop_index_2 < 4;
+					loop_index_2++) {
+					mask_value =
+						(0xFF << (loop_index_2 << 3));
+					peerinfo =
+						(temp_peerinfo & mask_value) >>
+						(loop_index_2 << 3);
+					temp_peer = peerinfo & 0x7F;
+					temp_peer_vld = (peerinfo & 0x80) >> 7;
+					if ((temp_peer_vld == 1) &&
+						(temp_peer == peer)) {
+						peerinfo = 0;
+						mask_value = ~mask_value;
+						temp_peerinfo &= mask_value;
+						*(pid2p_tbl + loop_index_1) =
+							temp_peerinfo;
+					}
+				}
+			}
+			spin_unlock_bh(&g_prid2pr_tbl_lock);
+		}
+		peer_handler_tbl->cfg_peer_count = 0;
+
+		dtlk_debug(DBG_RX, "%s: reset_peer, peer: %d\n", __func__, peer);
+		dre_dl_reset_fn = dlrx_get_dre_fn(DRE_RESET_FN);
+		if (likely(dre_dl_reset_fn))
+			dre_dl_reset_fn(DRE_RESET_PEER, peer);
+		else
+			dtlk_debug(DBG_ERR, "Function DRE_RESET_PEER is not registered!");
+
+		ppa_dl_dre_vapinfo_set(peer, 0, 0, 0);
+
+		/* Set the corresponding peer bit field value to 0 */
+		peer_bit_field_offset = peer >> 5;/* Divide by 32 */
+		peer_bit_field_index = peer % 32;
+		/* Calculate the mask value
+		* to set the corresponding peer bit to zero */
+		mask_value = ~(1 << peer_bit_field_index);
+		peer_bit_field[peer_bit_field_offset] &= mask_value;
+	}
+	return DTLK_SUCCESS;
+}
+
+
+/*
+* Remove peer ID PEER table
+*/
+int remove_peer_id_from_table(
+	uint32_t dlrx_peer_reg_handle,
+	uint32_t peer_id
+	)
+{
+	unsigned int handler_index;
+	unsigned int peer_index;
+	unsigned int peer_offset;
+	unsigned int peer;
+	unsigned int temp_peerinfo;
+	unsigned int mask_value;
+	volatile dlrx_cfg_ctxt_peer_handler_t *peer_handler_tbl = NULL;
+	volatile unsigned int *pid2p_tbl = DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(0);
+
+	handler_index = get_handler_index(dlrx_peer_reg_handle);
+
+	dtlk_debug(DBG_RX, "%s: peer: %d\n", __func__, handler_index);
+	if (handler_index == HANDLER_NOT_FOUND)
+		return DTLK_FAILURE;
+	else {
+		peer_index = peer_id >> 2;
+		peer_offset = peer_id % 4;
+		peer = (unsigned int)handler_index;
+		/* Get the handler index address by using the base address */
+		peer_handler_tbl =
+			(dlrx_cfg_ctxt_peer_handler_t *)DLRX_CFG_CTXT_PEER_HANDLER_BASE(peer);
+		/* Send the handler table data */
+		peer_handler_tbl->cfg_peer_count--;
+		mask_value = ~(0xFF << (peer_offset * 8));
+		spin_lock_bh(&g_prid2pr_tbl_lock);
+		temp_peerinfo = *(pid2p_tbl + peer_index);
+		temp_peerinfo &= mask_value;
+		*(pid2p_tbl + peer_index) = temp_peerinfo;
+		spin_unlock_bh(&g_prid2pr_tbl_lock);
+	}
+
+	return DTLK_SUCCESS;
+}
+
+int get_handler_index(
+	uint32_t dlrx_peer_reg_handle
+	)
+{
+	int index;
+	int handler_index = HANDLER_NOT_FOUND;
+	volatile dlrx_cfg_ctxt_peer_handler_t *peer_handler_tbl = NULL;
+
+	for (index = 0; index < MAX_PEER_NUM; index++) {
+		peer_handler_tbl =
+			(dlrx_cfg_ctxt_peer_handler_t *)DLRX_CFG_CTXT_PEER_HANDLER_BASE(index);
+		if (peer_handler_tbl->cfg_peer_handler ==
+			dlrx_peer_reg_handle)
+			return index;
+	}
+	return handler_index;
+}
+
+int get_free_peer_number(
+	unsigned int *peer_val
+	)
+{
+	unsigned int index;
+	unsigned int temp_bit_field;
+	unsigned int free_peer_num = 0;
+	unsigned int *peer_bit_field;
+
+	/* To store handler value and number
+	* of peer count for each handler
+	* NOTE : MAXIMUM SUPPORTED
+	* HANDLER VALUE IS 128
+	*/
+	/* have 4 element */
+	peer_bit_field = (unsigned int *)DLRX_CFG_CTXT_PEER_BITMAP_BASE(0);
+	for (index = 0; index < 4; index++) {
+		temp_bit_field = peer_bit_field[index];
+		/* No free peer in this Dword */
+		if (temp_bit_field == 0xFFFFFFFF) {
+			free_peer_num += 32;
+			continue;
+		}
+		while (temp_bit_field & 1) {
+			temp_bit_field >>= 1;
+			free_peer_num++;
+		}
+		break;
+	}
+	if (index >= 4)
+		return DTLK_FAILURE;
+
+	*peer_val = free_peer_num;
+	peer_bit_field[index] =
+		(peer_bit_field[index] | (1 << (*peer_val % 32)));
+
+	return DTLK_SUCCESS;
+}
+
+
+/* This function transfers control for DirectLink in CE-5 Rx in system.
+* The function gets called by QCA WLAN driver as part of handling
+* legacy interrupt when CE-5 handling is made.
+* Flags -- This is used for future use
+*/
+int32_t ppa_hook_dl_qca_rx_offload(
+	uint32_t flags
+	)
+{
+	int ret = DTLK_FAILURE;
+	dre_dl_main_fn_t dre_dl_main_fn;
+	/*dtlk_debug(DBG_RX, "%s\n", __func__);*/
+	dre_dl_main_fn = dlrx_get_dre_fn(DRE_MAIN_FN);
+	if (likely(dre_dl_main_fn))
+		ret = dre_dl_main_fn();
+	else
+		dtlk_debug(DBG_ERR, "FW Callback FN: dre_main is not registered");
+
+	return (int32_t)ret;
+}
+EXPORT_SYMBOL(ppa_hook_dl_qca_rx_offload);
+
+/*
+* This function picks a corresponding network packet buffer
+* for previous handed over message in callback. The function
+* gets called by QCA WLAN driver after its PPA_QCA_DL_RX_MSG_FN
+* callback gets a message of type RX_IND or RX_FRAG_IND to it.
+* This network buffer should be getting freed
+* inside QCA driver or somewhere in the path of protocol stack.
+*/
+int32_t ppa_dl_qca_get_rx_net_buf(
+	struct sk_buff **rx_skb,
+	uint32_t flags
+	)
+{
+	int ret = DTLK_SUCCESS;
+	dre_dl_getmsdu_fn_t dre_dl_getmsdu_fn;
+	unsigned int rx_pb, data_len;
+	/*dtlk_debug(DBG_RX, "%s: - \n", __func__);*/
+	*rx_skb = NULL;
+	dre_dl_getmsdu_fn = dlrx_get_dre_fn(DRE_GET_CURMSDU_FN);
+	if (likely(dre_dl_getmsdu_fn)) {
+		ret = dre_dl_getmsdu_fn(&rx_pb, &data_len);
+		if (ret != DTLK_SUCCESS)
+			return (int32_t)ret;
+	} else {
+		dtlk_debug(DBG_ERR, "FW CallBack FN: get_curmsdu is not registered!");
+		return (int32_t)ret;
+	}
+	/*dtlk_debug(DBG_RX, "     rx_pb[0x%x] len[%d]\n", __func__, rx_pb, data_len);*/
+	*rx_skb =
+		dlrx_skb_setup(
+			rx_pb,
+			rx_pb,
+			data_len + g_dlrx_cfg_offset_atten
+			);
+
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_qca_get_rx_net_buf);
+
+/* TODO:  Need discuss the mib functions */
+int32_t ppa_dl_qca_get_msg_mdu_stats(
+	PPA_DL_WLAN_MSG_STATS_t *msg_stats,
+	PPA_DL_WLAN_RX_MPDU_MSDU_STATS_t *mdu_stats,
+	uint32_t flags
+	)
+{
+	volatile dlrx_data_mib_t *wlan_mdu_stats = (dlrx_data_mib_t *)DLRX_DATA_MIB_BASE;
+	volatile dlrx_msg_mib_t *wlan_msg_stats = (dlrx_msg_mib_t *)DLRX_MSG_MIB_BASE;
+
+	msg_stats->ce4_cpu_msgs = wlan_msg_stats->total_ce4_cpu_msg;
+	msg_stats->ce5_cpu_msgs = wlan_msg_stats->total_ce5_cpu_msg;
+	msg_stats->rx_ind_msgs = wlan_msg_stats->total_rx_ind_msg;
+	msg_stats->rx_flush_msgs = wlan_msg_stats->total_rx_flush_msg;
+	msg_stats->tx_comp_msgs = wlan_msg_stats->total_tx_cmp_msg;
+	msg_stats->rx_ind_wl_msgs = wlan_msg_stats->total_rx_ind_wlan_msg;
+	msg_stats->rx_flush_wl_msgs = wlan_msg_stats->total_rx_flush_wlan_msg;
+	msg_stats->rx_frag_msgs = wlan_msg_stats->total_rx_frag_ind_msg;
+
+	mdu_stats->rx_mpdu_ok = wlan_mdu_stats->rx_success_mpdu;
+	mdu_stats->rx_msdu_ok = wlan_mdu_stats->rx_success_msdu;
+	mdu_stats->rx_mpdu_err2 = wlan_mdu_stats->rx_error2_mpdu;
+	mdu_stats->rx_msdu_err2 = wlan_mdu_stats->rx_error2_msdu;
+	mdu_stats->rx_mpdu_err3 = wlan_mdu_stats->rx_error3_mpdu;
+	mdu_stats->rx_msdu_err3 = wlan_mdu_stats->rx_error3_msdu;
+	mdu_stats->rx_mpdu_err4 = wlan_mdu_stats->rx_error4_mpdu;
+	mdu_stats->rx_msdu_err4 = wlan_mdu_stats->rx_error4_msdu;
+	mdu_stats->rx_mpdu_err5 = wlan_mdu_stats->rx_error5_mpdu;
+	mdu_stats->rx_msdu_err5 = wlan_mdu_stats->rx_error5_msdu;
+	mdu_stats->rx_mpdu_err6 = wlan_mdu_stats->rx_error6_mpdu;
+	mdu_stats->rx_msdu_err6 = wlan_mdu_stats->rx_error6_msdu;
+	mdu_stats->rx_mpdu_err7 = wlan_mdu_stats->rx_error7_mpdu;
+	mdu_stats->rx_msdu_err7 = wlan_mdu_stats->rx_error7_msdu;
+	mdu_stats->rx_mpdu_err8 = wlan_mdu_stats->rx_error8_mpdu;
+	mdu_stats->rx_msdu_err8 = wlan_mdu_stats->rx_error8_msdu;
+	mdu_stats->rx_mpdu_err9 = wlan_mdu_stats->rx_error9_mpdu;
+	mdu_stats->rx_msdu_err9 = wlan_mdu_stats->rx_error9_msdu;
+	mdu_stats->rx_mpdu_errA = wlan_mdu_stats->rx_errora_mpdu;
+	mdu_stats->rx_msdu_errA = wlan_mdu_stats->rx_errora_msdu;
+
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_qca_get_msg_mdu_stats);
+
+int32_t ppa_dl_qca_set_seq_mask(
+	uint32_t *dlrx_peer_reg_handle,
+	uint32_t ex_tid,
+	uint32_t seq_mask,
+	uint32_t flags
+	)
+{
+	int peer;
+	uint32_t *seq_mask_base = DLRX_DDR_SEQ_MASK_BASE;
+
+	if (unlikely(!dlrx_peer_reg_handle))
+		return DTLK_FAILURE;
+
+	peer = get_handler_index((uint32_t)dlrx_peer_reg_handle);
+	if (unlikely(peer == HANDLER_NOT_FOUND))
+		return DTLK_FAILURE;
+
+
+	seq_mask_base[(peer * 16) + ex_tid] = seq_mask;
+
+	return DTLK_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_qca_set_seq_mask);
+
+
+/*************************************************
+ *		   Functions called by datapath driver
+ *************************************************/
+void set_vap_itf_tbl(
+	uint32_t vap_id,
+	uint32_t fid
+	)
+{
+	volatile unsigned int *itf_tbl;
+	volatile unsigned int itf_id;
+	dtlk_debug(DBG_RX, "%s: vap_id[%d] fid[%d]\n", __func__, vap_id, fid);
+	if (vap_id >= MAX_VAP_NUM)
+		return;
+	/* Range is defined in the spec */
+	if (vap_id <= 7)
+		itf_tbl = DLRX_CFG_VAP2INT_MAP1_BASE;
+	else
+		itf_tbl = DLRX_CFG_VAP2INT_MAP2_BASE;
+
+
+	vap_id = vap_id % 8;
+	spin_lock_bh(&g_vap2int_tbl_lock);
+	itf_id = *(itf_tbl);
+	dtlk_debug(DBG_RX, "%s: itf_tbl[0x%p] itf_id[%x]\n", __func__, itf_tbl, itf_id);
+	*(itf_tbl) =
+		(itf_id & ~(0xF << (vap_id * 4))) |
+		((fid & 0xF) << (vap_id * 4));
+	dtlk_debug(DBG_RX, "%s: itf_tbl[%p] value[%x]\n", __func__, itf_tbl, *itf_tbl);
+	spin_unlock_bh(&g_vap2int_tbl_lock);
+
+	return;
+}
+
+
+/*************************************************
+ *			Export Functions
+ *************************************************/
+
diff --git a/drivers/net/ethernet/lantiq/directlink/dtlk_main.c b/drivers/net/ethernet/lantiq/directlink/dtlk_main.c
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/dtlk_main.c
@@ -0,0 +1,3844 @@
+/******************************************************************************
+
+				 Copyright (c) 2012, 2014, 2015
+					Lantiq Deutschland GmbH
+
+For licensing information, see the file 'LICENSE' in the root folder of
+this software module.
+
+******************************************************************************/
+
+
+/*####################################
+ *				Head File
+ * ####################################
+ */
+
+/*Common Head File
+ */
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/version.h>
+#include <linux/types.h>
+#include <linux/ctype.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <linux/miscdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ethtool.h>
+#include <linux/if_ether.h>
+#include <linux/if_arp.h>
+#include <asm/uaccess.h>
+#include <asm/unistd.h>
+#include <asm/irq.h>
+#include <asm/delay.h>
+#include <asm/addrspace.h>
+#include <asm/io.h>
+#include <linux/netdevice.h>
+#include <net/ppa_ppe_hal.h>
+#include <linux/list.h>
+#include <linux/delay.h>
+
+
+#include "./include/11ac_acc_data_structure_tx_be.h"
+#include "./include/dlrx_drv.h"
+#include <net/ppa_stack_al.h>
+#include "./include/dlrx_fw_data_structure_be.h"
+#include "./include/dltx_fw_data_structure_be.h"
+
+#include "./include/dlrx_fw_def.h"
+#include "./include/Dltx_fw_def.h"
+#include "./include/dlrx_wlan_api.h"
+#include "./include/dlrx_dre_api.h"
+#include "./include/dlrx_memory_lyt.h"
+
+#include "./include/dlrx_fw_version.h"
+#include "./include/directlink_tx_cfg.h"
+#include "./include/ltqmips_hal.h"
+#include <net/ppa_api_directpath.h>
+#include "./include/dltx_fw_comm_buf_data_structure_be.h"
+#include <net/ppa_api.h>
+#include <net/datapath_api.h>
+#include <net/ltq_mpe_api.h>
+#include <linux/dma-mapping.h>
+
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+#if defined(CONFIG_LANTIQ_MCAST_HELPER_MODULE) || defined(CONFIG_LANTIQ_MCAST_HELPER)
+#include "../../../../net/lantiq_ppa/ppa_api/ppa_api_core.h"
+#endif
+#endif
+#include <xway/switch-api/lantiq_gsw_api.h>
+
+#include <linux/pci.h>
+/*#define OLD_MPE_FAST_HOOK 1*/
+#ifndef OLD_MPE_FAST_HOOK
+#include <net/ltq_mpe_hal.h>
+#endif
+#define	MAX_DIRECTPATH_NUM	5
+#define MAX_DIRECTLINK_NUM 16
+struct ppe_directpath_data g_ppe_directpath_data[MAX_DIRECTPATH_NUM];
+struct dl_drv_address_map g_dl_drv_address;
+struct dl_buf_info g_dl_buf_info;
+#define RX_NOT_SKB 1
+#define MAX_TX_DESCRIPTOR 1420
+/* #define DLTX_UNCACHED 1 */
+/*****************************************************
+ *	 Macro definition
+ *****************************************************/
+#define MOD_AUTHOR			"Zhu YiXin, Ho Nghia Duc"
+#define MOD_DESCRIPTION		"Accelerate QCA 11AC TX RX Traffic"
+#define MOD_LICENCE			"GPL"
+#define DLRX_DRV_MAJOR		0
+#define DLRX_DRV_MID		2
+#define DLRX_DRV_MINOR		8
+#define DLRX_DRV_VERSION	((DLRX_DRV_MAJOR << 24) | (DLRX_DRV_MID << 16) | DLRX_DRV_MINOR)
+
+#define INLINE				inline
+#define DIRECTLINK_PROC_DIR	"dl"
+
+
+#define NUM_ENTITY(x)		(sizeof(x) / sizeof(*(x)))
+
+#define NEW_CHANGE 1
+
+int dl_param_tx_descriptor = MAX_TX_DESCRIPTOR;
+
+module_param(dl_param_tx_descriptor, int, S_IWUSR | S_IWGRP);
+MODULE_PARM_DESC(dl_param_tx_descriptor, "Establish number of TX DESCRIPTOR");
+
+/*****************************************************
+ *	External functions
+ *****************************************************/
+#ifdef OLD_MPE_FAST_HOOK
+enum MPE_Feature_Type {
+	DL_TX_1 = 0,
+	DL_TX_2
+};
+#define F_FEATURE_START     (1 << 25)
+#define F_FEATURE_STOP      (1 << 26)
+
+#ifdef NEW_CHANGE
+extern int mpe_hal_dl_alloc_resource(uint32_t memSize,
+	uint32_t *memAddr,
+	uint32_t flags);
+#else
+extern int mpe_hal_dl_alloc_resouce(uint32_t memSize,
+	uint32_t *memAddr,
+	uint32_t flags);
+
+#endif
+extern int mpe_hal_feature_start(
+	enum MPE_Feature_Type mpeFeature,
+	uint32_t port_id,
+	uint32_t *featureCfgBase,
+	uint32_t flags
+	);
+
+#endif
+
+/*****************************************************
+ *	Global Parameter
+ *****************************************************/
+uint32_t g_ce5_desc_ring_num = CE5_DEST_DESC_RING_NUM;
+uint32_t g_ce5_buf_ptr_ring_num = RX_PKT_BUF_PTR_RING_NUM;
+/* uint32_t g_dtlk_memsize = DTLK_TX_RSV_MEM_SIZE + DTLK_RX_RSV_MEM_SIZE; */
+u32 g11ACWirelessCardID = PEREGRINE_BOARD;
+u32 g11ACWirelessCardID_SUBTYPE = SUBTYPE_NONE_BOARD;
+#if 1
+struct device *g_mpe_dev;
+#endif
+uint32_t g_mpe_dltx_tc;
+/**************************************/
+
+/* !!! These three base address must be
+* initialized before access any FW structure !!! */
+unsigned int *ddr_base;
+unsigned int *ddr_mpe_base;
+unsigned int *ddr_mpe_comp_base;
+unsigned int *cfg_ctxt_base;
+unsigned int *pcie_base;
+
+extern dre_regfn_set_t g_dre_fnset;
+extern uint32_t g_dlrx_max_inv_header_len;
+extern uint32_t g_dlrx_cfg_offset_atten;
+
+#ifdef SUPPORT_11AC_MULTICARD
+#define PCI_VENDOR_ATHEROS 0x168C
+#define PCI_ATH_DEV_PEREGRINE 0x003C
+#define PCI_ATH_DEV_BEELINER 0x0040
+#define PCI_ATH_DEV_BEELINER_CASCADE 0x0046
+#endif
+
+#define MAX_DTLK_NUM	16
+#define MAX_RADIO_NUM	1
+/* can extend to 8 */
+#define MAX_TX_COMP_MAX 4
+static DEFINE_SPINLOCK(g_ppe_dtlk_spinlock);
+static struct ppe_radio_map	g_ppe_radio[MAX_RADIO_NUM];
+#define DTLK_RX_ADDR(offset) (ddr_base + offset)
+#define DTLK_RX_CTXT_ADDR(offset) (cfg_ctxt_base + offset)
+#define MPE_TX_ADDR(offset) (ddr_mpe_base + offset)
+#define MPE_TX_COML_ADDR(offset) (ddr_mpe_comp_base + offset)
+
+
+void (*set_vap_itf_tbl_fn)(uint32_t, uint32_t) = NULL;
+EXPORT_SYMBOL(set_vap_itf_tbl_fn);
+
+
+/*****************************************************
+ *	Internal Variables
+ *****************************************************/
+static struct proc_dir_entry *g_dtlk_proc_dir;
+
+struct dtlk_dgb_info {
+	char *cmd;
+	char *description;
+	uint32_t flag;
+};
+
+PPA_SUBIF gQuickRefSubIfFromVAPID[MAX_DTLK_NUM];
+
+
+static struct dtlk_dgb_info dtlk_dbg_enable_mask_str[] = {
+	{"err",		"error print",		DBG_ERR},
+	{"init",	"init print",		DBG_INIT},
+	{"rx",		"rx path print",	DBG_RX},
+	{"tx",		"tx path print",	DBG_TX},
+	{"cpu",		"cpu path print",	DBG_CPU},
+	{"proc",	"proc print",		DBG_PROC},
+	{"print",	"message print",	DBG_PRINT},
+	/* the last one */
+	{"all",		"enable all debug",	-1}
+};
+uint32_t g_dtlk_dbg_enable = DTLK_DBG_ENA;
+
+
+/*****************************************************
+ *	Internal functions
+ *****************************************************/
+static GSW_API_HANDLE gswr;
+static GSW_register_t old_pce_ctrl;
+static GSW_register_t old_pce_IGPTRM;
+
+static int gsw_enable_ingress_port_remove(int portnum)
+{
+	GSW_register_t regr;
+	int result = 0;
+	gswr = gsw_api_kopen("/dev/switch_api/1");
+	if (gswr == 0) {
+		dtlk_debug(DBG_ERR, "%s: Open SWAPI device FAILED !!\n", __func__);
+		return -EIO;
+	}
+	dtlk_debug(DBG_INIT, "%s: enable ingress at port [%d]\n", __func__, portnum);
+	/*PCE Control register*/
+	old_pce_ctrl.nRegAddr = (0x483 + (0xA * portnum));
+	if (gsw_api_kioctl(gswr, GSW_REGISTER_GET, (unsigned int)&old_pce_ctrl) < 0) {
+		dtlk_debug(DBG_ERR, "ERROR");
+		result = -EIO;
+		goto error;
+	}
+	dtlk_debug(DBG_INIT, "regr.nRegAddr:0x%08x, regr.nData=0x%08x\n", old_pce_ctrl.nRegAddr, old_pce_ctrl.nData);
+	regr.nData = old_pce_ctrl.nData;
+	regr.nRegAddr = (0x483 + (0xA * portnum));
+	regr.nData |= (0x4000);
+	if (gsw_api_kioctl(gswr, GSW_REGISTER_SET, (unsigned int)&regr) < 0) {
+		dtlk_debug(DBG_ERR, "ERROR");
+		result = -EIO;
+		goto error;
+	}
+	/*IGPTRM register*/
+	regr.nRegAddr = (0x544 + (0x10 * portnum));
+	if (gsw_api_kioctl(gswr, GSW_REGISTER_GET, (unsigned int)&old_pce_IGPTRM) < 0) {
+		dtlk_debug(DBG_ERR, "ERROR");
+		result = -EIO;
+		goto error;
+	}
+	dtlk_debug(DBG_INIT, "regr.nRegAddr:0x%08x, regr.nData=0x%08x\n", old_pce_IGPTRM.nRegAddr, old_pce_IGPTRM.nData);
+	regr.nRegAddr = (0x544 + (0x10 * portnum));
+	regr.nData = old_pce_IGPTRM.nData;
+	regr.nData |= (0xffff);
+	if (gsw_api_kioctl(gswr, GSW_REGISTER_SET, (unsigned int)&regr) < 0) {
+		dtlk_debug(DBG_ERR, "ERROR");
+		result = -EIO;
+		goto error;
+	}
+error:
+	gsw_api_kclose(gswr);
+	return result;
+}
+#if 0
+static int gsw_restore_ingress_port_remove(int portnum)
+{
+	GSW_register_t regr;
+	int result = 0;
+	gswr = gsw_api_kopen("/dev/switch_api/1");
+	if (gswr == 0) {
+		dtlk_debug(DBG_ERR, "%s: Open SWAPI device FAILED !!\n", __func__);
+		return -EIO;
+	}
+	/*PCE Control register*/
+	regr.nRegAddr = (0x483 + (0xA * portnum));
+	if (gsw_api_kioctl(gswr, GSW_REGISTER_GET, (unsigned int)&regr) < 0) {
+		dtlk_debug(DBG_ERR, "ERROR");
+		result = -EIO;
+		goto error;
+	}
+	dtlk_debug(DBG_INIT, "regr.nRegAddr:0x%08x, regr.nData=0x%08x\n", regr.nRegAddr, regr.nData);
+	regr.nRegAddr = (0x483 + (0xA * portnum));
+	regr.nData = old_pce_ctrl.nData;
+	if (gsw_api_kioctl(gswr, GSW_REGISTER_SET, (unsigned int)&regr) < 0) {
+		dtlk_debug(DBG_ERR, "ERROR");
+		result = -EIO;
+		goto error;
+	}
+	/*IGPTRM register*/
+	regr.nRegAddr = (0x544 + (0x10 * portnum));
+	if (gsw_api_kioctl(gswr, GSW_REGISTER_GET, (unsigned int)&regr) < 0) {
+		dtlk_debug(DBG_ERR, "ERROR");
+		result = -EIO;
+		goto error;
+	}
+	dtlk_debug(DBG_INIT, "regr.nRegAddr:0x%08x, regr.nData=0x%08x\n", regr.nRegAddr, regr.nData);
+	regr.nRegAddr = (0x544 + (0x10 * portnum));
+	regr.nData = old_pce_IGPTRM.nData;
+	if (gsw_api_kioctl(gswr, GSW_REGISTER_SET, (unsigned int)&regr) < 0) {
+		dtlk_debug(DBG_INIT, "ERROR");
+		result = -EIO;
+		goto error;
+	}
+
+error:
+	gsw_api_kclose(gswr);
+	return result;
+}
+#endif
+
+/* Function: dlrx_init_buf_size
+* Purpose: Initilize DLRX FW Buffer
+* Argument:
+*		dlrx_bufnum : dlrx_bufsize_t
+* Return: none
+*/
+static void dlrx_init_buf_size(
+	dlrx_bufsize_t *dlrx_bufnum
+	)
+{
+	/* Initializing the Length of data structure */
+	dlrx_bufnum->wlan_desc_num				= WLAN_DESC_NUM;
+	dlrx_bufnum->proto_desc_num				= PROTO_DESC_NUM;
+	dlrx_bufnum->cpu_ce5_desc_ring_num		= CPU_CE5_DESC_RING_NUM;
+	dlrx_bufnum->rx_pkt_buf_rel_msg_num		= RX_PKT_BUF_REL_MSG_NUM;
+	dlrx_bufnum->ce5_dest_desc_ring_num		= g_ce5_desc_ring_num;
+	dlrx_bufnum->ce5_dest_msg_buf_num		= g_ce5_desc_ring_num;
+	dlrx_bufnum->rx_pkt_buf_ptr_ring_num	= g_ce5_buf_ptr_ring_num;
+	dlrx_bufnum->rx_reorder_main_num		= RX_REORDER_MAIN_NUM;
+	dlrx_bufnum->rx_reorder_desc_link_num	= RX_REORDER_DESC_LINK_NUM;
+
+	return;
+}
+
+/** Function: ppa_dl_detect_11ac_card
+* Purpose: detect wireless card. Peregrine or Beeliner.
+* Argument: none
+* Return: card type.
+*/
+u32 ppa_dl_detect_11ac_card(void)
+{
+	dtlk_debug(DBG_INIT, "%s:g11ACWirelessCardID[%d] subtype[%d]\n",
+		__func__,
+		g11ACWirelessCardID,
+		g11ACWirelessCardID_SUBTYPE);
+	return g11ACWirelessCardID;
+}
+
+/** Function: dtlk_dev_from_vapid
+* Purpose: Get net device of given VAP.
+* Argument:
+*/
+struct net_device *dtlk_dev_from_vapid(
+	uint32_t vap_id
+	)
+{
+	struct net_device *dev = NULL;
+	int i;
+
+	if (vap_id >= MAX_DTLK_NUM) {
+		dtlk_debug(DBG_ERR, "VAP id [%d] is larger than the MAX DTLK NUM [%d]\n",
+				vap_id,
+				MAX_DTLK_NUM
+				);
+	}
+
+	spin_lock_bh(&g_ppe_dtlk_spinlock);
+	for (i = 0; i < MAX_DTLK_NUM; i++) {
+		if (g_ppe_radio[0].g_ppe_dtlk_data[i].flags & PPE_DTLK_VALID) {
+			if (g_ppe_radio[0].g_ppe_dtlk_data[i].vap_id == vap_id)
+				dev = (struct net_device *)g_ppe_radio[0].g_ppe_dtlk_data[i].dev;
+	   }
+	}
+	spin_unlock_bh(&g_ppe_dtlk_spinlock);
+
+	return dev;
+}
+EXPORT_SYMBOL(dtlk_dev_from_vapid);
+
+/** Function: wlan_detect_ath_card
+* Purpose: detect 11 QCA wireless card.
+* Argument: None
+* Return : None. The type of card will be saved to global variable named
+* g11ACWirelessCardID.
+*/
+static void wlan_detect_ath_card(void)
+{
+	int index = 0;
+	int ath_dev_id = PCI_ATH_DEV_PEREGRINE;
+	int found = 0;
+	struct pci_dev *dev_tel = NULL;
+
+	for (index = 0; index < 3; index++) {
+		dev_tel = pci_get_subsys(PCI_VENDOR_ATHEROS,
+				ath_dev_id,
+				PCI_ANY_ID,
+				PCI_ANY_ID,
+				NULL);
+		if (dev_tel)
+			found = 1;
+		if (found)
+			break;
+		else {
+			switch (ath_dev_id) {
+			case PCI_ATH_DEV_PEREGRINE:
+				ath_dev_id = PCI_ATH_DEV_BEELINER;
+			break;
+			case PCI_ATH_DEV_BEELINER:
+				ath_dev_id = PCI_ATH_DEV_BEELINER_CASCADE;
+				break;
+			default:
+				break;
+			}
+		}
+	}
+	if (!found)	{
+		dtlk_debug(DBG_ERR, "Can not found any Atheros card\n");
+		return ;
+	}
+	g11ACWirelessCardID_SUBTYPE = SUBTYPE_NONE_BOARD;
+	if (ath_dev_id == PCI_ATH_DEV_PEREGRINE) {
+		dtlk_debug(DBG_INIT, "Found PEREGRINE_BOARD card\n");
+		g11ACWirelessCardID = PEREGRINE_BOARD;
+	} else if (ath_dev_id == PCI_ATH_DEV_BEELINER) {
+		dtlk_debug(DBG_INIT, "Found BEELINER_BOARD card\n");
+		g11ACWirelessCardID = BEELINER_BOARD;
+		/* changed in firmware, using 4 instead of 1 */
+	} else if (ath_dev_id == PCI_ATH_DEV_BEELINER_CASCADE) {
+		dtlk_debug(DBG_INIT, "Found CASCADE_BOARD card\n");
+		g11ACWirelessCardID = BEELINER_BOARD;
+		g11ACWirelessCardID_SUBTYPE = SUBTYPE_BEELINER_CASCADE_BOARD;
+		/* changed in firmware, using 4 instead of 1 */
+	}
+}
+
+
+extern unsigned int skb_list_get_skb(
+	unsigned int rxpb_ptr
+	);
+
+/** Function: dlrx_data_structure_free
+* Purpose: Free all resources which allocated by DTLK
+* Argument: None
+* Return: None
+*/
+void dlrx_data_structure_free(void)
+{
+	dlrx_rxpb_ptr_ring_t *dlrx_rxpb_ring_ptr, *dlrx_rxpb_ring_ptr_org;
+	unsigned int index, j;
+	unsigned int currentV;
+	uint32_t numRingBuf;
+	dlrx_bufsize_t dlrx_bufnum;
+
+	dlrx_rxpb_ring_ptr =
+		(dlrx_rxpb_ptr_ring_t *)DLRX_DDR_RX_PKT_BUF_RING_BASE;
+	dlrx_rxpb_ring_ptr_org =
+		(dlrx_rxpb_ptr_ring_t *)DLRX_DDR_RX_PKT_BUF_RING_BASE;
+	/* Clear DLRX FW Buffer */
+	dlrx_init_buf_size(&dlrx_bufnum);
+
+	/* looking for duplicate
+	* initial 1024 -1
+	*/
+	numRingBuf = dlrx_bufnum.rx_pkt_buf_ptr_ring_num;
+	for (index = 0; index < (numRingBuf - 1); index++) {
+		currentV = (dlrx_rxpb_ring_ptr_org + index)->rxpb_ptr;
+		j = index + 1;
+		for (; j < (dlrx_bufnum.rx_pkt_buf_ptr_ring_num - 1); j++) {
+			if (currentV != 0 &&
+				currentV == (dlrx_rxpb_ring_ptr_org+j)->rxpb_ptr) {
+				/* dtlk_debug(DBG_RX, "Duplicate: %x index [%d]\n", currentV, j); */
+				(dlrx_rxpb_ring_ptr_org+j)->rxpb_ptr = 0;
+			}
+		}
+	}
+}
+
+
+/* * Function: dtlk_mem_base_get
+ * Purpose: Return the address of DTLK TX and DTLK RX.
+ *	  These value should get from MPE HAL
+ * Argument:
+ *	  dltx_base : uint32_t, contains DTLK TX base.
+ *	  dlrx_base : uint32_t, contains DTLK RX base.
+ * Return : None
+ */
+void dtlk_mem_base_get(
+	uint32_t *dltx_base,
+	uint32_t *dlrx_base
+	)
+{
+	if (dltx_base) {
+		/* *dltx_base = NULL; */
+		*dltx_base = g_dl_buf_info.tx_cfg_ctxt_buf_base;
+		dtlk_debug(DBG_INIT, "DTLK TX base :0x%x\n", *dltx_base);
+	}
+	if (dlrx_base) {
+		/* *dlrx_base = NULL; */
+		*dlrx_base = g_dl_buf_info.rx_msgbuf_base;
+		dtlk_debug(DBG_INIT, "DTLK RX base :0x%x\n", *dlrx_base);
+	}
+	return ;
+}
+EXPORT_SYMBOL(dtlk_mem_base_get);
+
+void dtlk_mem_comm_base_get(
+	uint32_t *dltx_comm_base
+	)
+{
+	if (dltx_comm_base)
+			*dltx_comm_base = g_dl_buf_info.comm_buf_base;
+
+	return;
+}
+EXPORT_SYMBOL(dtlk_mem_comm_base_get);
+void dtlk_get_bank_base(
+	uint32_t *dltx_bank_base
+	)
+{
+	if (dltx_bank_base) {
+		dma_addr_t phy_addr;
+		uint32_t fragment = (uint32_t)MPE_TX_ADDR(DLTX_FRAG_DATA_OFFSET);
+		phy_addr = dma_map_single(
+						g_mpe_dev,
+						(void *)fragment,
+						4096 * 16 * 4,
+						DMA_FROM_DEVICE
+						);
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "DMA error");
+		}
+		/*
+					dma_unmap_single(
+						g_mpe_dev,
+						phy_addr,
+						4,
+						DMA_FROM_DEVICE
+						);
+						*/
+		dtlk_debug(DBG_INIT, "%s: vir[0x%x] return[0x%x]\n", __func__, fragment, phy_addr);
+		*dltx_bank_base = phy_addr;
+	}
+	return;
+}
+EXPORT_SYMBOL(dtlk_get_bank_base);
+
+/* * Function: dtlk_mem_base_get
+ * Purpose: Return the address of DTLK TX and DTLK RX.
+ *	  These value should get from MPE HAL
+ * Argument:
+ *	  dtlk_ctxt : uint32_t, contains DTLK FW
+ * Return : None
+ */
+void dtlk_mem_sram_base_get(
+	uint32_t *dtlk_sram
+	)
+{
+	/* *dtlk_sram = NULL; */
+	*dtlk_sram = g_dl_buf_info.rx_cfg_ctxt_buf_base;
+}
+
+/* BEELINERTODO */
+#define  SIZE_BEELINER_MSDU_ID		1424
+#define  SIZE_BEELINER_FRAG_DESC	64
+static inline uint32_t __bswap32(
+	u_int32_t _x
+	)
+{
+	return (u_int32_t)(
+		  (((const u_int8_t *)(&_x))[0]) |
+		  (((const u_int8_t *)(&_x))[1] << 8) |
+		  (((const u_int8_t *)(&_x))[2] << 16) |
+		  (((const u_int8_t *)(&_x))[3] << 24))	;
+}
+
+/** Function: ppa_dl_qca_h2t_ring_init
+* Purpose: This function is called QCA driver to initialize H2T Ring buffer
+* Argument:
+* Return:
+*/
+#define __CE4SRC_BEELINER_HI			0x4
+#define __CE4SRC_MISC_IE_BEELINER_LOW	0xb034
+
+#define __CE4SRC_TARGET_WR_PTR_BEELINER_LOW		0xb03c
+#define __CE4SRC_TARGET_RD_PTR_BEELINER_LOW		0xb044
+
+
+uint32_t ppa_dl_qca_h2t_ring_init(
+	uint32_t h2tRingSize,
+	uint32_t entrySize,
+	uint32_t src_ring_base,
+	uint32_t pcie_base,
+	uint32_t flags)
+{
+	int i;
+	char *bufptr;
+
+
+
+	uint32_t BADR_TXPB;
+	uint32_t BADR_CE4DES;
+	uint16_t NUM_CE4DES;
+	uint32_t BADR_PCIEMEM;
+	uint32_t BADR_HTT_TXDES;
+	dltx_cfg_ctxt_ce4buf_t *dltx_cfg_txt;
+	dltx_cfg_ctxt_circular_list_t *dltx_cfg_ctxt_circular;
+	dltx_circular_list_t *dltx_circular;
+	dltx_cfg_ctxt_qca_vap_id_map_t *dltx_cfg_ctxt_qca_vap_id_map;
+	dltx_cfg_ctxt_buffer_pointer_table_t *dltx_cfg_ctxt_buffer_pointer_table;
+	dltx_cfg_ctxt_ce4_write_index_track_t *dltx_cfg_ctxt_ce4_write_index_track;
+	dltx_cfg_ctxt_cpu_ce4des_t *dltx_cfg_ctxt_cpu_ce4des;
+	dltx_cfg_ctxt_comm_buff_t *dltx_cfg_ctxt_comm_buff;
+	dltx_cfg_ctxt_frag_data_t *dltx_cfg_ctxt_frag_data;
+	dltx_cfg_ctxt_tx_msg_t *dltx_cfg_ctxt_tx_msg;
+	unsigned char offload_tx_desc_t[] = {
+	0X00, 0X42, 0X00, 0X01, /* DW0 */
+	0X00, 0X00, 0X00, 0X00, /* DW1 */
+	0X07, 0XC0, 0X40, 0X01, /* DW2 */
+	0X00, 0X01, 0X05, 0XEA, /* DW3 */
+	0X00, 0X00, 0X00, 0X00, /* DW4 byte swap */
+	0XFF, 0XFF, 0X00, 0X00 /* DW5 byte swap */
+	};
+
+	unsigned char offload_tx_src_ring_desc_t[] = {
+	0X00, 0X00, 0X00, 0X00, /* DW0 */
+	0X00, 0X04, 0X04, 0X04, /* DW1 */
+	/* metadata 14b =1, ByteSwapEN 1b=0, Gather 1b=0,
+	SourceBufferLen 16b=68 */
+	};
+
+	if ((h2tRingSize == 0x0) ||
+		(entrySize == 0x0) ||
+		(src_ring_base == 0x0) ||
+		(pcie_base == 0x0))
+		return PPA_FAILURE;
+
+	BADR_CE4DES = src_ring_base;
+
+	/* NUM_CE4DES = src_ring_size; */
+	NUM_CE4DES = h2tRingSize;
+
+	dtlk_mem_base_get(&BADR_TXPB, NULL);
+	BADR_PCIEMEM = 0xf0000000 | pcie_base;
+	/* TODO: GRX500 get TX from HAL layer, need to align with  MPE FW TX */
+	/* initialize CE4 List handling */
+	dltx_cfg_txt = (dltx_cfg_ctxt_ce4buf_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_CE4BUF_OFFSET);
+	dltx_cfg_txt->cfg_badr_ce4buf = BADR_CE4DES;
+	dltx_cfg_txt->cfg_ce4des_low = LOW_MARK;
+	dltx_cfg_txt->cfg_ce4_des_full = HIGH_MARK;
+	dltx_cfg_txt->cfg_ce4_read_index_addr = BADR_PCIEMEM + (__CE4SRC_BEELINER_HI << 16) + __CE4SRC_TARGET_RD_PTR_BEELINER_LOW;
+	dltx_cfg_txt->cfg_ce4_write_index_addr = BADR_PCIEMEM + (__CE4SRC_BEELINER_HI << 16) + __CE4SRC_TARGET_WR_PTR_BEELINER_LOW;
+	dltx_cfg_txt->cfg_num_ce4buf = NUM_CE4DES;
+	dltx_cfg_txt->load_ce4_read_index_req = 0x0;
+	dltx_cfg_txt->local_ce4_read_index = 0x0;
+	dltx_cfg_txt->local_ce4_write_index = 0x0;
+	dltx_cfg_txt->_dw_res0[0] = BADR_PCIEMEM;
+
+	/* initialize circular list */
+	dltx_cfg_ctxt_circular =
+	#ifdef DLTX_UNCACHED
+		(dltx_cfg_ctxt_circular_list_t *)KSEG1ADDR(MPE_TX_ADDR(DLTX_CFG_CTXT_CIRCULAR_LIST_OFFSET));
+		#else
+		(dltx_cfg_ctxt_circular_list_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_CIRCULAR_LIST_OFFSET);
+		#endif
+	dtlk_debug(DBG_INIT, "%s: dltx_cfg_ctxt_circular[%p]\n", __func__,
+		(void *)dltx_cfg_ctxt_circular);
+	#ifdef DLTX_UNCACHED
+	dltx_cfg_ctxt_circular->circular_list_badr = (unsigned int)KSEG1ADDR(MPE_TX_ADDR(DLTX_CIRCULAR_LIST_OFFSET));
+	#else
+	dltx_cfg_ctxt_circular->circular_list_badr = (unsigned int)(MPE_TX_ADDR(DLTX_CIRCULAR_LIST_OFFSET));
+	#endif
+	dtlk_debug(DBG_INIT, "%s: dltx_cfg_ctxt_circular->circular_list_badr[0x%x]\n",
+		__func__, dltx_cfg_ctxt_circular->circular_list_badr);
+	#if 0
+	dltx_cfg_ctxt_circular->circular_list_num = NUM_CE4DES;
+	#else
+	/*12-JUN-2015*/
+	/*dltx_cfg_ctxt_circular->circular_list_num = 0x400;*/
+	dltx_cfg_ctxt_circular->circular_list_num = dl_param_tx_descriptor;
+	#endif
+	dltx_cfg_ctxt_circular->circular_list_read_index = 0;
+	dltx_cfg_ctxt_circular->circular_list_write_index = 0;
+	dltx_cfg_ctxt_circular->consumed_pkt_ids = 0;
+	dltx_circular =
+			(dltx_circular_list_t *)dltx_cfg_ctxt_circular->circular_list_badr;
+	dtlk_debug(DBG_INIT, "%s: dltx_circular[%p] %d\n", __func__,
+		(void *)dltx_circular, dltx_cfg_ctxt_circular->circular_list_num);
+	for (i = 0; i < dltx_cfg_ctxt_circular->circular_list_num; i++) {
+		dltx_circular->packet_id = i + 1;
+		dltx_circular++;
+	}
+
+	/* Configure context QCA VAP ID */
+	dltx_cfg_ctxt_qca_vap_id_map =
+		(dltx_cfg_ctxt_qca_vap_id_map_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_QCA_VAP_ID_MAP_OFFSET);
+	dltx_cfg_ctxt_qca_vap_id_map->qca_vap_id_map_badr =
+		(unsigned int)MPE_TX_ADDR(DLTX_QCA_VAP_ID_MAP_OFFSET);
+	dltx_cfg_ctxt_qca_vap_id_map->qca_vap_id_map_num = MAX_DTLK_NUM;
+
+	/* Buffer pointer */
+	dltx_cfg_ctxt_buffer_pointer_table =
+		(dltx_cfg_ctxt_buffer_pointer_table_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_BUFFER_POINTER_TABLE_OFFSET);
+	dltx_cfg_ctxt_buffer_pointer_table->buffer_pointer_badr =
+		(unsigned int)MPE_TX_ADDR(DLTX_BUFFER_POINTER_TABLE_OFFSET);
+	dltx_cfg_ctxt_buffer_pointer_table->buffer_pointer_num = NUM_CE4DES;
+
+	/* Write CE4 Write index track */
+	dltx_cfg_ctxt_ce4_write_index_track =
+		(dltx_cfg_ctxt_ce4_write_index_track_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_CE4_WRITE_INDEX_TRACK_OFFSET);
+	dltx_cfg_ctxt_ce4_write_index_track->write_index_track_badr =
+		(unsigned int)MPE_TX_ADDR(DLTX_CE4_WRITE_INDEX_TRACK_OFFSET);
+	dltx_cfg_ctxt_ce4_write_index_track->write_index_track_num = NUM_CE4DES;
+
+	/* Comm CPU CE4 */
+	dltx_cfg_ctxt_cpu_ce4des =
+		(dltx_cfg_ctxt_cpu_ce4des_t *)MPE_TX_COML_ADDR(DLTX_CFG_CTXT_CPU_CE4DES_OFFSET);
+	dltx_cfg_ctxt_cpu_ce4des->cfg_badr_cpu_ce4 =
+		(unsigned int)MPE_TX_COML_ADDR(DLTX_CPU_CE4DES_FORMAT_OFFSET);
+	dltx_cfg_ctxt_cpu_ce4des->cfg_num_cpu_ce4 = 64;
+	dltx_cfg_ctxt_cpu_ce4des->cpu_ce4_read_index = 0;
+	dltx_cfg_ctxt_cpu_ce4des->cpu_ce4_write_index = 0;
+	dltx_cfg_ctxt_cpu_ce4des->cpu_ce4_ppe_read_index = 0;
+	dltx_cfg_ctxt_cpu_ce4des->cpu_ce4_msg_done = 0;
+
+	/* Comm TX Completion */
+	dltx_cfg_ctxt_comm_buff =
+		(dltx_cfg_ctxt_comm_buff_t *)MPE_TX_COML_ADDR(DLTX_CFG_CTXT_COMM_BUFF_OFFSET);
+	dltx_cfg_ctxt_comm_buff->cfg_badr_tx_cmpl_flag =
+		(unsigned int)MPE_TX_COML_ADDR(DLTX_TX_CMPL_FLAG_OFFSET);
+	dltx_cfg_ctxt_comm_buff->cfg_badr_tx_cmpl_buf =
+		(unsigned int)MPE_TX_COML_ADDR(DLTX_TX_CMPL_MSG_OFFSET);
+	dltx_cfg_ctxt_comm_buff->cfg_num_tx_cmpl_buf = MAX_TX_COMP_MAX;
+
+	/* Reset statictisc MIB */
+	memset((void *)MPE_TX_ADDR(DLTX_DATA_MIB_OFFSET),
+		0x0,
+		sizeof(dltx_data_mib_t));
+	/* Reset VAP MIB */
+	memset((void *)MPE_TX_ADDR(DLTX_VAP_DATA_MIB_OFFSET(0)),
+		0x0,
+		sizeof(dltx_vap_data_mib_t) * MAX_DTLK_NUM);
+
+	dltx_cfg_ctxt_frag_data =
+		(dltx_cfg_ctxt_frag_data_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_FRAG_DATA_OFFSET);
+	dltx_cfg_ctxt_frag_data->frag_data_badr =
+		(unsigned int)MPE_TX_ADDR(DLTX_FRAG_DATA_OFFSET);
+	dltx_cfg_ctxt_frag_data->frag_data_num = 4096;
+
+	dltx_cfg_ctxt_tx_msg =
+		(dltx_cfg_ctxt_tx_msg_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_TX_MSG_OFFSET);
+	dltx_cfg_ctxt_tx_msg->cfg_size_tx_header = SIZE_TXHEADER;
+
+	/*GRX350: the header for transmit should be intialized by MPE FW TX itself
+	* becase packet will be get from CBM, driver does not pre-allocate buffer
+	*/
+
+	/* HTT_TXDES defined in PPE spec
+	 * 5 HTT_TXDES template. each for one VAP (equal vdev_id ??)
+	 * HTT_TXDES has 8 DWORD. DWORD0 is 0x0, DWORD1 DWORD2 DWORD3 DWORD4
+	 * SIZE_HTT_TXDES info in DWORD1 DWORD2 DWORD3 DWORD4
+	 */
+	BADR_HTT_TXDES = (uint32_t)MPE_TX_ADDR(HTT_TX_DES_OFFSET(0));
+
+	for (i = 0; i < NUM_HTT_TXDES; i++) {
+		/* 32 or 16 <by default> */
+		bufptr = (char *)(BADR_HTT_TXDES + (i * LEN_HTT_TXDES));
+		memset(bufptr, 0x0, 4);
+		memcpy(bufptr + 4, offload_tx_desc_t, SIZE_HTT_TXDES);
+	}
+	/* 512 or 4096 */
+	for (i = 0; i < NUM_CE4DES; i++) {
+		bufptr = (char *)(BADR_CE4DES + (i * SIZE_CE4DES));
+		memcpy(bufptr, offload_tx_src_ring_desc_t, SIZE_CE4DES);
+	}
+
+	return (uint32_t)BADR_CE4DES;
+}
+EXPORT_SYMBOL(ppa_dl_qca_h2t_ring_init);
+
+
+uint32_t ppa_dl_qca_cpu_h2t_ring_init(uint32_t h2tCpuMsgRingSize,
+	uint32_t entrySize,
+	uint32_t flags
+	)
+{
+	dma_addr_t phy_addr;
+	dltx_cpu_ce4des_format_t *dltx_cpu_ce4des_format;
+	dltx_cfg_ctxt_cpu_ce4des_t *dltx_cfg_ctxt_cpu_ce4des;
+
+	dtlk_debug(DBG_INIT, "%s: ringsize[%d] entrysize[%d]\n", __func__, h2tCpuMsgRingSize, entrySize);
+	if ((h2tCpuMsgRingSize == 0x0) || (entrySize == 0x0))
+		return PPA_FAILURE;
+	if (h2tCpuMsgRingSize > 128)
+		return PPA_FAILURE;
+	dltx_cpu_ce4des_format =
+		(dltx_cpu_ce4des_format_t *)MPE_TX_COML_ADDR(DLTX_CPU_CE4DES_FORMAT_OFFSET);
+
+	dltx_cfg_ctxt_cpu_ce4des =
+		(dltx_cfg_ctxt_cpu_ce4des_t *)MPE_TX_COML_ADDR(DLTX_CFG_CTXT_CPU_CE4DES_OFFSET);
+	dltx_cfg_ctxt_cpu_ce4des->cfg_num_cpu_ce4 = h2tCpuMsgRingSize;
+	phy_addr = dma_map_single(
+				g_mpe_dev,
+				(void *)dltx_cpu_ce4des_format,
+				128 * 2 * 4,
+				DMA_FROM_DEVICE
+				);
+	if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+		dtlk_debug(DBG_ERR, "%s: DMA error", __func__);
+	}
+	/*dma_unmap_single(
+				g_mpe_dev,
+				phy_addr,
+				4,
+				DMA_FROM_DEVICE
+				);*/
+	dtlk_debug(DBG_INIT, "%s: return 0x%x %p h2tCpuMsgRingSize[%d]n",
+		__func__,
+		phy_addr,
+		dltx_cpu_ce4des_format,
+		h2tCpuMsgRingSize);
+	return phy_addr;
+}
+EXPORT_SYMBOL(ppa_dl_qca_cpu_h2t_ring_init);
+
+/** Function: ppa_dl_qca_cpu_h2t_ring_get_write_idx
+* Purpose: Get write index of MPE FW TX
+* Argument:
+*	 flags - unit32_t, not use
+* Return: None
+*/
+int32_t ppa_dl_qca_cpu_h2t_ring_get_write_idx(
+	uint32_t flags
+	)
+{
+	dltx_cfg_ctxt_cpu_ce4des_t *dltx_cfg_ctxt_cpu_ce4des
+			= (dltx_cfg_ctxt_cpu_ce4des_t *)MPE_TX_COML_ADDR(DLTX_CFG_CTXT_CPU_CE4DES_OFFSET);
+	return dltx_cfg_ctxt_cpu_ce4des->cpu_ce4_write_index;
+}
+EXPORT_SYMBOL(ppa_dl_qca_cpu_h2t_ring_get_write_idx);
+typedef dma_addr_t CE_addr_t;
+
+struct CE_src_desc {
+	CE_addr_t src_ptr;
+	u_int32_t	meta_data:12,
+				target_int_disable:1,
+				host_int_disable:1,
+				byte_swap:1,
+				gather:1,
+				nbytes:16;
+};
+
+/** Function: ppa_dl_qca_cpu_h2t_ring_write_msg
+* Purpose: Write message from CPU to MPE FW TX buffer
+* Argument:
+* Return: Current MPE FW TX write index.
+*/
+int32_t ppa_dl_qca_cpu_h2t_ring_write_msg(
+	uint32_t writeIndex,
+	uint32_t *msgPtr,
+	uint32_t msgLen,
+	uint32_t next_writeIndex,
+	uint32_t flags)
+{
+	dltx_cpu_ce4des_format_t *bufptr;
+	struct CE_src_desc *my_test;
+	dltx_cpu_ce4des_format_t *dltx_cpu_ce4des_format;
+	dltx_cfg_ctxt_cpu_ce4des_t *dltx_cfg_ctxt_cpu_ce4des =
+		(dltx_cfg_ctxt_cpu_ce4des_t *)MPE_TX_COML_ADDR(DLTX_CFG_CTXT_CPU_CE4DES_OFFSET);
+	dltx_cpu_ce4des_format =
+		(dltx_cpu_ce4des_format_t *)MPE_TX_COML_ADDR(DLTX_CPU_CE4DES_FORMAT_OFFSET);
+	if ((msgPtr == NULL) || (msgLen == 0x0))
+		return PPA_FAILURE;
+	my_test = (struct CE_src_desc *)msgPtr;
+	bufptr = dltx_cpu_ce4des_format + writeIndex;
+	dtlk_debug(DBG_CPU, "writeIndex[%d] bufprt[0x%p] msgLen[%d]\n", writeIndex, bufptr, msgLen);
+	/* descriptor is 2 DWs */
+	memcpy((char *)bufptr, (char *)msgPtr, msgLen);
+	dltx_cfg_ctxt_cpu_ce4des->cpu_ce4_write_index = next_writeIndex;
+	ppa_dl_dre_dma_writeback((unsigned int)bufptr, msgLen);
+	/*dtlk_debug(DBG_INIT, "           src_ptr[0x%x] nbytes[0x%x]\n",
+		my_test->src_ptr,
+		my_test->nbytes);*/
+	ppa_dl_dre_dma_writeback(KSEG0 | (0x0fffffff & my_test->src_ptr), my_test->nbytes);
+	return writeIndex;
+}
+EXPORT_SYMBOL(ppa_dl_qca_cpu_h2t_ring_write_msg);
+
+#define DRIVER_FREE_TX_COMPLETION 1
+
+struct qca_offload_tx_release_t {
+	uint8_t reserved1;
+	uint8_t num_msdus;
+	uint16_t reserved0;
+	uint16_t msdu_ids[129*2];
+};
+#ifdef DRIVER_FREE_TX_COMPLETION
+
+extern int cbm_buffer_free(uint32_t pid, uint32_t v_buf, uint32_t flag);
+/*extern int cbm_buffer_free_hw(uint32_t pid, uint32_t v_buf, uint32_t flag);*/
+
+void ppa_dl_dre_dma_invalidate1(
+	unsigned int startAddr,
+	unsigned int size
+	);
+
+#endif
+
+#define DL_FW_COMP_TRIES 10
+#define DL_FW_COMP_SLEEP 10000000
+#define DL_DBG_INVALIDATE_PACKETID 1
+void dl_sleep(unsigned int sleepCount)
+{
+	unsigned int i = 0;
+	for (i = 0; i < sleepCount; i++)
+		;
+}
+
+#if DTLK_DEBUG_TX_COMPLETION
+static int dtlk_dbg_tx_completion(int packetid, unsigned int pointer)
+{
+	dltx_packet_id_trace_circular_list_t *dltx_packet_id_trace_circular_list =
+		(dltx_packet_id_trace_circular_list_t *)MPE_TX_ADDR(DLTX_PACKET_ID_TRACE_CIRCULAR_LIST_OFFSET);
+	dltx_packet_id_trace_circular_list += (packetid - 1);
+	dltx_packet_id_trace_circular_list->tx_completion_count++;
+	dltx_packet_id_trace_circular_list->tx_completion_ptr[dltx_packet_id_trace_circular_list->tx_completion_count_idx] = pointer;
+	/* pr_err("%s: trace %d %p %p\n", __func__, packetid, pointer, dltx_packet_id_trace_circular_list);
+	*/
+	if (dltx_packet_id_trace_circular_list->tx_completion_count != dltx_packet_id_trace_circular_list->tx_count
+		/* || (dltx_packet_id_trace_circular_list->tx_completion_ptr )!= dltx_packet_id_trace_circular_list->tx_ptr
+		*/
+		) {
+		dtlk_debug(DBG_ERR, "====================ERROR:id[%d][%p]===============\n", packetid, (void *)pointer);
+		dtlk_debug(DBG_ERR, "\t\t\t:debug pointer[%p][[%d][%d][%p]]===============\n",
+			dltx_packet_id_trace_circular_list,
+			dltx_packet_id_trace_circular_list->tx_count,
+			dltx_packet_id_trace_circular_list->tx_completion_count,
+			(void *)dltx_packet_id_trace_circular_list->tx_ptr);
+		/* *(MPE_TX_ADDR(DLTX_PACKET_ID_TRACE_CIRCULAR_LIST_OFFSET) - 1) = 0xdeafbeef; stop TX */
+		return 1;/* print, do not exit */
+	} else {
+		dltx_packet_id_trace_circular_list->tx_completion_count_idx++;
+		if (dltx_packet_id_trace_circular_list->tx_completion_count_idx == DTLK_DEBUG_TX_COMPLETION_NUM - 4)
+			dltx_packet_id_trace_circular_list->tx_completion_count_idx = 0;
+	}
+	return 0;
+}
+#endif
+
+/** Function: ppa_dl_dre_txpkt_buf_release
+* Purpose: DLRX FW release buffer to PPE FW after receive
+*	 the TX complete message.
+* Not use anymore, TX will do it.
+*/
+int32_t ppa_dl_dre_txpkt_buf_release (
+	uint32_t num_msdus,
+	uint32_t *msg,
+	uint32_t flags
+	)
+{
+	int i;
+	struct qca_offload_tx_release_t *offload_tx;
+	dltx_tx_cmpl_msg_t *dltx_tx_cmpl_msg;
+	dltx_tx_cmpl_flag_t *dltx_tx_cmpl_flag;
+#ifndef DRIVER_FREE_TX_COMPLETION
+	int j;
+	int tries = DL_FW_COMP_TRIES;
+#endif
+	/* sanity check */
+	if (msg == NULL || !num_msdus) {
+		dtlk_debug(DBG_ERR, "------Invalid argument for releasing [0x%p] [%d]------\n", msg, num_msdus);
+		return PPA_FAILURE;
+	}
+	if (num_msdus > 64) {
+		dtlk_debug(DBG_ERR, "------Number of msdus is too big [0x%p] msdus[%d]------\n", msg, num_msdus);
+		num_msdus = 64;
+	}
+	/* find free slot */
+	offload_tx = (struct qca_offload_tx_release_t *)msg;
+	/* sanity check */
+	if (offload_tx == NULL)
+		return PPA_FAILURE;
+#ifndef DRIVER_FREE_TX_COMPLETION
+	/*rmb();*/
+	while (tries--) {
+		dltx_tx_cmpl_flag = (dltx_tx_cmpl_flag_t *)(MPE_TX_COML_ADDR(DLTX_TX_CMPL_FLAG_OFFSET));
+		dltx_tx_cmpl_msg = (dltx_tx_cmpl_msg_t *)(MPE_TX_COML_ADDR(DLTX_TX_CMPL_MSG_OFFSET));
+		for (i = 0; i < MAX_TX_COMP_MAX; i++) {
+			if (!dltx_tx_cmpl_flag->cmpl_status) {
+				/* copy the contain to the buffer */
+				dltx_tx_cmpl_msg = dltx_tx_cmpl_msg + i;
+				dltx_tx_cmpl_msg->num_pb_ptr_to_release = num_msdus;
+				memcpy(dltx_tx_cmpl_msg->free_txpb_ptr,
+					offload_tx->msdu_ids,
+					512 /*128*4*/
+					);
+				/*
+				if (num_msdus > 1){
+					dtlk_debug(DBG_TX, "%s: free at %d with num_msdus[%d]\n", __func__, i, num_msdus);
+					for(j = 0; j < (num_msdus + 1) / 2; j++){
+						dtlk_debug(DBG_TX, "%s: offload_tx[%d]",
+						__func__,
+						(offload_tx->msdu_ids[j] << 16) + offload_tx->msdu_ids[j+1]);
+						dtlk_debug(DBG_TX, "    packet_id[%08x]",
+						dltx_tx_cmpl_msg->free_txpb_ptr[j]);
+					}
+				}
+				*/
+				/* occupy this */
+				dltx_tx_cmpl_flag->cmpl_status = 1;
+				wmb();
+				break;
+			}
+			dltx_tx_cmpl_flag++;
+		}
+		ppa_dl_qca_ipi_interrupt();
+		if (i == MAX_TX_COMP_MAX) {
+			dtlk_debug(DBG_ERR, "------Too busy: cannot release------\n");
+			dl_sleep(DL_FW_COMP_SLEEP);
+			continue;
+		} else {
+			break;
+		}
+	}
+	if (!tries) {
+		dtlk_debug(DBG_ERR, "**************Error, cannot free***************\n");
+	}
+#else
+	dltx_tx_cmpl_flag = (dltx_tx_cmpl_flag_t *)(MPE_TX_COML_ADDR(DLTX_TX_CMPL_FLAG_OFFSET));
+	dltx_tx_cmpl_msg = (dltx_tx_cmpl_msg_t *)(MPE_TX_COML_ADDR(DLTX_TX_CMPL_MSG_OFFSET));
+	if (num_msdus) {
+		int current_write_index;
+		#ifdef DL_DBG_INVALIDATE_PACKETID
+		int old_write_index;
+		#endif
+		int numberOfFree = 0;
+		int previous_release = 0;
+		dltx_cfg_ctxt_circular_list_t *dltx_cfg_ctxt_circular_list
+		#ifdef DTLK_FIX_CACHE_COHENRENT
+			= (dltx_cfg_ctxt_circular_list_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_CIRCULAR_LIST_LINUX_OFFSET);
+		#else /* DTLK_FIX_CACHE_COHENRENT */
+			= (dltx_cfg_ctxt_circular_list_t *)MPE_TX_ADDR(DLTX_CFG_CTXT_CIRCULAR_LIST_OFFSET);
+		#endif /* DTLK_FIX_CACHE_COHENRENT */
+		dltx_circular_list_t *dltx_circular_list
+			= (dltx_circular_list_t *)MPE_TX_ADDR(DLTX_CIRCULAR_LIST_OFFSET);
+		struct qca_offload_tx_release_t *qca_tx_completion;
+		dltx_buffer_pointer_table_t *tx_pointer_table =
+			(dltx_buffer_pointer_table_t *)MPE_TX_ADDR(DLTX_BUFFER_POINTER_TABLE_OFFSET);
+		#ifdef DLTX_UNCACHED
+		dltx_cfg_ctxt_circular_list =
+			(dltx_cfg_ctxt_circular_list_t *)KSEG1ADDR(dltx_cfg_ctxt_circular_list);
+		#endif/* DLTX_UNCACHED	*/
+		current_write_index = dltx_cfg_ctxt_circular_list->circular_list_write_index;
+		#ifdef DL_DBG_INVALIDATE_PACKETID
+		old_write_index = current_write_index;
+		#endif
+		previous_release = dltx_cfg_ctxt_circular_list->_dw_res0[0];
+		qca_tx_completion = (struct qca_offload_tx_release_t *)msg;
+		/*
+		if (num_msdus > 1) {
+			dtlk_debug(DBG_TX, "Number of msdus: %d\n", num_msdus);
+		}
+		*/
+		for (i = 0; i < num_msdus; i++) {
+			dltx_buffer_pointer_table_t *tx_pointer_table_temp = NULL;
+			dltx_circular_list_t *dltx_circular_list_temp = NULL;
+			int tx_id = 0;
+			if ((i % 2) == 0)
+				tx_id = qca_tx_completion->msdu_ids[i+1];
+			else
+				tx_id = qca_tx_completion->msdu_ids[i-1];
+			/*get buffer pointer*/
+			tx_pointer_table_temp = tx_pointer_table;
+			tx_pointer_table_temp += (tx_id - 1);
+			tx_pointer_table_temp =
+	#ifdef DLTX_UNCACHED
+				(dltx_buffer_pointer_table_t *)KSEG1ADDR(tx_pointer_table_temp);
+				#else
+				(dltx_buffer_pointer_table_t *)(tx_pointer_table_temp);
+				#endif
+			/*
+			if (num_msdus > 1) {
+				dtlk_debug(DBG_TX, "    F: packet_id[%d] ptr[0x%08x] value[0x%08x]: write_index[%d]\n", tx_id, tx_pointer_table_temp, tx_pointer_table_temp->pointer_address, current_write_index);
+			}
+			*/
+			/*dltx_cfg_ctxt_circular_list = KSEG1ADDR(dltx_cfg_ctxt_circular_list);*/
+			/*dtlk_debug(DBG_TX, "%s: free tx id[%d] at 0x%08x pointer[0x%08x] read[%d]\n",
+			__func__,
+			tx_id,
+			tx_pointer_table,
+			tx_pointer_table->pointer_address,
+			dltx_cfg_ctxt_circular_list->circular_list_read_index);*/
+			/*ppa_dl_dre_dma_invalidate1(tx_pointer_table,32);*/
+#if DTLK_DEBUG_TX_COMPLETION
+			if (dtlk_dbg_tx_completion(tx_id, tx_pointer_table_temp->pointer_address)) {
+				/* break; */
+				dtlk_debug(DBG_ERR, "\tdon't break\n");
+			}
+#endif
+			if (tx_pointer_table_temp->pointer_address) {
+				/*free buffer first*/
+				#if 1
+				if (cbm_buffer_free(smp_processor_id(), tx_pointer_table_temp->pointer_address, 0) == -1) {
+					dtlk_debug(DBG_ERR, "CMB Pointer: [0x%08x] at id[%d] failed!Num[%d]\n", tx_pointer_table_temp->pointer_address, tx_id, num_msdus);
+				}
+				#else
+				if (cbm_buffer_free_hw(smp_processor_id(), tx_pointer_table_temp->pointer_address, 0) == -1) {
+					dtlk_debug(DBG_ERR, "CMB Pointer: [0x%08x] at id[%d] failed!Num[%d]\n", tx_pointer_table_temp->pointer_address, tx_id, num_msdus);
+				}
+				#endif
+				/*update free packet index to circular list*/
+				dltx_circular_list_temp = dltx_circular_list;
+				dltx_circular_list_temp += current_write_index;
+				dltx_circular_list_temp =
+				#ifdef DLTX_UNCACHED
+					(dltx_circular_list_t *)KSEG1ADDR(dltx_circular_list_temp);
+					#else
+					(dltx_circular_list_t *)(dltx_circular_list_temp);
+					#endif
+				dltx_circular_list_temp->packet_id = tx_id;
+				#ifdef DL_DBG_INVALIDATE_PACKETID
+				dltx_circular_list_temp =
+					(dltx_circular_list_t *)CACHE_ADDR(dltx_circular_list_temp);
+				dltx_circular_list_temp->packet_id = tx_id;
+				#endif
+				/*update write index*/
+				current_write_index++;
+				if (current_write_index >= dl_param_tx_descriptor) /* dltx_cfg_ctxt_circular_list->circular_list_num) */
+					current_write_index = 0;
+				/*update consume index*/
+				#if 0
+				dltx_cfg_ctxt_circular_list = KSEG1ADDR(dltx_cfg_ctxt_circular_list);
+				if (dltx_cfg_ctxt_circular_list->consumed_pkt_ids)
+					dltx_cfg_ctxt_circular_list->consumed_pkt_ids--;
+				else
+					dtlk_debug(DBG_ERR, "%s: problem!why free when consume is 0 num_msdus[%d]\n", __func__, num_msdus);
+				#else
+				numberOfFree++;
+				#endif
+
+
+			} else {
+				dtlk_debug(DBG_ERR, "%s: problem! NULL at [%d] num_msdus[%d]\n", __func__, tx_id, num_msdus);
+			}
+		}
+		if (dltx_cfg_ctxt_circular_list->_dw_res0[1] > previous_release)
+			dtlk_debug(DBG_ERR, "%s: %x %x %x ====DUC==== MEMORY CORRUPTION\n", __func__,
+				previous_release,
+				dltx_cfg_ctxt_circular_list->_dw_res0[1],
+				numberOfFree);
+		dltx_cfg_ctxt_circular_list->_dw_res0[1] = previous_release;
+		dltx_cfg_ctxt_circular_list->_dw_res0[2] = numberOfFree;
+		dltx_cfg_ctxt_circular_list->_dw_res0[0] = previous_release + numberOfFree;
+		dltx_cfg_ctxt_circular_list->circular_list_write_index = current_write_index;
+		/*ppa_dl_dre_dma_writeback(MPE_TX_ADDR(DLTX_CFG_CTXT_CIRCULAR_LIST_OFFSET),
+			sizeof(dltx_cfg_ctxt_circular_list_t));*/
+		/*wmb();*/
+	}
+#endif
+	/*dtlk_debug(DBG_TX, "%s: trigger IPI\n", __func__);*/
+	/* trigger IPI interrupt */
+	/*ppa_dl_qca_ipi_interrupt();*/
+	return PPA_SUCCESS;
+}
+EXPORT_SYMBOL(ppa_dl_dre_txpkt_buf_release);
+
+
+/** Function: ppa_dl_qca_get_vap_stats
+* Purpose: Get the VAP status
+* Argument:
+* Return: PPA_FAILURE or PPA_SUCCESS
+*/
+uint32_t ppa_dl_qca_get_vap_stats(
+	uint32_t vapId,
+	PPA_WLAN_VAP_Stats_t *vapStats,
+	uint32_t flags
+	)
+{
+	/* TODO : should get from DRLX buffer */
+	dtlk_debug(DBG_CPU, "%s: vapId[%u] [%p]\n", __func__, vapId, ddr_base);
+	if ((vapStats == NULL)
+		|| (vapId > MAX_VAPID)
+		) {
+		dtlk_debug(DBG_ERR, "Invalid vapID[%u]\n", vapId);
+		return PPA_FAILURE;
+	} else {
+		dltx_vap_data_mib_t *vap_mib_tx =
+				(dltx_vap_data_mib_t *)MPE_TX_ADDR(DLTX_VAP_DATA_MIB_OFFSET(vapId));
+
+		volatile vap_data_mib_t *vap_mib_rx =
+				(vap_data_mib_t *)DLRX_VAP_MIB_BASE(vapId);
+		uint64_t rxpdu = (uint64_t)vap_mib_rx->rx_rcv_pdu_low +
+			(((uint64_t)vap_mib_rx->rx_rcv_pdu_high) << 32);
+		uint64_t rxbytes = (uint64_t)vap_mib_rx->rx_rcv_bytes_low +
+			(((uint64_t)vap_mib_rx->rx_rcv_bytes_high) << 32);
+
+		uint64_t txpdu = (uint64_t)vap_mib_tx->txpdu_low +
+			(((uint64_t)vap_mib_tx->txpdu_high) << 32);
+		uint64_t txbytes = (uint64_t)vap_mib_tx->txbytes_low +
+			(((uint64_t)vap_mib_tx->txbytes_high) << 32);
+		vapStats->txdrop = vap_mib_tx->txdrop_low;
+		dtlk_debug(DBG_CPU, "%s: RX [%llu]\n", __func__, rxbytes);
+		/* get tx vap mib */
+		vapStats->txpdu = txpdu;
+		vapStats->txbytes = txbytes;
+		/* get rx vap mib */
+		vapStats->rx_rcv_pdu = rxpdu;
+		vapStats->rx_rcv_bytes = rxbytes;
+		vapStats->rx_discard_pdu = vap_mib_rx->rx_discard_pdu_low;
+		vapStats->rx_discard_bytes = vap_mib_rx->rx_discard_bytes_low;
+		vapStats->rx_fwd_pdu = vap_mib_rx->rx_fwd_pdu_low;
+		vapStats->rx_fwd_bytes = vap_mib_rx->rx_fwd_bytes_low;
+		vapStats->rx_inspect_pdu = vap_mib_rx->rx_inspect_pdu_low;
+		vapStats->rx_inspect_bytes = vap_mib_rx->rx_inspect_bytes_low;
+		vapStats->rx_pn_pdu = vap_mib_rx->rx_pn_pdu_low;
+		vapStats->rx_pn_bytes = vap_mib_rx->rx_pn_bytes_low;
+		vapStats->rx_drop_pdu = vap_mib_rx->rx_drop_pdu_low;
+		vapStats->rx_drop_bytes = vap_mib_rx->rx_drop_bytes_low;
+
+		dtlk_debug(DBG_CPU, "%s: vapId[%d] data returned:\n",
+			__func__,
+			vapId);
+		dtlk_debug(DBG_CPU, "RX[%llu] TX[%llu]\n",
+			vapStats->rx_rcv_bytes,
+			vapStats->txbytes);
+
+
+		return PPA_SUCCESS;
+	}
+	return PPA_FAILURE;
+}
+EXPORT_SYMBOL(ppa_dl_qca_get_vap_stats);
+/** Funtion: dtlk_id_from_subif
+* Purpose: Get
+*/
+int dtlk_get_radio_id_from_subif(
+	PPA_SUBIF *subIf
+	)
+{
+	int i;
+	/* sanity check */
+	if (!subIf)
+		return -1;
+	for (i = 0; i < MAX_RADIO_NUM; i++) {
+		if ((g_ppe_radio[i].flags & PPE_DTLK_VALID)
+				&& (g_ppe_radio[i].dl_sub_if.port_id ==
+					subIf->port_id))
+				return i;
+	}
+	return -1;
+}
+
+unsigned int ppa_dl_dre_get_sram_addr(void)
+{
+	return (unsigned int)cfg_ctxt_base;
+}
+EXPORT_SYMBOL(ppa_dl_dre_get_sram_addr);
+
+unsigned int ppa_dl_dre_get_kseg0(void)
+{
+	return KSEG0;
+}
+EXPORT_SYMBOL(ppa_dl_dre_get_kseg0);
+
+unsigned int ppa_dl_dre_get_kseg1(void)
+{
+	return KSEG1;
+}
+EXPORT_SYMBOL(ppa_dl_dre_get_kseg1);
+
+
+void ppa_dl_dre_dma_invalidate(
+	unsigned int startAddr,
+	unsigned int size
+	)
+{
+	#if 1
+	dma_addr_t phy_addr;
+	/*if (startAddr < KSEG0){
+		startAddr = 	KSEG1ADDR(startAddr);
+	} */
+	/*dtlk_debug(DBG_RX, "%s: invalidate 0x%x size[%d]\n",
+		__func__,
+		startAddr,
+		size
+		); */
+	if (!startAddr) {
+		dtlk_debug(DBG_ERR, "%s: rxpb_ptr is NULL\n", __func__);
+		return ;
+	}
+	if (g_mpe_dev) {
+		phy_addr = dma_map_single(g_mpe_dev,
+			(void *)startAddr,
+			size,
+			DMA_FROM_DEVICE
+			);
+		/*
+		dtlk_debug(DBG_RX, "%s:phy 0x%x\n", __func__, phy_addr); */
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "DMA address mapping error: buf: 0x%x, size: %d, dir: %d\n",
+			(u32)startAddr, size, DMA_FROM_DEVICE);
+			BUG();
+		}
+		/*
+		dma_unmap_single(g_mpe_dev,
+			phy_addr,
+			size,
+			DMA_FROM_DEVICE
+			); */
+	}
+	#else
+	dma_cache_inv(startAddr, size);
+	#endif
+}
+EXPORT_SYMBOL(ppa_dl_dre_dma_invalidate);
+void ppa_dl_dre_dma_invalidate1(
+	unsigned int startAddr,
+	unsigned int size
+	)
+{
+	#if 1
+	dma_addr_t phy_addr;
+	/*
+	if (startAddr < KSEG0){
+		startAddr = 	KSEG1ADDR(startAddr);
+	} */
+	/*dtlk_debug(DBG_RX, "%s: invalidate 0x%x size[%d]\n",
+		__func__,
+		startAddr,
+		size
+		); */
+	if (!startAddr) {
+		dtlk_debug(DBG_ERR, "%s: rxpb_ptr is NULL\n", __func__);
+		return ;
+	}
+	if (g_mpe_dev) {
+		phy_addr = dma_map_single(g_mpe_dev,
+			(void *)startAddr,
+			size,
+			DMA_FROM_DEVICE
+			);
+		/*
+		dtlk_debug(DBG_RX, "%s:phy 0x%x\n", __func__, phy_addr); */
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "DMA address mapping error: buf: 0x%x, size: %d, dir: %d\n",
+			(u32)startAddr, size, DMA_FROM_DEVICE);
+			BUG();
+		}
+		dma_unmap_single(g_mpe_dev,
+			phy_addr,
+			size,
+			DMA_FROM_DEVICE
+			);
+	}
+	#else
+	dma_cache_inv(startAddr, size);
+	#endif
+}
+
+inline void ppa_dl_dre_dma_writeback(
+	unsigned int startAddr,
+	unsigned int size
+	)
+{
+	#if 1
+	dma_addr_t phy_addr;
+	if (startAddr < KSEG0) {
+		startAddr = KSEG1ADDR(startAddr);
+	}
+	/*
+	dtlk_debug(DBG_RX, "%s: writeback 0x%x size[%d]\n",
+		__func__,
+		startAddr,
+		size
+		); */
+	if (!startAddr) {
+		dtlk_debug(DBG_ERR, "%s: rxpb_ptr is NULL\n", __func__);
+		return ;
+	}
+	if (g_mpe_dev) {
+		phy_addr = dma_map_single(g_mpe_dev,
+			(void *)startAddr,
+			size,
+			DMA_TO_DEVICE
+			);
+		/* dtlk_debug(DBG_RX, "%s:phy 0x%x\n", __func__, phy_addr); */
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "%s: DMA address mapping error: buf: 0x%x, size: %d, dir: %d\n",
+			__func__, (u32)startAddr, size, DMA_FROM_DEVICE);
+			BUG();
+		}
+		/*
+		dma_unmap_single(g_mpe_dev,
+			phy_addr,
+			size,
+			DMA_TO_DEVICE
+			); */
+	}
+	#else
+	dma_cache_wback((u32)startAddr, size);
+	#endif
+}
+EXPORT_SYMBOL(ppa_dl_dre_dma_writeback);
+
+
+inline void ppa_dl_dre_dma_wback_inv(
+	unsigned int startAddr,
+	unsigned int size
+	)
+{
+	#if 1
+	dma_addr_t phy_addr;
+	if (startAddr < KSEG0) {
+		startAddr = KSEG1ADDR(startAddr);
+	}
+	/*
+	dtlk_debug(DBG_RX, "%s: writeback 0x%x size[%d]\n",
+		__func__,
+		startAddr,
+		size
+		); */
+	if (!startAddr) {
+		dtlk_debug(DBG_ERR, "%s: rxpb_ptr is NULL\n", __func__);
+		return ;
+	}
+	if (g_mpe_dev) {
+		phy_addr = dma_map_single(g_mpe_dev,
+			(void *)startAddr,
+			size,
+			DMA_TO_DEVICE
+			);
+		/* dtlk_debug(DBG_RX, "%s:phy 0x%x\n", __func__, phy_addr); */
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "%s: DMA address mapping error: buf: 0x%x, size: %d, dir: %d\n",
+			__func__, (u32)startAddr, size, DMA_FROM_DEVICE);
+			BUG();
+		}
+		/*
+		dma_unmap_single(g_mpe_dev,
+			phy_addr,
+			size,
+			DMA_BIDIRECTIONAL
+			); */
+	}
+	#else
+	dma_cache_wback((u32)startAddr, size);
+	#endif
+}
+EXPORT_SYMBOL(ppa_dl_dre_dma_wback_inv);
+
+
+/** Funtion: dtlk_id_from_subif
+* Purpose: Get
+*/
+int dtlk_get_id_from_subif(
+	PPA_SUBIF *subIf
+	)
+{
+	int i;
+	int radio;
+	/* sanity check */
+	if (!subIf)
+		return -1;
+	radio = dtlk_get_radio_id_from_subif(subIf);
+	if (radio < 0 || radio >= MAX_RADIO_NUM) {
+		dtlk_debug(DBG_ERR, "%s:invalid id! if_id: %d",
+			__func__,
+			radio);
+		return -1;
+	}
+	for (i = 0; i < MAX_DTLK_NUM; i++) {
+		if ((g_ppe_radio[radio].g_ppe_dtlk_data[i].flags & PPE_DTLK_VALID)
+				&& (g_ppe_radio[radio].g_ppe_dtlk_data[i].dl_sub_if.port_id ==
+					subIf->port_id)
+				&& (g_ppe_radio[radio].g_ppe_dtlk_data[i].dl_sub_if.subif ==
+					subIf->subif)) {
+				return i;
+			}
+	}
+	return -1;
+}
+inline int dtlk_get_subif_from_vap_id(
+	PPA_SUBIF *subIf, int vap_id
+	)
+{
+	int radio;
+	/* sanity check */
+	if (!subIf)
+		return -1;
+	radio = dtlk_get_radio_id_from_subif(subIf);
+	if (radio < 0 || radio >= MAX_RADIO_NUM) {
+		dtlk_debug(DBG_ERR, "invalid radio: %d", radio);
+		return -1;
+	}
+	if (vap_id < 0 || vap_id >= MAX_DTLK_NUM) {
+		dtlk_debug(DBG_ERR, "Invalid VAP ID %d\n", vap_id);
+		return -1;
+	}
+	/*
+	dtlk_debug(DBG_INIT, "%s: vap_id[%d] port[%d] subif[%d]\n",
+		__func__,
+		vap_id,
+		gQuickRefSubIfFromVAPID[vap_id].port_id,
+		gQuickRefSubIfFromVAPID[vap_id].subif
+		); */
+	subIf->port_id = gQuickRefSubIfFromVAPID[vap_id].port_id;
+	subIf->subif = gQuickRefSubIfFromVAPID[vap_id].subif;
+	return 0;
+}
+
+/** Function: dltk_remove_quickrefsub
+* Purpose: remove sub interface entry in quick reference sub interface table
+* Argument: sub interface
+* Return: none. The entry in
+*/
+void dltk_remove_quickrefsub(PPA_SUBIF *subIf)
+{
+	int i = 0;
+	for (i = 0; i < MAX_DTLK_NUM; i++) {
+		if (gQuickRefSubIfFromVAPID[i].port_id == subIf->port_id &&
+			gQuickRefSubIfFromVAPID[i].subif == subIf->subif) {
+			gQuickRefSubIfFromVAPID[i].port_id = -1;
+			gQuickRefSubIfFromVAPID[i].subif = -1;
+		}
+	}
+}
+
+/** Function: dltk_update_radio
+* Purpose: update radio to datapath port(aka EP, aka port_id, aka pmac)
+*
+*/
+void dltk_update_radio_datapath_port(
+	unsigned radio_id,
+	unsigned vap_id,
+	PPA_SUBIF *subif,
+	unsigned int flag
+	)
+{
+	uint32_t *dltx_ep_radio_id
+		= (uint32_t *)g_dl_drv_address.dl_ep_2radio_addr;
+	dltx_qca_vap_id_map_t *dltx_qca_vap_id_map
+		= (dltx_qca_vap_id_map_t *)MPE_TX_ADDR(DLTX_QCA_VAP_ID_MAP_OFFSET);
+	dltx_ep_radio_id = dltx_ep_radio_id + subif->port_id;
+
+	dtlk_debug(DBG_INIT, "%s: radio_id[%d] vap_id[%d] subif->port_id[%d] subif->subif[%d]\n",
+		__func__, radio_id, vap_id, subif->port_id, subif->subif);
+	/* update subif to vap_id mapping */
+	dltx_qca_vap_id_map = dltx_qca_vap_id_map +
+		/*MAX_DTLK_NUM * subif->port_id + subif->subif;*/
+		subif->subif;
+	/* update port id */
+	/*if (flag & PPE_F_DTLK_REGISTER) {*/
+	if (flag & PPE_F_DTLK_DP_REGISTER) {
+		dtlk_debug(DBG_INIT, "%s: register\n", __func__);
+		*(dltx_ep_radio_id + radio_id) = radio_id;
+		dltx_qca_vap_id_map->qca_vap_id = vap_id;
+	} else {
+		dtlk_debug(DBG_INIT, "%s: deregister\n", __func__);
+		*(dltx_ep_radio_id + radio_id) = 0;
+		dltx_qca_vap_id_map->qca_vap_id = 0;
+	}
+}
+
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+
+#if defined(CONFIG_LANTIQ_MCAST_HELPER_MODULE) || defined(CONFIG_LANTIQ_MCAST_HELPER)
+typedef void (*Mcast_module_callback_t)(unsigned int grpidx,
+	struct net_device *netdev,
+	void *mc_stream,
+	unsigned int flag
+	);
+
+#endif
+
+
+int dl_m2c_add_peer(
+	uint32_t *mac_addr,
+	uint16_t peer_id,
+	uint16_t vap_id
+	)
+{
+	char *temp, *tempDL;
+	struct _dl_peer_mac_mapping_table *dl_m2c_table =
+		(struct _dl_peer_mac_mapping_table *)MPE_TX_ADDR(DLTX_CFG_CTXT_M2C_PEER_TABLE);
+	dtlk_debug(DBG_INIT, "======ADD: %d %d [%02x:%02x:%02x:%02x:%02x:%02x]\n",
+		peer_id, vap_id,
+		*(mac_addr),
+		*(mac_addr + 1),
+		*(mac_addr + 2),
+		*(mac_addr + 3),
+		*(mac_addr + 4),
+		*(mac_addr + 5)
+		);
+	if (peer_id >= MAX_PEER_NUM) {
+		dtlk_debug(DBG_ERR, "peer id is out of range %d\n", peer_id);
+		return DTLK_FAILURE;
+	}
+	if (mac_addr) {
+		dl_m2c_table = (dl_m2c_table + peer_id);
+		temp = (char *)(mac_addr);
+		tempDL = (char *)dl_m2c_table + 2;
+		memcpy((char *)tempDL, temp, 6);
+		dl_m2c_table->valid = 1;
+		dl_m2c_table->vap_id = vap_id;
+		return DTLK_SUCCESS;
+	}
+	dtlk_debug(DBG_ERR, "Invalid data %d\n", peer_id);
+	return DTLK_FAILURE;
+}
+int dl_m2c_find_peer(
+	unsigned char *peer_mac
+	);
+
+int dl_m2c_remove_peer(
+	uint32_t *mac_addr,
+	uint16_t peer_id,
+	uint16_t vap_id
+	)
+{
+	struct _dl_peer_mac_mapping_table *dl_m2c_table =
+		(struct _dl_peer_mac_mapping_table *)MPE_TX_ADDR(DLTX_CFG_CTXT_M2C_PEER_TABLE);
+	int peer_idx = 0;
+	dtlk_debug(DBG_INIT, "======REMOVE: %d %d [%02x:%02x:%02x:%02x:%02x:%02x]\n",
+		peer_id, vap_id,
+		*(mac_addr),
+		*(mac_addr + 1),
+		*(mac_addr + 2),
+		*(mac_addr + 3),
+		*(mac_addr + 4),
+		*(mac_addr + 5)
+		);
+#if 0
+	if (peer_id >= MAX_PEER_NUM) {
+		dtlk_debug(DBG_ERR, "peer id is out of range %d\n", peer_id);
+		return DTLK_FAILURE;
+	}
+	dl_m2c_table = (dl_m2c_table + peer_id);
+#else
+	peer_idx = dl_m2c_find_peer((unsigned char *)mac_addr);
+	if (peer_idx > -1) {
+		dl_m2c_table = (dl_m2c_table + peer_idx);
+		if (peer_idx != peer_id)
+			dtlk_debug(DBG_INIT, "REMOVE peer index[%d]#id[%d]\n",
+				peer_idx,
+				peer_id);
+	} else {
+		dtlk_debug(DBG_ERR, "Can not find peer id\n");
+		return DTLK_FAILURE;
+	}
+
+#endif
+	if (dl_m2c_table->valid) {
+		dl_m2c_table->valid = 0;
+		return DTLK_SUCCESS;
+	} else
+		dtlk_debug(DBG_ERR, "Peer is not valid %d\n", peer_id);
+
+	return DTLK_FAILURE;
+}
+
+int dl_m2c_find_peer(
+	unsigned char *peer_mac
+	)
+{
+	dtlk_debug(DBG_INIT, "%s %x:%x:%x:%x:%x:%x\n", __func__,
+		*peer_mac,
+		*(peer_mac + 1),
+		*(peer_mac + 2),
+		*(peer_mac + 3),
+		*(peer_mac + 4),
+		*(peer_mac + 5)
+		);
+	if (peer_mac) {
+		struct _dl_peer_mac_mapping_table *dl_m2c_table =
+		(struct _dl_peer_mac_mapping_table *)MPE_TX_ADDR(DLTX_CFG_CTXT_M2C_PEER_TABLE);
+		int i = 0;
+		char *temp = NULL;
+		for (i = 0; i < MAX_PEER_NUM; i++) {
+			if (dl_m2c_table->valid) {
+				temp = (char *)dl_m2c_table + 2;
+				if (!memcmp(peer_mac, temp, 6))
+					return i;
+			}
+			dl_m2c_table++;
+		}
+	}
+	dtlk_debug(DBG_ERR, "Can not find peer for %x:%x:%x:%x:%x:%x\n",
+		*peer_mac,
+		*(peer_mac + 1),
+		*(peer_mac + 2),
+		*(peer_mac + 3),
+		*(peer_mac + 4),
+		*(peer_mac + 5)
+		);
+	return -1;
+}
+void dl_dp_mcast_group_modify_bitmap(
+	unsigned int grpidx,
+	unsigned int peer_id,
+	unsigned int bSet
+	)
+{
+	dtlk_debug(DBG_INIT, "%s: Start 1 grpidx[%d] peer_id[%d] bSet[%d]\n", __func__, grpidx, peer_id, bSet);
+	if (grpidx < MAX_MCAST_GROUP &&
+		peer_id < MAX_PEER_NUM) {
+		int dwordOffset = peer_id / 32;
+		int bitmapOffset = peer_id % 32;
+		struct _dl_mcast_group_table *dl_mcast_group_table =
+			(struct _dl_mcast_group_table *)MPE_TX_ADDR(DLTX_CFG_CTXT_M2C_GROUP_TABLE);
+		dl_mcast_group_table += grpidx;
+		if (bSet) {
+			if ((dl_mcast_group_table->bitmap[dwordOffset]
+				& (1 << bitmapOffset)) == 0) {
+				dl_mcast_group_table->bitmap[dwordOffset] =
+					dl_mcast_group_table->bitmap[dwordOffset] | (1 << bitmapOffset);
+				dl_mcast_group_table->grpIdx++;
+				dl_mcast_group_table->valid = 1;
+			} else
+				dtlk_debug(DBG_INIT, "%s:peer id[%d] is already in multicast group[%d]\n", __func__, peer_id, grpidx);
+		} else {
+			dl_mcast_group_table->bitmap[dwordOffset] =
+				dl_mcast_group_table->bitmap[dwordOffset] & (~(1 << bitmapOffset));
+			if (dl_mcast_group_table->grpIdx > 0)
+				dl_mcast_group_table->grpIdx--;
+			if (dl_mcast_group_table->grpIdx == 0)
+				dl_mcast_group_table->valid = 0;
+		}
+	} else
+		dtlk_debug(DBG_ERR, "Invalid group index %d peer [%d]\n", grpidx, peer_id);
+	return;
+}
+int dl_dp_mcast_join(
+	unsigned int grpidx,
+	unsigned int peer_id,
+	unsigned int bJoin
+	)
+{
+	dtlk_debug(DBG_INIT, "%s: Start grpidx[%d] peer_id[%d] bJoin[%d]\n", __func__, grpidx, peer_id, bJoin);
+	if (grpidx < MAX_MCAST_GROUP) {
+		struct _dl_mcast_group_table *dl_mcast_group_table =
+			(struct _dl_mcast_group_table *)MPE_TX_ADDR(DLTX_CFG_CTXT_M2C_GROUP_TABLE);
+		dl_mcast_group_table += grpidx;
+		if (bJoin) {
+			dl_mcast_group_table->valid = 1;
+			dl_dp_mcast_group_modify_bitmap(grpidx, peer_id, 1);
+		} else
+			dl_dp_mcast_group_modify_bitmap(grpidx, peer_id, 0);
+	} else
+		dtlk_debug(DBG_ERR, "Invalid group index %d\n", grpidx);
+	return -1;
+}
+void dl_dp_mcast_cb(unsigned int grpidx,
+	struct net_device *netdev,
+	void *mc,
+	unsigned int flag
+	)
+{
+	int peer_id;
+	dtlk_debug(DBG_ERR, "%s: Start grpidx[%d] netdev[%s] flag[%d]\n", __func__, grpidx, netdev->name, flag);
+	if (mc) {
+		mcast_stream_t *mc_stream = (mcast_stream_t *)mc;
+		if (mc_stream->rx_dev && mc_stream->rx_dev->name)
+			dtlk_debug(DBG_INIT, "\tdev[%s]\n", mc_stream->rx_dev->name);
+		dtlk_debug(DBG_INIT, "\tdev[%x][%x][%x][%x][%x][%x]\n", mc_stream->macaddr[0],
+			mc_stream->macaddr[1],
+			mc_stream->macaddr[2],
+			mc_stream->macaddr[3],
+			mc_stream->macaddr[4],
+			mc_stream->macaddr[5]
+			);
+		dtlk_debug(DBG_INIT, "\tdev[%x][%x][%x][%x][%x][%x]\n", mc_stream->src_mac[0],
+			mc_stream->src_mac[1],
+			mc_stream->src_mac[2],
+			mc_stream->src_mac[3],
+			mc_stream->src_mac[4],
+			mc_stream->src_mac[5]
+			);
+		peer_id = dl_m2c_find_peer(mc_stream->macaddr);
+		switch (flag) {
+		case 1:
+			if (peer_id != -1) {
+				dl_dp_mcast_join(grpidx, peer_id, 1);
+			}
+			break;
+		case 2:
+			if (peer_id != -1) {
+				dl_dp_mcast_join(grpidx, peer_id, 0);
+			}
+			break;
+		default:
+			break;
+		}
+	}
+}
+
+
+int32_t dl_dp_register_mcast_module(
+	struct net_device *dev,
+	struct module *owner,
+	Mcast_module_callback_t cb,
+	unsigned int flags
+	)
+{
+    pr_info("[%s:%d] Entry [%s] [%d].\n", __func__, __LINE__, dev->name, flags);
+#if defined(CONFIG_LANTIQ_MCAST_HELPER_MODULE) || defined(CONFIG_LANTIQ_MCAST_HELPER)
+	mcast_helper_register_module(dev, owner, "DirectLink", (int32_t *)cb, flags);
+    pr_info("[%s:%d] Exit, returned 0.\n", __func__, __LINE__);
+	return DP_SUCCESS;
+#else /* #if defined(CONFIG_LANTIQ_MCAST_HELPER_MODULE) || defined(CONFIG_LANTIQ_MCAST_HELPER) */
+    pr_info("[%s:%d] Exit, returned -1.\n", __func__, __LINE__);
+	return DP_FAILURE;
+#endif /* #else */
+}
+
+#endif /* SUPPORT_MULTICAST_TO_UNICAST */
+
+int datapath_dtlk_register(
+	PPA_SUBIF *subIf,
+	PPA_DTLK_T *dtlk)
+{
+	int i;
+	int j;
+	int radio = -1;
+	struct ppe_radio_map *ppe_radio;
+
+	/* sanity check */
+	if (subIf == NULL || dtlk == NULL) {
+		dtlk_debug(DBG_ERR, "%s: invalid subif\n", __func__);
+		return PPA_EINVAL;
+	}
+	if (subIf->subif == -1) {
+		dtlk_debug(DBG_ERR, "%s: invalid subif value\n", __func__);
+		return PPA_EINVAL;
+	}
+	dtlk_debug(DBG_INIT, "%s: subIf->port_id[%d] subIf->subif[%d]\n", __func__, subIf->port_id, subIf->subif);
+	spin_lock_bh(&g_ppe_dtlk_spinlock);
+	/*if (dtlk->flags & PPE_F_DTLK_REGISTER) {*/
+	if (dtlk->flags & PPE_F_DTLK_DP_REGISTER) {
+		dtlk_debug(DBG_INIT, "%s: Register\n", __func__);
+		/* looking for free or right radio */
+		for (i = 0; i < MAX_RADIO_NUM; i++) {
+			if ((g_ppe_radio[i].flags & PPE_DTLK_VALID)
+				&& (g_ppe_radio[i].dl_sub_if.port_id == subIf->port_id)) {
+				ppe_radio = &g_ppe_radio[i];
+				for (j = 0; j < MAX_DTLK_NUM; j++) {
+					if (ppe_radio->g_ppe_dtlk_data[j].dl_sub_if.subif ==
+						subIf->subif) {
+						dtlk_debug(DBG_ERR, "Register duplicate wifi device: %s",
+							dtlk->dev->name);
+						goto err_exit;
+					}
+				}
+				radio = i;
+				dtlk_debug(DBG_INIT, "%s: Register: find valid radio[%d] with port[%d]\n", __func__, radio,
+				g_ppe_radio[i].dl_sub_if.port_id);
+			}
+			if (radio == -1 &&
+				((g_ppe_radio[0].flags &
+					PPE_DTLK_VALID) == 0)) {
+					dtlk_debug(DBG_INIT, "%s: Register: find free radio[%d]\n", __func__, i);
+				radio = i;
+			}
+		}
+		/* no free or don't match with existing datapath port */
+		if (radio == -1) {
+			dtlk_debug(DBG_ERR, "Register Fail, no more ports\n");
+			goto err_exit;
+		}
+		g_ppe_radio[radio].flags |= PPE_DTLK_VALID;
+		g_ppe_radio[radio].dl_sub_if.port_id = subIf->port_id;
+		dtlk_debug(DBG_INIT, "%s: Register: use free radio[%d] with port[%d]\n", __func__, radio, g_ppe_radio[radio].dl_sub_if.port_id);
+		ppe_radio = &(g_ppe_radio[radio]);
+		/* looking for free sub interface */
+		for (j = 0; j < MAX_DTLK_NUM; j++) {
+			if (ppe_radio->g_ppe_dtlk_data[j].dl_sub_if.subif ==
+				-1) {
+				dtlk_debug(DBG_INIT, "%s: Register: use free radio[%d] with sub[%d]\n", __func__,
+					radio,
+					j);
+				if (dtlk->dev)
+					g_ppe_radio[radio].g_ppe_dtlk_data[j].dev = (struct PPA_NETIF *)dtlk->dev;
+				else
+					dtlk_debug(DBG_ERR, "%s: DEV is NULL\n", __func__);
+				g_ppe_radio[radio].g_ppe_dtlk_data[j].vap_id = dtlk->vap_id;
+				ppe_radio->g_ppe_dtlk_data[j].dl_sub_if.port_id = subIf->port_id;
+				ppe_radio->g_ppe_dtlk_data[j].dl_sub_if.subif = subIf->subif;
+				/* update quick reference table */
+				gQuickRefSubIfFromVAPID[dtlk->vap_id].port_id = subIf->port_id;
+				gQuickRefSubIfFromVAPID[dtlk->vap_id].subif = subIf->subif;
+				g_ppe_radio[radio].g_ppe_dtlk_data[j].flags |= PPE_DTLK_VALID;
+				break;
+			}
+		 }
+		/*
+		dltk_update_radio_datapath_port(radio,
+			dtlk->vap_id,
+			&(gQuickRefSubIfFromVAPID[dtlk->vap_id]),
+			PPE_F_DTLK_REGISTER);
+			*/
+		dltk_update_radio_datapath_port(radio,
+			dtlk->vap_id,
+			&(gQuickRefSubIfFromVAPID[dtlk->vap_id]),
+			PPE_F_DTLK_DP_REGISTER);
+		if (dtlk->dev)
+			dtlk_debug(DBG_INIT, "%s: dtlk->dev->name[%s]\n", __func__, dtlk->dev->name);
+		else
+			dtlk_debug(DBG_ERR, "%s: wrong dtlk->dev is NULL\n", __func__);
+		if (set_vap_itf_tbl_fn)
+			set_vap_itf_tbl_fn(dtlk->vap_id, subIf->subif);
+		/* switch setting */
+		gsw_enable_ingress_port_remove(subIf->port_id);
+#if SUPPORT_MULTICAST_TO_UNICAST
+		/* register to mcast helper */
+		dl_dp_register_mcast_module(dtlk->dev,
+			 THIS_MODULE,
+			 dl_dp_mcast_cb,
+			 MC_F_REGISTER);
+#endif
+		} else {
+		/*looking for right radio with respective datapath port*/
+		dtlk_debug(DBG_INIT, "%s: DeRegister\n", __func__);
+		for (i = 0; i < MAX_RADIO_NUM; i++) {
+			if ((g_ppe_radio[i].flags & PPE_DTLK_VALID)
+				&& (g_ppe_radio[i].dl_sub_if.port_id == subIf->port_id)) {
+				radio = i;
+			}
+		}
+
+		if (radio == -1) {
+			dtlk_debug(DBG_ERR, "No record, deregistration failed\n");
+			goto err_exit;
+		}
+		ppe_radio = &g_ppe_radio[radio];
+		/* deregister VAP device */
+		for (j = 0; j < MAX_DTLK_NUM; j++) {
+			if (ppe_radio->g_ppe_dtlk_data[j].dl_sub_if.subif ==
+				subIf->subif) {
+				ppe_radio->g_ppe_dtlk_data[j].dev = NULL;
+				ppe_radio->g_ppe_dtlk_data[j].vap_id = -1;
+				ppe_radio->g_ppe_dtlk_data[j].flags &= (~PPE_DTLK_VALID);
+				ppe_radio->g_ppe_dtlk_data[j].dl_sub_if.port_id = -1;
+				ppe_radio->g_ppe_dtlk_data[j].dl_sub_if.subif = -1;
+				/* update quick reference table */
+				dltk_remove_quickrefsub(subIf);
+				break;
+			}
+		}
+		dltk_update_radio_datapath_port(radio,
+			dtlk->vap_id,
+			&(gQuickRefSubIfFromVAPID[dtlk->vap_id]),
+			PPE_F_DTLK_DEREGISTER);
+		if (set_vap_itf_tbl_fn)
+			set_vap_itf_tbl_fn(dtlk->vap_id, 0xF);
+#if defined(CONFIG_LANTIQ_MCAST_HELPER_MODULE) || defined(CONFIG_LANTIQ_MCAST_HELPER)
+		/* register to mcast helper */
+		dl_dp_register_mcast_module(dtlk->dev,
+			 THIS_MODULE,
+			 dl_dp_mcast_cb,
+			 MC_F_DEREGISTER);
+#endif
+	}
+	spin_unlock_bh(&g_ppe_dtlk_spinlock);
+
+	return PPA_SUCCESS;
+
+err_exit:
+	spin_unlock_bh(&g_ppe_dtlk_spinlock);
+
+	return PPA_EINVAL;
+}
+EXPORT_SYMBOL(datapath_dtlk_register);
+
+/** Function: dltx_data_structure_init
+* Purpose: Init DLTX data structure
+* Argument: None
+* Return: None.
+*	List of initialization: TX free buffer management.
+*
+*/
+int dltx_data_structure_init(void)
+{
+	memset((void *)g_dl_buf_info.tx_cfg_ctxt_buf_base,
+		0,
+		g_dl_buf_info.tx_cfg_ctxt_buf_size
+		);
+	/* init comm buffer */
+	memset((void *)g_dl_buf_info.comm_buf_base,
+		0,
+		g_dl_buf_info.comm_buf_size);
+	return DTLK_SUCCESS;
+}
+
+int dlrx_data_structure_init(void)
+{
+	unsigned int index;
+	struct sk_buff *new_skb;
+	unsigned int seqid;
+	unsigned int temp_ce5_buf_size;
+	unsigned int shift_size = 0;
+	dlrx_bufsize_t dlrx_bufnum;
+	/**************************************/
+	/* Pointer to various data structures with respect to config context
+	dlrx_cfg_ctxt_dma_t *dlrx_cfg_ctxt_dma_des_wlan_ptr;*/
+	/* dlrx_cfg_ctxt_dma_t *dlrx_cfg_ctxt_dma_des_gswip_ptr; */
+
+
+
+	dlrx_cfg_ctxt_cpu_ce5des_t *dlrx_cfg_ctxt_cpu_ce5des_ptr;
+	dlrx_ce5des_format_t *dlrx_ce5des_format_ptr;
+
+	dlrx_cfg_ctxt_ce5des_t *dlrx_cfg_ctxt_ce5des_ptr;
+	dlrx_cfg_ctxt_ce5buf_t *dlrx_cfg_ctxt_ce5buf_ptr;
+
+	dlrx_cfg_ctxt_rxpb_ptr_ring_t *dlrx_cfg_ctxt_rxpb_ptr_ring_ptr;
+
+	dlrx_cfg_ctxt_ro_mainlist_t *dlrx_cfg_ctxt_ro_mainlist_ptr;
+	dlrx_cfg_ctxt_ro_linklist_t *dlrx_cfg_ctxt_ro_linklist_ptr;
+
+	dlrx_cfg_ctxt_rxpb_ptr_rel_msgbuf_t *dlrx_cfg_ctxt_rxpb_ptr_rel_msgbuf_ptr;
+	dlrx_cfg_global_t *dlrx_cfg_global_ptr;
+
+	/** This is the reorder main list in DDR memory
+	* The starting of this	base address is stored in
+	* "dlrx_cfg_ctxt_ro_mainlist_t" structure. */
+	dlrx_ro_mainlist_t *dlrx_ro_mainlist_ptr;
+	dlrx_ro_linklist_t *dlrx_ro_linklist_ptr;
+
+	dlrx_rxpb_ptr_ring_t *dlrx_rxpb_ring_ptr;
+	dlrx_cfg_vap2int_map1_t *dlrx_cfg_vap2int_map1_ptr;
+	dlrx_cfg_vap2int_map2_t *dlrx_cfg_vap2int_map2_ptr;
+	dlrx_cfg_ctxt_rxpb_t *dlrx_cfg_ctxt_rxpb_ptr;
+
+	uint32_t *msg_buf_base;
+
+	/* The below base addresses will be used by FW */
+	dtlk_mem_base_get(NULL, (uint32_t *)&ddr_base);
+	if (!ddr_base) {
+		dtlk_debug(DBG_ERR, "No memory for DLRX\n");
+		return DTLK_FAILURE;
+	}
+	dtlk_mem_sram_base_get((uint32_t *)&cfg_ctxt_base);
+	if (!cfg_ctxt_base) {
+		ddr_base = 0;
+		dtlk_debug(DBG_ERR, "No memory for DLRX Context base\n");
+		return DTLK_FAILURE;
+	}
+	/* ddr_base = (unsigned int *)KSEG0ADDR(ddr_base); */
+
+	/* Set the memory range to 0 */
+	memset((void *)ddr_base, 0, g_dl_buf_info.rx_msgbuf_size);
+	memset((void *)cfg_ctxt_base, 0, g_dl_buf_info.rx_cfg_ctxt_buf_size);
+
+#ifdef SUPPORT_11AC_MULTICARD
+	if (ppa_dl_detect_11ac_card() ==  PEREGRINE_BOARD) {
+		g_dlrx_max_inv_header_len = MAX_INV_PEREGRINE_HEADER_LEN;
+		g_dlrx_cfg_offset_atten = QCA_PEREGRINE_11AC_CFG_OFFSET_ATTEN;
+	} else {
+		if (g11ACWirelessCardID_SUBTYPE == SUBTYPE_NONE_BOARD) {
+			g_dlrx_max_inv_header_len = MAX_INV_BEELINER_HEADER_LEN;
+			g_dlrx_cfg_offset_atten = QCA_BEELINER_11AC_CFG_OFFSET_ATTEN;
+		} else {
+			g_dlrx_max_inv_header_len = MAX_INV_CASCADE_HEADER_LEN;
+			g_dlrx_cfg_offset_atten = QCA_CASCADE_11AC_CFG_OFFSET_ATTEN;
+		}
+	}
+#else
+	g_dlrx_max_inv_header_len = MAX_INV_PEREGRINE_HEADER_LEN;
+	g_dlrx_cfg_offset_atten = QCA_PEREGRINE_11AC_CFG_OFFSET_ATTEN;
+#endif
+	/* Initializing the Length of data structure */
+	dlrx_init_buf_size(&dlrx_bufnum);
+	dlrx_cfg_ctxt_cpu_ce5des_ptr =
+		(dlrx_cfg_ctxt_cpu_ce5des_t *)DLRX_CFG_CTXT_CPU_CE5DES_BASE;
+	/* Initializing CPU CE5 Destination Ring Pointers
+	* ==> 2 * (1 * 8) DWORDS ( this CPU_CE5DES is in SB )
+	*/
+	dlrx_cfg_ctxt_cpu_ce5des_ptr->cfg_badr_cpu_ce5 =
+		(unsigned int)DLRX_DDR_CPU_CE5_DESC_BASE;
+	dlrx_cfg_ctxt_cpu_ce5des_ptr->cfg_num_cpu_ce5 =
+		dlrx_bufnum.cpu_ce5_desc_ring_num;
+	dlrx_cfg_ctxt_cpu_ce5des_ptr->cpu_ce5_read_index = 0;
+	dlrx_cfg_ctxt_cpu_ce5des_ptr->cpu_ce5_write_index = 1;
+	dlrx_cfg_ctxt_cpu_ce5des_ptr->cpu_ce5_msg_done = 1;
+
+	dlrx_cfg_ctxt_rxpb_ptr_rel_msgbuf_ptr =
+		(dlrx_cfg_ctxt_rxpb_ptr_rel_msgbuf_t *)DLRX_CFG_CTXT_RXPB_PTR_REL_MSGBUF_BASE;
+	/* Initializing RX PB Release Message Buffer
+	* ==> 2 * (2 * 128) DWORDS */
+	dlrx_cfg_ctxt_rxpb_ptr_rel_msgbuf_ptr->cfg_badr_rel_msgbuf =
+		(unsigned int)DLRX_DDR_RX_PKT_BUF_REL_MSG_BASE;
+	dlrx_cfg_ctxt_rxpb_ptr_rel_msgbuf_ptr->cfg_num_rel_msgbuf =
+		dlrx_bufnum.rx_pkt_buf_rel_msg_num;
+
+	dlrx_cfg_ctxt_rxpb_ptr =
+		(dlrx_cfg_ctxt_rxpb_t *)DLRX_CFG_CTXT_RXPB_BASE;
+	dlrx_cfg_ctxt_rxpb_ptr->cfg_offset_atten = 4;
+	dlrx_cfg_ctxt_rxpb_ptr->cfg_size_rxpktdes = g_dlrx_cfg_offset_atten;
+
+	dlrx_cfg_ctxt_rxpb_ptr_ring_ptr =
+		(dlrx_cfg_ctxt_rxpb_ptr_ring_t *)DLRX_CFG_CTXT_RXPB_PTR_RING_BASE;
+
+	/* Initializing RX PB Ring Ptr ===> 256 * (1 * 8) DWORDS */
+	dlrx_cfg_ctxt_rxpb_ptr_ring_ptr->cfg_badr_rxpb_ptr_ring =
+		(unsigned int)DLRX_DDR_RX_PKT_BUF_RING_BASE;
+	dlrx_cfg_ctxt_rxpb_ptr_ring_ptr->cfg_num_rxpb_ptr_ring =
+		dlrx_bufnum.rx_pkt_buf_ptr_ring_num;
+	dlrx_cfg_ctxt_rxpb_ptr_ring_ptr->rxpb_ptr_read_index = 0;
+	dlrx_cfg_ctxt_rxpb_ptr_ring_ptr->rxpb_ptr_write_index =
+		RX_PKT_BUF_PTR_RING_ALLOC_NUM - 1;
+	dlrx_rxpb_ring_ptr =
+		(dlrx_rxpb_ptr_ring_t *)DLRX_DDR_RX_PKT_BUF_RING_BASE;
+	/* initial 1024 -1 */
+	for (index = 0;
+		index < RX_PKT_BUF_PTR_RING_ALLOC_NUM;
+		index++) {
+		/* Initializing RX PB PTR ==> 4096 * (1 * 4) DWORDS */
+		new_skb = alloc_skb_rx();
+		if (new_skb == NULL)
+			return DTLK_FAILURE;
+		else {
+			dma_addr_t phy_addr;
+			#if 0
+			/* list_add((struct list_head *)new_skb, &g_rxbp_skblist); */
+			dma_cache_inv((u32)new_skb->data,
+				new_skb->end - new_skb->data
+				);
+			dlrx_rxpb_ring_ptr->rxpb_ptr =
+				CPHYSADDR((uint32_t)new_skb->data);
+			#else
+			phy_addr = dma_map_single(
+				g_mpe_dev,
+				#ifndef RX_NOT_SKB
+				(void *)new_skb->data,
+				new_skb->end - new_skb->data,
+				#else
+				(void *) ((unsigned char *)new_skb + 128),
+				1920,
+				#endif
+				DMA_FROM_DEVICE
+				);
+			if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+				dtlk_debug(DBG_ERR, "%s: DMA error\n", __func__);
+			}
+			/*dma_unmap_single(
+				g_mpe_dev,
+				phy_addr,
+				new_skb->end - new_skb->data,
+				DMA_FROM_DEVICE
+				);
+				*/
+			#endif
+			/*
+			dma_cache_inv((u32)new_skb->data,
+				new_skb->end - new_skb->data
+				);*/
+			dlrx_rxpb_ring_ptr->rxpb_ptr = phy_addr;
+			/* dtlk_debug(DBG_INIT, "%s: %x\n",__func__,new_skb); */
+			dlrx_rxpb_ring_ptr++;
+		}
+	}
+	/* This is message ring initialization */
+	dlrx_cfg_ctxt_ce5buf_ptr =
+		(dlrx_cfg_ctxt_ce5buf_t *)DLRX_CFG_CTXT_CE5BUF_BASE;
+	/* Initializing CE5 Buffers and Buffer format pointers
+	* ====> 4096 * 512 Bytes */
+	dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_ce5buf =
+		(unsigned int)DLRX_DDR_CE5BUF_BASE;
+	dlrx_cfg_ctxt_ce5buf_ptr->cfg_num_ce5buf =
+		dlrx_bufnum.ce5_dest_msg_buf_num;
+	dlrx_cfg_ctxt_ce5buf_ptr->cfg_size_ce5buf =
+		DLRX_CE5_DEST_BUF_SIZE;
+	temp_ce5_buf_size = DLRX_CE5_DEST_BUF_SIZE;
+
+	while (temp_ce5_buf_size != 1) {
+		shift_size++;
+		temp_ce5_buf_size >>= 1;
+	}
+	dlrx_cfg_ctxt_ce5buf_ptr->cfg_size_shift_ce5buf = shift_size;
+
+	/* initial msg buf type to 0xFF */
+	msg_buf_base = (uint32_t *)DLRX_DDR_CE5BUF_BASE;
+	for (index = 0;
+		index < dlrx_bufnum.ce5_dest_msg_buf_num;
+		index++) {
+		*(msg_buf_base + index * 512 / 4 + 2) = 0xFF;
+	}
+	/* Initializing Actual CE5 Descriptors format ====>4096 * 2 DWORDS */
+	/* This is ce5 descriptor initialization */
+	dlrx_ce5des_format_ptr = (dlrx_ce5des_format_t *)DLRX_DDR_CE5DESC_BASE;
+	for (index = 0; index < dlrx_bufnum.ce5_dest_msg_buf_num; index++) {
+		dlrx_ce5des_format_ptr->dest_ptr =
+			dma_map_single(
+			g_mpe_dev,
+			(void *)dlrx_cfg_ctxt_ce5buf_ptr->cfg_badr_ce5buf +
+			 (index << dlrx_cfg_ctxt_ce5buf_ptr->cfg_size_shift_ce5buf),
+			512,
+			DMA_FROM_DEVICE
+			);
+		if (unlikely(dma_mapping_error(g_mpe_dev, dlrx_ce5des_format_ptr->dest_ptr))) {
+			dtlk_debug(DBG_ERR, "%s: DMA error", __func__);
+		}
+		/*dma_unmap_single(
+			g_mpe_dev,
+			dlrx_ce5des_format_ptr->dest_ptr,
+			4,
+			DMA_FROM_DEVICE
+			);*/
+		dlrx_ce5des_format_ptr->meta_data = 0;
+		dlrx_ce5des_format_ptr->nbytes	= 0;
+		dlrx_ce5des_format_ptr++;
+	}
+	dlrx_cfg_ctxt_ce5des_ptr =
+		(dlrx_cfg_ctxt_ce5des_t *)DLRX_CFG_CTXT_CE5DES_BASE;
+	/* Initializing General Configuration of CE5
+	* Destination Descriptors ===>  1 * 4 DWORDS
+	* (only used by driver) */
+	dlrx_cfg_ctxt_ce5des_ptr->cfg_badr_ce5des =
+		(unsigned int)(DLRX_DDR_CE5DESC_BASE);
+	dlrx_cfg_ctxt_ce5des_ptr->cfg_num_ce5des =
+		dlrx_bufnum.ce5_dest_desc_ring_num;
+	dtlk_debug(DBG_INIT, "%s: dlrx_cfg_ctxt_ce5des_ptr->cfg_num_ce5des[%d]\n",
+		__func__,
+		dlrx_cfg_ctxt_ce5des_ptr->cfg_num_ce5des
+		);
+
+	dlrx_cfg_ctxt_ro_mainlist_ptr =
+		(dlrx_cfg_ctxt_ro_mainlist_t *)DLRX_CFG_CTXT_RO_MAINLIST_BASE;
+	/* Initializing RX REORDER Mainlist Ptr
+	* ===> 128 * 16 = 2048 domains
+	==> Each domain == 64 + 4 DWORDS */
+	dlrx_cfg_ctxt_ro_mainlist_ptr->cfg_badr_ro_mainlist =
+		(unsigned int)DLRX_DDR_RO_MAINLIST_BASE;
+	dlrx_cfg_ctxt_ro_mainlist_ptr->cfg_num_ro_mainlist =
+		dlrx_bufnum.rx_reorder_main_num;
+	dlrx_cfg_ctxt_ro_mainlist_ptr->ro_mainlist_ptr = NULL_PTR;
+
+	dlrx_ro_mainlist_ptr = (dlrx_ro_mainlist_t *)DLRX_DDR_RO_MAINLIST_BASE;
+	for (index = 0; index < dlrx_bufnum.rx_reorder_main_num; index++) {
+		dlrx_ro_mainlist_ptr->first_ptr = NULL_PTR;
+		for (seqid = 1; seqid < 64; seqid++)
+			dlrx_ro_mainlist_ptr->_dw_res0[seqid-1] = NULL_PTR;
+		dlrx_ro_mainlist_ptr++;
+	}
+
+	dlrx_cfg_ctxt_ro_linklist_ptr =
+		(dlrx_cfg_ctxt_ro_linklist_t *) DLRX_CFG_CTXT_RO_LINKLIST_BASE;
+	/* Initializing RX REORDER Linklist Ptr
+	* ===> 4095 Desc ==> Each Desc == 6 DWORDS */
+	dlrx_cfg_ctxt_ro_linklist_ptr->cfg_badr_ro_linklist =
+		(unsigned int)DLRX_DDR_RO_LINKLIST_BASE;
+	dlrx_cfg_ctxt_ro_linklist_ptr->cfg_num_ro_linklist =
+		dlrx_bufnum.rx_reorder_desc_link_num;
+	dlrx_cfg_ctxt_ro_linklist_ptr->free_num_ro_linklist =
+		dlrx_cfg_ctxt_ro_linklist_ptr->cfg_num_ro_linklist - 1;
+	dlrx_cfg_ctxt_ro_linklist_ptr->ro_des_free_head_index = 0;
+	dlrx_cfg_ctxt_ro_linklist_ptr->ro_des_free_tail_index =
+		dlrx_cfg_ctxt_ro_linklist_ptr->cfg_num_ro_linklist - 1;
+
+	dlrx_ro_linklist_ptr = (dlrx_ro_linklist_t *)DLRX_DDR_RO_LINKLIST_BASE;
+	for (index = 0; index < dlrx_bufnum.rx_reorder_desc_link_num;
+		index++) {
+		dlrx_ro_linklist_ptr->next_ptr = index + 1;
+		dlrx_ro_linklist_ptr++;
+	}
+	dlrx_cfg_global_ptr = (dlrx_cfg_global_t *)DLRX_CFG_GLOBAL_BASE;
+	/* Initializing GLOBAL CONFIGURATION STRUCTURE */
+	dlrx_cfg_global_ptr->dltx_enable = 0;
+	dlrx_cfg_global_ptr->dlrx_enable = 0;
+	dlrx_cfg_global_ptr->dlrx_pcie_base = (unsigned int)pcie_base;
+	dlrx_cfg_global_ptr->dlrx_ddr_base = (unsigned int)ddr_base;
+	dlrx_cfg_global_ptr->dlrx_cfg_ctxt_base = (unsigned int)cfg_ctxt_base;
+	dlrx_cfg_global_ptr->dlrx_cfg_ctxt_max_size = DLRX_CFG_CTXT_MAX_SIZE;
+	dlrx_cfg_global_ptr->dlrx_cfg_unload = 0;
+#ifdef SUPPORT_11AC_MULTICARD
+	dlrx_cfg_global_ptr->dlrx_qca_hw = ppa_dl_detect_11ac_card();
+	dlrx_cfg_global_ptr->dlrx_qca_hw_sub_type = g11ACWirelessCardID_SUBTYPE;
+#else
+	dlrx_cfg_global_ptr->dlrx_qca_hw = 0;
+#endif
+	dlrx_cfg_vap2int_map1_ptr =
+		(dlrx_cfg_vap2int_map1_t *) DLRX_CFG_VAP2INT_MAP1_BASE;
+	dlrx_cfg_vap2int_map2_ptr =
+		(dlrx_cfg_vap2int_map2_t *) DLRX_CFG_VAP2INT_MAP2_BASE;
+	dlrx_cfg_vap2int_map1_ptr->vap0 = 0xF;
+	dlrx_cfg_vap2int_map1_ptr->vap1 = 0xF;
+	dlrx_cfg_vap2int_map1_ptr->vap2 = 0xF;
+	dlrx_cfg_vap2int_map1_ptr->vap3 = 0xF;
+	dlrx_cfg_vap2int_map1_ptr->vap4 = 0xF;
+	dlrx_cfg_vap2int_map1_ptr->vap5 = 0xF;
+	dlrx_cfg_vap2int_map1_ptr->vap6 = 0xF;
+	dlrx_cfg_vap2int_map1_ptr->vap7 = 0xF;
+	dlrx_cfg_vap2int_map2_ptr->vap8 = 0xF;
+	dlrx_cfg_vap2int_map2_ptr->vap9 = 0xF;
+	dlrx_cfg_vap2int_map2_ptr->vap10 = 0xF;
+	dlrx_cfg_vap2int_map2_ptr->vap11 = 0xF;
+	dlrx_cfg_vap2int_map2_ptr->vap12 = 0xF;
+	dlrx_cfg_vap2int_map2_ptr->vap13 = 0xF;
+	dlrx_cfg_vap2int_map2_ptr->vap14 = 0xF;
+	dlrx_cfg_vap2int_map2_ptr->vap15 = 0xF;
+
+	return DTLK_SUCCESS;
+}
+
+
+/** Function: get_next_argument.
+ * Description: Get the next valid argument from given string, ignore space
+ * Argument: pSrc [IN]: source pointer
+ * Return: pSrc[OUT]: new pointer points to the starting of valid argument
+ *			  len[OUT]: the len of ignorance space.
+*/
+static char *get_next_argument(
+	char *pSrc,
+	int *len
+	)
+{
+	char *pTemp = pSrc;
+	if (pTemp == NULL) {
+		*len = 0;
+		return NULL;
+	}
+
+	while (pTemp != NULL && *pTemp == ' ') {
+		pTemp++;
+	}
+
+	return pTemp;
+
+}
+/** Function: Compare strings follow by given number of length,
+ * ignore case senstive.
+ * Description: Compare two strings, ignore the case sensitive
+ * Argument: p1 [IN]: source pointer 1
+ *				   p2 [IN]: source pointer 2
+ *				   n [IN]: length of string to compare.
+ * Return:0: identical
+ *			 other: not match
+*/
+static INLINE int strincmp(
+	const char *p1,
+	const char *p2, int n
+	)
+{
+	int c1 = 0, c2;
+
+	while (n && *p1 && *p2)	{
+		c1 = *p1 >= 'A' && *p1 <= 'Z' ? *p1 + 'a' - 'A' : *p1;
+		c2 = *p2 >= 'A' && *p2 <= 'Z' ? *p2 + 'a' - 'A' : *p2;
+		c1 -= c2;
+		if (c1)
+			return c1;
+		p1++;
+		p2++;
+		n--;
+	}
+
+	return n ? *p1 - *p2 : c1;
+}
+
+/**	Proc struct def
+ */
+/* Functions and structure support proc/dl/peer_to_vap */
+static int proc_read_dtlk_peer_to_vap(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	int i = 0;
+	seq_printf(seq, "\n");
+	seq_printf(seq, "Peer to VAP and PN Configuration table: \n");
+	seq_printf(seq, "PN type: 0-no PN check,1-48 bit PB,2-128 bit PB Even,3-128 bit PB Odd\n");
+	seq_printf(seq, "\n");
+	seq_printf(seq, "[ ID:Acc:PN:Vap] [ ID:Acc:PN:Vap]\n");
+	for (i = 0; i < MAX_PEER_NUM; i += 2) {
+		uint32_t peer0 = 0, peer1 = 0;
+		peer0 = *(volatile uint32_t *)DLRX_CFG_PEER_TO_VAP_PN_BASE(i);
+		peer1 = *(volatile uint32_t *)DLRX_CFG_PEER_TO_VAP_PN_BASE(i + 1);
+		seq_printf(seq, "[%3d:%3d:%2d:%3d] [%3d:%3d:%2d:%3d]\n",
+			i,
+			(peer0 & 0x40),
+			(peer0 & 0x30),
+			(peer0 & 0xF),
+			i + 1,
+			(peer1 & 0x40),
+			(peer1 & 0x30),
+			(peer1 & 0xF)
+			);
+	}
+	seq_printf(seq, "\n");
+	return 0;
+}
+/* Functions and structure support proc/dl/peer_id */
+static int proc_read_dtlk_peer_id(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	int i = 0;
+	seq_printf(seq, "\n");
+	seq_printf(seq, "Peer ID to peer table address: %p\n",
+		DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(0));
+	seq_printf(seq, "\n");
+	seq_printf(seq, "Valid Peer ID table:\n");
+	seq_printf(seq, "  [ ID:   Peer]\n");
+	for (i = 0; i < MAX_PEERID_NUM/4; i++) {
+		uint32_t regs = 0;
+		uint8_t peerid0 = 0, peerid1 = 0, peerid2 = 0, peerid3 = 0;
+		regs = *(uint32_t *)DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(i);
+		peerid0 = ((regs) & 0xff);
+		peerid1 = ((regs >>  8) & 0xff);
+		peerid2 = ((regs >> 16) & 0xff);
+		peerid3 = ((regs >> 24) & 0xff);
+		if ((peerid0 >> 7) & 1)
+			seq_printf(seq, "  [%3d:%7d]\n", i * 4, (peerid0 & 0x7f));
+
+		if ((peerid1 >> 7) & 1)
+			seq_printf(seq, "  [%3d:%7d]\n", i * 4 + 1, (peerid1 & 0x7f));
+
+		if ((peerid2 >> 7) & 1)
+			seq_printf(seq, "  [%3d:%7d]\n", i * 4 + 2, (peerid2 & 0x7f));
+
+		if ((peerid3 >> 7) & 1)
+			seq_printf(seq, "  [%3d:%7d]\n", i * 4 + 3, (peerid3 & 0x7f));
+
+	}
+	seq_printf(seq, "\n");
+
+	return 0;
+}
+/* Functions and structure support proc/dl/wifi_port */
+static int proc_read_dtlk_wifi_port(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	int i = 0;
+	int radio = 0;
+	if (g_ppe_radio[0].flags | PPE_DTLK_VALID) {
+		seq_printf(seq, "Radio [%d]: data port [%d]\n",
+			radio,
+			g_ppe_radio[0].dl_sub_if.port_id);
+	for (i = 0; i < MAX_VAP_NUM; i++) {
+		struct net_device *vapDev = dtlk_dev_from_vapid(i);
+		if (vapDev) {
+			int directpathID = 0;
+			uint32_t vap2int;
+			if (i < MAX_VAP_NUM / 2)
+				vap2int = *(uint32_t *)DLRX_CFG_VAP2INT_MAP1_BASE;
+			else
+				vap2int = *(uint32_t *)DLRX_CFG_VAP2INT_MAP2_BASE;
+
+			directpathID = (vap2int >> i*4) & 0xf;
+			/*
+			if (directpathID == 0xf)
+				directpathID = -1;
+				*/
+			seq_printf(seq,
+				"  [%d]: Sub interface: %d, VAP id: %d, wifi dev: %s\n",
+				i,
+				directpathID,
+				i,
+				vapDev->name
+				);
+		} else
+			seq_printf(seq, "  [%d]: Invalid\n", i);
+	}
+	} else {
+		seq_printf(seq, "Radio [%d]: Invalid data port\n", radio);
+	}
+
+
+	return 0;
+}
+
+static int proc_read_dtlk_peer_to_vap_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_dtlk_peer_to_vap, NULL);
+}
+
+static int proc_read_dtlk_peer_id_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_dtlk_peer_id, NULL);
+}
+
+static int proc_read_dtlk_wifi_port_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_dtlk_wifi_port, NULL);
+}
+
+static struct file_operations g_proc_file_peer_to_vap_seq_fops = {
+	.owner		= THIS_MODULE,
+	.open		= proc_read_dtlk_peer_to_vap_seq_open,
+	.read		= seq_read,
+	.llseek 	= seq_lseek,
+	.release	= single_release
+};
+
+static struct file_operations g_proc_file_peer_id_seq_fops = {
+	.owner		= THIS_MODULE,
+	.open		= proc_read_dtlk_peer_id_seq_open,
+	.read		= seq_read,
+	.llseek 	= seq_lseek,
+	.release	= single_release
+};
+
+static struct file_operations g_proc_file_wifi_port_seq_fops = {
+	.owner		= THIS_MODULE,
+	.open		= proc_read_dtlk_wifi_port_seq_open,
+	.read		= seq_read,
+	.llseek 	= seq_lseek,
+	.release	= single_release
+};
+
+static int proc_read_mem(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	return 0;
+}
+static int proc_read_mem_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_mem, NULL);
+}
+static INLINE int get_token(
+	char **p1,
+	char **p2,
+	int *len,
+	int *colon
+	) {
+	int tlen = 0;
+	while (*len && !((**p1 >= 'A' && **p1 <= 'Z') ||
+		(**p1 >= 'a' && **p1 <= 'z') ||
+		(**p1 >= '0' && **p1 <= '9'))) {
+		(*p1)++;
+		(*len)--;
+	}
+	if (!*len)
+		return 0;
+
+	if  (*colon) {
+		*colon = 0;
+		*p2 = *p1;
+		while (*len && **p2 > ' ' && **p2 != ',') {
+			if (**p2 == ':') {
+				*colon = 1;
+				break;
+			}
+			(*p2)++;
+			(*len)--;
+			tlen++;
+		}
+		**p2 = 0;
+	} else {
+		*p2 = *p1;
+		while (*len && **p2 > ' ' && **p2 != ',') {
+			(*p2)++;
+			(*len)--;
+			tlen++;
+		}
+		**p2 = 0;
+	}
+
+	return tlen;
+}
+
+static INLINE void ignore_space(
+	char **p,
+	int *len
+	)
+{
+	while (*len && (**p <= ' ' || **p == ':' ||
+		**p == '.' || **p == ',')) {
+		(*p)++;
+		(*len)--;
+	}
+}
+static INLINE int stricmp(
+	const char *p1,
+	const char *p2
+	)
+{
+	int c1, c2;
+
+	while (*p1 && *p2) {
+		c1 = *p1 >= 'A' && *p1 <= 'Z' ? *p1 + 'a' - 'A' : *p1;
+		c2 = *p2 >= 'A' && *p2 <= 'Z' ? *p2 + 'a' - 'A' : *p2;
+		c1 -= c2;
+		if (c1)
+			return c1;
+		p1++;
+		p2++;
+	}
+
+	return *p1 - *p2;
+}
+
+static INLINE int get_number(
+	char **p,
+	int *len,
+	int is_hex
+	)
+{
+	int ret = 0;
+	int n = 0;
+
+	if ((*p)[0] == '0' && (*p)[1] == 'x') {
+		is_hex = 1;
+		(*p) += 2;
+		(*len) -= 2;
+	}
+
+	if (is_hex) {
+		while (*len && ((**p >= '0' && **p <= '9') ||
+			(**p >= 'a' && **p <= 'f') ||
+			(**p >= 'A' && **p <= 'F'))) {
+			if (**p >= '0' && **p <= '9')
+				n = **p - '0';
+			else if (**p >= 'a' && **p <= 'f')
+			   n = **p - 'a' + 10;
+			else if (**p >= 'A' && **p <= 'F')
+				n = **p - 'A' + 10;
+			ret = (ret << 4) | n;
+			(*p)++;
+			(*len)--;
+		}
+	} else {
+		while (*len && **p >= '0' && **p <= '9') {
+			n = **p - '0';
+			ret = ret * 10 + n;
+			(*p)++;
+			(*len)--;
+		}
+	}
+
+	return ret;
+}
+
+static ssize_t proc_write_mem(
+	struct file *file,
+	const char __user *buf,
+	size_t count,
+	loff_t *data
+	)
+{
+	char *p1, *p2;
+	int len;
+	int colon;
+	unsigned long *p = NULL;
+	unsigned long dword;
+	char local_buf[900];
+	int i, n, l;
+
+
+	len = sizeof(local_buf) < count ? sizeof(local_buf) - 1 : count;
+	len = len - copy_from_user(local_buf, buf, len);
+	local_buf[len] = 0;
+
+	p1 = local_buf;
+	p2 = NULL;
+	colon = 1;
+	while (get_token(&p1, &p2, &len, &colon)) {
+		if (stricmp(p1, "w") == 0 ||
+			stricmp(p1, "write") == 0 ||
+			stricmp(p1, "r") == 0 ||
+			stricmp(p1, "read") == 0)
+			break;
+
+		p1 = p2;
+		colon = 1;
+	}
+
+	if (*p1 == 'w') {
+		ignore_space(&p2, &len);
+		if (p2[0] == 's' && p2[1] == 'w' &&
+			(p2[2] == ' ' || p2[2] == '\t')) {
+			/*
+			unsigned long temp;
+			is_switch = 1;
+			p2 += 3;
+			len -= 3;
+			ignore_space(&p2, &len);
+			temp = get_number(&p2, &len, 1);
+			p = (unsigned long *)AR10_SWIP_MACRO_REG(temp);
+			*/
+		} else {
+			p = (unsigned long *)get_number(&p2, &len, 1);
+			/* p = (unsigned long *)sb_addr_to_fpi_addr_convert( (unsigned long) p); */
+		}
+
+		if ((u32)p >= KSEG0)
+			while (1) {
+				ignore_space(&p2, &len);
+				if (!len || !((*p2 >= '0' && *p2 <= '9') ||
+					(*p2 >= 'a' && *p2 <= 'f') ||
+					(*p2 >= 'A' && *p2 <= 'F')))
+					break;
+
+				*p++ = (u32)get_number(&p2, &len, 1);
+			}
+	} else if (*p1 == 'r')	{
+		ignore_space(&p2, &len);
+		if (p2[0] == 's' && p2[1] == 'w' &&
+			(p2[2] == ' ' || p2[2] == '\t')) {
+			/* do nothing */
+		} else {
+			p = (unsigned long *)get_number(&p2, &len, 1);
+			/* p = (unsigned long *)sb_addr_to_fpi_addr_convert( (unsigned long) p); */
+		}
+		/* printk("%s: p[0x%x] KSEG0[0x%x]\n", __func__, (u32)p, KSEG0); */
+		if ((u32)p >= KSEG0) {
+			ignore_space(&p2, &len);
+			n = (int)get_number(&p2, &len, 0);
+			if (n) {
+				char str[32] = {0};
+				char *pch = str;
+				int k;
+				char c;
+
+				n += (l = ((int)p >> 2) & 0x03);
+				p = (unsigned long *)((u32)p & ~0x0F);
+				for (i = 0; i < n; i++) {
+					if ((i & 0x03) == 0) {
+						printk("%08X:", (u32)p);
+						pch = str;
+					}
+					if (i < l) {
+						printk("		 ");
+						sprintf(pch, "	  ");
+					} else {
+						dword = *p;
+						printk(" %08X", (u32)dword);
+						for (k = 0; k < 4; k++) {
+							c = ((char *)&dword)[k];
+							pch[k] = c < ' ' ? '.' : c;
+						}
+					}
+					p++;
+					pch += 4;
+					if ((i & 0x03) == 0x03) {
+						pch[0] = 0;
+						printk(" ; %s\n", str);
+					}
+				}
+				if ((n & 0x03) != 0x00) {
+					for (k = 4 - (n & 0x03); k > 0; k--)
+						printk("		 ");
+					pch[0] = 0;
+					printk(" ; %s\n", str);
+				}
+			}
+		}
+	}
+
+	return count;
+}
+
+static struct file_operations g_proc_file_mem_seq_fops = {
+	.owner	= THIS_MODULE,
+	.open	= proc_read_mem_seq_open,
+	.read	= seq_read,
+	.write	= proc_write_mem,
+	.llseek	= seq_lseek,
+	.release	= single_release,
+};
+#define DTLK_SWITCH_DISABLE_PARSE 1
+#if DTLK_SWITCH_DISABLE_PARSE
+extern int (*datapath_dtlk_switch_parser)(void);
+int dtlk_switch_parser(void)
+{
+	dltx_cfg_global_t *mpe_dl_tx_cfg_global =
+					(dltx_cfg_global_t *)MPE_TX_ADDR(DLTX_CFG_GLOBAL_OFFSET);
+	return mpe_dl_tx_cfg_global->switch_parser_flag;
+}
+#endif
+static int proc_read_parser(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	dltx_cfg_global_t *mpe_dl_tx_cfg_global =
+				(dltx_cfg_global_t *)MPE_TX_ADDR(DLTX_CFG_GLOBAL_OFFSET);
+	printk("%s: switch flag[%d]\n", __func__, mpe_dl_tx_cfg_global->switch_parser_flag);
+	seq_printf(seq, "Current switch parser: %s\n",
+		mpe_dl_tx_cfg_global->switch_parser_flag == 1 ? "Enable" : "Disable");
+	return 0;
+}
+static int proc_read_parser_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_parser, NULL);
+}
+
+static ssize_t proc_write_parser(
+	 struct file *file,
+	 const char __user *buf,
+	 size_t count,
+	 loff_t *data
+	 )
+{
+	char *p1, *p2;
+	int len;
+	int colon;
+
+
+	char local_buf[900];
+
+
+	dltx_cfg_global_t *mpe_dl_tx_cfg_global =
+			(dltx_cfg_global_t *)MPE_TX_ADDR(DLTX_CFG_GLOBAL_OFFSET);
+
+	len = sizeof(local_buf) < count ? sizeof(local_buf) - 1 : count;
+	len = len - copy_from_user(local_buf, buf, len);
+	local_buf[len] = 0;
+
+	p1 = local_buf;
+	p2 = NULL;
+	colon = 1;
+	while (get_token(&p1, &p2, &len, &colon)) {
+		if (stricmp(p1, "disable") == 0 ||
+			stricmp(p1, "enable") == 0)
+			break;
+		p1 = p2;
+		colon = 1;
+	}
+
+	if (*p1 == 'd') {
+		printk("%s: Disable switch parser\n", __func__);
+		mpe_dl_tx_cfg_global->switch_parser_flag = 0;
+	} else {
+		printk("%s: Enable switch parser\n", __func__);
+		mpe_dl_tx_cfg_global->switch_parser_flag = 1;
+	}
+	return count;
+}
+
+static struct file_operations g_proc_file_parser_seq_fops = {
+	.owner  = THIS_MODULE,
+	.open	 = proc_read_parser_seq_open,
+	.read	 = seq_read,
+	.write  = proc_write_parser,
+	.llseek = seq_lseek,
+	.release	 = single_release,
+};
+
+
+
+
+ /* Functions and structure support proc/dtlk/reg */
+static int proc_read_dtlk_reg(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	volatile dlrx_cfg_vap2int_map1_t *vap2int_map1 =
+		(dlrx_cfg_vap2int_map1_t *)DLRX_CFG_VAP2INT_MAP1_BASE;
+	volatile dlrx_cfg_vap2int_map2_t *vap2int_map2 =
+		(dlrx_cfg_vap2int_map2_t *)DLRX_CFG_VAP2INT_MAP2_BASE;
+	seq_printf(seq, "Firmware registers information\n");
+	seq_printf(seq, "			CFG_VAP2INT_MAP1: %p\n", vap2int_map1);
+	seq_printf(seq, "	VAP0: %d\n", vap2int_map1->vap0);
+	seq_printf(seq, "	VAP1: %d\n", vap2int_map1->vap1);
+	seq_printf(seq, "	VAP2: %d\n", vap2int_map1->vap2);
+	seq_printf(seq, "	VAP3: %d\n", vap2int_map1->vap3);
+	seq_printf(seq, "	VAP4: %d\n", vap2int_map1->vap4);
+	seq_printf(seq, "	VAP5: %d\n", vap2int_map1->vap5);
+	seq_printf(seq, "	VAP6: %d\n", vap2int_map1->vap6);
+	seq_printf(seq, "	VAP7: %d\n", vap2int_map1->vap7);
+	seq_printf(seq, "			CFG_VAP2INT_MAP2: %p\n", vap2int_map2);
+	seq_printf(seq, "	VAP8: %d\n", vap2int_map2->vap8);
+	seq_printf(seq, "	VAP9: %d\n", vap2int_map2->vap9);
+	seq_printf(seq, "	VAP10: %d\n", vap2int_map2->vap10);
+	seq_printf(seq, "	VAP11: %d\n", vap2int_map2->vap11);
+	seq_printf(seq, "	VAP12: %d\n", vap2int_map2->vap12);
+	seq_printf(seq, "	VAP13: %d\n", vap2int_map2->vap13);
+	seq_printf(seq, "	VAP14: %d\n", vap2int_map2->vap14);
+	seq_printf(seq, "	VAP15: %d\n", vap2int_map2->vap15);
+
+	return 0;
+}
+
+static int proc_read_dtlk_reg_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_dtlk_reg, NULL);
+}
+
+
+
+static struct file_operations g_proc_file_reg_seq_fops = {
+	.owner		= THIS_MODULE,
+	.open		= proc_read_dtlk_reg_seq_open,
+	.read		= seq_read,
+	.llseek 	= seq_lseek,
+	.release	= single_release
+};
+
+ /* Functions and structure support proc/dtlk/ver */
+static int proc_read_dtlk_ver(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	 dltx_cfg_global_t *mpe_dl_tx_cfg_global =
+				 (dltx_cfg_global_t *)MPE_TX_ADDR(DLTX_CFG_GLOBAL_OFFSET);
+
+	seq_printf(seq, "DirectLink driver information: \n");
+	seq_printf(seq, "	 Version: %d.%d.%d\n",
+		DLRX_DRV_MAJOR,
+		DLRX_DRV_MID,
+		DLRX_DRV_MINOR
+		);
+	seq_printf(seq, "DLRX Firmware information: \n");
+	seq_printf(seq, "    Version:%08x\n", DRE_FW_VERSION);
+	seq_printf(seq, "    Feature:%08x\n", DRE_FW_FEATURE);
+	seq_printf(seq, "DLTX Firmware information: \n");
+	seq_printf(seq, "	 Version:%08x\n", mpe_dl_tx_cfg_global->fw_ver_id);
+	seq_printf(seq, "	 Feature:%08x\n", mpe_dl_tx_cfg_global->fw_feature);
+
+	return 0;
+}
+
+static int proc_read_dtlk_ver_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_dtlk_ver, NULL);
+}
+
+
+
+static struct file_operations g_proc_file_ver_seq_fops = {
+	.owner		= THIS_MODULE,
+	.open		= proc_read_dtlk_ver_seq_open,
+	.read		= seq_read,
+	.llseek 	= seq_lseek,
+	.release	= single_release
+};
+/* Functions and structure support proc/dtlk/mib */
+static int proc_read_dtlk_mib(struct seq_file *seq, void *v)
+{
+	int i = 0;
+	uint64_t generalRXDrops = 0;
+	uint64_t generalRXErrors = 0;
+	uint64_t generalTXDrops = 0;
+
+	for (i = 0; i < MAX_DTLK_NUM; i++) {
+		struct net_device *vapDev = dtlk_dev_from_vapid(i);
+		if (vapDev) {
+			/* TODO: implement function to get mib from vap */
+			volatile vap_data_mib_t *vap_mib_rx =
+				(vap_data_mib_t *)DLRX_VAP_MIB_BASE(i);
+			dltx_vap_data_mib_t *vap_mib_tx =
+				(dltx_vap_data_mib_t *)MPE_TX_ADDR(DLTX_VAP_DATA_MIB_OFFSET(i));
+			uint64_t rxpdu =
+				(uint64_t)vap_mib_rx->rx_rcv_pdu_low +
+				(((uint64_t)vap_mib_rx->rx_rcv_pdu_high) << 32);
+			uint64_t rxbytes =
+				(uint64_t)vap_mib_rx->rx_rcv_bytes_low +
+				(((uint64_t)vap_mib_rx->rx_rcv_bytes_high) << 32);
+			uint64_t txdrops =
+				(uint64_t)vap_mib_tx->txdrop_low +
+				(((uint64_t)vap_mib_tx->txdrop_high) << 32);
+			uint64_t rxerros =
+				((uint64_t)vap_mib_rx->rx_pn_bytes_low +
+				(((uint64_t)vap_mib_rx->rx_pn_bytes_high) << 32)) +
+				((uint64_t)vap_mib_rx->rx_discard_pdu_low +
+				(((uint64_t)vap_mib_rx->rx_discard_pdu_high) << 32));
+			uint64_t rxdrops = (uint64_t)vap_mib_rx->rx_drop_pdu_low +
+				(((uint64_t)vap_mib_rx->rx_drop_pdu_high) << 32);
+			uint64_t txpdu = (uint64_t)vap_mib_tx->txpdu_low +
+				(((uint64_t)vap_mib_tx->txpdu_high) << 32);
+			uint64_t txbytes = (uint64_t)vap_mib_tx->txbytes_low +
+				(((uint64_t)vap_mib_tx->txbytes_high) << 32);
+			seq_printf(seq, "VAP-Id = %d\n", i);
+			seq_printf(seq, "  VAP-Name = %s\n", vapDev->name);
+			seq_printf(seq, "   tx_pkts    = %llu\n", txpdu);
+			seq_printf(seq, "   tx_bytes   = %llu\n", txbytes);
+			seq_printf(seq, "   tx_drops   = %llu\n", txdrops);
+			seq_printf(seq, "   rx_pkts    = %llu\n", rxpdu);
+			seq_printf(seq, "   rx_bytes   = %llu\n", rxbytes);
+			seq_printf(seq, "   rx_error_pkts = %llu\n", rxerros);
+			seq_printf(seq, "   rx_drops_pkts = %llu\n", rxdrops);
+			seq_printf(seq, "\n");
+			generalTXDrops += txdrops;
+			generalRXDrops += rxdrops;
+			generalRXErrors += rxerros;
+		} else {
+			seq_printf(seq, "VAP-Id = %d\n", i);
+			seq_printf(seq, "  VAP-Name = Unassigned\n");
+		}
+	}
+	seq_printf(seq, "\n");
+	seq_printf(seq, "General RX Drops = %10llu General RX Errors = %10llu\n",
+		generalRXDrops,
+		generalRXErrors
+		);
+	seq_printf(seq, "General TX Drops = %10llu\n", generalTXDrops);
+	return 0;
+}
+
+static int proc_read_dtlk_mib_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_dtlk_mib, NULL);
+}
+
+static ssize_t proc_write_dtlk_mib_seq(
+	struct file *file,
+	const char __user *buf,
+	size_t count,
+	loff_t *data
+	)
+{
+	int len;
+	char str[64];
+	char *p;
+
+	int spaceLen = 0;
+	int i;
+	uint32_t vapMask = 0;
+	memset(str, 0, 64);
+	len = min(count, (size_t)((unsigned long)sizeof(str) - 1));
+	len -= copy_from_user(str, buf, len);
+	while (len && str[len - 1] <= ' ')
+		len--;
+	str[len] = 0;
+	for (p = str; *p && *p <= ' '; p++, len--)
+		;
+	if (!*p)
+		return count;
+	/* first, looking for VAP from user input  */
+
+	p = get_next_argument(p, &spaceLen);
+	len -= spaceLen;
+	if (p == NULL) {
+		dtlk_debug(
+		DBG_PROC,
+		"%s: Invalid input\n",
+		__func__
+		);
+		return count;
+	}
+	/* get vap id */
+	if (strincmp(p, "reset", strlen("reset")) == 0) {
+		p += strlen("reset");
+		len -= strlen("reset");
+
+		while (p && *p) {
+			int vapID = 0;
+			p = get_next_argument(p, &spaceLen);
+			if (!p)
+				break;
+
+			len -= spaceLen;
+			if (strincmp(p, "all", strlen("all")) == 0) {
+				/* mask all */
+				vapMask = 0xffffffff;
+				break;
+			} else {
+				if (*p >= '0' && *p <= '9') {
+					sscanf(p, "%d", &vapID);
+					if (vapID >= MAX_VAP_NUM) {
+						dtlk_debug(
+							DBG_PROC,
+							"%s: invalid VAP id [%d]\n",
+							__func__,
+							vapID);
+						break;/* while */
+					}
+					vapMask |= 1 << vapID;
+					if (vapID > 9) {
+						len -= 2;
+						p += 2;
+					} else {
+						len -= 1;
+						p += 1;
+					}
+				} else
+					break;
+			}
+			if (!p)
+				break;
+			p += 1;
+			len -= 1;
+		}
+	} else if (strincmp(p, "help", 4) == 0 || *p == '?') {
+		dtlk_debug(DBG_PROC, "echo reset <0 1 2 ...> > /proc/%s/wifi_mib\n",
+			DIRECTLINK_PROC_DIR);
+		dtlk_debug(DBG_PROC, "echo reset all > /proc/%s/wifi_mib\n",
+			DIRECTLINK_PROC_DIR);
+		return count;
+	}
+
+	dtlk_debug(
+		DBG_PROC,
+		"%s: Going to clear: 0x%08x\n",
+		__func__,
+		vapMask
+		);
+	/* secondly, clear vap mib counter */
+	if (vapMask == 0xffffffff) {
+		dre_dl_reset_fn_t dre_dl_reset_fn;
+		uint32_t *ptrTxMib = (void *)DTLK_RX_ADDR(__D6_PER_VAP_MIB_BASE);
+		/* clear rx mib counter
+		* resetMib->allreq = 1;
+		* clear tx mib counter
+		*/
+		memset(ptrTxMib, 0x0, sizeof(mib_table_t)*MAX_VAP_NUM);
+		dre_dl_reset_fn = g_dre_fnset.dre_dl_reset_fn;
+		if (likely(dre_dl_reset_fn))
+			dre_dl_reset_fn(DRE_RESET_MIB, 0xff);
+		else
+			dtlk_debug(DBG_ERR, "%s: Function DRE_RESET_MIB is not registered!\n", __func__);
+	} else {
+		dre_dl_reset_fn_t dre_dl_reset_fn;
+		dre_dl_reset_fn = g_dre_fnset.dre_dl_reset_fn;
+		for (i = 0; i < MAX_VAP_NUM; i++) {
+			if ((1 << i) & vapMask) {
+				uint32_t *ptrTxMib =
+					(void *)DTLK_RX_ADDR(__D6_PER_VAP_MIB_BASE) +
+					i*sizeof(mib_table_t);
+				memset(ptrTxMib, 0x0, sizeof(mib_table_t));
+				if (likely(dre_dl_reset_fn))
+					dre_dl_reset_fn(DRE_RESET_MIB, i);
+				else
+					dtlk_debug(DBG_ERR, "%s:DRE_RESET_MIB is not registered!\n",
+						__func__
+						);
+			}
+		}
+	}
+	return count;
+
+}
+
+
+static struct file_operations g_proc_file_mib_seq_fops = {
+	.owner		= THIS_MODULE,
+	.open		= proc_read_dtlk_mib_seq_open,
+	.read		= seq_read,
+	.write		= proc_write_dtlk_mib_seq,
+	.llseek 	= seq_lseek,
+	.release	= single_release
+};
+/** ####################################
+ *			  Local Function
+ * ####################################
+ */
+
+/* Functions and structure support proc/dtlk/dbg*/
+static int proc_read_dtlk_dbg(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	int i;
+	/* skip -1 */
+	for (i = 0; i < NUM_ENTITY(dtlk_dbg_enable_mask_str) - 1; i++)
+		seq_printf(seq, "%-10s(%-40s):		  %-5s\n",
+			dtlk_dbg_enable_mask_str[i].cmd,
+			dtlk_dbg_enable_mask_str[i].description,
+			(g_dtlk_dbg_enable & dtlk_dbg_enable_mask_str[i].flag) ? "enabled" : "disabled"
+			);
+
+	return 0;
+
+}
+
+static int proc_read_dtlk_dbg_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_dtlk_dbg, NULL);
+}
+
+static ssize_t proc_write_dtlk_dbg_seq(
+	struct file *file,
+	const char __user *buf,
+	size_t count, loff_t *data
+	)
+{
+	int len;
+	char str[64];
+	char *p;
+	int f_enable = 0;
+	int f_dtlk = 0;
+	int i;
+	int spaceLen = 0;
+	dltx_cfg_global_t *dltx_cfg_global =
+			(dltx_cfg_global_t *)MPE_TX_ADDR(DLTX_CFG_GLOBAL_OFFSET);
+	memset(str, 0, 64);
+	len = min(count, (size_t)((unsigned long)sizeof(str) - 1));
+	len -= copy_from_user(str, buf, len);
+	while (len && str[len - 1] <= ' ')
+		len--;
+	str[len] = 0;
+	for (p = str; *p && *p <= ' '; p++, len--)
+		;
+	if (!*p)
+		return count;
+
+	if (strincmp(p, "dltx", 4) == 0) {
+		p += 4;
+		len -= 4;
+		f_dtlk = 1;
+	} else if (strincmp(p, "enable", 6) == 0) {
+		p += 6;
+		len -= 6;
+		f_enable = 1;
+	} else if (strincmp(p, "disable", 7) == 0) {
+		p += 7;
+		len -= 7;
+		f_enable = -1;
+	} else if (strincmp(p, "help", 4) == 0 || *p == '?') {
+		 dtlk_debug(DBG_PRINT, "echo <enable/disable/dltx> [");
+		 for (i = 0; i < NUM_ENTITY(dtlk_dbg_enable_mask_str); i++)
+			dtlk_debug(DBG_PRINT, "%s/", dtlk_dbg_enable_mask_str[i].cmd);
+		 dtlk_debug(DBG_PRINT, "] > /proc/%s/dbg\n", DIRECTLINK_PROC_DIR);
+		 return count;
+	}
+
+	p = get_next_argument(p, &spaceLen);
+	if (p == NULL) {
+		dtlk_debug(DBG_ERR, "NULL pointer\n");
+		return count;
+	}
+	len -= spaceLen;
+
+	if (f_enable) {
+		if ((len <= 0) || (p[0] >= '0' && p[1] <= '9')) {
+			if (f_enable > 0)
+				g_dtlk_dbg_enable |= (~DTLK_DBG_ENA);
+			else
+				g_dtlk_dbg_enable &= DTLK_DBG_ENA;
+		} else {
+			do {
+				for (i = 0; i < NUM_ENTITY(dtlk_dbg_enable_mask_str); i++) {
+					if (dtlk_dbg_enable_mask_str[i].cmd == NULL)
+						break;
+					if (strlen(p) < strlen(dtlk_dbg_enable_mask_str[i].cmd))
+						continue;
+					if (strincmp(p,
+						dtlk_dbg_enable_mask_str[i].cmd,
+						strlen(dtlk_dbg_enable_mask_str[i].cmd)) == 0) {
+						if (f_enable > 0)
+							g_dtlk_dbg_enable |= dtlk_dbg_enable_mask_str[i].flag;
+						else
+							g_dtlk_dbg_enable &= ~dtlk_dbg_enable_mask_str[i].flag;
+						/* skip one blank */
+						p += strlen(dtlk_dbg_enable_mask_str[i].cmd);
+						p = get_next_argument(p, &spaceLen);
+						if (p == NULL) {
+							break;
+						}
+						/*skip one blank. len maybe negative
+						* now if there is no other parameters
+						*/
+						len -= strlen(dtlk_dbg_enable_mask_str[i].cmd) + spaceLen;
+						break;
+					}
+				}
+			} while (i < NUM_ENTITY(dtlk_dbg_enable_mask_str) && p);
+		}
+	}
+	if (f_dtlk) {
+		/* enable debug in DLTX */
+		dtlk_debug(DBG_PROC, "DEBUG: enable DLTX debug\n");
+		dltx_cfg_global->debug_print_enable = 1;
+	} else {
+		dtlk_debug(DBG_PROC, "DEBUG: disable DLTX debug\n");
+		dltx_cfg_global->debug_print_enable = 0;
+	}
+
+	return count;
+
+}
+
+
+static struct file_operations g_proc_file_dbg_seq_fops = {
+	.owner		= THIS_MODULE,
+	.open		= proc_read_dtlk_dbg_seq_open,
+	.read		= seq_read,
+	.write		= proc_write_dtlk_dbg_seq,
+	.llseek 	= seq_lseek,
+	.release	= single_release
+};
+
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+
+static int proc_read_m2c(
+	struct seq_file *seq,
+	void *v
+	)
+{
+	struct _dl_mcast_group_table *dl_m2c_group_tbl =
+				(struct _dl_mcast_group_table *)MPE_TX_ADDR(DLTX_CFG_CTXT_M2C_GROUP_TABLE);
+	int i, j;
+	dtlk_debug(DBG_PROC, "%s\n", __func__);
+	for (i = 0; i < MAX_MCAST_GROUP; i++) {
+		if (dl_m2c_group_tbl->valid) {
+			seq_printf(seq, "Group: %d\n", i);
+			for (j = 0; j < MAX_PEER_NUM; j++) {
+				int byteOff = j / 32;
+				int bitOff = j % 32;
+				if (dl_m2c_group_tbl->bitmap[byteOff] & (1 << bitOff)) {
+					struct _dl_peer_mac_mapping_table *dl_m2c_peer_tbl =
+						(struct _dl_peer_mac_mapping_table *)MPE_TX_ADDR(DLTX_CFG_CTXT_M2C_PEER_TABLE);
+					dl_m2c_peer_tbl += j;
+					seq_printf(seq, "\tPeer: %d [%x:%x:%x:%x:%x:%x]\n",
+						i,
+						dl_m2c_peer_tbl->mac5,
+						dl_m2c_peer_tbl->mac4,
+						dl_m2c_peer_tbl->mac3,
+						dl_m2c_peer_tbl->mac2,
+						dl_m2c_peer_tbl->mac1,
+						dl_m2c_peer_tbl->mac0
+						);
+				}
+			}
+		}
+		dl_m2c_group_tbl++;
+	}
+	return 0;
+}
+static int proc_read_m2c_seq_open(
+	struct inode *inode,
+	struct file *file
+	)
+{
+	return single_open(file, proc_read_m2c, NULL);
+}
+
+static ssize_t proc_write_m2c(
+	 struct file *file,
+	 const char __user *buf,
+	 size_t count,
+	 loff_t *data
+	 )
+{
+	return count;
+}
+
+static struct file_operations g_proc_file_m2c_seq_fops = {
+	.owner  = THIS_MODULE,
+	.open	 = proc_read_m2c_seq_open,
+	.read	 = seq_read,
+	.write  = proc_write_m2c,
+	.llseek = seq_lseek,
+	.release	 = single_release,
+};
+
+
+#endif
+/**
+  * proc_file_create - Create proc files for driver
+  *
+  *
+  * All proc files will be located in /proc/dtlk. Called by
+  * dlrx_drv_init
+  * Return: 0 : success. Others: fail
+  */
+static INLINE int proc_file_create(void)
+{
+	struct proc_dir_entry *res;
+	int ret = 0;
+
+	if (g_dtlk_proc_dir) {
+		dtlk_debug(DBG_ERR, "More than one DirectLink device found!\n");
+		return -EEXIST;
+	}
+
+	/* create parent proc directory */
+	g_dtlk_proc_dir = proc_mkdir(DIRECTLINK_PROC_DIR, NULL);
+	/* create mib */
+	res  = proc_create("wifi_mib",
+		S_IRUGO|S_IWUSR,
+		g_dtlk_proc_dir,
+		&g_proc_file_mib_seq_fops
+		);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create mib\n");
+		return -ENODEV;
+	}
+
+	/* create wifi_port */
+	res = proc_create("wifi_port",
+		S_IRUGO,
+		g_dtlk_proc_dir,
+		&g_proc_file_wifi_port_seq_fops
+		);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create wifi_port\n");
+		return -ENODEV;
+	}
+
+	/* create peer_id */
+	res  = proc_create("peer_id",
+		S_IRUGO,
+		g_dtlk_proc_dir,
+		&g_proc_file_peer_id_seq_fops
+		);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create peer_id\n");
+		return -ENODEV;
+	}
+
+	/* create peer_to_vap */
+	res = proc_create("peer_to_vap",
+		S_IRUGO,
+		g_dtlk_proc_dir,
+		&g_proc_file_peer_to_vap_seq_fops
+		);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create peer_to_vap\n");
+		return -ENODEV;
+	}
+
+
+	/* create dbg */
+	res = proc_create("dbg",
+		S_IRUGO|S_IWUSR,
+		g_dtlk_proc_dir,
+		&g_proc_file_dbg_seq_fops
+		);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create dbg\n");
+		ret = -ENODEV;
+	}
+	/* create mem */
+	res = proc_create("mem",
+		S_IRUGO|S_IWUSR,
+		g_dtlk_proc_dir,
+		&g_proc_file_mem_seq_fops
+		);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create dbg\n");
+		ret = -ENODEV;
+	}
+
+	/* create ver */
+	res  = proc_create("ver",
+		S_IRUGO,
+		g_dtlk_proc_dir,
+		&g_proc_file_ver_seq_fops
+		);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create version\n");
+		ret = -ENODEV;
+	}
+
+	/* create reg */
+	res  = proc_create("reg",
+		S_IRUGO,
+		g_dtlk_proc_dir,
+		&g_proc_file_reg_seq_fops
+		);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create register\n");
+		ret = -ENODEV;
+	}
+
+	/* create parser */
+	res  = proc_create("parser",
+		S_IRUGO,
+		g_dtlk_proc_dir,
+		&g_proc_file_parser_seq_fops
+	);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create register\n");
+		ret = -ENODEV;
+	}
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+	/* create parser */
+	res  = proc_create("m2c",
+		S_IRUGO,
+		g_dtlk_proc_dir,
+		&g_proc_file_m2c_seq_fops
+	);
+
+	if (!res) {
+		dtlk_debug(DBG_ERR, "Failed to create register\n");
+		ret = -ENODEV;
+	}
+#endif
+	return ret;
+}
+
+/**
+  * proc_file_create - Delete all proc files created by this driver
+  *
+  *
+  * Delete all proc files in /proc/dtlk.
+  * Called by dlrx_drv_exit.
+  */
+static INLINE void proc_file_delete(void)
+{
+	/* delete reg  entry */
+	remove_proc_entry("reg", g_dtlk_proc_dir);
+	/* delete ver  entry */
+	remove_proc_entry("ver", g_dtlk_proc_dir);
+	/* delete mib entry */
+	remove_proc_entry("wifi_mib", g_dtlk_proc_dir);
+	/* delete dbg */
+	remove_proc_entry("dbg", g_dtlk_proc_dir);
+	#if 0
+	/* delete test */
+	remove_proc_entry("test", g_dtlk_proc_dir);
+	#endif
+	/* delete wifi_port */
+	remove_proc_entry("wifi_port", g_dtlk_proc_dir);
+
+	/* delete peer_id */
+	remove_proc_entry("peer_id", g_dtlk_proc_dir);
+
+	/* delete peer_to_vap */
+	remove_proc_entry("peer_to_vap", g_dtlk_proc_dir);
+
+	/* delete mem */
+	remove_proc_entry("mem", g_dtlk_proc_dir);
+
+	/* delete parser */
+	remove_proc_entry("parser", g_dtlk_proc_dir);
+	/* delete m2c */
+	remove_proc_entry("m2c", g_dtlk_proc_dir);
+
+	/* delete parent proc directory */
+	remove_proc_entry(DIRECTLINK_PROC_DIR, NULL);
+
+	g_dtlk_proc_dir = NULL;
+}
+
+void dtlk_variables_api_init(void){
+	int i, j;
+	for (i = 0; i < MAX_RADIO_NUM; i++) {
+		struct ppe_radio_map *radio = &g_ppe_radio[i];
+		radio->flags = 0;
+		radio->dl_sub_if.port_id = -1;
+		radio->dl_sub_if.subif = -1;
+		for (j = 0; j < MAX_DTLK_NUM; j++) {
+			struct ppe_dtlk_map *dtlk =
+				&(radio->g_ppe_dtlk_data[j]);
+			memset(&radio->g_ppe_dtlk_data[j],
+				0,
+				sizeof(struct ppe_dtlk_map));
+			dtlk->dev = NULL;
+			dtlk->dl_sub_if.port_id = -1;
+			dtlk->dl_sub_if.subif = -1;
+			dtlk->owner = NULL;
+			dtlk->vap_id = -1;
+		}
+	}
+}
+#ifdef NEW_CHANGE
+
+extern int (*datapath_dtlk_register_fn)(PPA_SUBIF *subIf, PPA_DTLK_T *dtlk);
+#endif
+static void dl_init_dltx_memory(struct dl_buf_info dl_mem)
+{
+	if (dl_mem.tx_cfg_ctxt_buf_size && dl_mem.tx_cfg_ctxt_buf_base) {
+		memset((void *)(dl_mem.tx_cfg_ctxt_buf_base), 0, dl_mem.tx_cfg_ctxt_buf_size);
+		ppa_dl_dre_dma_writeback(dl_mem.tx_cfg_ctxt_buf_base,
+			dl_mem.tx_cfg_ctxt_buf_size);
+	}
+	if (dl_mem.rx_cfg_ctxt_buf_size && dl_mem.rx_cfg_ctxt_buf_base) {
+		memset((void *)(dl_mem.rx_cfg_ctxt_buf_base), 0, dl_mem.rx_cfg_ctxt_buf_size);
+		ppa_dl_dre_dma_writeback(dl_mem.rx_cfg_ctxt_buf_base,
+			dl_mem.rx_cfg_ctxt_buf_size);
+	}
+	if (dl_mem.rx_msgbuf_size && dl_mem.rx_msgbuf_base) {
+		memset((void *)(dl_mem.rx_msgbuf_base), 0, dl_mem.rx_msgbuf_size);
+		ppa_dl_dre_dma_writeback(dl_mem.rx_msgbuf_base,
+			dl_mem.rx_msgbuf_size);
+	}
+	if (dl_mem.uncached_addr_size && dl_mem.uncached_addr_base) {
+		memset((void *)dl_mem.uncached_addr_base, 0, dl_mem.uncached_addr_size);
+		ppa_dl_dre_dma_writeback(dl_mem.uncached_addr_base,
+			dl_mem.uncached_addr_size);
+	}
+	if (dl_mem.comm_buf_size && dl_mem.comm_buf_base) {
+		memset((void *)(dl_mem.comm_buf_base), 0, dl_mem.comm_buf_size);
+		ppa_dl_dre_dma_writeback(dl_mem.comm_buf_base,
+			dl_mem.comm_buf_size);
+	}
+
+}
+int __init dlrx_drv_init(void)
+{
+	struct dl_drv_address_map dl_resource;
+	if (g_ce5_desc_ring_num >= CE5_DEST_DESC_RING_NUM)
+		g_ce5_desc_ring_num = CE5_DEST_DESC_RING_NUM;
+
+	if (g_ce5_buf_ptr_ring_num < g_ce5_desc_ring_num)
+	   g_ce5_buf_ptr_ring_num = g_ce5_desc_ring_num;
+	dtlk_debug(DBG_INIT, "DirectLink's parameters\n");
+	dtlk_debug(DBG_INIT, "\tNumber of TX DESCRIPTOR: %d\n", dl_param_tx_descriptor);
+#ifdef PROFILING
+	initProfiling();
+#endif
+	wlan_detect_ath_card();
+	#ifdef NEW_CHANGE
+	datapath_dtlk_register_fn = datapath_dtlk_register;
+	#endif
+	/* Get DirectLink resource from MPE HAL */
+	#if 1
+	g_mpe_dev = mpe_hal_dl_get_dev();
+	#endif
+	#ifdef NEW_CHANGE
+	if (mpe_hal_dl_alloc_resource(0, (uint32_t *)&dl_resource, 0) < 0) {
+		dtlk_debug(DBG_ERR, "Can not get DL BUF INFO resource\n");
+		return -1;
+	}
+	#else
+	if (mpe_hal_dl_alloc_resouce(0, (uint32_t *)&dl_resource, 0) < 0) {
+		dtlk_debug(DBG_ERR, "Can not get DL BUF INFO resource\n");
+		return -1;
+	}
+	#endif
+#if DTLK_SWITCH_DISABLE_PARSE
+	datapath_dtlk_switch_parser = dtlk_switch_parser;
+#endif
+	dtlk_debug(DBG_INIT, "%s: 0x%x 0x%x\n",
+		__func__,
+		dl_resource.dl_buf_info_addr,
+		dl_resource.dl_ep_2radio_addr
+		);
+	memcpy(&g_dl_buf_info,
+		(struct dl_buf_info *)dl_resource.dl_buf_info_addr,
+		sizeof(g_dl_buf_info)
+		);
+	dl_init_dltx_memory(g_dl_buf_info);
+	g_dl_drv_address.dl_buf_info_addr = dl_resource.dl_buf_info_addr;
+	g_dl_drv_address.dl_ep_2radio_addr = dl_resource.dl_ep_2radio_addr;
+
+	dtlk_debug(DBG_INIT, "DirectLink resource from MPE HAL\n");
+	dtlk_debug(DBG_INIT, "    COMM base[%x]\n",
+		g_dl_buf_info.comm_buf_base);
+	dtlk_debug(DBG_INIT, "    COMM size[%d]\n",
+		g_dl_buf_info.comm_buf_size);
+	dtlk_debug(DBG_INIT, "    RX CFG context base[%x]\n",
+		g_dl_buf_info.rx_cfg_ctxt_buf_base);
+	dtlk_debug(DBG_INIT, "    RX CFG context size[%d]\n",
+		g_dl_buf_info.rx_cfg_ctxt_buf_size);
+	dtlk_debug(DBG_INIT, "    RX Message base[%x]\n",
+		g_dl_buf_info.rx_msgbuf_base);
+	dtlk_debug(DBG_INIT, "    RX Message size[%d]\n",
+		g_dl_buf_info.rx_msgbuf_size);
+	dtlk_debug(DBG_INIT, "    TX CFG context base[%x]\n",
+		g_dl_buf_info.tx_cfg_ctxt_buf_base);
+	dtlk_debug(DBG_INIT, "    TX CFG context size[%d]\n",
+		g_dl_buf_info.tx_cfg_ctxt_buf_size);
+	dtlk_debug(DBG_INIT, "    Uncached context base[%x]\n",
+		g_dl_buf_info.uncached_addr_base);
+	dtlk_debug(DBG_INIT, "    Uncached context size[%d]\n",
+		g_dl_buf_info.uncached_addr_size);
+	if (g_mpe_dev) {
+	#if 0
+		dma_addr_t phy_addr;
+		phy_addr = dma_map_single(
+						g_mpe_dev,
+						(void *)g_dl_buf_info.tx_cfg_ctxt_buf_base,
+						g_dl_buf_info.tx_cfg_ctxt_buf_size,
+						DMA_FROM_DEVICE
+						);
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "DMA error");
+		}
+		phy_addr = dma_map_single(
+						g_mpe_dev,
+						(void *)g_dl_buf_info.rx_cfg_ctxt_buf_base,
+						g_dl_buf_info.rx_cfg_ctxt_buf_size,
+						DMA_FROM_DEVICE
+						);
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "DMA error");
+		}
+		phy_addr = dma_map_single(
+						g_mpe_dev,
+						(void *)g_dl_buf_info.rx_msgbuf_base,
+						g_dl_buf_info.rx_msgbuf_size,
+						DMA_FROM_DEVICE
+						);
+		if (unlikely(dma_mapping_error(g_mpe_dev, phy_addr))) {
+			dtlk_debug(DBG_ERR, "DMA error");
+		}
+		#endif
+		/*
+		phy = dma_map_single(
+						g_mpe_dev,
+						(void *)g_dl_buf_info.comm_buf_base,
+						4,
+						DMA_FROM_DEVICE
+						);
+					dma_unmap_single(
+						g_mpe_dev,
+						phy,
+						4,
+						DMA_FROM_DEVICE
+						);
+						*/
+		dtlk_debug(DBG_INIT, "    COMM base[%x] KSEG0[0x%x] KSEG1[0x%x] [0x%x]\n",
+		g_dl_buf_info.comm_buf_base,
+		KSEG0,
+		KSEG1,
+		(unsigned int)CPHYSADDR(g_dl_buf_info.comm_buf_base));
+		} else{
+		dtlk_debug(DBG_ERR, "%s: device is null\n", __func__);
+		}
+	if (g_dl_buf_info.rx_cfg_ctxt_buf_base) {
+		uint32_t test = g_dl_buf_info.rx_cfg_ctxt_buf_base;
+		dtlk_debug(DBG_INIT, "Test tao lao: 0x%x\n", test);
+	}
+	/* Memory resources */
+	ddr_mpe_base = (unsigned int *)(g_dl_buf_info.tx_cfg_ctxt_buf_base);
+	ddr_mpe_comp_base = (unsigned int *)(g_dl_buf_info.comm_buf_base);
+	/* Initialize data structure */
+	if (dlrx_data_structure_init() == DTLK_SUCCESS)
+		dtlk_rx_api_init();
+	if (dltx_data_structure_init() != DTLK_SUCCESS) {
+		dtlk_debug(DBG_ERR, "%s:cannot initialize DLTX\n", __func__);
+	}
+	dtlk_variables_api_init();
+	set_vap_itf_tbl_fn = set_vap_itf_tbl;
+	dtlk_debug(DBG_INIT, "%s: before create proc\n", __func__);
+	proc_file_create();
+
+	dtlk_debug(DBG_INIT, "DLRX driver init successfully!\n");
+	dtlk_debug(DBG_INIT, "DLRX driver version: 0x%x\n",
+		DLRX_DRV_VERSION);
+	/*Configure MPE DL TX*/
+	if (ddr_mpe_base) {
+		dltx_cfg_global_t *mpe_dl_tx_cfg_global =
+			(dltx_cfg_global_t *)MPE_TX_ADDR(DLTX_CFG_GLOBAL_OFFSET);
+		mpe_dl_tx_cfg_global->dltx_enable = 1;
+		mpe_dl_tx_cfg_global->dltx_base_address = (unsigned int)ddr_mpe_base;
+		mpe_dl_tx_cfg_global->switch_parser_flag = 0;
+	}
+	/* start MPE DL TX,assume we are running one radio */
+	mpe_hal_feature_start(DL_TX_1, 0, NULL, F_FEATURE_START);
+	return 0;
+
+}
+
+#define DLTX_DRV_TO_EXIT 1
+#define DLTX_DRV_TO_DEBUG 2
+
+static void dltx_stop(void)
+{
+	dltx_drv_msg_t *dltx_cfg_ctxt_drv_msg;
+	dltx_cfg_ctxt_drv_msg = (dltx_drv_msg_t *)MPE_TX_COML_ADDR(DLTX_DRV_MSG_OFFSET);
+	dltx_cfg_ctxt_drv_msg->valid = 1;
+	dltx_cfg_ctxt_drv_msg->action_type = DLTX_DRV_TO_EXIT;
+	ppa_dl_qca_ipi_interrupt();
+}
+static void __exit dlrx_drv_exit(void)
+{
+	int retries = 3;
+	dltx_cfg_global_t *mpe_dl_tx_cfg_global =
+			(dltx_cfg_global_t *)MPE_TX_ADDR(DLTX_CFG_GLOBAL_OFFSET);
+
+	/* firstly: check for all activities and stop them
+	firstly: stop RX */
+	#ifdef NEW_CHANGE
+	datapath_dtlk_register_fn = NULL;
+	#endif
+#if DTLK_SWITCH_DISABLE_PARSE
+	datapath_dtlk_switch_parser = NULL;
+#endif
+#ifdef SUPPORT_UNLOAD_DTLK
+	/* ppa_dp_dlrx_exit(); */
+	dtlk_debug(DBG_INIT,
+		"%s:Not disable DMA 7\n",
+		__func__
+		);
+#endif
+
+	/* secondly: stop firmware */
+
+	/* clean proc */
+	proc_file_delete();
+	dtlk_debug(DBG_INIT, "After proc delete\n");
+	dtlk_debug(DBG_INIT,
+		"%s: Try to free all buffer in replenish list\n",
+		__func__
+		);
+	dtlk_rx_api_exit();
+	/*Stop MPE DL TX*/
+	/*Configure MPE DL TX*/
+	dltx_stop();
+	while (mpe_dl_tx_cfg_global->dltx_enable && retries) {
+		msleep(1000);
+		retries--;
+		dtlk_debug(DBG_INIT, "Try again\n");
+	}
+
+	dtlk_debug(DBG_INIT, "After dtlk_rx_api_exit\n");
+	mpe_hal_feature_start(DL_TX_1, 0, NULL, F_FEATURE_STOP);
+
+	return;
+}
+
+
+/* Module Definitions */
+module_init(dlrx_drv_init);
+module_exit(dlrx_drv_exit);
+
+MODULE_AUTHOR(MOD_AUTHOR);
+MODULE_DESCRIPTION(MOD_DESCRIPTION);
+MODULE_LICENSE(MOD_LICENCE);
+
diff --git a/drivers/net/ethernet/lantiq/directlink/include/11ac_acc_data_structure_tx_be.h b/drivers/net/ethernet/lantiq/directlink/include/11ac_acc_data_structure_tx_be.h
new file mode 100644
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/11ac_acc_data_structure_tx_be.h
@@ -0,0 +1,155 @@
+
+#ifndef __11AC_ACC_DATA_STRUCTURE_TX_BE_H_
+#define __11AC_ACC_DATA_STRUCTURE_TX_BE_H_
+
+typedef struct {
+	unsigned int _res0:24;
+	unsigned int int7:1;
+	unsigned int int6:1;
+	unsigned int int5:1;
+	unsigned int int4:1;
+	unsigned int int3:1;
+	unsigned int int2:1;
+	unsigned int int1:1;
+	unsigned int int0:1;
+} cfg_dirlink_int_t;
+
+typedef struct {
+	unsigned int size;
+} cfg_size_txpb_t;
+
+typedef struct {
+	unsigned int num;
+} cfg_num_txpb_t;
+
+typedef struct {
+	unsigned int addr;
+} cfg_badr_txpb_t;
+
+typedef struct {
+	unsigned int size;
+} cfg_size_txheader_t;
+
+typedef struct {
+	unsigned int num;
+} cfg_num_ce4des_t;
+
+typedef struct {
+	unsigned int num;
+} cfg_ce4des_low_t;
+
+typedef struct {
+	unsigned int num;
+} cfg_ce4des_full_t;
+
+typedef struct {
+	unsigned int addr;
+} cfg_badr_ce4des_t;
+
+typedef struct {
+	unsigned int index;
+} dma_rxdes_index_t;
+
+typedef struct {
+	unsigned int num;
+} free_num_txpb_t;
+
+typedef struct {
+	unsigned int index;
+} local_ce4_read_index_t;
+
+typedef struct {
+	unsigned int req;
+} local_ce4_read_index_req_t;
+
+typedef struct {
+	unsigned int _res0:15;
+	unsigned int fraglen:17;
+	unsigned int payloadlen:16;
+	unsigned int flags:8;
+	unsigned int endpointid:8;
+	unsigned int _res1:16;
+	unsigned int controlbyte1:8;
+	unsigned int controlbyte0:8;
+	unsigned int _res2:1;
+	unsigned int cksum:2;
+	unsigned int mib:1;
+	unsigned int postponded:1;
+	unsigned int exttid:5;
+	unsigned int vdevid:6;
+	unsigned int pkttype:3;
+	unsigned int pktsubtype:5;
+	unsigned int msgtype:8;
+	unsigned int id:16;
+	unsigned int len:16;
+	unsigned int _dw_res0[3];
+} htt_txdes_t;
+
+typedef struct {
+	unsigned int status;
+} free_tx_pb_status_t;
+
+typedef struct {
+	unsigned int status;
+} free_tx_pb_group32_status_t;
+
+typedef struct {
+	unsigned int status;
+} free_tx_pb_group1024_status_t;
+
+typedef struct {
+	unsigned int _res0:8;
+	unsigned int num_pb_pointers:8;
+	unsigned int _res1:16;
+	unsigned int free_pb_ptr[128];
+} tx_buf_release_msg0_t;
+
+typedef struct {
+	unsigned int _res0:8;
+	unsigned int num_pb_pointers:8;
+	unsigned int _res1:16;
+	unsigned int free_pb_ptr[128];
+} tx_buf_release_msg1_t;
+
+typedef struct {
+	unsigned int txpdu;
+	unsigned int txbytes;
+	unsigned int rx_fwd_pdu;
+	unsigned int rx_fwd_bytes;
+	unsigned int rx_inspect_pdu;
+	unsigned int rx_inspect_bytes;
+	unsigned int rx_discard_pdu;
+	unsigned int rx_discard_bytes;
+	unsigned int txpdu_high;
+	unsigned int txbytes_high;
+	unsigned int rx_drop_pdu;
+	unsigned int rx_drop_bytes;
+	unsigned int rx_rcv_pdu;
+	unsigned int rx_rcv_bytes;
+	unsigned int _dw_res0[2];
+} mib_table_t;
+
+typedef struct {
+	unsigned int src_buf_ptr;
+	unsigned int metadata:14;
+	unsigned int bytesw:1;
+	unsigned int gather:1;
+	unsigned int src_buf_len:16;
+} ce4_src_ring_desc_t;
+
+typedef struct {
+	unsigned int own:1;
+	unsigned int c:1;
+	unsigned int sop:1;
+	unsigned int eop:1;
+	unsigned int byte_offset:5;
+	unsigned int rx_sideband:4;
+	unsigned int _res1:3;
+	unsigned int data_len:16;
+	unsigned int _res2:2;
+	unsigned int dataptr:27;
+	unsigned int _res3:3;
+} soc_dma_desc_t;
+
+#endif
+
diff --git a/drivers/net/ethernet/lantiq/directlink/include/Dltx_fw_def.h b/drivers/net/ethernet/lantiq/directlink/include/Dltx_fw_def.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/Dltx_fw_def.h
@@ -0,0 +1,84 @@
+#ifndef __DLTX_FW_DEF_H__
+#define __DLTX_FW_DEF_H__
+
+/*extern struct genconf gc;*/
+
+#define dl_kseg0 KSEG0
+#define dl_kseg1 KSEG1
+
+
+
+/*#define TX_CFG_CTXT_BUF_BASE                            gc.dl_buffer_info.tx_cfg_ctxt_buf_base*/
+
+
+#define DLTX_CE4_WRITE_INDEX_TRACK_OFFSET			0  /*4096 dwords*/
+
+#define DLTX_CIRCULAR_LIST_OFFSET					0x1000 /*Byte offset: 0x4000    4096 dwords*/
+
+#define DLTX_BUFFER_POINTER_TABLE_OFFSET			0x2000 /*Byte offset: 0x8000    4096 dwords*/
+
+#define HTT_TX_DES_OFFSET(vap)						(0x3000 + (vap * (8)))  /*Byte offset: 0xC000   16*8 = 128 dwords*/
+
+#define DLTX_QCA_VAP_ID_MAP_OFFSET					0x3080  /*Byte offset: 0xC200 16 dwords*/
+
+#define DLTX_VAP_DATA_MIB_OFFSET(vap)				(0x3090 + (vap * (16))) /*Byte offset: 0xC240   16*16 = 256 dwords*/
+
+#define DLTX_DATA_MIB_OFFSET						0x3190 /*Byte offset: 0xC640   8 dwords*/
+
+#define DLTX_CFG_CTXT_CE4BUF_OFFSET					0x3198 /*Byte offset: 0xC660  16 dwords*/
+
+#define DLTX_CFG_CTXT_CIRCULAR_LIST_OFFSET			0x31A8 /*Byte offset: 0xC6A0   8 dwords*/
+
+#define DLTX_CFG_CTXT_BUFFER_POINTER_TABLE_OFFSET	0x31B0 /*Byte offset: 0xC6C0  4 dwords*/
+
+#define DLTX_CFG_CTXT_CE4_WRITE_INDEX_TRACK_OFFSET	0x31B4 /*Byte offset: 0xC6D0  4 dwords*/
+
+#define DLTX_CFG_CTXT_TX_MSG_OFFSET				    0x31B8 /*Byte offset: 0xC6E0  4 dwords*/
+
+#define DLTX_CFG_CTXT_QCA_VAP_ID_MAP_OFFSET			0x31BC /*Byte offset: 0xC6F0  4 dwords*/
+
+#define DLTX_CTXT_MSG_OFFSET						0x31C0 /*Byte offset: 0xC700  24 dwords*/
+
+#define DLTX_CFG_GLOBAL_OFFSET						0x31D8 /*Byte offset: 0xC760 16 dwords*/
+
+#define DLTX_CFG_CTXT_CIRCULAR_LIST_LINUX_OFFSET	0x31E8 /*Byte offset: 0xC7a0 16 dwords*/
+
+#define DLTX_FRAG_DATA_OFFSET                       0x3200 /*Byte offset: 0xC800  16 * 4096 = 65536 dwords*/
+
+#define DLTX_CFG_CTXT_FRAG_DATA_OFFSET              0x13200 /*Byte offset: 0x4C7A0  4 dwords*/
+
+#define DLTX_CFG_CTXT_M2C_PEER_TABLE                0x13204 /*Byte offset: 0x4C810  128(peer) * 2 dwords*/
+
+#define DLTX_CFG_CTXT_M2C_GROUP_TABLE               0x13304 /*Byte offset: 0x4CC10  64(group) * 5 dwords*/
+
+#define DLTX_PACKET_ID_TRACE_CIRCULAR_LIST_OFFSET	0x20000 /* Byte offset: 1(tx) + 1(tx_ptr) + 1(completion) + 1(comple_ptr) + 64(dwords) x1000    4096 dwords */
+
+/*Structure offsets for communication buffer structures*/
+
+#define DLTX_TX_CMPL_FLAG_OFFSET					0	  /*2*8 = 16 dwords*/
+
+#define DLTX_TX_CMPL_MSG_OFFSET						0x10    /*Byte offset: 0x40    8* 129 = 1032 dwords*/
+
+#define DLTX_CFG_CTXT_CPU_CE4DES_OFFSET				0x418  /*Byte offset: 0x1060  8 dwords*/
+
+#define DLTX_CPU_CE4DES_FORMAT_OFFSET				0x420  /*Byte offset: 0x1080  128 * 2 = 256 dwords*/
+
+#define DLTX_CFG_CTXT_COMM_BUFF_OFFSET				0x520 /*Byte offset: 0x1480    8 dwords*/
+
+#define DLTX_DRV_MSG_OFFSET							0x528 /*Byte offset: 0x14A0  64 dwords*/
+
+
+/*Hardware addresses*/
+
+/*address in QCA 11ac target*/
+/*CE4 base address*/
+#define CE4SRC_BEELINER_HI                          0x4
+#define CE4SRC_MISC_IE_BEELINER_LOW                 0xB034
+
+/*CE4 read and write index*/
+#define CE4SRC_TARGET_WR_PTR_BEELINER_LOW           0xB03C
+#define CE4SRC_TARGET_RD_PTR_BEELINER_LOW           0xB044
+
+
+#endif
+
diff --git a/drivers/net/ethernet/lantiq/directlink/include/directlink_tx_cfg.h b/drivers/net/ethernet/lantiq/directlink/include/directlink_tx_cfg.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/directlink_tx_cfg.h
@@ -0,0 +1,79 @@
+#ifndef __11AC_ACC_TX_ADDR_DEF_CFG_INC
+#define __11AC_ACC_TX_ADDR_DEF_CFG_INC
+
+#define __EMA_CMD_BUF				0x3000
+#define __EMA_DATA_BUF				0x3080
+
+/* EMA accessible config/ctxt */
+/* 0x31A8-0x31AF */
+#define __CPU_CE4_READ_INDEX		0x31AB
+#define __CPU_CE4_WRITE_INDEX		0x31AC
+
+/* context */
+#define __LOCAL_CE4_READ_INDEX		0x31a8
+#define __LOCAL_CE4_WRITE_INDEX		0x31a9
+#define __CPU_CE4_PPE_READ_INDEX	0x31aa
+#define __LOCAL_CHIP_ID_ADDR		0x31ad
+#define __CPU_CE4_SW_IDX			0x31ae
+
+#define __D6_HTT_TX_DES_BASE		0x36D0
+/* 8 * 16 entries */
+#define __D6_HTT_TX_DES_SIZE		128
+#define __D6_SUPPORT_VAP_NUM		16
+
+#define __D6_PER_VAP_MIB_BASE		0x4F00
+/* 16 * 16 (VAP)  */
+#define __D6_PER_VAP_MIB_SIZE		156
+
+/* #define __D6_TX_CFG_BASE	0x5F00-0x5F1F */
+#define __CFG_DIRLINK_INT			0x5F00
+#define __CFG_SIZE_TXPB				0x5F01
+#define __CFG_INT2VAP_MAP			0x5F02
+#define __CFG_BADR_TXPB				0x5F03
+#define __CFG_SIZE_TXHEADER			0x5F04
+#define __CFG_NUM_CE4SRCDES			0x5F05
+#define __CFG_CE4DES_LOW			0x5F06
+#define __CFG_CE4DES_FULL			0x5F07
+#define __CFG_BADR_CE4SRCDES		0x5F08
+#define __CFG_QCAMEM_BASE			0x5F09
+#define __CFG_SIZE_CPUSRCDES		0x5F0a
+
+/* support BEELINER */
+#define __CFG_BOARD_TYPE			0x5F0B
+#define __BEELINER_FRAG_DES_BASE	0x5EF0
+
+
+/* __D6_TX_CTX_BASE	   0x5F20=>0x5F3F */
+#define __DMA_RXDES_INDEX			0x5F20
+#define __FREE_NUM_TXPB				0x5F21
+
+#define __LOCAL_CE4_READ_INDEX_REQ	0x5F22
+
+#define __CE4_READ_REQ_PERIOD_CFG	0x5F23
+#define __CE4_READ_REQ_PERIOD_CNT	0x5F24
+#define __FREE_PB_PTR_ADDR			0x5F25
+
+
+#define __D6_TX_PB_STATUS_BASE		0x5F40
+/* 1 + 4 + 128 to maintain 4K bytes packet buffer */
+#define __D6_TX_PB_STATUS_SIZE		133
+#define __FREE_PB_GROUP1024_STATUS		0x5F40
+#define __FREE_PB_GROUP32_STATUS_BASE	0x5F41
+#define __FREE_PB_GROUP32_STATUS_SIZE	4
+#define __FREE_PB_STATUS_BASE			0x5F45
+#define __FREE_PB_STATUS_SIZE			128
+
+#define __D6_RXDMA7_DES_BASE			0x5FD0
+/* 2 * 8 entries */
+#define __D6_RXDMA7_DES_SIZE			16
+
+#define __D6_TXPB_MSG0_BASE				0x5C00
+#define __D6_TXPB_MSG0_SIZE				129
+
+#define __D6_TXPB_MSG1_BASE				0x5C90
+#define __D6_TXPB_MSG1_SIZE				129
+
+/* CPU CE4 Descriptor Queue buffer 64*2 DWs */
+#define __CPU_CE4_BUF_BASE				0x5D40
+
+#endif
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dlrx_dre_api.h b/drivers/net/ethernet/lantiq/directlink/include/dlrx_dre_api.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dlrx_dre_api.h
@@ -0,0 +1,227 @@
+#ifndef __DLRX_DRE_API_H__
+#define __DLRX_DRE_API_H__
+
+enum {
+	DRE_MAIN_FN = 0,
+	DRE_GET_VERSION_FN,
+	DRE_RESET_FN,
+	DRE_GET_MIB_FN,
+	DRE_GET_CURMSDU_FN,
+	DRE_SET_MEMBASE_FN,
+	DRE_SET_RXPN_FN,
+	DRE_SET_DLRX_UNLOAD,
+	DRE_MAX_FN
+};
+
+enum {
+	DRE_RESET_MIB,
+	DRE_RESET_PEER,
+};
+
+enum {
+	DRE_MSG_MIB,
+	DRE_VAP_MIB,
+	DRE_DATA_MIB,
+};
+
+enum {
+	MIN_PEERID = 0,
+	MAX_PEERID = 127
+};
+
+enum {
+	MIN_VAPID = 0,
+	MAX_VAPID = 15
+};
+
+enum {
+	PEER_INVALID = 0,
+	PEER_VALID	 = 1,
+};
+
+enum {
+	INVALIDATE_HEADER = 0,
+	INVALIDATE_FULL
+};
+
+enum {
+	PEREGRINE_BOARD = 0,
+	BEELINER_BOARD
+};
+
+enum {
+	SUBTYPE_NONE_BOARD = 0,
+	SUBTYPE_BEELINER_CASCADE_BOARD
+};
+
+enum {
+	LOAD_QCA = 0,
+	UNLOAD_QCA = 1
+};
+
+
+#define RESET_ALLVAP	0xFF
+#define MAX_PEERID_NUM	1056
+#define MAX_PEER_NUM	128
+#define MAX_VAP_NUM		16
+#define MAX_INV_PEREGRINE_HEADER_LEN	256
+#define MAX_INV_BEELINER_HEADER_LEN		320
+#define MAX_INV_CASCADE_HEADER_LEN		324
+
+#define QCA_PEREGRINE_11AC_CFG_OFFSET_ATTEN   248
+#define QCA_BEELINER_11AC_CFG_OFFSET_ATTEN	 296
+#define QCA_CASCADE_11AC_CFG_OFFSET_ATTEN	 300
+
+#define DTLK_INVALID_ITFID			0xF
+
+typedef struct dre_register_func_set {
+	void *dre_dl_main_fn;
+	void *dre_dl_getver_fn;
+	void *dre_dl_reset_fn;
+	void *dre_dl_getmib_fn;
+	void *dre_dl_getmsdu_fn;
+	void *dre_dl_set_membase_fn;
+	void *dre_dl_set_rxpn_fn;
+	void *dre_dl_set_dlrx_unload_t;
+} dre_regfn_set_t;
+
+typedef int (*dre_dl_main_fn_t)(void);
+typedef unsigned int (*dre_dl_getver_fn_t)(void);
+/* reset type, vap id(0-15)/peer id(0-127) */
+typedef void (*dre_dl_reset_fn_t)(
+			unsigned int reset_type,
+			unsigned int id_num
+			);
+typedef unsigned int (*dre_dl_getmib_fn_t)(
+			unsigned int mib_type,
+			unsigned int vapid
+			);
+/* return base addr and data len */
+typedef int (*dre_dl_getmsdu_fn_t)(
+			unsigned int *rxpb_ptr,
+			unsigned int *data_len
+			);
+/* configure the base address */
+typedef int (*dre_dl_set_membase_fn_t)(
+			unsigned int ddr_membase,
+			unsigned int cfg_ctxt_membase,
+			unsigned int pcie_membase
+			);
+/* set rxpn */
+typedef int (*dre_dl_set_rxpn_fn_t)(
+			unsigned int peer,
+			unsigned int *rxpn
+			);
+typedef void (*dre_dl_set_dlrx_unload_t)(void);
+
+
+/* API to support dre to send pkt to switch via dma */
+extern int ppa_dl_dre_gswip_dma_send(
+	unsigned int vap_id,
+	unsigned int rxpb_ptr,
+	unsigned int data_ptr,
+	unsigned int data_len,
+	unsigned int release_flag,
+	unsigned int pmac_hdr_ptr,
+	unsigned int unmap_type
+	);
+
+/* API to support dre to send pkt to protocol stack*/
+extern int ppa_dl_dre_ps_send(
+	unsigned int rxpb_ptr,
+	unsigned int data_ptr,
+	unsigned int data_len,
+	unsigned int vap_id
+	);
+
+/* API to support dre to send pkt to wlan driver */
+extern int ppa_dl_dre_wlan_pkt_send(
+	unsigned int rxpb_ptr,
+	unsigned int data_len,
+	unsigned int pktstatus,
+	unsigned int msg_ptr,
+	unsigned int vap_id,
+	unsigned int flags
+	);
+
+/* API to support dre to send message to wlan driver */
+extern int ppa_dl_dre_wlan_msg_send(
+	unsigned int msg_type,
+	unsigned int msg_ptr,
+	unsigned int msg_len,
+	unsigned int flags
+	);
+
+/* API to support dre to release buff after receive the TX complete message */
+extern int ppa_dl_dre_txpkt_buf_release(
+	unsigned int num_msdus,
+	unsigned int *msg,
+	unsigned int flags
+	);
+
+/* API to support dre to register callback functons */
+extern int ppa_dl_dre_fn_register(
+	unsigned int regno,
+	void *func
+	);
+
+/* API to get peer via peer id */
+extern int ppa_dl_dre_peer_from_peerid(
+	unsigned int peerid,
+	unsigned int *peer
+	);
+
+/* API to get vap info via peer */
+extern int ppa_dl_dre_vapinfo_from_peer(
+	unsigned int peer,
+	unsigned int *vapid,
+	unsigned int *sec_type,
+	unsigned int *acc_dis
+	);
+
+/* API to get interface id via vap id */
+extern unsigned int ppa_dl_dre_itf_from_vapid(
+	unsigned int vap_id
+	);
+
+/*API to set the vapinfo */
+extern int ppa_dl_dre_vapinfo_set(
+	unsigned int peer,
+	unsigned int vapid,
+	unsigned int sec_type,
+	unsigned int acc_dis
+	);
+
+
+/* API to allocate a rxpb pkt buffer to FW */
+extern unsigned int dlrx_dl_dre_rxpb_buf_alloc(void);
+
+/*API to free the rxpb buffer*/
+extern int ppa_dl_dre_rxpb_buf_free(
+	unsigned int rxpb_ptr
+	);
+
+extern unsigned int ppa_dl_dre_get_sram_addr(void);
+
+extern void ppa_dl_dre_dma_invalidate(
+		unsigned int startAddr,
+		unsigned int size
+		);
+
+extern void ppa_dl_dre_dma_writeback(
+		unsigned int startAddr,
+		unsigned int size
+		);
+
+extern void ppa_dl_dre_dma_wback_inv(
+		unsigned int startAddr,
+		unsigned int size
+		);
+
+extern unsigned int ppa_dl_dre_get_kseg0(void);
+
+extern unsigned int ppa_dl_dre_get_kseg1(void);
+
+extern void ppa_dl_dre_peer_act_fn(unsigned int peer_id);
+
+#endif
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dlrx_drv.h b/drivers/net/ethernet/lantiq/directlink/include/dlrx_drv.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dlrx_drv.h
@@ -0,0 +1,98 @@
+#ifndef __DLRX_DRV_H__
+#define __DLRX_DRV_H__
+#include <linux/klogging.h>
+
+/****************************************************
+ *	Extern Variable Declaration
+ ****************************************************/
+extern uint32_t g_dtlk_dbg_enable;
+
+/****************************************************
+ *	Extern Variable Declaration
+ ****************************************************/
+extern struct sk_buff *alloc_skb_rx(void);
+extern struct net_device *dtlk_dev_from_vapid(
+	uint32_t
+	);
+extern void dtlk_rx_api_init(void);
+extern void dtlk_rx_api_exit(void);
+extern void set_vap_itf_tbl(
+	uint32_t vap_id,
+	uint32_t itf_id
+	);
+
+/****************************************************
+ *	Macro Definition
+ ****************************************************/
+#define DTLK_PACKET_SIZE		2048
+#define DTLK_ALIGNMENT			32
+#define DMA_CPU_OWNBIT			0
+
+#define DTLK_SUCCESS			0
+#define DTLK_FAILURE			-1
+#define DTLK_ERROR				-2
+
+#define HANDLER_FOUND			0
+#define HANDLER_NOT_FOUND		-1
+#define PEER_FIRST				1
+
+#define DTLK_DBG				1
+#define ENABLE_DTLK_DBG			1
+
+#define SUPPORT_UNLOAD_DTLK		1
+#define SUPPORT_11AC_MULTICARD 1
+
+#define DTLK_FIX_CACHE_COHENRENT 1
+#define DTLK_DEBUG_TX_COMPLETION 1
+
+#define SUPPORT_MULTICAST_TO_UNICAST 1
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+#define MAX_MCAST_GROUP 64
+#endif
+/*#define PROFILING 1*/
+
+#ifdef PROFILING
+extern void	initProfiling(void);
+#endif
+
+
+#define ASSERT(cond, fmt, arg...) do { if (!(cond)) LOGF_KLOG_ERR_RATELIMITED("%s:%d:%s: " fmt "\n", __FILE__, __LINE__, __func__, ##arg); } while (0)
+
+/*
+ *	Debug Print Mask
+ *	Note, once you add a new DBG_ macro,
+ * don't forget to add it in DBG_ENABLE_MASK_ALL also !!!!
+ */
+#define DBG_ERR		BIT(0)
+#define DBG_INIT	BIT(1)
+#define DBG_RX		BIT(2)
+#define DBG_TX		BIT(3)
+#define DBG_CPU		BIT(4)
+#define DBG_PROC	BIT(5)
+#define DBG_PRINT	BIT(6)
+
+
+
+
+
+
+
+#define DTLK_DBG_ENA (DBG_ERR | DBG_INIT | DBG_PRINT)
+#define DTLK_DBG_ENABLE_MASK_ALL (DBG_RX | DBG_TX | DBG_CPU | DBG_PROC)
+
+#define dtlk_debug(dbg_level, fmt, arg...) \
+	do { \
+		if ((g_dtlk_dbg_enable & dbg_level)) { \
+			if (dbg_level & DBG_ERR) { \
+				LOGF_KLOG_ERR_RATELIMITED(fmt, ##arg); \
+			} else if ((dbg_level & DBG_PRINT) || \
+					(dbg_level & DBG_INIT)) { \
+				LOGF_KLOG_INFO_RATELIMITED(fmt, ##arg); \
+			} else { \
+				LOGF_KLOG_DEBUG_RATELIMITED(fmt, ##arg); \
+			} \
+		} \
+	} \
+	while (0)
+
+#endif /* __DLRX_DRV_H__ */
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_data_structure_be.h b/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_data_structure_be.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_data_structure_be.h
@@ -0,0 +1,833 @@
+
+#ifndef __DLRX_FW_DATA_STRUCTURE_BE_H_
+#define __DLRX_FW_DATA_STRUCTURE_BE_H_
+
+    typedef struct {
+
+        unsigned int msdu_load_status:1;
+        unsigned int insig1:28;
+        unsigned int mcast_bcast:1;
+        unsigned int insig0:2;
+
+        unsigned int insig3:8;
+        unsigned int msdu_chain_num:8;
+        unsigned int insig2:16;
+
+        unsigned int insig5:4;
+        unsigned int seqid:12;
+        unsigned int insig4:16;
+
+        unsigned int pn_31_0;
+
+        unsigned int insig6:16;
+        unsigned int pn_47_32:16;
+
+        unsigned int insig7:18;
+        unsigned int msdu_len:14;
+
+        unsigned int insig8;
+
+        unsigned int insig9;
+
+        unsigned int insig10;
+
+        unsigned int pn_63_48:16;
+        unsigned int insig11:16;
+
+        unsigned int pn_95_64;
+
+        unsigned int pn_127_96;
+
+        unsigned int insig13:16;
+        unsigned int last_msdu:1;
+        unsigned int first_msdu:1;
+        unsigned int insig12:14;
+
+    } dlrx_rxpb_hdr_peregrine_t;
+
+    typedef struct {
+
+        unsigned int msdu_load_status:1;
+        unsigned int insig1:28;
+        unsigned int mcast_bcast:1;
+        unsigned int insig0:2;
+
+        unsigned int insig3:8;
+        unsigned int msdu_chain_num:8;
+        unsigned int insig2:16;
+
+        unsigned int insig5:4;
+        unsigned int seqid:12;
+        unsigned int insig4:16;
+
+        unsigned int pn_31_0;
+
+        unsigned int insig6:16;
+        unsigned int pn_47_32:16;
+
+        unsigned int insig7:18;
+        unsigned int msdu_len:14;
+
+        unsigned int insig8;
+
+        unsigned int insig9;
+
+        unsigned int insig10;
+
+        unsigned int insig11;
+
+        unsigned int pn_63_48:16;
+        unsigned int insig12:16;
+
+        unsigned int pn_95_64;
+
+        unsigned int pn_127_96;
+
+        unsigned int insig14:16;
+        unsigned int last_msdu:1;
+        unsigned int first_msdu:1;
+        unsigned int insig13:14;
+
+        unsigned int insig15;
+
+        unsigned int insig16;
+
+        unsigned int insig17;
+
+        unsigned int insig19:19;
+        unsigned int l3_header_padding:3;
+        unsigned int insig18:10;
+
+        unsigned int insig20;
+
+    } dlrx_rxpb_hdr_beeliner_t;
+
+    typedef struct {
+
+        unsigned int rsvd3:4;
+        unsigned int src_int:4;
+        unsigned int rsvd2:4;
+        unsigned int dest_int:4;
+        unsigned int rsvd1:3;
+        unsigned int fwd1:1;
+        unsigned int vap:4;
+        unsigned int rsvd0:6;
+        unsigned int discard:1;
+        unsigned int fwd:1;
+
+    } dlrx_rxpb_pmac_hdr_t;
+
+    typedef struct {
+
+        unsigned int rsvd0:16;
+        unsigned int mpdu_status:8;
+        unsigned int fw_rx_desc_byte:8;
+
+    } dlrx_rxpb_wlan_drv_hdr_t;
+
+    typedef struct {
+
+        unsigned int htt_hdr[2];
+
+        unsigned int peer_id:16;
+        unsigned int rsvd0:1;
+        unsigned int rv:1;
+        unsigned int fv:1;
+        unsigned int ext_tid:5;
+        unsigned int msg_type:8;
+
+        unsigned int mpdu_ranges_num:8;
+        unsigned int release_end_seqid:6;
+        unsigned int release_start_seqid:6;
+        unsigned int flush_end_seqid:6;
+        unsigned int flush_start_seqid:6;
+
+        unsigned int rsvd2;
+
+        unsigned int rsvd3;
+
+        unsigned int rsvd4;
+
+        unsigned int rsvd5;
+
+        unsigned int rsvd6;
+
+        unsigned int rsvd7;
+
+        unsigned int rsvd8;
+
+        unsigned int rsvd9;
+
+        unsigned int rsvd10;
+
+        unsigned int rsvd11:16;
+        unsigned int fw_rx_desc_byte_num:16;
+
+    } dlrx_ind_msg_t;
+
+    typedef struct {
+
+        unsigned int rsvd2_msdu3:2;
+        unsigned int inspect_msdu3:1;
+        unsigned int rsvd1_msdu3:3;
+        unsigned int forward_msdu3:1;
+        unsigned int discard_msdu3:1;
+        unsigned int rsvd2_msdu2:2;
+        unsigned int inspect_msdu2:1;
+        unsigned int rsvd1_msdu2:3;
+        unsigned int forward_msdu2:1;
+        unsigned int discard_msdu2:1;
+        unsigned int rsvd2_msdu1:2;
+        unsigned int inspect_msdu1:1;
+        unsigned int rsvd1_msdu1:3;
+        unsigned int forward_msdu1:1;
+        unsigned int discard_msdu1:1;
+        unsigned int rsvd2_msdu0:2;
+        unsigned int inspect_msdu0:1;
+        unsigned int rsvd1_msdu0:3;
+        unsigned int forward_msdu0:1;
+        unsigned int discard_msdu0:1;
+
+    } fw_rx_desc_byte_t;
+
+    typedef struct {
+
+        unsigned int mpdu_status_mpdu_range1:8;
+        unsigned int mpdu_cnt_mpdu_range1:8;
+        unsigned int mpdu_status_mpdu_range0:8;
+        unsigned int mpdu_cnt_mpdu_range0:8;
+
+    } ctxt_mpdu_t;
+
+    typedef struct {
+
+        unsigned int htt_hdr[2];
+
+        unsigned int rsvd1:3;
+        unsigned int ext_tid:5;
+        unsigned int peer_id:16;
+        unsigned int msg_type:8;
+
+        unsigned int rsvd4:2;
+        unsigned int flush_end_seqid:6;
+        unsigned int rsvd3:2;
+        unsigned int flush_start_seqid:6;
+        unsigned int mpdu_status:8;
+        unsigned int rsvd2:8;
+
+    } dlrx_flush_msg_t;
+
+    typedef struct {
+
+        unsigned int htt_hdr[2];
+
+        unsigned int peer_id:16;
+        unsigned int rsvd0:2;
+        unsigned int fv:1;
+        unsigned int ext_tid:5;
+        unsigned int msg_type:8;
+
+        unsigned int rsvd2:20;
+        unsigned int flush_end_seqid:6;
+        unsigned int flush_start_seqid:6;
+
+        unsigned int rsvd3:16;
+        unsigned int fw_rx_desc_byte_num:16;
+
+        unsigned int padding:24;
+        unsigned int fw_rx_desc_byte_msdu0:8;
+
+        unsigned int rsvd4:20;
+        unsigned int rxpb_ptr_read_index:12;
+
+    } dlrx_frag_ind_msg_t;
+
+    typedef struct {
+
+        unsigned int htt_hdr[2];
+
+        unsigned int _res0:8;
+        unsigned int pb_ptr_rel_num:8;
+        unsigned int _res1:5;
+        unsigned int status:3;
+        unsigned int msg_type:8;
+
+        unsigned int free_txpb_ptr[128];
+
+    } dlrx_tx_cmpl_msg_t;
+
+    typedef struct {
+
+        unsigned int last_pn_dw0;
+
+        unsigned int last_pn_dw1;
+
+        unsigned int last_pn_dw2;
+
+        unsigned int last_pn_dw3;
+
+        unsigned int mcast_bcast:1;
+        unsigned int msdu_num:15;
+        unsigned int first_ptr:16;
+
+        unsigned int _dw_res0[63];
+
+    } dlrx_ro_mainlist_t;
+
+    typedef struct {
+
+        unsigned int pn_dw0;
+
+        unsigned int pn_dw1;
+
+        unsigned int pn_dw2;
+
+        unsigned int pn_dw3;
+
+        unsigned int next_ptr:12;
+        unsigned int rsvd0:1;
+        unsigned int inspect:1;
+        unsigned int discard:1;
+        unsigned int fwd:1;
+        unsigned int msdu_len:16;
+
+        unsigned int rxpb_ptr;
+
+    } dlrx_ro_linklist_t;
+
+    typedef struct {
+
+        unsigned int rsvd1:9;
+        unsigned int pb_ptr_rel_num:7;
+        unsigned int rsvd0:16;
+
+        unsigned int rxpb_ptr[127];
+
+    } dlrx_rxpb_ptr_rel_msg_t;
+
+    typedef struct {
+
+        unsigned int txpdu_low;
+
+        unsigned int txpdu_high;
+
+        unsigned int txbytes_low;
+
+        unsigned int txbytes_high;
+
+        unsigned int txdrop_low;
+
+        unsigned int txdrop_high;
+
+        unsigned int rx_fwd_pdu_low;
+
+        unsigned int rx_fwd_pdu_high;
+
+        unsigned int rx_fwd_bytes_low;
+
+        unsigned int rx_fwd_bytes_high;
+
+        unsigned int rx_inspect_pdu_low;
+
+        unsigned int rx_inspect_pdu_high;
+
+        unsigned int rx_inspect_bytes_low;
+
+        unsigned int rx_inspect_bytes_high;
+
+        unsigned int rx_discard_pdu_low;
+
+        unsigned int rx_discard_pdu_high;
+
+        unsigned int rx_discard_bytes_low;
+
+        unsigned int rx_discard_bytes_high;
+
+        unsigned int rx_pn_pdu_low;
+
+        unsigned int rx_pn_pdu_high;
+
+        unsigned int rx_pn_bytes_low;
+
+        unsigned int rx_pn_bytes_high;
+
+        unsigned int rx_drop_pdu_low;
+
+        unsigned int rx_drop_pdu_high;
+
+        unsigned int rx_drop_bytes_low;
+
+        unsigned int rx_drop_bytes_high;
+
+        unsigned int rx_rcv_pdu_low;
+
+        unsigned int rx_rcv_pdu_high;
+
+        unsigned int rx_rcv_bytes_low;
+
+        unsigned int rx_rcv_bytes_high;
+
+        unsigned int _dw_res0[2];
+
+    } vap_data_mib_t;
+
+    typedef struct {
+
+        unsigned int rx_gswip_packets_low;
+
+        unsigned int rx_gswip_packets_high;
+
+        unsigned int rx_gswip_bytes_low;
+
+        unsigned int rx_gswip_bytes_high;
+
+        unsigned int rx_wlan_packets_low;
+
+        unsigned int rx_wlan_packets_high;
+
+        unsigned int rx_wlan_bytes_low;
+
+        unsigned int rx_wlan_bytes_high;
+
+        unsigned int rx_protocol_stack_packets_low;
+
+        unsigned int rx_protocol_stack_packets_high;
+
+        unsigned int rx_protocol_stack_bytes_low;
+
+        unsigned int rx_protocol_stack_bytes_high;
+
+        unsigned int rx_forward_packets_low;
+
+        unsigned int rx_forward_packets_high;
+
+        unsigned int rx_forward_bytes_low;
+
+        unsigned int rx_forward_bytes_high;
+
+        unsigned int _dw_res0[16];
+
+    } vap_data_misc_mib_t;
+
+    typedef struct {
+
+        unsigned int rx_success_mpdu;
+
+        unsigned int rx_success_msdu;
+
+        unsigned int rx_error2_mpdu;
+
+        unsigned int rx_error2_msdu;
+
+        unsigned int rx_error3_mpdu;
+
+        unsigned int rx_error3_msdu;
+
+        unsigned int rx_error4_mpdu;
+
+        unsigned int rx_error4_msdu;
+
+        unsigned int rx_error5_mpdu;
+
+        unsigned int rx_error5_msdu;
+
+        unsigned int rx_error6_mpdu;
+
+        unsigned int rx_error6_msdu;
+
+        unsigned int rx_error7_mpdu;
+
+        unsigned int rx_error7_msdu;
+
+        unsigned int rx_error8_mpdu;
+
+        unsigned int rx_error8_msdu;
+
+        unsigned int rx_error9_mpdu;
+
+        unsigned int rx_error9_msdu;
+
+        unsigned int rx_errora_mpdu;
+
+        unsigned int rx_errora_msdu;
+
+        unsigned int rx_drop_error5;
+
+        unsigned int rx_drop_ro_linklist;
+
+        unsigned int rx_drop_congestion_packets;
+
+        unsigned int _dw_res0[9];
+
+    } dlrx_data_mib_t;
+
+    typedef struct {
+
+        unsigned int total_ce4_cpu_msg;
+
+        unsigned int total_ce5_cpu_msg;
+
+        unsigned int total_rx_ind_msg;
+
+        unsigned int total_rx_flush_msg;
+
+        unsigned int total_tx_cmp_msg;
+
+        unsigned int total_rx_ind_wlan_msg;
+
+        unsigned int total_rx_flush_wlan_msg;
+
+        unsigned int total_rx_frag_ind_msg;
+
+        unsigned int total_rx_invalid_tid_msg;
+
+        unsigned int _dw_res0[3];
+
+    } dlrx_msg_mib_t;
+
+    typedef struct {
+
+        unsigned int total_chained_mpdu;
+
+        unsigned int total_chained_msdu;
+
+        unsigned int _dw_res0[14];
+
+    } dlrx_misc_mib_t;
+
+    typedef struct {
+
+        unsigned int vld3:1;
+        unsigned int peer3:7;
+        unsigned int vld2:1;
+        unsigned int peer2:7;
+        unsigned int vld1:1;
+        unsigned int peer1:7;
+        unsigned int vld0:1;
+        unsigned int peer0:7;
+
+    } dlrx_cfg_peer_id_to_peer_map_t;
+
+    typedef struct {
+
+        unsigned int rsvd0:25;
+        unsigned int acc_dis:1;
+        unsigned int sec_type:2;
+        unsigned int vap:4;
+
+    } dlrx_cfg_peer_to_vap_pn_t;
+
+    typedef struct {
+
+        unsigned int req:1;
+        unsigned int rsvd0:24;
+        unsigned int peer:7;
+
+    } dlrx_cfg_peer_reset_t;
+
+    typedef struct {
+
+        unsigned int req:1;
+        unsigned int rsvd0:24;
+        unsigned int peer:7;
+
+    } dlrx_cfg_invalid_tid_t;
+
+    typedef struct {
+
+        unsigned int allreq:1;
+        unsigned int vapreq:1;
+        unsigned int rsvd0:26;
+        unsigned int vap:4;
+
+    } dlrx_cfg_mib_reset_t;
+
+    typedef struct {
+
+        unsigned int vap7:4;
+        unsigned int vap6:4;
+        unsigned int vap5:4;
+        unsigned int vap4:4;
+        unsigned int vap3:4;
+        unsigned int vap2:4;
+        unsigned int vap1:4;
+        unsigned int vap0:4;
+
+    } dlrx_cfg_vap2int_map1_t;
+
+    typedef struct {
+
+        unsigned int vap15:4;
+        unsigned int vap14:4;
+        unsigned int vap13:4;
+        unsigned int vap12:4;
+        unsigned int vap11:4;
+        unsigned int vap10:4;
+        unsigned int vap9:4;
+        unsigned int vap8:4;
+
+    } dlrx_cfg_vap2int_map2_t;
+
+    typedef struct {
+
+        unsigned int rxpb_ptr;
+
+    } dlrx_rxpb_ptr_ring_t;
+
+    typedef struct {
+
+        unsigned int own:1;
+        unsigned int c:1;
+        unsigned int sop:1;
+        unsigned int eop:1;
+        unsigned int _res0:3;
+        unsigned int byte_off:2;
+        unsigned int _res1:7;
+        unsigned int data_len:16;
+
+        unsigned int _res2:2;
+        unsigned int data_ptr:27;
+        unsigned int _res3:2;
+        unsigned int data_ptr_rel:1;
+
+    } dlrx_dma_des_t;
+
+    typedef struct {
+
+        unsigned int cfg_badr_dma;
+
+        unsigned int cfg_num_dma;
+
+        unsigned int txdes_index;
+
+        unsigned int rsvd0;
+
+    } dlrx_cfg_ctxt_dma_t;
+
+    typedef struct {
+
+        unsigned int cfg_badr_ce5buf;
+
+        unsigned int cfg_num_ce5buf;
+
+        unsigned int cfg_size_ce5buf;
+
+        unsigned int cfg_size_shift_ce5buf;
+
+        unsigned int cfg_badr_target_ce5_read_index;
+
+        unsigned int cfg_badr_target_ce5_write_index;
+
+        unsigned int local_ce5_read_index;
+
+        unsigned int local_ce5_parsing_index;
+
+        unsigned int ce5_msg_type;
+
+        unsigned int _dw_res0[3];
+
+    } dlrx_cfg_ctxt_ce5buf_t;
+
+    typedef struct {
+
+        unsigned int cfg_badr_ce5des;
+
+        unsigned int cfg_num_ce5des;
+
+        unsigned int msg_len;
+
+        unsigned int _dw_res0;
+
+    } dlrx_cfg_ctxt_ce5des_t;
+
+    typedef struct {
+
+        unsigned int dest_ptr;
+
+        unsigned int meta_data:14;
+        unsigned int byte_swap:1;
+        unsigned int gather:1;
+        unsigned int nbytes:16;
+
+    } dlrx_ce5des_format_t;
+
+    typedef struct {
+
+        unsigned int cfg_badr_cpu_ce5;
+
+        unsigned int cfg_num_cpu_ce5;
+
+        unsigned int cpu_ce5_read_index;
+
+        unsigned int cpu_ce5_write_index;
+
+        unsigned int cpu_ce5_msg_done;
+
+        unsigned int _dw_res0[3];
+
+    } dlrx_cfg_ctxt_cpu_ce5des_t;
+
+    typedef struct {
+
+        unsigned int cfg_badr_rxpb_ptr_ring;
+
+        unsigned int cfg_num_rxpb_ptr_ring;
+
+        unsigned int rxpb_ptr_write_index;
+
+        unsigned int rxpb_ptr_read_index;
+
+        unsigned int _dw_res0[4];
+
+    } dlrx_cfg_ctxt_rxpb_ptr_ring_t;
+
+    typedef struct {
+
+        unsigned int cfg_size_rxpktdes;
+
+        unsigned int cfg_offset_atten;
+
+        unsigned int _dw_res0[2];
+
+    } dlrx_cfg_ctxt_rxpb_t;
+
+    typedef struct {
+
+        unsigned int cfg_badr_ro_linklist;
+
+        unsigned int cfg_num_ro_linklist;
+
+        unsigned int free_num_ro_linklist;
+
+        unsigned int cur_ro_des_ptr;
+
+        unsigned int cur_ro_des_index;
+
+        unsigned int prev_ro_des_index;
+
+        unsigned int ro_des_free_head_index;
+
+        unsigned int ro_des_free_tail_index;
+
+        unsigned int _dw_res0[8];
+
+    } dlrx_cfg_ctxt_ro_linklist_t;
+
+    typedef struct {
+
+        unsigned int cfg_badr_ro_mainlist;
+
+        unsigned int cfg_num_ro_mainlist;
+
+        unsigned int ro_mainlist_ptr;
+
+        unsigned int _dw_res0[5];
+
+    } dlrx_cfg_ctxt_ro_mainlist_t;
+
+    typedef struct {
+
+        unsigned int mpdu_cnt;
+
+        unsigned int mpdu_status;
+
+        unsigned int mpdu_range_index;
+
+        unsigned int mpdu_index;
+
+        unsigned int msdu_mpdu_index;
+
+        unsigned int msdu_index;
+
+        unsigned int peer;
+
+        unsigned int ext_tid;
+
+        unsigned int seqid;
+
+        unsigned int total_seqid;
+
+        unsigned int start_seqid;
+
+        unsigned int vap;
+
+        unsigned int sec_type;
+
+        unsigned int pn_pass;
+
+        unsigned int total_msdu;
+
+        unsigned int check_rv_pending;
+
+        unsigned int ext_ro_mainlist_ptr;
+
+        unsigned int ext_msg_ptr;
+
+        unsigned int peer_vld;
+
+        unsigned int acc_dis;
+
+        unsigned int _res0:26;
+        unsigned int inspect:1;
+        unsigned int _res1:3;
+        unsigned int forward:1;
+        unsigned int discard:1;
+
+        unsigned int _dw_res0[27];
+
+    } dlrx_ctxt_msg_t;
+
+    typedef struct {
+
+        unsigned int cfg_badr_rel_msgbuf;
+
+        unsigned int cfg_num_rel_msgbuf;
+
+        unsigned int _dw_res0[2];
+
+    } dlrx_cfg_ctxt_rxpb_ptr_rel_msgbuf_t;
+
+    typedef struct {
+
+        unsigned int dltx_enable;
+
+        unsigned int dlrx_enable;
+
+        unsigned int dlrx_pcie_base;
+
+        unsigned int dlrx_ddr_base;
+
+        unsigned int dlrx_cfg_ctxt_base;
+
+        unsigned int dlrx_cfg_ctxt_max_size;
+
+        unsigned int fw_ver_id;
+
+        unsigned int fw_feature;
+
+        unsigned int debug_print_enable;
+
+        unsigned int dlrx_cfg_unload;
+
+        unsigned int dlrx_qca_hw;
+
+        unsigned int dlrx_congestion_bit_timeout;
+
+        unsigned int dlrx_timout_count_th;
+
+        unsigned int dlrx_qca_hw_sub_type;
+
+        unsigned int _dw_res0[2];
+
+    } dlrx_cfg_global_t;
+
+    typedef struct {
+
+        unsigned int cfg_peer_handler;
+
+        unsigned int cfg_peer_count;
+
+    } dlrx_cfg_ctxt_peer_handler_t;
+
+#endif
+
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_def.h b/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_def.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_def.h
@@ -0,0 +1,475 @@
+#ifndef __DLRX_FW_DEF_H__
+#define __DLRX_FW_DEF_H__
+/* In DDR */
+#include <linux/io.h>
+#include <linux/kernel.h>
+
+#define TEST_GRX350 0
+#define OPTIMIZE_PERF 1
+extern unsigned int *ddr_base, *pcie_base, *cfg_ctxt_base;
+extern unsigned int dl_kseg0,dl_kseg1;
+
+#define DLRX_GRX330_BOARD_CFG 0
+
+#if (defined (DLRX_GRX330_BOARD_CFG) && (DLRX_GRX330_BOARD_CFG == 1))
+	/* 1 x 12 dwords */
+	#define DLRX_MSG_MIB_BASE                               \
+			(unsigned int *)(ddr_base)
+
+	/* 1 x 32 dwords */
+	#define DLRX_DATA_MIB_BASE                              \
+			(unsigned int *)(ddr_base + 0x0C)
+
+	/* 132 x 1 dwords i.e 528 x 1 bytes - - Location moved below due
+	to increase in number of peer id's
+	#define DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(i)            \
+			(unsigned int *)(ddr_base + 0x2C  + i) */
+
+	/* 128x 1 dwords i.e 528 peers x 4 bytes */
+	#define DLRX_CFG_PEER_TO_VAP_PN_BASE(i)                 \
+			(unsigned int *)(ddr_base + 0xB0 + i)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_PEER_RESET_BASE                        \
+			(unsigned int *)(ddr_base + 0x130)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_INVALID_TID_BASE                       \
+			(unsigned int *)(ddr_base + 0x131)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_MIB_RESET_BASE                         \
+			(unsigned int *)(ddr_base + 0x132)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_VAP2INT_MAP1_BASE                      \
+			(unsigned int *)(ddr_base + 0x133)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_VAP2INT_MAP2_BASE                      \
+			(unsigned int *)(ddr_base + 0x134)
+
+	/* 1x16 dword */
+	#define DLRX_MISC_MIB_BASE                              \
+			(unsigned int *)(ddr_base + 0x140)
+
+	/* 1X4 dword */
+	#define DLRX_SKB_POOL_CTXT                              \
+			(unsigned int *)(ddr_base + 0x150)
+
+	/* total_size for ddr_base: 0x150 dwords */
+
+	/* 32 x 16 dwords i.e 16 x 128 bytes Note: this is in SB,
+		sharing with DLRX TX!! */
+	#define DLRX_VAP_MIB_BASE(i)                            \
+			(unsigned int *)(ddr_base + 0x200 + ((i)*32))
+
+	/* 32 x 16 dwords */
+	#define DLRX_VAP_MIB_MISC_BASE(i)                       \
+			(unsigned int *)(ddr_base + 0x400 + ((i)*32))
+
+	/* 255 * 2 DWORDS  move to SRAM
+	#define DLRX_DDR_GSWIP_DMA_DESC_BASE                    \
+			(volatile unsigned int *)( ddr_base + 0x500 ) */
+
+	/*255 * 2 DWORDS */
+	#define DLRX_DDR_PROTO_DMA_DESC_BASE                    \
+			(unsigned int *)(ddr_base + 0x700)
+
+	/* 128 * 2 DWORDS */
+	#define DLRX_DDR_RX_PKT_BUF_REL_MSG_BASE                \
+			(unsigned int *)(ddr_base + 0x900)
+
+	/* 4096 * 1 DWORDS */
+	#define DLRX_DDR_RX_PKT_BUF_RING_BASE                   \
+			(unsigned int *)(ddr_base + 0xa00)
+
+	/* 2048 * (64 + 4) DWORDS */
+	#define DLRX_DDR_RO_MAINLIST_BASE                       \
+			(unsigned int *)(ddr_base + 0x1a00)
+
+	/* 4096 * 6 DWORDS */
+	#define DLRX_DDR_RO_LINKLIST_BASE                       \
+			(unsigned int *)(ddr_base + 0x23a00)
+
+	/* 2 * (1 * 8) DWORDS */
+	#define DLRX_DDR_CPU_CE5_DESC_BASE                      \
+			(unsigned int *)(ddr_base + 0x29a00)
+
+	/* 2048 * 2 DWORDS (shift to SRAM)
+	#define DLRX_DDR_CE5DESC_BASE                                       \
+			(volatile unsigned int *)(ddr_base + 0x2a000) */
+
+	/* 264 x 1 dwords i.e 1056 x 1 bytes */
+	#define DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(i)            \
+			(unsigned int *)(ddr_base + 0x2a000 + i)
+
+	/* 2048 * 512 Bytes (2e000 -*/
+	#define DLRX_DDR_CE5BUF_BASE                            \
+			(unsigned int *)(ddr_base + 0x2e000)
+
+	/* 128*16 Dword */
+	#define DLRX_DDR_SEQ_MASK_BASE                          \
+			(unsigned int *)(ddr_base + 0x6e000)
+
+
+	/*dword? */
+
+	#define DLRX_TARGET_CE5_PEREGRINE                       0x00058800
+	#define DLRX_TARGET_CE5_BEELINER                        0x0004B400
+
+	#define DLRX_TARGET_CE5_READ_INDEX(base)                \
+			(volatile unsigned int *)(pcie_base + ((base+0x48)>>2))
+
+	/* 1 dword? */
+	#define DLRX_TARGET_CE5_WRITE_INDEX(base)               \
+			(volatile unsigned int *)(pcie_base + ((base+0x40)>>2))
+
+	/* 4 dword */
+	#define DLRX_CFG_CTXT_GSWIP_DMA_BASE                    \
+			(unsigned int *)(cfg_ctxt_base)
+
+	/* 4 dword */
+	#define DLRX_CFG_CTXT_WLAN_DMA_BASE                     \
+			(unsigned int *)(cfg_ctxt_base + 0x04)
+
+	/* 4 dword */
+	#define DLRX_CFG_CTXT_PROT_DMA_BASE                     \
+			(unsigned int *)(cfg_ctxt_base + 0x08)
+
+	/* 1 x 12 dwords */
+	#define DLRX_CFG_CTXT_CE5BUF_BASE                       \
+			(unsigned int *)(cfg_ctxt_base + 0x0C)
+
+	/* 1 x 4 dwords */
+	#define DLRX_CFG_CTXT_CE5DES_BASE                       \
+			(unsigned int *)(cfg_ctxt_base + 0x18)
+
+	/* 1 x 8 dword */
+	#define DLRX_CFG_CTXT_CPU_CE5DES_BASE                   \
+			(unsigned int *)(cfg_ctxt_base + 0x1C)
+
+	/* 1 x 8 dwords */
+	#define DLRX_CFG_CTXT_RXPB_PTR_RING_BASE                \
+			(unsigned int *)(cfg_ctxt_base + 0x24)
+	/*#define DLRX_CFG_CTXT_RXPB_PTR_RING_BASE               \
+			(unsigned int *)(ddr_base + 0x158) */
+
+	/* 1 x 4 dwords */
+	#define DLRX_CFG_CTXT_RXPB_BASE                         \
+			(unsigned int *)(cfg_ctxt_base + 0x2C)
+
+	/* 1 x 16 dwords */
+	#define DLRX_CFG_CTXT_RO_LINKLIST_BASE                  \
+			(unsigned int *)(cfg_ctxt_base + 0x30)
+
+	/* 1 x 8 dword */
+	#define DLRX_CFG_CTXT_RO_MAINLIST_BASE                  \
+			(unsigned int *)(cfg_ctxt_base + 0x40)
+
+	/* 1 x 48 dwords */
+	#define DLRX_CTXT_MSG_BASE                              \
+			(unsigned int *)(cfg_ctxt_base + 0x48)
+
+	/* 1 x 4 dwords */
+	#define DLRX_CFG_CTXT_RXPB_PTR_REL_MSGBUF_BASE          \
+			(unsigned int *)(cfg_ctxt_base + 0x78)
+
+	/* 1 x 8 dwords */
+	#define DLRX_CFG_GLOBAL_BASE                            \
+			(unsigned int *)(cfg_ctxt_base + 0x80)
+
+	/* 128 x 2 dwords i.e. 128 peers x 2 dwords */
+	#define DLRX_CFG_CTXT_PEER_HANDLER_BASE(i)              \
+			(unsigned int *)(cfg_ctxt_base + 0x90 + (i) * 2)
+
+	/* 4 x 1 dwords */
+	#define DLRX_CFG_CTXT_PEER_BITMAP_BASE(i)               \
+			(unsigned int *)(cfg_ctxt_base + 0x190 + i)
+
+	/* 255 * 2 DWORDS */
+	#define DLRX_DDR_GSWIP_DMA_DESC_BASE                    \
+			(volatile unsigned int *)(cfg_ctxt_base + 0x200)
+
+	/* 512 * 2 DWORDS (shift from  SRAM) */
+	#define DLRX_DDR_CE5DESC_BASE                           \
+			(volatile unsigned int *)(cfg_ctxt_base + 0x400)
+
+	/* total size for cfg_ctxt_base allocation: 8kbyte */
+#else
+
+	#define RX_CFG_CTXT_BUF_BASE                            cfg_ctxt_base
+	#define RX_MSG_BUF_BASE                                 ddr_base
+
+	/* 1 x 12 dwords */
+	#define DLRX_MSG_MIB_BASE                               \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE)
+
+	/* 1 x 32 dwords */
+	#define DLRX_DATA_MIB_BASE                              \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x0C)
+
+	/* 128x 1 dwords i.e 528 peers x 4 bytes */
+	#define DLRX_CFG_PEER_TO_VAP_PN_BASE(i)                 \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2C + i)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_PEER_RESET_BASE                        \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0xB0)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_INVALID_TID_BASE                       \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0xB1)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_MIB_RESET_BASE                         \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0xB2)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_VAP2INT_MAP1_BASE                      \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0xB3)
+
+	/* 1 x 1 dword */
+	#define DLRX_CFG_VAP2INT_MAP2_BASE                      \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0xB4)
+
+	/* 1x16 dword */
+	#define DLRX_MISC_MIB_BASE                              \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0xC0)
+
+	/* 1X4 dword */
+	#define DLRX_SKB_POOL_CTXT                              \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0xD0)
+
+	/* 32 x 16 dwords i.e 16 x 128 bytes Note: this is in SB, sharing
+		with DLRX TX!! */
+	#define DLRX_VAP_MIB_BASE(i)                            \
+		(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0xE0 + ((i)*32))
+
+	/* 32 x 16 dwords */
+	#define DLRX_VAP_MIB_MISC_BASE(i)                       \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2E0 + \
+							((i)*32))
+
+	/* 255 * 2 DWORDS */
+	#define DLRX_DDR_PROTO_DMA_DESC_BASE                    \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x500)
+
+	/* 128 * 2 DWORDS */
+	#define DLRX_DDR_RX_PKT_BUF_REL_MSG_BASE                \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x700)
+
+	/* 4096 * 1 DWORDS */
+	// TODO: Need to define this as a seperate address as KSEG1 address is not guaranteed 
+	#define DLRX_DDR_RX_PKT_BUF_RING_BASE                   \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x800)
+
+	/* 2048 * (64 + 4) DWORDS */
+	#define DLRX_DDR_RO_MAINLIST_BASE                       \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x1800)
+
+	/* 4096 * 6 DWORDS */
+	#define DLRX_DDR_RO_LINKLIST_BASE                       \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x23800)
+
+	/* 2 * (1 * 8) DWORDS */
+	#define DLRX_DDR_CPU_CE5_DESC_BASE                      \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x29800)
+
+	/* 264 x 1 dwords i.e 1056 x 1 bytes */
+	#define DLRX_CFG_PEER_ID_TO_PEER_MAP_BASE(i)            \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2a000 + i)
+
+	/* 128*16 Dword */
+	#define DLRX_DDR_SEQ_MASK_BASE                          \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2a200)
+
+	/* 4 dword */
+	#define DLRX_CFG_CTXT_GSWIP_DMA_BASE                    \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa00)
+
+	/* 4 dword */
+	#define DLRX_CFG_CTXT_WLAN_DMA_BASE                     \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa04)
+
+	/* 4 dword */
+	#define DLRX_CFG_CTXT_PROT_DMA_BASE                     \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa08)
+
+	/* 1 x 12 dwords */
+	#define DLRX_CFG_CTXT_CE5BUF_BASE                       \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa0C)
+
+	/* 1 x 4 dwords */
+	#define DLRX_CFG_CTXT_CE5DES_BASE                       \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa18)
+
+	/* 1 x 8 dword */
+	#define DLRX_CFG_CTXT_CPU_CE5DES_BASE                   \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa1C)
+
+	/* 1 x 8 dwords */
+	#define DLRX_CFG_CTXT_RXPB_PTR_RING_BASE                \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa24)
+
+	/* 1 x 4 dwords */
+	#define DLRX_CFG_CTXT_RXPB_BASE                         \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa2C)
+
+	/* 1 x 16 dwords */
+	#define DLRX_CFG_CTXT_RO_LINKLIST_BASE                  \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa30)
+
+	/* 1 x 8 dword */
+	#define DLRX_CFG_CTXT_RO_MAINLIST_BASE                  \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa40)
+
+	/* 1 x 48 dwords */
+	#define DLRX_CTXT_MSG_BASE                              \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa48)
+
+	/* 1 x 4 dwords */
+	#define DLRX_CFG_CTXT_RXPB_PTR_REL_MSGBUF_BASE          \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa78)
+
+	/* 1 x 8 dwords */
+	#define DLRX_CFG_GLOBAL_BASE                            \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa80)
+
+	/* 128 x 2 dwords i.e. 128 peers x 2 dwords */
+	#define DLRX_CFG_CTXT_PEER_HANDLER_BASE(i)              \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2aa90 + \
+							(i) * 2)
+
+	/* 4 x 1 dwords */
+	#define DLRX_CFG_CTXT_PEER_BITMAP_BASE(i)               \
+			(unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2ab90 + i)
+
+	/* 255 * 2 DWORDS  */
+	#define DLRX_DDR_GSWIP_DMA_DESC_BASE                    \
+		(volatile unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2ac00)
+
+	/* 512 * 2 DWORDS (shift from  SRAM) */
+	#define DLRX_DDR_CE5DESC_BASE                           \
+		(volatile unsigned int *)(RX_CFG_CTXT_BUF_BASE + 0x2ae00)
+
+	/* 2048 * 512 Bytes (2e000 -*/
+	#define DLRX_DDR_CE5BUF_BASE                            \
+			(unsigned int *)(RX_MSG_BUF_BASE)
+
+
+	#define DLRX_TARGET_CE5_PEREGRINE                       0x00058800
+	#define DLRX_TARGET_CE5_BEELINER                        0x0004B400
+
+	#define DLRX_TARGET_CE5_READ_INDEX(base)                \
+		(volatile unsigned int *)(pcie_base + ((base+0x48)>>2))
+
+	/* 1 dword? */
+	#define DLRX_TARGET_CE5_WRITE_INDEX(base)               \
+		(volatile unsigned int *)(pcie_base + ((base+0x40)>>2))
+#endif
+
+/* Message type */
+#define HTT_RX_IND_MSG                                  0x1
+#define HTT_RX_FLUSH_MSG                                0x2
+#define HTT_RX_FRAG_IND_MSG                             0xA
+#define HTT_TX_CMP_MSG                                  0x7
+
+/* Not actual message type, defined to identify message being sent
+	to wlan driver/cpu_ce5/cpu_ce4/invalid_tid */
+#define HTT_RX_CPU_CE4                                  0xB
+#define HTT_RX_CPU_CE5                                  0xC
+#define HTT_RX_IND_MSG_WLAN                             0xD
+#define HTT_RX_FLUSH_MSG_WLAN                           0xE
+#define HTT_RX_INVALID_TID                              0xF
+
+
+/* MPDU status */
+#define MPDU_STATUS_SUCCESS                             0x1
+#define MPDU_STATUS_FCS_ERROR                           0x2
+#define MPDU_STATUS_DUPLICATE_ERROR                     0x3
+#define MPDU_STATUS_REPLAY_ERROR                        0x4
+#define MPDU_STATUS_INVALID_PEER                        0x5
+#define MPDU_STATUS_UNAUTHORIZED_PEER                   0x6
+#define MPDU_STATUS_OUT_OF_SYNC_PEER                    0x7
+#define MPDU_STATUS_MANAGEMENT_CONTROL                  0x8
+#define MPDU_STATUS_TKIP_MIB_ERROR                      0x9
+#define MPDU_STATUS_DECRYPT_ERROR                       0xA
+#define MSDU_STATUS_ERROR_5_DROP                        0xB
+#define MSDU_STATUS_RO_LINKLIST_DROP                    0xC
+#define MSDU_STATUS_CHAIN_MSDU_DROP                     0xD
+
+/* Security Type */
+#define SEC_TYPE_DISABLE                                0x0
+#define SEC_TYPE_PN_48                                  0x1
+#define SEC_TYPE_PN_128_EVEN                            0x2
+#define SEC_TYPE_PN_128_ODD                             0x3
+
+#define NUM_PEER                                        128
+#define NUM_TID                                         16
+#define NUM_SEQ_ID                                      64
+
+/* Need to define a value for NULL_PTR as 0 is also a valid pointer */
+/* Set to 0xFFF as the next_ptr value in dlrx_ro_linklist_t is 12 bits length */
+#define NULL_PTR                                        0xFFF
+
+#define INVALID_TID                                     31
+
+#define HTT_INVALID_PEER                                0xFFFF
+#define PHY_ADDR_MASK                                   0x1FFFFFFF
+/*
+    This is the enumeration for Special Received MPDU Status. Used by
+    \ref PPA_QCA_DL_RX_SPL_PKT_FN.
+*/
+
+/* Inspect Flag Set Rx Packet */
+#define WLAN_INSPECT_TYPE                               0x1
+
+
+#define USE_CACHED_ADDR                                 1
+#define DRE_DBG_PRINT_ENABLE                     1
+
+/*#define DBG_CACHED_ADDR                                 1 */
+#define HTT_RX_BUF_SIZE                                 1920
+#define HTT_MSG_BUF_SIZE                                512
+extern void  dre_dma_map(unsigned int addr, unsigned int size);
+extern void dre_dma_unmap(unsigned int  addr, unsigned int size);
+
+#if defined (USE_CACHED_ADDR) && USE_CACHED_ADDR
+
+   #define dre_dma_map(addr , size)      ppa_dl_dre_dma_writeback(addr , size)
+   #define dre_dma_unmap(addr , size)    ppa_dl_dre_dma_invalidate(addr , size)
+   #define dre_dma_wback_invalidate(addr , size)	ppa_dl_dre_dma_wback_inv(addr , size)
+//   #define dre_dma_map(addr , size)	  dma_cache_wback(addr , size)
+ // #define dre_dma_unmap(addr , size)	  dma_cache_inv(addr , size)
+
+
+#else
+
+    #define dre_dma_map(addr , size)
+    #define dre_dma_unmap(addr , size)
+	#define dre_dma_wback_invalidate(addr , size)
+#endif
+
+#if (defined (DLRX_GRX330_BOARD_CFG) && (DLRX_GRX330_BOARD_CFG == 1))
+#define VIR_TO_PHY(addr)  CPHYSADDR(addr)
+#define UNCACHE_ADDR(addr)  KSEG1ADDR(addr) //kseg1 
+#define CACHE_ADDR(addr)  KSEG0ADDR(addr)) // Kseg0(virtual)
+#else
+#define VIR_TO_PHY(addr)  ((((unsigned int)addr)  & 0x0FFFFFFF) | 0x20000000)
+#define PHY_TO_VIRT(addr) ((addr & 0x0fffffff) | dl_kseg0)	// virtual by default is cached addr (0x8000_0000)
+#define VIRT_TO_IOCU(addr) (((addr) & 0x1fffffff)|0xC0000000) // virtual to IOCU i.e 2 and 8 convert to C-D
+#define UNCACHE_ADDR(addr)  ((((uint32_t)addr)&(0x0FFFFFFF))|dl_kseg1) //kseg1 
+#define CACHE_ADDR(addr)  ((((uint32_t)addr)&(0x0FFFFFFF))| dl_kseg0) // Kseg0(virtual)
+#endif
+
+#if defined(DBG_CACHED_ADDR) && DBG_CACHED_ADDR
+#define dre_print(fmt, arg...)  do { printk(KERN_WARNING ":%d:%s: " \
+				fmt "\n", __LINE__, __func__, ##arg); } \
+				while (0)
+#else
+#define dre_print(fmt, arg...)
+#endif
+
+#endif
+
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_version.h b/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_version.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dlrx_fw_version.h
@@ -0,0 +1,6 @@
+#ifndef __DLRX_FW_VERSION_H__
+#define __DLRX_FW_VERSION_H__
+/*Version file for dlrx_fw*/
+#define DRE_FW_VERSION                0x00000145
+#define DRE_FW_FEATURE                0x11AC0100
+#endif
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dlrx_memory_lyt.h b/drivers/net/ethernet/lantiq/directlink/include/dlrx_memory_lyt.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dlrx_memory_lyt.h
@@ -0,0 +1,65 @@
+
+#ifndef __DLRX_MEMORY_LYT_H_
+#define __DLRX_MEMORY_LYT_H_
+
+/* The maximum size is fixed for DLRX FW as 4Kbyte */
+#define DLRX_CFG_CTXT_MAX_SIZE	0x2000
+
+/* Definition of length for each Data Structure */
+#define GSWIP_DESC_NUM				254
+#define WLAN_DESC_NUM				254
+#define PROTO_DESC_NUM				254
+
+#define CPU_CE5_DESC_RING_NUM		2
+#define RX_PKT_BUF_REL_MSG_NUM		2
+#define CE5_DEST_DESC_RING_NUM		512
+#define CE5_DEST_MSG_BUF_NUM		CE5_DEST_DESC_RING_NUM
+/* Must >= desc ring num  */
+/* this value should be 2^n */
+#define RX_PKT_BUF_PTR_RING_NUM		1024 /*test here, 512*/
+#define RX_PKT_BUF_PTR_RING_ALLOC_NUM		1024 /*test here, 512*/
+#define RX_REORDER_MAIN_NUM			2048
+#define RX_REORDER_DESC_LINK_NUM	4095
+
+#define RX_PEER_ID_PEER_MAP			132
+#define RX_PEER_TO_VAP_PN			128
+#define RX_PEER_RESET				1
+#define RX_VAP2INT_MAP1				1
+#define RX_VAP2INT_MAP2				1
+
+#define DLRX_CE5_DEST_BUF_SIZE	512
+
+
+#define TRUE 1
+#define FALSE 0
+
+#define ZERO 0
+#define ONE 1
+
+#define VALID 1
+
+/* DMA	Related Definition */
+#define DMA_BASE			0xBE104100
+#define DMA_CS				(volatile u32*)(DMA_BASE + 0x18)
+#define DMA_CCTRL			(volatile u32*)(DMA_BASE + 0x1C)
+#define DMA_CDBA			(volatile u32*)(DMA_BASE + 0x20)
+#define DMA_CDLEN			(volatile u32*)(DMA_BASE + 0x24)
+#define DMA_CIS				(volatile u32*)(DMA_BASE + 0x28)
+#define DMA_CIE				(volatile u32*)(DMA_BASE + 0x2C)
+#define PPE_TX_CH_NO		3
+
+typedef struct {
+	uint32_t gswip_desc_num;
+	uint32_t wlan_desc_num;
+	uint32_t proto_desc_num;
+	uint32_t cpu_ce5_desc_ring_num;
+	uint32_t rx_pkt_buf_rel_msg_num;
+	uint32_t ce5_dest_desc_ring_num;
+	uint32_t ce5_dest_msg_buf_num;
+	uint32_t rx_pkt_buf_ptr_ring_num;
+	uint32_t rx_reorder_main_num;
+	uint32_t rx_reorder_desc_link_num;
+} dlrx_bufsize_t;
+
+
+#endif
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dlrx_wlan_api.h b/drivers/net/ethernet/lantiq/directlink/include/dlrx_wlan_api.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dlrx_wlan_api.h
@@ -0,0 +1,198 @@
+#ifndef __DLRX_DL_WLAN_API_H__
+#define __DLRX_DL_WLAN_API_H__
+#include <net/ppa_ppe_hal.h>
+/*********************************************
+ *	Macro definition
+ *********************************************/
+#define PPA_F_REGISTER		1
+#define PPA_F_DEREGISTER	2
+
+/*********************************************
+ *	Structure Definition
+ *********************************************/
+/*
+	This is the enumeration for PN check type.
+*/
+typedef enum {
+	/*! No Packet Number Check for this Security Type of VAP */
+	PPA_WLAN_NO_PN_CHECK = 0,
+	/*! 48-bit Packet Number Check for this Security Type of VAP */
+	PPA_WLAN_48_BIT_PN_CHECK = 1,
+	/*! 128-bit Even Packet Number Check for WAPI Security Type (TBC) */
+	PPA_WLAN_128_BIT_EVEN_PN_CHECK = 2,
+	/*! 128-bit Odd Packet Number Check for WAPI Security Type (TBC) */
+	PPA_WLAN_128_BIT_ODD_PN_CHECK = 3
+} PPA_WLAN_PN_CHECK_Type_t;
+
+/*!
+\brief This is the enumeration for Peer configuration
+ with Security Type. Used by  \ref ppa_dl_qca_set_peer_cfg.
+*/
+typedef enum {
+	PPA_WLAN_ADD_PEER_ID = 1,
+	PPA_WLAN_REMOVE_PEER = 2,
+	PPA_WLAN_REMOVE_PEER_ID = 3,
+	PPA_WLAN_SET_PN_CHECK = 4,
+	PPA_WLAN_SET_PN_CHECK_WITH_RXPN = 5
+} PPA_QCA_PEER_ADD_REMOVE_FLAG_Type_t;
+/*
+* This is the enumeration for Special Received MPDU Status.
+* Used by  \ref PPA_QCA_DL_RX_SPL_PKT_FN.
+*/
+typedef enum {
+	/* Inspect Flag Set Rx Packet */
+	PPA_WLAN_INSPECT_TYPE = 0x1,
+	/* Invalid Peer Packet */
+	PPA_WLAN_INV_PEER_TYPE = 0x5,
+	/* MIC Error Packet */
+	PPA_WLAN_MIC_ERROR_TYPE = 0x9,
+} PPA_WLAN_SPL_PKT_Type_t;
+
+/*
+* This is the data structure for Message Statistics Counters.
+* Used by PPA_DL_WLAN_STATS_t.
+*/
+typedef struct {
+	uint32_t ce4_cpu_msgs;
+	uint32_t ce5_cpu_msgs;
+	uint32_t rx_ind_msgs;
+	uint32_t rx_flush_msgs;
+	uint32_t tx_comp_msgs;
+	uint32_t rx_ind_wl_msgs;
+	uint32_t rx_flush_wl_msgs;
+	uint32_t rx_frag_msgs;
+} PPA_DL_WLAN_MSG_STATS_t;
+
+/*
+* This is the data structure for Receive MPDU & MSDU
+* related Statistics Counters - Successful and Error. Used by
+* PPA_DL_WLAN_STATS_t.
+*/
+typedef struct {
+	uint32_t rx_mpdu_ok;
+	uint32_t rx_msdu_ok;
+	uint32_t rx_mpdu_err2;
+	uint32_t rx_msdu_err2;
+	uint32_t rx_mpdu_err3;
+	uint32_t rx_msdu_err3;
+	uint32_t rx_mpdu_err4;
+	uint32_t rx_msdu_err4;
+	uint32_t rx_mpdu_err5;
+	uint32_t rx_msdu_err5;
+	uint32_t rx_mpdu_err6;
+	uint32_t rx_msdu_err6;
+	uint32_t rx_mpdu_err7;
+	uint32_t rx_msdu_err7;
+	uint32_t rx_mpdu_err8;
+	uint32_t rx_msdu_err8;
+	uint32_t rx_mpdu_err9;
+	uint32_t rx_msdu_err9;
+	uint32_t rx_mpdu_errA;
+	uint32_t rx_msdu_errA;
+} PPA_DL_WLAN_RX_MPDU_MSDU_STATS_t;
+
+typedef int32_t (*PPA_QCA_DL_RX_MSG_FN)(
+	void *reg_handle,
+	uint32_t msg_type,
+	uint32_t msg_len,
+	uint32_t *msg,
+	uint32_t flags
+	);
+typedef int32_t (*PPA_QCA_DL_RX_SPL_PKT_FN)(
+	void *reg_handle,
+	uint32_t pkt_status,
+	uint32_t pkt_len,
+	struct sk_buff *pkt_skb,
+	uint32_t *msg,
+	uint32_t flags
+	);
+typedef int32_t (*PPA_QCA_DL_VAP_STATS_GET_FN)(
+	void *reg_handle,
+	uint16_t vap_id,
+	PPA_WLAN_VAP_Stats_t *vap_stats,
+	uint32_t flags
+	);
+typedef int32_t (*PPA_QCA_DL_RX_MARK_PEER_ACTIVE)(
+	void *reg_handle,
+	uint32_t peer_id
+	);
+
+
+/*
+ * This is the data structure for QCA specific
+ * PPA Direct Link Callbacks registration,
+ * which provides the necessary callback to PPA DL Driver.
+ * Used by \ref ppa_dl_qca_register.
+ */
+typedef struct {
+	/* Pointer to QCA Driver Rx Msg function callback. */
+	PPA_QCA_DL_RX_MSG_FN		 rx_msg_fn;
+	/* Pointer to QCA Driver Rx Special Packets function callback */
+	PPA_QCA_DL_RX_SPL_PKT_FN	 rx_splpkt_fn;
+	/* Pointer to QCA Driver Statistics Query fucniton Callback */
+	PPA_QCA_DL_VAP_STATS_GET_FN  vap_stats_fn;
+	/* Pointer to QCA Driver supports bandwidth steering */
+	PPA_QCA_DL_RX_MARK_PEER_ACTIVE peer_act_fn;
+} PPA_QCA_DL_RX_CB;
+
+
+
+extern void ppa_dl_qca_register(
+	void *dl_rx_handle,
+	PPA_QCA_DL_RX_CB *dl_qca_rxcb,
+	uint32_t flags
+	);
+extern void ppa_dl_qca_t2h_ring_init(
+	uint32_t *t2h_ring_sz,
+	uint32_t *dst_ring_base,
+	uint32_t pcie_baddr,
+	uint32_t flags
+	);
+extern void ppa_dl_qca_t2h_pktbuf_pool_manage(
+	uint32_t *alloc_idx_ptr,
+	uint32_t *t2h_rxpb_ring_sz,
+	uint32_t *rxpb_ring_base,
+	uint32_t flags
+	);
+
+extern int32_t ppa_hook_dl_qca_rx_offload(
+	uint32_t flags
+	);
+
+/* This new function added to get the next rxpb pointer */
+extern int32_t ppa_dl_qca_get_rx_net_buf(
+	struct sk_buff **rx_skb,
+	uint32_t flags
+	);
+
+extern void ppa_directlink_manage(
+	char *name,
+	uint32_t flags
+	);
+
+extern int32_t ppa_dl_qca_set_peer_cfg(
+	uint32_t *dlrx_peer_reg_handle,
+	uint16_t peer_id,
+	uint16_t vap_id,
+	PPA_WLAN_PN_CHECK_Type_t pn_chk_type,
+	uint32_t *rxpn,
+	uint32_t flags,
+	uint8_t *mac_addr
+	);
+extern int32_t ppa_dl_qca_set_seq_mask(
+	uint32_t *dlrx_peer_reg_handle,
+	uint32_t ex_tid,
+	uint32_t seq_mask,
+	uint32_t flags
+	);
+
+/* API to clear vap's mib */
+extern int ppa_dl_qca_clear_stats(
+	uint32_t vapId,
+	uint32_t flags
+	);
+
+
+extern void ppa_dl_qca_ipi_interrupt(void);
+
+#endif
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dltx_fw_comm_buf_data_structure_be.h b/drivers/net/ethernet/lantiq/directlink/include/dltx_fw_comm_buf_data_structure_be.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dltx_fw_comm_buf_data_structure_be.h
@@ -0,0 +1,76 @@
+#ifndef __DLTX_FW_COMM_BUF_DATA_STRUCTURE_BE_H_
+#define __DLTX_FW_COMM_BUF_DATA_STRUCTURE_BE_H_
+
+typedef struct {
+
+	unsigned int rsvd14:31;
+	unsigned int cmpl_status:1;
+
+	unsigned int tx_cmpl_mib;
+
+} dltx_tx_cmpl_flag_t;
+
+typedef struct {
+
+	unsigned int rsvd7:8;
+	unsigned int num_pb_ptr_to_release:8;
+	unsigned int rsvd8:8;
+	unsigned int msg_type:8;
+
+	unsigned int free_txpb_ptr[128];
+
+} dltx_tx_cmpl_msg_t;
+
+typedef struct {
+
+	unsigned int cfg_badr_cpu_ce4;
+
+	unsigned int cfg_num_cpu_ce4;
+
+	unsigned int cpu_ce4_read_index;
+
+	unsigned int cpu_ce4_write_index;
+
+	unsigned int cpu_ce4_ppe_read_index;
+
+	unsigned int cpu_ce4_msg_done;
+
+	unsigned int _dw_res0[2];
+
+} dltx_cfg_ctxt_cpu_ce4des_t;
+
+typedef struct {
+
+	unsigned int source_buffer_pointer;
+
+	unsigned int meta_data:14;
+	unsigned int byte_swap:1;
+	unsigned int gather:1;
+	unsigned int source_buffer_length:16;
+
+} dltx_cpu_ce4des_format_t;
+
+typedef struct {
+
+	unsigned int cfg_badr_tx_cmpl_flag;
+
+	unsigned int cfg_badr_tx_cmpl_buf;
+
+	unsigned int cfg_num_tx_cmpl_buf;
+
+	unsigned int _dw_res0[5];
+
+} dltx_cfg_ctxt_comm_buff_t;
+
+typedef struct {
+
+	unsigned int valid;
+
+	unsigned int action_type;
+
+	unsigned int _dw_res0[62];
+
+} dltx_drv_msg_t;
+
+#endif
+
diff --git a/drivers/net/ethernet/lantiq/directlink/include/dltx_fw_data_structure_be.h b/drivers/net/ethernet/lantiq/directlink/include/dltx_fw_data_structure_be.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/dltx_fw_data_structure_be.h
@@ -0,0 +1,356 @@
+#ifndef __DLTX_FW_DATA_STRUCTURE_BE_H_
+#define __DLTX_FW_DATA_STRUCTURE_BE_H_
+
+typedef struct {
+
+	unsigned int packet_pointer;
+
+	unsigned int rsvd0:16;
+	unsigned int fragment_length:16;
+
+	unsigned int rsvd1;
+
+	unsigned int rsvd2;
+
+	unsigned int rsvd3;
+
+	unsigned int rsvd4;
+
+	unsigned int payload_len:16;
+	unsigned int flags:8;
+	unsigned int endpoint_id:8;
+
+	unsigned int rsvd5:16;
+	unsigned int control_bytes_1:8;
+	unsigned int control_bytes_2:8;
+
+	unsigned int rsvd6:1;
+	unsigned int chk_sum:2;
+	unsigned int mib:1;
+	unsigned int postponed:1;
+	unsigned int ext_tid:5;
+	unsigned int vdec_id:6;
+	unsigned int pkt_type:3;
+	unsigned int pkt_subtype:5;
+	unsigned int msg_type:8;
+
+	unsigned int pb_pointer:16;
+	unsigned int length:16;
+
+	unsigned int frag_desc_pointer;
+
+	unsigned int peer_id;
+
+} dltx_msg_header_t;
+
+typedef struct {
+
+	unsigned int rsvd9:3;
+	unsigned int tunnel_id:4;
+	unsigned int flow_id:8;
+	unsigned int eth_type:2;
+	unsigned int dest_sub_if_id:15;
+
+	unsigned int session_id:12;
+	unsigned int tcp_err:1;
+	unsigned int nat:1;
+	unsigned int dec:1;
+	unsigned int enc:1;
+	unsigned int mpe2:1;
+	unsigned int mpe1:1;
+	unsigned int color:2;
+	unsigned int ep:4;
+	unsigned int res:4;
+	unsigned int class:4;
+
+	unsigned int dram_address;
+
+	unsigned int own:1;
+	unsigned int c_bit:1;
+	unsigned int sop:1;
+	unsigned int eop:1;
+	unsigned int dic:1;
+	unsigned int pdu_type:1;
+	unsigned int byte_offset:3;
+	unsigned int rsvd10:7;
+	unsigned int data_length:16;
+
+} dltx_dma_rx_desc_t;
+
+typedef struct {
+
+	unsigned int source_buffer_pointer;
+
+	unsigned int meta_data:14;
+	unsigned int byte_swap:1;
+	unsigned int gather:1;
+	unsigned int source_buffer_length:16;
+
+} dltx_ce4des_format_t;
+
+typedef struct {
+
+	unsigned int ce4_write_index;
+
+} dltx_ce4_write_index_track_t;
+
+typedef struct {
+
+	unsigned int packet_id;
+
+} dltx_circular_list_t;
+
+typedef struct {
+
+	unsigned int pointer_address;
+
+} dltx_buffer_pointer_table_t;
+
+typedef struct {
+
+	unsigned int rsvd11:15;
+	unsigned int frag_len:17;
+
+	unsigned int payloadlen:16;
+	unsigned int flags:8;
+	unsigned int endpointid:8;
+
+	unsigned int rsvd12:16;
+	unsigned int controlbyte1:8;
+	unsigned int controlbyte2:8;
+
+	unsigned int rsvd13:1;
+	unsigned int chksum:2;
+	unsigned int mib:1;
+	unsigned int postponed:1;
+	unsigned int exttid:5;
+	unsigned int vdevid:6;
+	unsigned int pkttype:3;
+	unsigned int pktsubtype:5;
+	unsigned int msgtype:8;
+
+	unsigned int packet_id:16;
+	unsigned int length:16;
+
+	unsigned int _dw_res0[3];
+
+} htt_tx_des_t;
+
+typedef struct {
+
+	unsigned int qca_vap_id;
+
+} dltx_qca_vap_id_map_t;
+
+typedef struct {
+
+	unsigned int txpdu_low;
+
+	unsigned int txpdu_high;
+
+	unsigned int txbytes_low;
+
+	unsigned int txbytes_high;
+
+	unsigned int txdrop_low;
+
+	unsigned int txdrop_high;
+
+	unsigned int _dw_res0[10];
+
+} dltx_vap_data_mib_t;
+
+typedef struct {
+
+	unsigned int cpu_ce4_msg_low;
+
+	unsigned int cpu_ce4_msg_high;
+
+	unsigned int cpu_ce4_bytes_low;
+
+	unsigned int cpu_ce4_bytes_high;
+
+	unsigned int _dw_res0[4];
+
+} dltx_data_mib_t;
+
+typedef struct {
+
+	unsigned int cfg_badr_ce4buf;
+
+	unsigned int cfg_num_ce4buf;
+
+	unsigned int cfg_ce4_read_index_addr;
+
+	unsigned int cfg_ce4_write_index_addr;
+
+	unsigned int local_ce4_read_index;
+
+	unsigned int local_ce4_write_index;
+
+	unsigned int load_ce4_read_index_req;
+
+	unsigned int cfg_ce4des_low;
+
+	unsigned int cfg_ce4_des_full;
+
+	unsigned int _dw_res0[7];
+
+} dltx_cfg_ctxt_ce4buf_t;
+
+typedef struct {
+
+	unsigned int circular_list_badr;
+
+	unsigned int circular_list_num;
+
+	unsigned int circular_list_read_index;
+
+	unsigned int circular_list_write_index;
+
+	unsigned int consumed_pkt_ids;
+
+	unsigned int _dw_res0[3];
+
+} dltx_cfg_ctxt_circular_list_t;
+
+typedef struct {
+
+	unsigned int buffer_pointer_badr;
+
+	unsigned int buffer_pointer_num;
+
+	unsigned int _dw_res0[2];
+
+} dltx_cfg_ctxt_buffer_pointer_table_t;
+
+typedef struct {
+
+	unsigned int write_index_track_badr;
+
+	unsigned int write_index_track_num;
+
+	unsigned int _dw_res0[2];
+
+} dltx_cfg_ctxt_ce4_write_index_track_t;
+
+typedef struct {
+
+	unsigned int cfg_size_tx_header;
+
+	unsigned int _dw_res0[3];
+
+} dltx_cfg_ctxt_tx_msg_t;
+
+typedef struct {
+
+	unsigned int qca_vap_id_map_badr;
+
+	unsigned int qca_vap_id_map_num;
+
+	unsigned int _dw_res0[2];
+
+} dltx_cfg_ctxt_qca_vap_id_map_t;
+
+typedef struct {
+
+	unsigned int ext_tid;
+
+	unsigned int pkt_type;
+
+	unsigned int pkt_subtype;
+
+	unsigned int msg_type;
+
+	unsigned int pb_pointer;
+
+	unsigned int pb_length;
+
+	unsigned int peer_id;
+
+	unsigned int vap;
+
+	unsigned int radio_id;
+
+	unsigned int _dw_res0[15];
+
+} dltx_ctxt_msg_t;
+
+typedef struct {
+
+	unsigned int dltx_enable;
+
+	unsigned int dltx_base_address;
+
+	unsigned int fw_ver_id;
+
+	unsigned int fw_feature;
+
+	unsigned int debug_print_enable;
+
+	unsigned int switch_parser_flag;
+
+	unsigned int qca_addr_dbg;
+
+	unsigned int _dw_res0[9];
+
+} dltx_cfg_global_t;
+
+typedef struct {
+
+	unsigned int fragment_ptr[16];
+
+} dltx_frag_data_t;
+
+typedef struct {
+
+	unsigned int frag_data_badr;
+
+	unsigned int frag_data_num;
+
+	unsigned int _dw_res0[2];
+
+} dltx_cfg_ctxt_frag_data_t;
+
+#ifdef SUPPORT_MULTICAST_TO_UNICAST
+struct _dl_mcast_group_table {
+	/* first dw */
+	unsigned int valid:1;
+	unsigned int res:23;
+	unsigned int grpIdx:8;
+	/* Bit map */
+	unsigned int bitmap[4];
+};
+
+struct _dl_peer_mac_mapping_table {
+	/* first dw */
+	unsigned int valid:1;
+	unsigned int vap_id:4;
+	unsigned int res:11;
+	unsigned int mac5:8;
+	unsigned int mac4:8;
+	/* second dw */
+	unsigned int mac3:8;
+	unsigned int mac2:8;
+	unsigned int mac1:8;
+	unsigned int mac0:8;
+};
+#endif /* SUPPORT_MULTICAST_TO_UNICAST */
+
+#define DTLK_DEBUG_TX_COMPLETION_NUM 16
+typedef struct {
+
+	unsigned int tx_count;
+
+	unsigned int tx_ptr;
+
+	unsigned int tx_completion_count;
+
+	unsigned int tx_completion_count_idx;
+
+	unsigned int tx_completion_ptr[DTLK_DEBUG_TX_COMPLETION_NUM - 4];
+
+} dltx_packet_id_trace_circular_list_t;
+
+#endif
+
diff --git a/drivers/net/ethernet/lantiq/directlink/include/ltqmips_hal.h b/drivers/net/ethernet/lantiq/directlink/include/ltqmips_hal.h
new file mode 100755
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/directlink/include/ltqmips_hal.h
@@ -0,0 +1,77 @@
+#ifndef LTQMIPS_HAL_H
+#define LTQMIPS_HAL_H
+struct ppe_dtlk_map{
+	uint32_t	vap_id;
+	struct PPA_NETIF *dev;
+	uint32_t	flags;
+	uint32_t	dl_rx_pkts; /* receive from WIFI HW */
+	uint32_t	dl_tx_pkts; /* send to WIFI HW */
+	uint32_t	dl_rx_drop_pkts;
+	uint32_t	dl_tx_drop_pkts;
+	PPA_SUBIF	dl_sub_if;
+	struct module	*owner;
+};
+
+struct ppe_radio_map{
+	uint32_t	flags;
+	PPA_SUBIF	dl_sub_if;
+	struct ppe_dtlk_map g_ppe_dtlk_data[16];
+};
+
+
+#define __DIRLINK_ENABLE 0x5E00
+#define PHYADDR_MASK 0x1FFFFFFF
+
+#define __D6_RX_MIB_SIZE	__D6_SUPPORT_VAP_NUM
+#define __D6_RX_MIB_BASE	__D6_PER_VAP_MIB_BASE
+
+#define SIZE_CE4DES	8
+#define SIZE_CPUSRCDES	64
+#define SIZE_HTT_TXDES	16
+#define LEN_HTT_TXDES	32
+#define NUM_HTT_TXDES	8
+#define SIZE_TXPB	2048
+#define NUM_TXPB	4096
+#define RESERVED_TXPB	8
+/* 8 DWORD, DWORD0 pkt buffer address, DWORD1 pkt len, not inited, DWORD2 0 */
+#define PBPTR_TXPB	32
+/* point to packet addr */
+#define PBADDR_TXPB 64
+#define SIZE_TXDES 24
+#define SIZE_TXHEADER 44
+#define LOW_MARK 0x200
+#define HIGH_MARK 2
+#define DMA_RX_CH7_DESC_BASE DTLK_RX_ADDR(__D6_RXDMA7_DES_BASE)
+#define DMA_RX_CH7_DESC_NUM 8
+
+
+struct offload_tx_release_t {
+	uint8_t reserved1;
+	uint8_t num_msdus;
+	uint16_t reserved0;
+	uint16_t msdu_ids[__D6_TXPB_MSG0_SIZE*2];
+};
+
+typedef struct {
+	uint32_t rx_mpdu_ok;
+	uint32_t rx_msdu_ok;
+	uint32_t rx_mpdu_err2;
+	uint32_t rx_msdu_err2;
+	uint32_t rx_mpdu_err3;
+	uint32_t rx_msdu_err3;
+	uint32_t rx_mpdu_err4;
+	uint32_t rx_msdu_err4;
+	uint32_t rx_mpdu_err5;
+	uint32_t rx_msdu_err5;
+	uint32_t rx_mpdu_err6;
+	uint32_t rx_msdu_err6;
+	uint32_t rx_mpdu_err7;
+	uint32_t rx_msdu_err7;
+	uint32_t rx_mpdu_err8;
+	uint32_t rx_msdu_err8;
+	uint32_t rx_mpdu_err9;
+	uint32_t rx_msdu_err9;
+	uint32_t rx_mpdu_errA;
+	uint32_t rx_msdu_errA;
+} PPA_WLAN_Rx_MPDU_MSDU_Stats_t;
+#endif
